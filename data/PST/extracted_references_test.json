{
    "621454435aee126c0f1d7065": [
        "Enriching Word Vectors with Subword Information",
        "None",
        "Data Voids: Where Missing Data Can Easily Be Exploited",
        "Language Models are Few-Shot Learners",
        "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation",
        "Truth, Lies, and Automation: How Language Models Could Change Disinformation",
        "Bing's Top Search Results Contain an Alarming Amount of Disinformation",
        "All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "The tactics &amp; tropes of the Internet Research Agency",
        "The antivaccination infodemic on social media: A behavioral analysis",
        "Attention Guided Graph Convolutional Networks for Relation Extraction",
        "UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification",
        "The Curious Case of Neural Text Degeneration",
        "Automatic Detection of Generated Text is Easiest when Humans are Fooled",
        "The Amazing World of Neural Language Generation",
        "Adversarial Examples for Evaluating Reading Comprehension Systems",
        "I'm Not Mad\": Commonsense Implications of Negation and Contradiction",
        "Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly",
        "All the News That's Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
        "A Multi-Level Attention Model for Evidence-Based Fact Checking",
        "Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes",
        "Towards Few-shot Fact-Checking via Perplexity",
        "Language Models as Fact Checkers?",
        "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
        "A Paragraph-level Multi-task Learning Model for Scientific Fact-Verification",
        "Adapting Open Domain Fact Extraction and Verification to COVID-FACT through In-Domain Language Modeling",
        "Fine-grained Fact Verification with Kernel Graph Attention Network",
        "Combining Fact Extraction and Verification with Neural Semantic Matching Networks",
        "A Decomposable Attention Model for Natural Language Inference",
        "None",
        "KILT: a Benchmark for Knowledge Intensive Language Tasks",
        "Language Models as Knowledge Bases",
        "Scientific Claim Verification with VerT5erini",
        "Language Models are Unsupervised Multitask Learners",
        "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
        "COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic",
        "Ecosystem or Echo-System? Exploring Content Sharing across Alternative Media Domains",
        "Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification",
        "Automated Fact Checking: Task Formulations, Methods and Future Directions",
        "FEVER: a Large-scale Dataset for Fact Extraction and VERification",
        "The spread of true and false news online",
        "Fact or Fiction: Verifying Scientific Claims",
        "Concealed Data Poisoning Attacks on NLP Models",
        "Coreferential Reasoning Learning for Language Representation",
        "UCL Machine Reading Group: Four Factor Framework For Fact Finding (HexaF)",
        "Defending Against Neural Fake News",
        "PEGA-SUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization",
        "Reasoning Over Semantic-Level Graph for Fact Checking",
        "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification"
    ],
    "6221834e5aee126c0f23c25c": [
        "Approximating extent measures of points",
        "Gradient based sample selection for online continual learning",
        "Scail: Classifier weights scaling for class incremental learning",
        "Flexible dataset distillation: Learn labels instead of images",
        "End-to-end incremental learning",
        "Super-samples from kernel herding",
        "The epic-kitchens dataset: Collection, challenges and baselines",
        "Imagenet: A large-scale hierarchical image database",
        "The PASCAL Visual Object Classes Challenge",
        "Facility location: concepts, models, algorithms and case studies",
        "Introduction to core-sets: an updated survey",
        "Scalable training of mixture models via coresets",
        "A ptas for k-means clustering based on weak coresets",
        "Turning big data into tiny data: Constant-size coresets for kmeans, pca and projective clustering",
        "Generative adversarial nets",
        "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
        "Auto-encoding variational bayes",
        "Optimal continual learning has perfect memory and is np-hard",
        "Learning multiple layers of features from tiny images",
        "The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale. IJCV",
        "Gradient-based learning applied to document recognition. Proceedings of the IEEE",
        "Microsoft coco: Common objects in context",
        "Conditional generative adversarial nets",
        "Dataset meta-learning from kernel-ridge regression",
        "Suppressing mislabeled data via grouping and self-attention",
        "Crafting better contrastive views for siamese representation learning",
        "Youtube-boundingboxes: A large high-precision human-annotated data set for object detection in video",
        "icarl: Incremental classifier and representation learning",
        "Active learning for convolutional neural networks: A core-set approach",
        "Convolutional neural networks applied to house numbers digit classification",
        "Small-gan: Speeding up gan training using core-sets",
        "Generative teaching networks: Accelerating neural architecture search by learning to generate synthetic training data",
        "An empirical study of example forgetting during deep neural network learning",
        "Suppressing uncertainties for large-scale facial expression recognition",
        "Region attention networks for pose and occlusion robust facial expression recognition",
        "Mask aware network for masked face recognition in the wild",
        "An efficient training approach for very large scale face recognition",
        "None",
        "Submodularity in data subset selection and active learning",
        "Facility location: concepts, models, algorithms and case studies",
        "Fashionmnist: a novel image dataset for benchmarking machine learning algorithms",
        "Free lunch for few-shot learning: Distribution calibration",
        "Objects in semantic topology",
        "Bridging the gap between few-shot and many-shot learning via distribution calibration",
        "Single-view 3d object reconstruction from shape priors in memory",
        "Adaptive semantic-visual tree for hierarchical embeddings",
        "Online coreset selection for rehearsal-based continual learning",
        "Understanding deep learning requires rethinking generalization",
        "Morphmlp: A self-attention free, mlp-like backbone for image and video",
        "Learning dynamical human-joint affinity for 3d pose estimation in videos",
        "Graph-based few-shot learning with transformed feature propagation and optimal class allocation",
        "Dataset condensation with differentiable siamese augmentation",
        "Dataset condensation with distribution matching",
        "Dataset condensation with gradient matching"
    ],
    "621ee1835aee126c0f26a902": [
        "Tensorflow GNN",
        "Community detection and stochastic block models: recent developments",
        "Friends and neighbors on the web. Social networks",
        "Graph neural networks with convolutional filters",
        "The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems",
        "Gnn-film: Graph neural networks with feature-wise linear modulation",
        "How Attentive are Graph Attention Networks? arXiv preprint",
        "Machine learning on graphs: A model and comprehensive taxonomy",
        "Can graph neural networks count substructures? arXiv preprint",
        "Leveraging procedural generation to benchmark reinforcement learning",
        "Are we really making much progress? A worrying analysis of recent neural recommendation approaches",
        "Measures of the amount of ecologic association between species",
        "Benchmarking graph neural networks",
        "A fair comparison of graph neural networks for graph classification",
        "Fast Graph Representation Learning with PyTorch Geometric",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Open Graph Benchmark: Datasets for machine learning on graphs",
        "The distribution of the flora in the alpine zone",
        "Stochastic blockmodels and community structure in networks",
        "A comparative study for unsupervised network representation learning",
        "How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Wilds: A benchmark of in-the-wild distribution shifts",
        "Vertex similarity in networks",
        "DEEPERBIGGERBETTER for OGB-LSC at KDD cup 2021",
        "Troubling trends in machine learning scholarship",
        "On graph classification networks, datasets and baselines",
        "Reproducible Evaluations of Network Representation Learning Models Using EvalNE. WWW'21, Workshop on Graph Learning Benchmarks",
        "Tudataset: A collection of benchmark datasets for learning with graphs",
        "Adversarial NLI: A new benchmark for natural language understanding",
        "Hierarchical organization of modularity in metabolic networks",
        "Do cifar-10 classifiers generalize to cifar-10?",
        "The Network Data Repository with Interactive Graph Analytics and Visualization",
        "Scale-Free, Attributed and Class-Assortative Graph Generation to Facilitate Introspection of Graph Neural Networks. WWW'21, Workshop on Graph Learning Benchmarks",
        "Pitfalls of graph neural network evaluation",
        "Masked label prediction: Unified message passing model for semisupervised classification",
        "Alfred: A benchmark for interpreting grounded instructions for everyday tasks",
        "Statistical methods",
        "A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on Danish commons",
        "Who belongs in the family?",
        "Graph clustering with graph neural networks",
        "Synthetic Graph Generation to Benchmark Graph Learning. WWW'21, Workshop on Graph Learning Benchmarks",
        "None",
        "Break it down: A question understanding benchmark",
        "Simplifying graph convolutional networks",
        "A comprehensive survey on graph neural networks",
        "How powerful are graph neural networks? arXiv preprint",
        "Design space for graph neural networks",
        "A pipeline for fair comparison of graph neural networks in node classification tasks",
        "Predicting missing links via local information",
        "Beyond homophily in graph neural networks: Current limitations and effective designs"
    ],
    "621635aa91e011b46d7ce15d": [
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks",
        "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "Inductive Representation Learning on Large Graphs",
        "Deep Residual Learning for Image Recognition",
        "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Policy-GNN: Aggregation Optimization for Graph Neural Networks",
        "Fake News Detection Using Deep Learning",
        "MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation",
        "DeepGCNs: Can GCNs Go As Deep As CNNs",
        "Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning",
        "SIGN: Scalable Inception Graph Neural Networks",
        "One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction",
        "Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced training",
        "Going deeper with convolutions",
        "Densely Connected Multi-Dilated Convolutional Networks for Dense Prediction Tasks",
        "Graph Attention Networks",
        "Simplifying Graph Convolutional Networks",
        "A Comprehensive Survey on Graph Neural Networks. IEEE Trans. Neural Networks Learn. Syst",
        "Rumor detection based on propagation graph neural network with attention mechanism",
        "How Powerful are Graph Neural Networks",
        "Graph Convolutional Neural Networks for Web-Scale Recommender Systems",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks",
        "Learning Graph Neural Networks with Deep Graph Library",
        "Modeling polypharmacy side effects with graph convolutional networks"
    ],
    "620f0e735aee126c0fec4734": [
        "Graph neural diffusion",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Scalable graph neural networks via bidirectional propagation",
        "Simple and deep graph convolutional networks",
        "A simple framework for contrastive learning of visual representations",
        "Debiased contrastive learning",
        "Graphgt: Machine learning datasets for deep graph generation and transformation",
        "Inductive representation learning on large graphs",
        "Contrastive multi-view representation learning on graphs",
        "Momentum contrast for unsupervised visual representation learning",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Multi-scale contrastive siamese networks for selfsupervised graph representation learning",
        "A method for stochastic optimization",
        "Variational graph auto-encoders",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Diffusion improves graph learning",
        "Revisiting k-means: New algorithms via bayesian nonparametrics",
        "Prototypical contrastive learning of unsupervised representations",
        "Least squares quantization in pcm",
        "Query-driven active surveying for collective classification",
        "Representation learning with contrastive predictive coding",
        "Adversarially regularized graph autoencoder for graph embedding",
        "Metropolis-hastings data augmentation for graph neural networks",
        "Symmetric graph convolutional autoencoder for unsupervised graph representation learning",
        "Graph representation learning via graphical mutual information maximization",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Gibbs sampling for the uninitiated",
        "Collective classification in network data",
        "Prototypical networks for few-shot learning",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Adaboosting graph convolutional networks into deep models",
        "Graph Attention Networks",
        "Deep graph infomax. In ICLR",
        "Marginalized graph autoencoder for graph clustering",
        "Simplifying graph convolutional networks",
        "How powerful are graph neural networks?",
        "Graph contrastive learning with augmentations",
        "Distribution-induced bidirectional generative adversarial network for graph representation learning",
        "Learning with local and global consistency",
        "Simple spectral graph convolution",
        "Graph neural networks with heterophily",
        "Semisupervised learning using gaussian fields and harmonic functions",
        "Deep Graph Contrastive Representation Learning",
        "Deep graph contrastive representation learning"
    ],
    "622183525aee126c0f23c7c2": [
        "Bridging the lexical chasm: statistical approaches to answer-finding",
        "The bq corpus: A large-scale domain-specific chinese corpus for sentence semantic equivalence identification",
        "Proceedings of the 2018 conference on empirical methods in natural language processing",
        "Neural graph matching networks for chinese short text matching",
        "Revisiting pretrained models for Chinese natural language processing",
        "Pre-training with whole word masking for chinese bert",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Lattice cnns for matching based chinese question answering",
        "Lcqmc: A large-scale chinese question matching corpus",
        "Let: Linguistic knowledge enhanced graph transformer for chinese short text matching",
        "Glyce: Glyph-vectors for chinese character representations",
        "Learning semantic representations using convolutional neural networks for web search",
        "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection",
        "Continue training and adaption for n-gram enhanced text encoders",
        "Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation",
        "Attention is all you need",
        "Learning natural language inference with lstm",
        "Bilateral multi-perspective matching for natural language sentences"
    ],
    "62451c2b5aee126c0f47ac08": [
        "5-shot 5-way 5-shot 3-way 1-shot 10-way 5-shot 5-way 5-shot 3-way 1-shot 10-way 5-shot 5-way 5-shot 3-way 1-shot GCN CEL",
        "Guneet Singh Dhillon, Pratik Chaudhari, Avinash Ravichandran, and Stefano Soatto. A baseline for few-shot image classification",
        "Jeh and Widom, 2003] Glen Jeh and Jennifer Widom. Scaling personalized web search",
        "None",
        "Estimating node importance in knowledge graphs using graph neural networks",
        "Prototypical networks for few-shot learning",
        "Explaining the power-law degree distribution in a social commerce network",
        "Rethinking few-shot image classification: a good embedding is all you need",
        "Veli?kovi? et al., 2017] Petar Veli?kovi?, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks",
        "Graph few-shot learning with attribute matching",
        "Cline: Contrastive learning with semantic negative examples for natural language understanding",
        "How powerful are graph neural net",
        "On few-shot node classification in graph metalearning"
    ],
    "6226c93d5aee126c0fd57ba8": [
        "Dbpedia: A nucleus for a web of open data",
        "Mutual information neural estimation",
        "Translating embeddings for modeling multirelational data",
        "Multi-channel graph neural network for entity alignment",
        "Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment",
        "Multilingual knowledge graph embeddings for cross-lingual knowledge alignment",
        "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
        "Learning and development in neural networks: The importance of starting small",
        "Yago: A core of semantic knowledge unifying wordnet and wikipedia",
        "Learning to exploit long-term relational dependencies in knowledge graphs",
        "Logmap: Logic-based and scalable ontology matching",
        "Semisupervised classification with graph convolutional networks",
        "Continuous control with deep reinforcement learning",
        "Human-level control through deep reinforcement learning",
        "Rectified linear units improve restricted boltzmann machines",
        "2019a. Semi-supervised entity alignment via knowledge graph embedding with awareness of degree difference",
        "Improving cross-lingual entity alignment via optimal transport",
        "Weakly-supervised knowledge graph alignment with adversarial learning",
        "Mastering the game of go with deep neural networks and tree search",
        "PARIS: Probabilistic alignment of relations, instances, and schema",
        "Cross-lingual entity alignment via joint attributepreserving embedding",
        "Bootstrapping entity alignment with knowledge graph embedding",
        "Knowledge graph alignment network with gated multi-hop neighborhood aggregation",
        "A benchmarking study of embedding-based entity alignment for knowledge graphs",
        "BERT-INT: A bertbased interaction model for knowledge graph alignment",
        "Representation learning with contrastive predictive coding",
        "Graph attention networks",
        "Wikidata: a free collaborative knowledgebase. Communications of the",
        "Reasoning like human: Hierarchical reinforcement learning for knowledge graph reasoning",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Cross-lingual knowledge graph alignment via graph convolutional networks",
        "Knowledge graph alignment with entity-pair embedding",
        "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
        "A learning algorithm for continually running fully recurrent neural networks",
        "Relation-aware entity alignment for heterogeneous knowledge graphs",
        "Deeppath: A reinforcement learning method for knowledge graph reasoning",
        "Coordinated reasoning for crosslingual knowledge graph alignment",
        "Collective entity alignment via adaptive features",
        "Reinforcement learningbased collective entity alignment with adaptive features",
        "Iterative entity alignment via joint knowledge embeddings",
        "RAGA: relation-aware graph attention networks for global entity alignment"
    ],
    "6243ca915aee126c0fbd0aa0": [
        "chuanwei ruan, korpeoglu, sushant kumar, and kannan achan",
        "Fast Graph Representation Learning with PyTorch Geometric",
        "Large Minibatch SGD: Training ImageNet in 1 Hour",
        "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs",
        "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "Seamless operability between C++11 and Python",
        "Recurrent Event Network: Autoregressive Structure Inferenceover Temporal Knowledge Graphs",
        "Representation Learning for Dynamic Graphs: A Survey",
        "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks",
        "GDELT: Global data on events, location, and tone",
        "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
        "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs",
        "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "Temporal Graph Networks for Deep Learning on Dynamic Graphs",
        "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models",
        "DySAT: Deep Neural Representation Learning on Dynamic Graphs via Self-Attention Networks",
        "DyRep: Learning Representations over Dynamic Graphs",
        "Attention is all you need",
        "Bipartite Dynamic Representations for Abuse Detection",
        "FlexGraph: a flexible and efficient distributed framework for GNN training",
        "Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks",
        "APAN: Asynchronous Propagation Attention Network for Real-Time Temporal Graph Embedding",
        "DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs"
    ],
    "62296c7b5aee126c0f57d7aa": [
        "The surprising power of graph neural networks with random node initialization",
        "Breaking the limits of message passing graph neural networks",
        "Algebraic methods in the congested clique",
        "The open catalyst 2020 (oc20) dataset and community challenges",
        "tri, tri again\": Finding triangles and small subgraphs in a distributed setting",
        "On the power of the congested clique model",
        "Simple gnn regularisation for 3d molecular property prediction and beyond",
        "Inductive representation learning on large graphs",
        "A large-scale challenge for machine learning on graphs",
        "Highly accurate protein structure prediction with alphafold",
        "Mst in o (1) rounds of congested clique",
        "What graph neural networks cannot learn: depth vs width",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Random features strengthen graph neural networks",
        "Rotation invariant graph neural networks using spin convolutions",
        "Attention is all you need",
        "On layer normalization in the transformer architecture",
        "How powerful are graph neural networks?",
        "Do transformers really perform bad for graph representation?",
        "An introduction to electrocatalyst design using machine learning for renewable energy storage"
    ],
    "624fa8db5aee126c0f3a5be7": [
        "TensorFlow Datasets, a collection of ready-to-use datasets",
        "Vivit: A video vision transformer",
        "Stochastic variational video prediction",
        "Overfitting in pixel-level video prediction",
        "Is space-time attention all you need for video understanding",
        "WaveGrad: Estimating gradients for waveform generation",
        "PixelSNAIL: An improved autoregressive generative model",
        "3d u-net: learning dense volumetric segmentation from sparse annotation",
        "Adversarial video generation on complex datasets",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Diffusion models beat GANs on image synthesis",
        "Latent neural differential equations for video generation",
        "Classifier-free diffusion guidance",
        "Axial attention in multidimensional transformers",
        "Denoising diffusion probabilistic models",
        "Cascaded diffusion models for high fidelity image generation",
        "Lower dimensional kernels for video discriminators",
        "Variational diffusion models",
        "DiffWave: A versatile diffusion model for audio synthesis",
        "VideoFlow: A flow-based generative model for video",
        "Stochastic adversarial video prediction",
        "Generating high fidelity images with subscale pixel networks and multidimensional upscaling",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "Improved denoising diffusion probabilistic models",
        "U-Net: Convolutional networks for biomedical image segmentation",
        "Palette: Image-to-image diffusion models",
        "Image super-resolution via iterative refinement",
        "Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal GAN",
        "Progressive distillation for fast sampling of diffusion models",
        "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
        "Self-attention with relative position representations",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Denoising diffusion implicit models",
        "Generative modeling by estimating gradients of the data distribution",
        "Score-based generative modeling through stochastic differential equations. International Conference on Learning Representations",
        "A dataset of 101 human actions classes from videos in the wild",
        "Learning spatiotemporal features with 3d convolutional networks",
        "Mocogan: Decomposing motion and content for video generation",
        "Neural stochastic differential equations: Deep latent gaussian models in the diffusion limit",
        "Attention is all you need",
        "A connection between score matching and denoising autoencoders",
        "Predicting video with vqvae",
        "Non-local neural networks",
        "Scaling autoregressive video models",
        "Deblurring via stochastic refinement",
        "Videogpt: Video generation using vq-vae and transformers",
        "Markov decision process for video generation",
        "Wide residual networks"
    ],
    "6243ca9b5aee126c0fbd1cfd": [
        "On a routing problem",
        "Dynamic programming",
        "Size-invariant graph representations for graph classification extrapolations",
        "Geometric deep learning: Grids, groups, graphs, geodesics, and gauges",
        "Combinatorial optimization and reasoning with graph neural networks",
        "Natural graph networks",
        "Categories, relations and dynamic programming",
        "Neural algorithmic reasoners are implicit planners",
        "Cohomology and massless fields",
        "An invitation to applied category theory: seven sketches in compositionality",
        "Neural shuffle-exchange networks-sequence processing in o",
        "Neural tangent kernel: Convergence and generalization in neural networks",
        "How does a neural network's architecture impact its robustness to noisy labels?",
        "Solving mixed integer programs using neural networks",
        "Normalized attention without probability cage",
        "Learning to simulate complex physics with graph networks",
        "None",
        "Towards scale-invariant graphrelated problem solving by iterative homogeneous gnns",
        "Neural algorithmic reasoning. Patterns",
        "Graph attention networks",
        "Neural execution of graph algorithms",
        "Razvan Pascanu, Oriol Vinyals, and Charles Blundell. Pointer graph networks",
        "Raia Hadsell, Razvan Pascanu, and Charles Blundell. Reasoning-modulated representations",
        "Comprehending monads",
        "Integral transforms and the pull-push perspective, i. The n-Category Caf?",
        "How to transfer algorithmic reasoning knowledge to learn new algorithms?",
        "How powerful are graph neural networks? arXiv preprint",
        "What can neural networks reason about? arXiv preprint"
    ],
    "623d33155aee126c0f100f50": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Spectral networks and locally connected networks on graphs",
        "Intriguing properties of contrastive losses",
        "Hinton. A simple framework for contrastive learning of visual representations",
        "Cuco: Graph representation with curriculum contrastive learning",
        "Graph neural networks for social recommendation",
        "Hassani and Khasahmadi, 2020] K. Hassani and A. H. Khasahmadi. Contrastive multi-view representation learning on graphs",
        "Momentum contrast for unsupervised visual representation learning",
        "Strategies for pre-training graph neural networks",
        "Semisupervised classification with graph convolutional networks",
        "Self-organization in a perceptual network",
        "Tudataset: A collection of benchmark datasets for learning with graphs",
        "Learning distributed representations of graphs",
        "Representation learning with contrastive predictive coding",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "On mutual information maximization for representation learning",
        "Graph attention networks",
        "Deep graph infomax",
        "Reducing word omission errors in neural machine translation: A contrastive learning approach",
        "xMoCo: Cross momentum contrastive learning for open-domain question answering",
        "Graph contrastive learning with augmentations",
        "Graph contrastive learning automated",
        "Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting",
        "Adversarial complementary learning for weakly supervised object localization",
        "From canonical correlation analysis to self-supervised graph neural networks",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "625e1a335aee126c0feca4ba": [
        "The surprising power of graph neural networks with random node initialization",
        "Local and global properties in networks of processors",
        "How graph neural networks go beyond weisfeiler-lehman?",
        "On exact computation with an infinitely wide neural net",
        "Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks",
        "On the power of color refinement",
        "Expressive power of invariant and equivariant graph neural networks",
        "Canonical labelling of graphs in linear average time",
        "Random graph isomorphism",
        "The logical expressiveness of graph neural networks",
        "Rademacher and Gaussian complexities: Risk bounds and structural results",
        "Interaction networks for learning about objects, relations and physics",
        "Relational inductive biases, deep learning, and graph networks",
        "On a routing problem",
        "Equivariant Subgraph Aggregation Networks. arXiv e-prints, art",
        "Weisfeiler and Lehman go cellular: CW networks",
        "Weisfeiler and Lehman go topological: Message passing simplicial networks",
        "Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting",
        "Spectral networks and deep locally connected networks on graphs",
        "An optimal lower bound on the number of variables for graph identification",
        "An optimal lower bound on the number of variables for graph identification",
        "Combinatorial optimization and reasoning with graph neural networks. arXiv e-prints, art",
        "On generalization bounds of a family of recurrent neural networks",
        "On the equivalence between graph isomorphism testing and function approximation with GNNs",
        "Can graph neural networks count substructures?",
        "Discovering symbolic models from deep learning with inductive biases",
        "Approximation by superpositions of a sigmoidal function",
        "Discriminative embeddings of latent variable models for structured data",
        "Learning combinatorial optimization algorithms over graphs",
        "Coloring graph neural net-works for node disambiguation",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Understanding the representation power of graph neural networks in learning graph topology",
        "ETA prediction with graph neural networks in Google Maps",
        "Graph neural tangent kernel: Fusing graph neural networks with graph kernels",
        "Gradient descent finds global minima of deep neural networks",
        "Gradient descent provably optimizes over-parameterized neural networks",
        "Graph Neural Networks are Dynamic Programmers. arXiv e-prints, art",
        "Convolutional networks on graphs for learning molecular fingerprints",
        "A generalization of transformer networks to graphs",
        "Generalization and representational limits of graph neural networks",
        "The expressive power of kth-order invariant graph networks",
        "Let's agree to degree: Comparing graph convolutional networks in the message-passing framework",
        "Neural message passing for quantum chemistry",
        "A new model for learning in graph domains",
        "Pebble games and linear equations",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Representation learning on graphs: Methods and applications",
        "Graph Representation Learning",
        "Deep models of interactions across sets",
        "Weak models of distributed computing, with connections to modal logic",
        "Complexity Theory Retrospective, chapter Describing graphs: A first-order approach to graph canonization",
        "Neural tangent kernel: Convergence and generalization in neural networks",
        "Inferring and executing programs for visual reasoning",
        "Polynomial bounds for the VC dimension of sigmoidal and general Pfaffian networks",
        "A congruence theorem for trees",
        "Universal invariant and equivariant graph neural networks",
        "Graphs identified by logics with counting",
        "Semi-supervised classification with graph convolutional networks",
        "Vapnik-Chervonenkis dimension of recurrent neural networks",
        "On tables of random numbers",
        "On the generalization of equivariance and convolution in neural networks to the action of compact groups",
        "Covariant compositional networks for learning graphs",
        "Deep learning for symbolic mathematics",
        "Transferability of spectral graph convolutional neural networks",
        "A PAC-bayesian approach to generalization bounds for graph neural networks",
        "Sign and Basis Invariant Networks for Spectral Graph Representation Learning",
        "Locality in distributed graph algorithms",
        "Neural subgraph isomorphism counting",
        "What graph neural networks cannot learn: depth vs width",
        "How hard is to distinguish graphs with graph neural networks?",
        "The power of graph convolutional networks to distinguish random graph models",
        "The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision",
        "Provably powerful graph networks",
        "Invariant and equivariant graph networks",
        "On the universality of invariant networks",
        "Automatic generation of complementary descriptors with molecular graph networks",
        "Motifnet: a motif-based graph convolutional network for directed graphs",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Relational pooling for graph representations",
        "Janossy pooling: Learning deep permutationinvariant functions for variable-size inputs",
        "What can be computed locally?",
        "Distributed Computing: A Locality-Sensitive Approach",
        "From graph low-rank global attention to 2-FWL approximation",
        "PointNet: Deep learning on point sets for 3D classification and segmentation",
        "Deep Learning with Sets and Point Clouds. arXiv e-prints, art",
        "Equivariance through parameter-sharing",
        "The grgaph isomorphism disease",
        "Graphon neural networks and the transferability of graph neural networks",
        "Graph neural networks: architectures, stability and transferability",
        "Learning to simulate complex physics with graph networks",
        "A simple neural network module for relational reasoning",
        "Measuring abstract reasoning in neural networks",
        "Approximation ratios of graph neural networks for combinatorial problems",
        "Random features strengthen graph neural networks",
        "The graph neural network model",
        "Computational capabilities of graph neural networks",
        "The Vapnik-Chervonenkis dimension of graph and recursive neural networks",
        "Learning with kernels. Adaptive Computation and Machine Learning",
        "Counting Substructures with Higher-Order Graph Neural Networks: Possibility and Impossibility Results",
        "Neural arithmetic logic units",
        "A Collection of Mathematical Problems",
        "On the uniform convergence of relative frequencies of events to their probabilities",
        "Neural execution of graph algorithms",
        "Stability and generalization of graph convolutional neural networks",
        "Building powerful and equivariant graph neural networks with structural message-passing",
        "On the limitations of representing functions on sets",
        "On Construction and Identification of Graphs",
        "A reduction of a graph to a canonical form and an algebra arising during this reduction",
        "How powerful are graph neural networks?",
        "What can neural networks reason about?",
        "How neural networks extrapolate: From feedforward to graph neural networks",
        "Universal approximations of invariant maps by neural networks. Constructive Approximation",
        "From local structures to size generalization in graph neural networks",
        "Neural-symbolic VQA: Disentangling reasoning from vision and language understanding",
        "Do transformers really perform badly for graph representation?",
        "Identity-aware graph neural networks",
        "Deep sets",
        "Graph-bert: Only attention is needed for learning graph representations",
        "Persistence enhanced graph neural network",
        "Modeling polypharmacy side effects with graph convolutional networks"
    ],
    "62393e7f5aee126c0f126162": [
        "Recent advances in graph partitioning",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "Stochastic training of graph convolutional networks with variance reduction",
        "Scalable graph neural networks via bidirectional propagation",
        "Differentiated graph computation and partitioning on skewed graphs",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Minimal variance sampling with provable guarantees for fast training of graph neural networks",
        "Scalable and expressive graph neural networks via historical embeddings",
        "P3: Distributed deep graph learning at scale",
        "Powergraph: Distributed graph-parallel computation on natural graphs",
        "International Conference on Machine Learning",
        "Inductive representation learning on large graphs",
        "Fast and efficient pipeline parallel dnn training",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Adaptive sampling towards fast graph representation learning",
        "Improving the accuracy, scalability, and performance of graph neural networks with roc",
        "A fast and high quality multilevel scheme for partitioning irregular graphs",
        "Semi-supervised classification with graph convolutional networks",
        "One weird trick for parallelizing convolutional neural networks",
        "Pytorch-biggraph: A large-scale graph embedding system",
        "Pytorch distributed: Experiences on accelerating data parallel training",
        "A network-centric hardware/algorithm co-design to accelerate distributed training of deep neural networks",
        "Pipe-sgd: A decentralized pipelined sgd framework for distributed deep net training",
        "EXACT: Scalable graph neural networks training via extreme activation compression",
        "NeuGraph: Parallel deep neural network computation on large graphs",
        "A lightweight infrastructure for graph analytics",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Ligra: a lightweight graph processing framework for shared memory",
        "Optimization of collective communication operations in mpich",
        "Dorylus: affordable, scalable, and accurate gnn training with distributed cpu servers and serverless threads",
        "Reducing communication in graph neural network training",
        "Graph attention networks",
        "PipeGCN: Efficient full-graph training of graph convolutional networks with pipelined feature communication",
        "Deep graph library: A graphcentric, highly-performant package for graph neural networks",
        "How powerful are graph neural networks?",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Graphsaint: Graph sampling based inductive learning method",
        "Link prediction based on graph neural networks",
        "Distdgl: distributed graph neural network training for billion-scale graphs",
        "A comprehensive graph neural network platform",
        "Gemini: A computation-centric distributed graph processing system",
        "Layer-dependent importance sampling for training deep and large graph convolutional networks"
    ],
    "6241273e5aee126c0f292ae3": [
        "BLUE4 ROUGE1 ROUGE2 ROUGEL BLUE4 ROUGE1 ROUGE2 ROUGEL BLUE4 ROUGE1 ROUGE2 ROUGEL T0",
        "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning",
        "Language Models are Few-Shot Learners",
        "Neural collaborative reasoning",
        "Wide &amp; deep learning for recommender systems",
        "Unifying Vision-and-Language Tasks via Text Generation",
        "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
        "Towards conversational recommender systems",
        "A troubling analysis of reproducibility and progress in recommender systems research",
        "Are we really making much progress? A worrying analysis of recent neural recommendation approaches",
        "Jeong Min Lee, Ronay Ak, and Even Oldridge. 2021. Transformers4Rec: Bridging the Gap between NLP and Sequential/Session-Based Recommendation",
        "Learning to generate product reviews from attributes",
        "The Turking Test: Can Language Models Understand Instructions? arXiv preprint",
        "Popcorn: Human-in-the-loop Popularity Debiasing in Conversational Recommender Systems",
        "Learning attribute-to-feature mappings for cold-start recommendations",
        "Making pre-trained language models better few-shot learners",
        "Improving Personalized Explanation Generation through Visualization",
        "PPT: Pre-trained Prompt Tuning for Few-shot Learning",
        "DeepFM: a factorization-machine based neural network for CTR prediction",
        "Practical lessons from predicting clicks on ads at facebook",
        "Session-based Recommendations with Recurrent Neural Networks",
        "A survey on conversational recommender systems",
        "How can we know what language models know?",
        "Matrix factorization techniques for recommender systems",
        "Addressing cold-start problem in recommendation systems",
        "Melu: Meta-learned user preference estimator for cold-start recommendation",
        "The power of scale for parameter-efficient prompt tuning",
        "From zero-shot learning to cold-start recommendation",
        "Generate neural template explanations for recommendation",
        "Personalized Transformer for Explainable Recommendation",
        "Neural rating regression with abstractive tips generation for recommendation",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Amazon. com recommendations: Item-to-item collaborative filtering",
        "What Makes Good In-Context Examples for GPT-3?",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "GPT Understands, Too",
        "Decoupled Weight Decay Regularization",
        "Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity",
        "Hierarchical gating networks for sequential recommendation",
        "Cross-domain recommendation: An embedding and mapping approach",
        "Content-based recommendation systems",
        "Learning How to Ask: Querying LMs with Mixtures of Soft Prompts",
        "Language models are unsupervised multitask learners",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Factorization machines",
        "BPR: Bayesian Personalized Ranking from Implicit Feedback",
        "Neural collaborative filtering vs. matrix factorization revisited",
        "Grouplens: An open architecture for collaborative filtering of netnews",
        "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "Item-based collaborative filtering recommendation algorithms",
        "Methods and metrics for cold-start recommendations",
        "Neural Machine Translation of Rare Words with Subword Units",
        "One4all User Representation for Recommender Systems in E-commerce",
        "Scaling Law for Recommendation Models: Towards Generalpurpose User Representations",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Relational learning via collective matrix factorization",
        "Rec: Sequential recommendation with bidirectional encoder representations from transformer",
        "Conversational recommender system",
        "Counterfactual explainable recommendation",
        "Personalized top-n sequential recommendation via convolutional sequence embedding",
        "A meta-learning perspective on cold-start recommendations for items",
        "Attention is all you need",
        "Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework",
        "Finetuned Language Models are Zero-Shot Learners",
        "Learning from Task Descriptions",
        "Neural news recommendation with multi-head self-attention",
        "Reinforcement knowledge graph reasoning for explainable recommendation",
        "Crossing the Format Boundary of Text and Boxes: Towards Unified Vision-Language Modeling",
        "One person, one model, one world: Learning continual user representation without forgetting",
        "Feature-level Deeper Self-Attention Network for Sequential Recommendation",
        "Joint representation learning for top-n recommendation with heterogeneous information sources",
        "Explainable recommendation: A survey and new perspectives",
        "Towards conversational search and recommendation: System ask, user respond",
        "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis",
        "Do users rate or review? Boost phrase-level sentiment labeling with review-level sentiment classification",
        "Joint deep modeling of users and items using reviews for recommendation",
        "S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization",
        "Learning to Prompt for Vision-Language Models",
        "Cross-Domain Recommendation: Challenges, Progress, and Prospects"
    ],
    "6271e0e75aee126c0f574720": [
        "Basic Linear Algebra Subprograms",
        "Think fast: a tensor streaming processor (TSP) for accelerating deep learning workloads",
        "Introducing the Scalable Matrix Extension for the Armv9-A Architecture",
        "Qualcomm? Cloud Al 100: 12TOPS/W Scalable, High Performance and Low Latency Deep Learning Inference Accelerator",
        "Volta: Performance and Programmability",
        "MOM: a matrix SIMD instruction set architecture for multimedia applications",
        "None",
        "Accelerating reduction and scan using tensor core units",
        "Accelerating fourier and number theoretic transforms using tensor cores and warp shuffles",
        "Algorithms",
        "Egemm-tc: Accelerating scientific computing on tensor cores with extended precision",
        "Algorithm 97: Shortest path",
        "AWB-GCN: A graph convolutional network accelerator with runtime workload rebalancing",
        "SparTen: A sparse tensor accelerator for convolutional neural networks",
        "Harnessing gpu tensor cores for fast fp16 arithmetic to speed up mixed-precision iterative refinement solvers",
        "Graphicionado: A high-performance and energy-efficient accelerator for graph analytics",
        "Chapter 7 -fast minimum spanning tree computation",
        "ExTensor: An accelerator for sparse tensor algebra",
        "Thrust: A parallel template library",
        "Relational queries with a tensor processing unit",
        "Accelerating Applications using Edge Tensor Processing Units",
        "TCUDB: Accelerating Database with Tensor Processors",
        "Intrinsics for Intel(R) Advanced Matrix Extensions (Intel(R) AMX) Instructions",
        "cuASR: CUDA Algebra for Semirings",
        "None",
        "A Domain-specific Supercomputer for Training Deep Neural Networks",
        "Proceedings of the 44th Annual International Symposium on Computer Architecture, ISCA '17",
        "All-pairs shortest-paths for large graphs on the gpu",
        "Mathematical foundations of the graphblas",
        "Accel-sim: An extensible simulation framework for validated gpu modeling",
        "On the shortest spanning subtree of a graph and the traveling salesman problem. Proceedings of the",
        "TensorDIMM: A practical nearmemory processing architecture for embeddings and tensor operations in deep learning",
        "TensorPRAM: Designing a scalable heterogeneous deep learning accelerator with byte-addressable prams",
        "Tensorcrypto: High throughput acceleration of lattice-based cryptography using tensor core on gpu",
        "Investigation of model techniques-first annual report-6 june 1956-1 july 1957-a study of model techniques for communication systems",
        "tcfft: A fast half-precision fft library for nvidia tensor cores",
        "Ascend: a scalable and unified architecture for ubiquitous deep neural network computing: Industry track paper",
        "ECL-APSP v1",
        "NDS: N-Dimensional Storage",
        "Large-scale discrete fourier transform on tpus",
        "Accelerating mri reconstruction on tpus",
        "Nonuniform fast fourier transform on tpus",
        "A multi-stage cuda kernel for floyd-warshall",
        "Cuda Floyd Warshall implementation",
        "Just how dense are dense graphs in the real world? a methodological note",
        "Accelerating probabilistic volumetric mapping using ray-tracing graphics hardware",
        "Semiring frameworks and algorithms for shortest-distance problems",
        "Simulation of Quantum Many-Body Dynamics with Tensor Processing Units: Floquet Prethermalization",
        "Exploiting Locality in Graph Analytics through Hardware-Accelerated Traversal Scheduling",
        "PHI: Architectural Support for Synchronization-and Bandwidth-Efficient Commutative Scatter Updates",
        "Exploring the binary precision capabilities of tensor cores for epistasis detection",
        "NVIDIA A100 Tensor Core GPU Architecture",
        "NVIDIA T4 TENSOR CORE GPU",
        "Warp Level Matrix Multiply-Accumulate Instructions",
        "NVIDIA Hopper Architecture In-Depth",
        "cuBool: sparse Boolean linear algebra for NVIDIA CUDA",
        "SCNN: An accelerator for compressed-sparse convolutional neural networks",
        "SIGMA: A sparse and irregular gemm accelerator with flexible interconnects for dnn training",
        "Modeling deep learning accelerator enabled gpus",
        "Fast and memory-efficient minimum spanning tree on the gpu",
        "Exploiting hardware-accelerated ray tracing for monte carlo particle transport with openmc",
        "Generalizing matrix multiplication for efficient computations on modern computers",
        "Brief announcement: The problem based benchmark suite",
        "Graphr: Accelerating graph processing using reram",
        "Ma-tRaptor: A sparse-sparse matrix multiplication accelerator based on row-wise product",
        "Tensaurus: A versatile accelerator for mixed sparse-dense tensor computations",
        "Energy Efficiency Boost in the AI-Infused POWER10 Processor",
        "Exploiting spatial architectures for edit distance algorithms",
        "?ric Debreuve. kNN-CUDA",
        "IEEE Annals of the History of Computing",
        "A hybrid systolic-dataflow architecture for inductive matrix algorithms",
        "Hitting the memory wall: Implications of the obvious",
        "Gamma: Leveraging Gustavson's Algorithm to Accelerate Sparse Matrix Multiplication",
        "Graphp: Reducing communication for pim-based graph processing with efficient data partition",
        "SpArch: Efficient architecture for sparse matrix multiplication",
        "Cambricon-S: Addressing irregularity in sparse neural networks through a cooperative software/hardware approach",
        "Sparse tensor core: Algorithm and hardware co-design for vector-wise sparse neural networks on modern GPUs",
        "RTNN: Accelerating Neighbor Search Using Hardware Ray Tracing",
        "Graphq: Scalable pim-based graph processing"
    ],
    "6274c91a5aee126c0f71246a": [
        "Learning with pseudoensembles",
        "Translating embeddings for modeling multi-relational data",
        "Multi-channel graph neural network for entity alignment",
        "Deep clustering for unsupervised learning of visual features",
        "Multilingual knowledge graph embeddings for cross-lingual knowledge alignment",
        "Generating An Optimal Interview Question Plan Using A Knowledge Graph And Integer Linear Programming",
        "Enriching contextualized language model from knowledge graph for biomedical information extraction",
        "Deep graph matching consensus",
        "SMR: Medical knowledge graph embedding for safe medicine recommendation",
        "Learning to exploit long-term relational dependencies in knowledge graphs",
        "A unified model for cross-domain and semisupervised named entity recognition in chinese social media",
        "Collaborative filtering for implicit feedback datasets",
        "Temporal ensembling for semi-supervised learning",
        "Pseudo-label: The simple and efficient semisupervised learning method for deep neural networks",
        "Semi-supervised entity alignment via joint knowledge embedding model and cross-graph model",
        "Guiding cross-lingual entity alignment via adversarial knowledge embedding",
        "Visual Pivoting for (Unsupervised) Entity Alignment",
        "Exploring and Evaluating Attributes, Values, and Structures for Entity Alignment",
        "Boosting the Speed of Entity Alignment 10*: Dual Attention Matching Network with Normalized Hard Sample Mining",
        "From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment",
        "MRAEA: an efficient and robust entity alignment approach for cross-lingual knowledge graph",
        "Relational Reflection Entity Alignment",
        "Semisupervised entity alignment via knowledge graph embedding with awareness of degree difference",
        "Rea: Robust cross-lingual entity alignment between knowledge graphs",
        "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding",
        "Transductive semi-supervised deep learning using min-max features",
        "Multi-stage self-supervised learning for graph convolutional networks on graphs with few labeled nodes",
        "Knowledge Association with Hyperbolic Knowledge Graph Embeddings",
        "Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding",
        "Cross-lingual entity alignment via joint attribute-preserving embedding",
        "Bootstrapping Entity Alignment with Knowledge Graph Embedding",
        "Transedge: Translating relation-contextualized embeddings for knowledge graphs",
        "Knowledge graph alignment network with gated multi-hop neighborhood aggregation",
        "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results",
        "Entity Alignment between Knowledge Graphs Using Attribute Embeddings",
        "Graph attention networks",
        "Cross-lingual knowledge graph alignment via graph convolutional networks",
        "Knowledge Graph Alignment with Entity-Pair Embedding",
        "Relation-aware entity alignment for heterogeneous knowledge graphs",
        "Jointly learning entity and relation representations for entity alignment",
        "Non-local Neural Networks",
        "Self-training with noisy student improves imagenet classification",
        "Cross-lingual knowledge graph alignment via graph matching neural network",
        "Cross-lingual knowledge graph alignment via graph matching neural network",
        "Dynamic Knowledge Graph Alignment",
        "Aligning cross-lingual entities with multi-aspect information",
        "Collective Embedding-based Entity Alignment via Adaptive Features",
        "Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs",
        "Relation-Aware Neighborhood Matching Model for Entity Alignment"
    ],
    "626b868a6750f822a0a5e16d": [
        "CM3: A causal masked multimodal model of the internet",
        "Self-supervised multimodal versatile networks",
        "VQA: Visual question answering",
        "None",
        "ReZero is all you need: Fast convergence at large depth",
        "Frozen in time: A joint video and image encoder for end-to-end retrieval",
        "Learning feed-forward one-shot learners",
        "Meta-learning with differentiable closed-form solvers",
        "JAX: composable transformations of Python+NumPy programs",
        "Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition",
        "High-performance largescale image recognition without normalization",
        "Language models are few-shot learners",
        "Gender shades: Intersectional accuracy disparities in commercial gender classification",
        "End-to-end object detection with transformers",
        "Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts",
        "Visualgpt: Data-efficient adaptation of pretrained language models for image captioning",
        "Pix2seq: A language modeling framework for object detection",
        "Microsoft COCO captions: Data collection and evaluation server",
        "UNITER: Universal image-text representation learning",
        "Unifying vision-and-language tasks via text generation",
        "None",
        "Visual dialog",
        "Does object recognition work for everyone",
        "Virtex: Learning visual representations from textual annotations",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Crosstransformers: spatially-aware few-shot transfer",
        "Long-term recurrent convolutional networks for visual recognition and description",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "MAGMA-multimodal augmentation of generative models through adapter-based finetuning",
        "One-shot learning of object categories",
        "Model-agnostic meta-learning for fast adaptation of deep networks",
        "VIOLET: End-to-end video-language transformers with masked visual-token modeling",
        "Large-scale adversarial training for vision-and-language representation learning",
        "The Pile: An 800GB dataset of diverse text for language modeling",
        "Datasheets for datasets",
        "Meta-learning probabilistic inference for prediction",
        "Generating sequences with recurrent neural networks",
        "Doing more with less: meta-reasoning and meta-learning in humans and machines",
        "KAT: A knowledge augmented transformer for vision-and-language",
        "VizWiz grand challenge: Answering visual questions from blind people",
        "Low-shot visual recognition by shrinking and hallucinating features",
        "Transformer language models without positional encodings still learn positional information",
        "Women also snowboard: Overcoming bias in captioning models",
        "Decoupling the role of data, attention, and losses in multimodal transformers",
        "Gaussian error linear units (GELUs)",
        "Haiku: Sonnet for JAX",
        "Long short-term memory",
        "Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models",
        "Parameter-efficient transfer learning for NLP",
        "Universal language model fine-tuning for text classification",
        "Scaling up vision-language pre-training for image captioning",
        "Attention on attention for image captioning",
        "Global pooling, more than meets the eye: Position information is encoded channel-wise in CNNs",
        "Perceiver: General perception with iterative attention",
        "MURAL: multimodal, multitask retrieval across languages",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "Xiaohu Qie, and Mike Zheng Shou. All in one: Exploring unified video-language pre-training",
        "Exploring the limits of language modeling",
        "Scaling laws for neural language models",
        "The Hateful Memes Challenge: Detecting hate speech in multimodal memes",
        "One shot learning of simple visual concepts",
        "The power of scale for parameter-efficient prompt tuning",
        "Align before fuse: Vision and language representation learning with momentum distillation",
        "BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation",
        "HERO: Hierarchical encoder for video+language omni-representation pre-training",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Oscar: Object-semantics aligned pre-training for vision-language tasks",
        "What makes good in-context examples for",
        "Optimization of image description metrics using policy gradient methods",
        "Enhancing textual cues in multi-modal transformers for vqa. VizWiz Challenge",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
        "UniVL: A unified video and language pre-training model for multimodal understanding and generation",
        "VC-GPT: Visual conditioned GPT for end-to-end generative vision-and-language pre-training",
        "Ok-VQA: A visual question answering benchmark requiring external knowledge",
        "Categorization and naming in children: Problems of induction",
        "ORBIT: A real-world few-shot dataset for teachable object recognition",
        "Catastrophic interference in connectionist networks: The sequential learning problem. The Psychology of Learning and Motivation",
        "Teaching language models to support answers with verified quotes",
        "HowTo100M: Learning a text-video embedding by watching hundred million narrated video clips",
        "RareAct: A video dataset of unusual interactions",
        "End-to-end learning of visual representations from uncurated instructional videos",
        "Recurrent neural network based language model",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "Model cards for model reporting",
        "ClipCap: CLIP prefix for image captioning",
        "Large-scale pretraining for visual dialog: A simple state-of-the-art baseline",
        "True few-shot learning with language models",
        "Red teaming language models with language models",
        "Mingxing Tan, and Quoc V. Le. Combined scaling for zero-shot transfer learning",
        "Train short, test long: Attention with linear biases enables input length extrapolation",
        "Winner team Mia at TextVQA Challenge 2021: Vision-and-language representation learning with pre-trained sequence-to-sequence model",
        "Language models are unsupervised multitask learners",
        "Learning transferable visual models from natural language supervision",
        "None",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "ZeRO: Memory optimizations toward training trillion parameter models",
        "Hierarchical text-conditional image generation with clip latents",
        "Selfcritical sequence training for image captioning",
        "Fast and flexible multi-task classification using conditional neural adaptive processes",
        "Prompt programming for large language models: Beyond the few-shot paradigm",
        "Gender bias in coreference resolution",
        "ImageNet large scale visual recognition challenge",
        "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "Diagnosing gender bias in image recognition systems",
        "Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning",
        "Megatron-LM: Training multi-billion parameter language models using model parallelism",
        "Towards VQA models that can read",
        "FLAVA: A foundational language and vision alignment model",
        "A short note on the Kinetics-700-2020 human action dataset",
        "Prototypical networks for few-shot learning",
        "Primer: Searching for efficient transformers for language modeling",
        "Energy and policy considerations for deep learning in NLP",
        "Pre-training of generic visual-linguistic representations",
        "VideoBERT: A joint model for video and language representation learning",
        "VL-Adapter: Parameter-efficient transfer learning for vision-and-language tasks",
        "Generating text with recurrent neural networks",
        "LXMERT: Learning cross-modality encoder representations from transformer",
        "YFCC100M: The new data in multimedia research",
        "None",
        "Rethinking few-shot image classification: a good embedding is all you need?",
        "Fixing the train-test resolution discrepancy",
        "Metadataset: A dataset of datasets for learning to learn from few examples",
        "Multimodal few-shot learning with frozen language models",
        "Attention is all you need",
        "Show and tell: A neural image caption generator",
        "Matching networks for one shot learning",
        "UFO: A unified transformer for vision-language representation learning",
        "Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework",
        "What language model architecture and pretraining objective work best for zero-shot generalization?",
        "VLMo: Unified vision-language pretraining with mixture-of-modality-experts",
        "VATEX: A large-scale, high-quality multilingual dataset for video-and-language research",
        "Vd-bert: A unified vision and dialog transformer with bert",
        "SimVLM: Simple visual language model pretraining with weak supervision",
        "Finetuned language models are zero-shot learners",
        "Geoffrey Irving, and Iason Gabriel. Ethical and social risks of harm from language models",
        "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time",
        "STAR: A Benchmark for Situated Reasoning in Real-World Videos",
        "Next-QA: Next phase of questionanswering to explaining temporal actions",
        "Xiangnan He, and Yueting Zhuang. Video question answering via gradually refined attention over appearance and motion",
        "Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization",
        "VLM: Task-agnostic video-language model pre-training for video understanding",
        "Achieving human parity on visual question answering",
        "Multiview transformers for video recognition",
        "Just ask: Learning to answer questions from millions of narrated videos",
        "An empirical study of GPT-3 for few-shot knowledge-based VQA",
        "TAP: Text-aware pre-training for text-VQA and text-caption",
        "Xin Jiang, and Chunjing Xu. FILIP: Fine-grained interactive language-image pre-training",
        "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
        "A new foundation model for computer",
        "BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "MERLOT: Multimodal neural script knowledge models",
        "MERLOT reserve: Neural script knowledge through vision and language and sound",
        "Socratic models: Composing zero-shot multimodal reasoning with language",
        "Scaling vision transformers",
        "LiT: Zero-shot transfer with locked-image text tuning",
        "VinVL: Revisiting visual representations in vision-language models",
        "Understanding and evaluating racial biases in image captioning",
        "Calibrate before use: Improving few-shot performance of language models",
        "Learning to prompt for vision-language models",
        "Towards automatic learning of procedures from web instructional videos",
        "Unified vision-language pre-training for image captioning and vqa",
        "ActBERT: Learning global-local video-text representations",
        "Enhance multimodal transformer with external label and in-domain pretrain: Hateful meme challenge winning solution",
        "Vatex video captioning challenge 2020: Multi-view features and hybrid reward strategies for video captioning",
        "Uni-Perceiver: Pre-training unified architecture for generic perception for zero-shot and few-shot tasks",
        "Fast context adaptation via meta-learning"
    ],
    "626754bb5aee126c0fbccbaa": [
        "Generalization Bounds for the Area Under the ROC Curve",
        "Context-sensitive query auto-completion",
        "The extreme classification repository: Multi-label datasets and code",
        "Counterfactual Reasoning and Learning Systems",
        "From RankNet to LambdaRank to LambdaMART: An Overview",
        "Learning to Rank using Gradient Descent",
        "A Survey of Query Auto Completion in Information Retrieval",
        "Time-sensitive Personalized Query Auto-Completion",
        "Prefix-Adaptive and Time-Sensitive Personalized Query Auto Completion",
        "Diversifying Query Auto-Completion",
        "XGBoost: A Scalable Tree Boosting System",
        "XGBoost: A Scalable Tree Boosting System",
        "Ranking and empirical minimization of U-statistics",
        "Performance of recommender algorithms on top-n recommendation tasks",
        "Fast, Accurate Detection of 100, 000 Object Classes on a Single Machine",
        "Learning to Attend, Copy, and Generate for Session-Based Query Suggestion",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "A probabilistic theory of pattern recognition",
        "Doubly Robust Policy Evaluation and Learning",
        "More Robust Doubly Robust Off-policy Evaluation",
        "Accelerating Large-Scale Inference with Anisotropic Vector Quantization",
        "Support vector learning for ordinal regression",
        "A generalization of sampling without replacement from a finite universe",
        "Personalized Language Model for Query Auto-Completion",
        "Cumulated gain-based evaluation of IR techniques",
        "Optimizing Search Engines Using Clickthrough Data",
        "A Support Vector Method for Multivariate Performance Measures",
        "Deep Learning with Logged Bandit Feedback",
        "Unbiased learning-to-rank with biased feedback",
        "Online and Stochastic Gradient Methods for Non-decomposable Loss Functions",
        "Inferring Networks of Substitutable and Complementary Products",
        "Image-Based Recommendations on Styles and Substitutes",
        "Fast Label Embeddings for Extremely Large Output Spaces",
        "A Neural Language Model for Query Auto-Completion",
        "Parabel: Partitioned Label Trees for Extreme Classification with Application to Dynamic Search Advertising",
        "Are Neural Rankers still Outperformed by Gradient Boosted Decision Trees?",
        "Unbiased Comparative Evaluation of Ranking Functions",
        "Learning to personalize query auto-completion",
        "Time-sensitive query auto-completion",
        "Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)",
        "A Hierarchical Recurrent Encoder-Decoder For Generative Context-Aware Query Suggestion",
        "Learning from Logged Implicit Exploration Data",
        "CAB: Continuous Adaptive Blending Estimator for Policy Evaluation and Learning",
        "Batch learning from logged bandit feedback through counterfactual risk minimization",
        "Off-policy evaluation for slate recommendation",
        "Probability in high dimension",
        "High-dimensional statistics: A non-asymptotic viewpoint",
        "Hashing for Similarity Search: A Survey",
        "Efficient Neural Query Auto Completion",
        "Learning to Rank with Selection Bias in Personal Search",
        "Position bias estimation for unbiased learning to rank in personal search",
        "Optimal and Adaptive Off-policy Evaluation in Contextual Bandits",
        "Transformers: State-of-the-Art Natural Language Processing",
        "Session-Aware Query Auto-completion using Extreme Multi-label Ranking",
        "Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback",
        "PD-Sparse: A Primal and Dual Sparse Approach to Extreme Multiclass and Multilabel Classification",
        "Pecos: Prediction for enormous and correlated output spaces"
    ],
    "627332775aee126c0f18d585": [
        "Incorporating domain knowledge into topic modeling via dirichlet forest priors",
        "Nonparametric spherical topic modeling with word embeddings",
        "Latent dirichlet allocation",
        "Dataless text classification with descriptive lda",
        "Specter: Document-level representation learning using citation-informed transformers",
        "Medical subject headings used to search the biomedical literature",
        "Gaussian lda for topic models with word embeddings",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Topic modeling in embedding spaces",
        "Measuring nominal scale agreement among many raters",
        "Anchored correlation explanation: Topic modeling with minimal domain knowledge",
        "Finding scientific topics",
        "Probabilistic latent semantic indexing",
        "Incorporating lexical priors into topic models",
        "Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Neural word embedding as implicit matrix factorization. NIPS'14",
        "On the sentence embeddings from pre-trained language models",
        "Tat-Seng Chua, and Maosong Sun",
        "Graphine: A dataset for graph-aware terminology definition generation",
        "The stanford corenlp natural language processing toolkit",
        "Hidden factors and hidden topics: understanding rating dimensions with review text",
        "Discriminative topic mining via categoryname guided text embedding",
        "Text classification using label names only: A language model self-training approach",
        "Distributed representations of words and phrases and their compositionality",
        "Optimizing semantic coherence in topic models",
        "Automatic evaluation of topic coherence",
        "Improving topic models with latent feature word representations",
        "Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec",
        "Exploring the space of topic coherence measures",
        "Neural machine translation of rare words with subword units",
        "Automated phrase mining from massive text corpora",
        "Tired of topic models? clusters of pretrained word embeddings make for fast and good topics too! In EMNLP'20",
        "Pte: Predictive text embedding through large-scale heterogeneous text networks",
        "Topic modeling with contextualized word representation clusters",
        "Multi-document summarization using sentence-based topic models",
        "Textomics: A dataset for genomics data summary generation",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "Collaboratively improving topic discovery and word embeddings by coordinating global and local contexts",
        "A correlated topic model using word embeddings",
        "React: Online multimodal embedding for recencyaware spatiotemporal activity modeling",
        "Motifclass: Weakly supervised text classification with higher-order metadata information",
        "Minimally supervised categorization of text with metadata"
    ],
    "621ee1895aee126c0f26af67": [
        "RECON: relation extraction using knowledge graph context in a graph neural network",
        "Geometric deep learning: going beyond euclidean data",
        "A multi-scale approach for graph link prediction",
        "Rethinking graph neural architecture search from message-passing",
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Scalable graph neural networks via bidirectional propagation",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "On the equivalence of decoupled graph convolution network and label propagation",
        "Single-and multi-objective evolutionary design optimization assisted by gaussian random field metamodels",
        "Learning to Identify High Betweenness Centrality Nodes from Scratch: A Novel Graph Neural Network Approach",
        "EAT-NAS: Elastic architecture transfer for accelerating large-scale neural architecture search",
        "SIGN: Scalable Inception Graph Neural Networks",
        "Graph Neural Architecture Search",
        "Syntax-guided text generation via graph neural network",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "AutoML: A survey of the stateof-the-art",
        "RetaGNN: Relational temporal attentive graph neural networks for holistic sequential recommendation",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Accelerating graph sampling for graph machine learning using GPUs",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Spam Review Detection with Graph Convolutional Networks",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "MFES-HB: Efficient Hyperband with Multi-Fidelity Quality Measurements",
        "Openbox: A generalized black-box optimization service",
        "VolcanoML: speeding up end-to-end AutoML via scalable search space decomposition",
        "One-shot graph neural architecture search with dynamic search space",
        "Graph Partition Neural Networks for Semi-Supervised Classification",
        "DARTS: Differentiable Architecture Search",
        "Pick and choose: a GNN-based imbalanced learning approach for fraud detection",
        "Improving Graph Neural Networks with Structural Adaptive Receptive Fields",
        "Degnn: Improving graph neural networks with graph decomposition",
        "Lasagne: A multi-layer graph convolutional network framework via node-aware deep architecture",
        "Geometric matrix completion with recurrent multi-graph neural networks",
        "Motifnet: a motifbased graph convolutional network for directed graphs",
        "Geom-GCN: Geometric Graph Convolutional Networks",
        "Predicting Customer Value with Social Relationships via Motif-based Graph Attention Networks",
        "Deepinf: Social influence prediction with deep learning",
        "Pathfinder Discovery Networks for Neural Message Passing",
        "Pitfalls of graph neural network evaluation",
        "ProxyBO: Accelerating Neural Architecture Search via Bayesian Optimization with Zero-cost Proxies",
        "Adaptive propagation graph convolutional network",
        "Dorylus: Affordable, Scalable, and Accurate {GNN} Training with Distributed {CPU} Servers and Serverless Threads",
        "Graph Attention Networks",
        "Label propagation through linear neighborhoods",
        "FlexGraph: a flexible and efficient distributed framework for GNN training",
        "Graph structure estimation neural networks",
        "Mixed-Curvature Multi-Relational Graph Neural Network for Knowledge Graph Completion",
        "Zero-shot recognition via semantic embeddings and knowledge graphs",
        "GNNAdvisor: An Adaptive and Efficient Runtime System for GNN Acceleration on GPUs",
        "Deep reasoning with knowledge graph for social relationship understanding",
        "Simplifying graph convolutional networks",
        "Graph neural networks in recommender systems: a survey",
        "Hashing-accelerated graph neural networks for link prediction",
        "Seastar: vertex-centric programming for graph neural networks",
        "A comprehensive survey on graph neural networks",
        "Representation learning on graphs with jumping knowledge networks",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Design space for graph neural networks",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "ROD: reception-aware online distillation for sparse graphs",
        "Evaluating deep graph neural networks",
        "Node Dependent Local Smoothing for Scalable Graph Learning",
        "Graph attention multi-layer perceptron",
        "Automated Machine Learning on Graphs: A Survey",
        "Distdgl: distributed graph neural network training for billion-scale graphs",
        "Auto-gnn: Neural architecture search of graph neural networks",
        "Simple spectral graph convolution"
    ],
    "628749425aee126c0ffee615": [
        "Fine-grained named entity typing over distantly supervised data based on refined representations",
        "Fine-grained named entity typing over distantly supervised data via refinement in hyperbolic space",
        "Improving distantly-supervised entity typing with compact latent space clustering",
        "Hierarchical entity typing via multi-level learning to rank",
        "Webly supervised learning of convolutional networks",
        "Ultra-fine entity typing",
        "Improving fine-grained entity typing with entity linking",
        "Prompt-learning for fine-grained entity typing",
        "A hybrid neural model for type classification of entity mentions",
        "Classification in the presence of label noise: A survey",
        "Contextdependent fine-grained entity type tagging",
        "Training deep neural-networks using a noise adaptation layer",
        "Using trusted data to train deep networks on labels corrupted by severe noise",
        "Long short-term memory",
        "Adam: A method for stochastic optimization",
        "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks",
        "Enhancing label representations with relational inductive bias constraint for fine-grained entity typing",
        "An attentive fine-grained entity typing model with latent type representation",
        "Fine-grained entity recognition",
        "Fine-grained entity typing via label reasoning",
        "Exploring fine-grained entity type constraints for distantly supervised relation extraction",
        "Distant supervision for relation extraction without labeled data",
        "Modeling fine-grained entity types with box embeddings",
        "Fine-grained entity typing for domain independent entity linking",
        "Learning to denoise distantly-labeled data for entity typing",
        "On the complementary nature of knowledge graph embedding, fine grain entity types, and language modeling",
        "Making deep neural networks robust to label noise: A loss correction approach",
        "Glove: Global vectors for word representation",
        "Deeptype: Multilingual entity linking by neural type system evolution",
        "Composite binary losses",
        "AFET: automatic finegrained entity typing by hierarchical partial-label embedding",
        "Label noise reduction in entity typing by heterogeneous partial-label embedding",
        "Alleviate dataset shift problem in fine-grained entity typing with virtual adversarial training",
        "An attentive neural architecture for fine-grained entity type classification",
        "Symmetric cross entropy for robust learning with noisy labels",
        "Bbn pronoun coreference and entity type corpus. Linguistic Data Consortium",
        "Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium",
        "Modeling noisy hierarchical types in fine-grained entity typing: A contentbased weighting approach",
        "Improving neural fine-grained entity typing with knowledge attention",
        "Neural finegrained entity type classification with hierarchyaware loss",
        "Embedding methods for fine grained entity type classification",
        "Learning with noise: Improving distantly-supervised fine-grained entity typing via automatic relabeling",
        "Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation",
        "Attention-based bidirectional long short-term memory networks for relation classification"
    ],
    "62451c2b5aee126c0f47ab40": [
        "Htlm: Hyper-text pre-training and prompting of language models",
        "Pancreatic cancer and thromboembolic disease, 150 years after trousseau. Hepatobiliary surgery and nutrition",
        "Learning to retrieve reasoning paths over wikipedia graph for question answering",
        "Automatic semantic classification of scientific literature according to the hallmarks of cancer",
        "Scibert: Pretrained language model for scientific text",
        "Content-based citation recommendation",
        "None",
        "Translating embeddings for modeling multirelational data",
        "Comet: Commonsense transformers for automatic knowledge graph construction",
        "Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research",
        "Language models are fewshot learners",
        "Crossdocument language modeling",
        "Wikipedia entities as rendezvous across languages: Grounding multilingual language models by predicting wikipedia hyperlinks",
        "Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation",
        "Pre-training tasks for embedding-based large-scale retrieval",
        "Reading wikipedia to answer opendomain questions",
        "Specter: Document-level representation learning using citation-informed transformers",
        "The pascal recognising textual entailment challenge",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Ncbi disease corpus: a resource for disease name recognition and concept normalization",
        "Automatically constructing a corpus of sentential paraphrases",
        "Searchqa: A new q&amp;a dataset augmented with context from a search engine",
        "Mrqa 2019 shared task: Evaluating generalization in reading comprehension",
        "Making pre-trained language models better fewshot learners",
        "The third pascal recognizing textual entailment challenge",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Realm: Retrievalaugmented language model pre-training",
        "The second pascal recognising textual entailment challenge",
        "Integrating graph contextualized knowledge into pre-trained language models",
        "Measuring massive multitask language understanding",
        "On near-uniform url sampling",
        "The ddi corpus: An annotated corpus with pharmacological substances and drug-drug interactions",
        "Strategies for pre-training graph neural networks",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "Pubmedqa: A dataset for biomedical research question answering",
        "Spanbert: Improving pre-training by representing and predicting spans",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "Dense passage retrieval for open-domain question answering",
        "Exploiting citation knowledge in personalised recommendation of recent scientific publications",
        "Unifiedqa: Crossing format boundaries with a single qa system",
        "Introduction to the bio-entity recognition task at jnlpba",
        "Gael P?rez Rodr?guez, Georgios Tsatsaronis, and Ander Intxaurrondo",
        "Natural questions: a benchmark for question answering research",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "The inductive bias of in-context learning: Rethinking pretraining example design",
        "Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the-art",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
        "Roberta: A robustly optimized bert pretraining approach",
        "Decoupled weight decay regularization",
        "Pretraining for ad-hoc retrieval: Hyperlink is also you need",
        "Concepts: core readings",
        "Results of the seventh edition of the bioasq challenge",
        "A corpus with multi-level annotations of patients, interventions and outcomes to support language processing for medical literature",
        "Unified open-domain question answering with structured and unstructured knowledge",
        "Language models as knowledge bases?",
        "Normalization rates of compression ultrasonography in patients with a first episode of deep vein thrombosis of the lower limbs: association with recurrence and new thrombosis",
        "Scientific paper summarization using citation summary networks",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Weakly supervised pretraining for multi-hop retriever",
        "Towards controllable biases in language generation",
        "Overview of biocreative ii gene mention recognition",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Biosses: a semantic sentence similarity estimation system for the biomedical domain",
        "Colake: Contextualized language and knowledge embedding",
        "Newsqa: A machine comprehension dataset",
        "Well-read students learn better: On the importance of pre-training compact models",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "2021a. Relational message passing for knowledge graph completion",
        "Kepler: A unified model for knowledge embedding and pre-trained language representation",
        "Neural network acceptability judgments",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
        "Scisummnet: A large annotated corpus and content-impact models for scientific paper summarization with citation networks",
        "QA-GNN: Reasoning with language models and knowledge graphs for question answering"
    ],
    "6233f88d5aee126c0f94b61a": [
        "Synthetic QA corpora generation with roundtrip consistency",
        "Model compression",
        "HiddenCut: Simple data augmentation for natural language understanding with better generalizability",
        "On the efficacy of knowledge distillation",
        "AutoAugment: Learning augmentation policies from data",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Improved regularization of convolutional neural networks with cutout",
        "Self-training improves pre-training for natural language understanding",
        "Understanding back-translation at scale",
        "A minimax approach to supervised learning",
        "A survey of data augmentation approaches for NLP",
        "Born again neural networks",
        "Evaluating models' local decision boundaries via contrast sets",
        "Augmenting data with mixup for sentence classification: An empirical study",
        "Distilling the knowledge in a neural network",
        "The curious case of neural text degeneration",
        "Learning data manipulation for augmentation and weighting",
        "DAIR: Data augmented invariant regularization",
        "TinyBERT: Distilling BERT for natural language understanding",
        "Not far away, not so close: Sample efficient nearest neighbour data augmentation via MiniMax",
        "Learning the difference that makes a difference with counterfactually-augmented data",
        "SciTail: A textual entailment dataset from science question answering",
        "Contextual augmentation: Data augmentation by words with paradigmatic relations",
        "Tilted empirical risk minimization",
        "Focal loss for dense object detection",
        "RoBERTa: A robustly optimized BERT pretraining approach",
        "An exploration of data augmentation and sampling techniques for domain-agnostic question answering",
        "Learning word vectors for sentiment analysis",
        "A SICK cure for the evaluation of compositional distributional semantic models",
        "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
        "Effective transfer learning for identifying similar questions: Matching user questions to COVID-19 FAQs",
        "The effect of natural distribution shift on question answering models",
        "On the stability of fine-tuning BERT: Misconceptions, explanations, and strong baselines",
        "SSMBA: Self-supervised manifold based data augmentation for improving out-of-domain robustness",
        "Adversarial NLI: A new benchmark for natural language understanding",
        "fairseq: A fast, extensible toolkit for sequence modeling",
        "CoDA: Contrast-enhanced and diversity-promoting data augmentation for natural language understanding",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "MATE-KD: Masked adversarial TExt, a companion to knowledge distillation",
        "Changing the world by changing the data",
        "everyone wants to do the model work, not the data work\": Data cascades in high-stakes ai",
        "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
        "Improving neural machine translation models with monolingual data",
        "End-to-end synthetic data generation for domain adaptation of question answering systems",
        "A simple but toughto-beat data augmentation approach for natural language understanding and generation",
        "Generalizing to unseen domains via adversarial data augmentation",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Neural networks are more productive teachers than human raters: Active mixup for data-efficient knowledge distillation from a blackbox model",
        "EDA: Easy data augmentation techniques for boosting performance on text classification tasks",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Transformers: State-of-the-art natural language processing",
        "Conditional BERT contextual augmentation",
        "Unsupervised data augmentation for consistency training",
        "Reweighting augmented samples by minimizing the maximal expected loss",
        "HellaSwag: Can a machine really finish your sentence?",
        "mixup: Beyond empirical risk minimization",
        "Character-level convolutional networks for text classification",
        "PAWS: Paraphrase adversaries from word scrambling"
    ],
    "628c4ce15aee126c0ff596d4": [
        "Protein complexes and functional modules in molecular networks",
        "The interface of protein-protein complexes: analysis of contacts and prediction of interactions",
        "Mass spectrometry supported determination of protein complex structure",
        "Computational methods in drug discovery",
        "Prediction of protein assemblies, the next frontier: The CASP14-CAPRI experiment",
        "High-Performance Deep Learning Toolbox for Genome-Scale Prediction of Protein Structure and Function",
        "DIPS-Plus: The Enhanced Database of Interacting Protein Structures for Interface Prediction",
        "Geometric Transformers for Protein Interface Contact Prediction",
        "3D-equivariant graph neural networks for protein model quality assessment",
        "The prospects and opportunities of protein structure prediction with AI",
        "Benchmarking of structure refinement methods for protein complex models",
        "E (n) equivariant graph neural networks",
        "Overcoming barriers to membrane protein structure determination",
        "Highly accurate protein structure prediction with AlphaFold",
        "Accurate prediction of protein structures and interactions using a three-track neural network",
        "AlphaFold Protein Structure Database: Massively expanding the structural coverage of protein-sequence space with high-accuracy models",
        "AlphaFold2 and the future of structural biology",
        "Geometric deep learning of RNA structure",
        "Equibind: Geometric deep learning for drug binding structure prediction",
        "Transformer protein language models are unsupervised structure learners",
        "Multi-Scale Representation Learning on Proteins",
        "Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures",
        "Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning",
        "Fast end-to-end learning on protein surfaces",
        "Learning from protein structure with geometric vector perceptrons",
        "Iterative refinement graph neural network for antibody sequence-structure co-design",
        "Structure-based protein function prediction using graph convolutional networks",
        "Protein model quality assessment using rotation-equivariant, hierarchical neural networks",
        "Protein interaction interface region prediction by geometric deep learning",
        "AlphaFold and implications for intrinsically disordered proteins",
        "AlphaFold Accelerates Artificial Intelligence Powered Drug Discovery: Efficient Discovery of a Novel Cyclin-dependent Kinase 20 (CDK20) Small Molecule Inhibitor",
        "Learning physics confers pose-sensitivity in structure-based virtual screening",
        "Structure prediction drives materials discovery",
        "Physics-informed deep neural network for rigid-body protein docking",
        "Independent SE (3)-Equivariant Models for End-to-End Rigid Protein Docking",
        "Protein complex prediction with AlphaFold-Multimer",
        "Side-chain Packing Using SE (3)-Transformer",
        "Improved protein structure refinement guided by deep learning based accuracy estimation",
        "DeepRefiner: highaccuracy protein structure refinement by deep network calibration",
        "Fast and effective protein model refinement using deep graph neural networks",
        "Atomic protein structure refinement using all-atom graph representations and SE(3)-equivariant graph neural networks",
        "DISTEMA: distance map-based estimation of single protein model accuracy with attentive 2D convolutional neural network",
        "Protein model quality assessment using 3D oriented convolutional neural networks",
        "ProteinGCN: Protein model quality assessment using graph convolutional networks",
        "GraphQA: protein model quality assessment using graph convolutional networks",
        "Relational inductive biases, deep learning, and graph networks",
        "Learning inductive biases with simple neural networks",
        "In search of the real inductive bias: On the role of implicit regularization in deep learning",
        "Rotation equivariant vector field networks",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "Group equivariant convolutional networks",
        "Se (3)-transformers: 3d roto-translation equivariant attention networks",
        "Geometric and Physical Quantities improve E(3) Equivariant Message Passing",
        "E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials",
        "Efficient Equivariant Network",
        "Generalization capabilities of translationally equivariant neural networks",
        "Factorized Attention: Self-Attention with Linear Complexities",
        "Interpretable learning for self-driving cars by visualizing causal attention",
        "Linear Attention Transformer",
        "An alternative probabilistic interpretation of the huber loss",
        "Very deep graph neural networks via noise regularisation",
        "lDDT: a local superposition-free score for comparing protein structures and models using distance difference tests",
        "Dockground: a comprehensive data resource for modeling of protein complexes",
        "Accurate prediction of inter-protein residue-residue contacts for homo-oligomeric protein complexes",
        "The EVcouplings Python framework for coevolutionary sequence analysis",
        "Scoring function for automated assessment of protein structure template quality",
        "MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets",
        "On the relationship between sequence and structure similarities in proteomics",
        "Sequence variations within protein families are linearly related to structural variations",
        "Comparative protein structure modeling using MOD-ELLER",
        "GalaxyRefineComplex: Refinement of protein-protein complex model structures driven by interface repacking",
        "PyRosetta: a script-based interface for implementing molecular modeling algorithms using Rosetta",
        "Protein Docking Model Evaluation by Graph Neural Networks",
        "DockQ: a quality measure for protein-protein docking models",
        "Evaluation of model refinement in CASP14",
        "Decoupled weight decay regularization",
        "Reduced surface: an efficient way to compute molecular surfaces",
        "Generative models for graph-based protein design",
        "Python 3 Reference Manual",
        "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "PyTorch Lightning",
        "Fast Graph Representation Learning with PyTorch Geometric",
        "Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks",
        "Table 5: Performance of different refinement methods, including ablation studies, on all test datasets",
        "None",
        "None"
    ],
    "62466dd35aee126c0f8b79e7": [
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Knowledgeable or educated guess? revisiting language models as knowledge bases",
        "Word association norms, mutual information, and lexicography",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Hinrich Sch?tze, and Yoav Goldberg. 2021a. Measuring and improving consistency in pretrained language models",
        "Alon Jacovi, and Yoav Goldberg. 2021b. Amnesic probing: Behavioral explanation with amnesic counterfactuals",
        "T-rex: A large scale alignment of natural language with knowledge base triples",
        "Causal inference in natural language processing: Estimation, prediction, interpretation and beyond",
        "Uri Shalit, and Roi Reichart. 2021b. Causalm: Causal model explanation through counterfactual language models",
        "Predicting the future with wikidata and wikipedia",
        "How can we know what language models know?",
        "SpanBERT: Improving pre-training by representing and predicting spans",
        "Multilingual LAMA: Investigating knowledge in multilingual pretrained language models",
        "Pearson's Correlation Coefficient",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Understanding neural networks through representation erasure",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Causality",
        "Language models as knowledge bases?",
        "E-BERT: Efficient-yet-effective entity embeddings for BERT",
        "Estimating causal effects of treatments in randomized and nonrandomized studies",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "Interpreting deep learning models in natural language processing: A review",
        "Use of wikipedia categories in entity ranking",
        "Investigating gender bias in language models using causal mediation analysis",
        "Wikidata: a free collaborative knowledgebase",
        "Factual probing is [MASK]: Learning vs. learning to recall"
    ],
    "622032395aee126c0fe2f8a2": [
        "Translating embeddings for modeling multi-relational data",
        "Multi-Channel Graph Neural Network for Entity Alignment",
        "JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge Alignment",
        "Multilingual knowledge graph embeddings for cross-lingual knowledge alignment",
        "A simple framework for contrastive learning of visual representations",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "All nlp tasks are generation tasks: A general pretraining framework",
        "Knowledge graph based search system",
        "Language-agnostic bert sentence embedding",
        "Deep Graph Matching Consensus",
        "Learning to exploit long-term relational dependencies in knowledge graphs",
        "A survey on knowledge graph-based recommender systems",
        "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models",
        "Pre-trained models: Past, present and future",
        "A joint embedding method for entity alignment of knowledge bases",
        "Momentum contrast for unsupervised visual representation learning",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Semi-supervised entity alignment via joint knowledge embedding model and cross-graph model",
        "AliMeKG: Domain Knowledge Graph Construction and Application in E-commerce",
        "Rimom: A dynamic multistrategy ontology alignment framework",
        "Rule-based method for entity resolution",
        "OAG_know: Self-supervised Learning for Linking Knowledge Graphs",
        "Self-supervised learning: Generative or contrastive",
        "Knowledge graph refinement: A survey of approaches and evaluation methods",
        "Semisupervised entity alignment via knowledge graph embedding with awareness degree difference",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Language models are unsupervised multitask learners",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Modeling multi-mapping relations for precise cross-lingual entity alignment",
        "Cross-lingual entity alignment via joint attribute-preserving embedding",
        "Bootstrapping Entity Alignment with Knowledge Graph Embedding",
        "Transedge: Translating relation-contextualized embeddings for knowledge graphs",
        "Knowledge graph alignment network with gated multi-hop neighborhood aggregation",
        "Using Bayesian decision for ontology mapping",
        "BERT-INT: a BERT-based interaction model for knowledge graph alignment",
        "Entity alignment between knowledge graphs using attribute embeddings",
        "Graph Attention Networks",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Cross-lingual knowledge graph alignment via graph convolutional networks",
        "Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs",
        "Jointly Learning Entity and Relation Representations for Entity Alignment",
        "Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network",
        "Aligning Cross-Lingual Entities with Multi-Aspect Information",
        "COTSAE: CO-Training of Structure and Attribute Embeddings for Entity Alignment",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
        "Graph contrastive learning with augmentations",
        "A comprehensive survey of entity alignment for knowledge graphs",
        "Collective Embedding-based Entity Alignment via Adaptive Features",
        "Oag: Toward linking large-scale heterogeneous entity graphs",
        "Mego2vec: Embedding matched ego networks for user alignment across social networks",
        "Multi-view Knowledge Graph Embedding for Entity Alignment",
        "Cosnet: Connecting heterogeneous social networks with local and global consistency",
        "Iterative Entity Alignment via Joint Knowledge Embeddings",
        "Neighborhood-Aware Attentional Representation for Multilingual Knowledge Graphs",
        "Relation-Aware Neighborhood Matching Model for Entity Alignment"
    ],
    "6296d90e5aee126c0f730b92": [
        "Beta wavelets. synthesis and application to lossy image compression",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Outlier aware network embedding for attributed networks",
        "Computer vision and deep learning-based data anomaly detection method for structural health monitoring. Structural Health Monitoring",
        "On the use of the coefficient of variation as a measure of diversity",
        "Beyond lowfrequency information in graph convolutional networks",
        "Libsvm: a library for support vector machines",
        "Diffusion wavelets. Applied and computational harmonic analysis",
        "Deterrent: Knowledge guided graph attention network for detecting healthcare misinformation",
        "The relationship between precision-recall and roc curves",
        "Compactly supported one-cyclic wavelets derived from beta distributions",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Deep anomaly detection on attributed networks",
        "Graph neural networks with adaptive frequency response filter",
        "Learning structural node embeddings via diffusion wavelets",
        "Enhancing graph neural network-based fraud detectors against camouflaged fraudsters",
        "Fast beta wavelet network-based feature extraction for image copy detection",
        "Diffusion scattering transforms on graphs",
        "Procedures for detecting outlying observations in samples",
        "Inductive representation learning on large graphs",
        "Wavelets on graphs via spectral graph theory",
        "Data Mining: Concepts and Techniques",
        "Learning arbitrary graph spectral filters via bernstein approximation",
        "An architecture of fast beta wavelet networks for image classification",
        "The advanced theory of statistics. The advanced theory of statistics",
        "Semi-supervised classification with graph convolutional networks",
        "Rev2: Fraudulent user prediction in rating platforms",
        "Graph convolutional neural networks with complex rational spectral filters",
        "Deconvolutional networks on graph data",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Intention-aware heterogeneous graph attention networks for fraud transactions detection",
        "Pick and choose: A gnn-based imbalanced learning approach for fraud detection",
        "Alleviating the inconsistency problem of applying graph neural network to fraud detection",
        "A comprehensive survey on graph anomaly detection with deep learning",
        "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews",
        "Scattering GCN: overcoming oversmoothness in graph convolutional networks",
        "Geometric scattering attention networks",
        "The application of data mining techniques in financial fraud detection: A classification framework and an academic review of literature",
        "Graph-based anomaly detection",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Scikit-learn: Machine learning in python",
        "A toolbox for signal processing on graphs",
        "Collective opinion spam detection: Bridging review networks and metadata",
        "Interpretable, multidimensional, multimodal anomaly detection with negative sampling for detection of device failure",
        "Spectral graph theory and its applications",
        "Anomaly detection for cybersecurity of the substations",
        "None",
        "A semi-supervised graph attentive network for financial fraud detection",
        "Deep graph library: A graphcentric, highly-performant package for graph neural networks",
        "Simplifying graph convolutional networks",
        "Beyond low-pass filtering: Graph convolutional networks with automatic filtering",
        "Graph wavelet neural network",
        "How powerful are graph neural networks? ICLR",
        "Error-bounded graph anomaly loss for gnns",
        "A synergistic approach for graph anomaly detection with pattern mining and feature learning"
    ],
    "62997c0b5aee126c0f77cecc": [
        "Sequence-to-sequence contrastive learning for text recognition",
        "Deep batch active learning by diverse, uncertain gradient lower bounds",
        "Mine your own view: Self-supervised learning through across-sample prediction",
        "Are all negatives created equal in contrastive instance discrimination? arXiv preprint",
        "Unsupervised learning of visual features by contrasting cluster assignments",
        "Emerging properties in self-supervised vision transformers",
        "A simple framework for contrastive learning of visual representations",
        "Exploring simple siamese representation learning",
        "Improved baselines with momentum contrastive learning",
        "An empirical study of training self-supervised vision transformers",
        "Learning a similarity metric discriminatively, with application to face verification",
        "Debiased contrastive learning",
        "Imagenet: A large-scale hierarchical image database",
        "Unsupervised metric learning with synthetic examples",
        "Robust contrastive learning using negative samples with diminished semantics",
        "Self-supervised pretraining of visual features in the wild",
        "Bootstrap your own latent: A new approach to self-supervised learning",
        "Deep residual learning for image recognition",
        "Momentum contrast for unsupervised visual representation learning",
        "Learning deep representations by mutual information estimation and maximization",
        "Adco: Adversarial contrast for efficient learning of unsupervised representations from self-trained negative adversaries",
        "Boosting contrastive self-supervised learning with false negative cancellation",
        "Hard negative mixing for contrastive learning",
        "Mix-up contrastive learning for visual representation",
        "Adam: A method for stochastic optimization",
        "Skip-thought vectors",
        "Revisiting contrastive learning through the lens of neighborhood component analysis: an integrated framework",
        "None",
        "Tiny imagenet visual recognition challenge",
        "FFCV: an optimized data pipeline for accelerating ML training",
        "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks",
        "A domain-agnostic strategy for contrastive representation learning",
        "Efficient self-supervised vision transformers for representation learning",
        "Prototypical contrastive learning of unsupervised representations",
        "Simple and principled uncertainty estimation with deterministic deep learning via distance awareness",
        "An efficient framework for learning sentence representations",
        "Active contrastive learning of audio-visual video representations",
        "Open set recognition through deep neural network uncertainty: Does out-of-distribution detection require generative classifiers?",
        "Representation learning with contrastive predictive coding",
        "Videomoco: Contrastive video representation learning with temporally adversarial examples",
        "Spatiotemporal contrastive video representation learning",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Contrastive learning with hard negative samples",
        "A theoretical analysis of contrastive unsupervised representation learning",
        "Max-margin contrastive learning",
        "Un-mix: Rethinking image mixtures for unsupervised visual representation learning",
        "Un-mix: Rethinking image mixtures for unsupervised visual representation learning",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Contrastive domain adaptation",
        "Contrastive multiview coding",
        "Propagate yourself: Exploring pixel-level consistency for unsupervised visual representation learning",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "How powerful are graph neural networks? arXiv preprint",
        "Graph contrastive learning with augmentations",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "S4l: Self-supervised semi-supervised learning",
        "mixup: Beyond empirical risk minimization",
        "Uncertainty-based decision making using deep reinforcement learning",
        "Eqco: Equivalent rules for self-supervised contrastive learning",
        "Improving contrastive learning by visualizing feature transformation",
        "Local aggregation for unsupervised learning of visual embeddings"
    ],
    "622183525aee126c0f23c770": [
        "Robust bi-tempered logistic loss based on bregman divergences",
        "Unsupervised label noise modeling and loss correction",
        "A closer look at memorization in deep networks",
        "A theory of learning from different domains",
        "Analysis of representations for domain adaptation",
        "Noise against noise: stochastic label noise helps combat inherent label noise",
        "Big self-supervised models are strong semi-supervised learners",
        "Improved baselines with momentum contrastive learning",
        "Exploring simple siamese representation learning",
        "A framework using contrastive learning for classification with noisy labels",
        "A minimax approach to supervised learning",
        "Can cross entropy loss be robust to label noise?",
        "Robust loss functions under label noise for deep neural networks",
        "Contrastive learning improves model robustness under label noise",
        "Understanding the difficulty of training deep feedforward neural networks",
        "Bootstrap your own latent -A new approach to self-supervised learning",
        "Coteaching: Robust training of deep neural networks with extremely noisy labels",
        "Improving generalization by controlling labelnoise information in neural network weights",
        "Deep residual learning for image recognition",
        "Supervised contrastive learning",
        "CURL: contrastive unsupervised representations for reinforcement learning",
        "Learning invariant representations and risks for semi-supervised domain adaptation",
        "Dividemix: Learning with noisy labels as semi-supervised learning",
        "Learning from noisy data with robust representation learning",
        "Mopro: Webly supervised learning with momentum prototypes",
        "Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks",
        "Early-learning regularization prevents memorization of noisy labels",
        "Active contrastive learning of audio-visual video representations",
        "Normalized loss functions for deep learning with noisy labels",
        "What do neural networks learn when trained with random labels?",
        "Noise tolerance under risk minimization",
        "Coresets for robust training of deep neural networks against noisy labels",
        "Making deep neural networks robust to label noise: A loss correction approach",
        "Faster R-CNN: towards real-time object detection with region proposal networks",
        "Grad-cam: Visual explanations from deep networks via gradient-based localization",
        "SELFIE: refurbishing unclean samples for robust deep learning",
        "Learning from noisy labels with deep neural networks: A survey",
        "An information theoretic framework for multi-view learning",
        "Self-supervised learning from a multi-view perspective",
        "Representation learning with contrastive predictive coding",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Symmetric cross entropy for robust learning with noisy labels",
        "Combating noisy labels by agreement: A joint training method with co-regularization",
        "Robust early-learning: Hindering the memorization of noisy labels",
        "Are anchor points really indispensable in label-noise learning?",
        "Learning from massive noisy labeled data for image classification",
        "Learning from massive noisy labeled data for image classification",
        "Detco: Unsupervised contrastive learning for object detection",
        "L dmi: A novel information-theoretic loss function for training deep nets robust to label noise",
        "Dual T: reducing estimation error for transition matrix in label-noise learning",
        "Probabilistic end-to-end noise correction for learning with noisy labels",
        "How does disagreement help generalization against label corruption?",
        "Understanding deep learning requires rethinking generalization",
        "Learning with feature-dependent label noise: A progressive approach",
        "Generalized cross entropy loss for training deep neural networks with noisy labels"
    ],
    "628d9e795aee126c0f9791fd": [
        "Domain Adaptation with Adversarial Training and Graph Embeddings",
        "Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings",
        "Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking",
        "Spectral Networks and Locally Connected Networks on Graphs",
        "Simple and Deep Graph Convolutional Networks",
        "Explaining knowledge distillation by quantifying the knowledge",
        "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks",
        "Feature-maplevel Online Adversarial Knowledge Distillation",
        "Adversarial attack on graph structured data",
        "Convolutional Networks on Graphs for Learning Molecular Fingerprints",
        "Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure",
        "GN-NAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings",
        "Protein Interface Prediction using Graph Convolutional Networks",
        "Born-Again Neural Networks",
        "Residual error based knowledge distillation",
        "Neural Message Passing for Quantum Chemistry",
        "Generative Adversarial Nets",
        "Graph Representation Learning",
        "Inductive Representation Learning on Large Graphs",
        "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",
        "Distilling the Knowledge in a Neural Network",
        "OGB-LSC: A Large-Scale Challenge for",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "Image-to-Image Translation with Conditional Adversarial Networks",
        "TinyBERT: Distilling BERT for Natural Language Understanding",
        "Node Similarity Preserving Graph Convolutional Networks",
        "Adam: A method for stochastic optimization",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Encoding Social Information with Graph Convolutional Networks for Political Perspective Detection in News Media",
        "Training Graph Neural Networks with 1000 Layers",
        "Deepergcn: All you need to train deeper gcns",
        "Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning",
        "Image Labeling on a Network: Using Social-Network Metadata for Image Classification",
        "Automating the Construction of Internet Portals with Machine Learning",
        "Query-driven active surveying for collective classification",
        "Conditional Image Synthesis with Auxiliary Classifier GANs",
        "FitNets: Hints for Thin Deep Nets",
        "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis",
        "Dis-tilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
        "Collective Classification in Network Data. AI Mag",
        "Opening the black box of deep neural networks via information",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "Deep Graph Infomax",
        "Graphgan: Graph representation learning with generative adversarial nets",
        "Microsoft academic graph: When experts are not enough",
        "KDGAN: Knowledge Distillation with Generative Adversarial Networks",
        "Adversarial Distillation for Learning with Privileged Provisions",
        "Adversarial Learning of Portable Student Networks",
        "KDD '22",
        "New theory cracks open the black box of deep learning",
        "How Powerful are Graph Neural Networks?",
        "Representation Learning on Graphs with Jumping Knowledge Networks",
        "Training Shallow and Thin Networks for Acceleration via Knowledge Distillation with Conditional Adversarial Networks",
        "Extract the Knowledge of Graph Neural Networks and Go Beyond it: An Effective Knowledge Distillation Framework",
        "Training Deep Neural Networks in Generations: A More Tolerant Teacher Educates Better Students",
        "Distilling Knowledge From Graph Convolutional Networks",
        "Do Transformers Really Perform Bad for Graph Representation? arXiv preprint",
        "Graph Convolutional Neural Networks for Web-Scale Recommender Systems",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "Reliable Data Distillation on Graph Convolutional Network",
        "Graph Attention Multi-Layer Perceptron"
    ],
    "6287492a5aee126c0ffe8231": [
        "Evaluating topic coherence using distributional semantics",
        "Pre-training is a hot topic: Contextualized document embeddings improve topic coherence",
        "Cross-lingual contextualized topic models with zero-shot learning",
        "Probabilistic topic models",
        "Latent dirichlet allocation",
        "Language models are few-shot learners",
        "Neural models for documents with metadata",
        "Gaussian LDA for topic models with word embeddings",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Topic modeling in embedding spaces",
        "None",
        "Generative adversarial nets",
        "A kernel two-sample test",
        "Improving Neural Topic Models using Knowledge Distillation",
        "Neural topic modeling with cycleconsistent adversarial training",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Adam: A method for stochastic optimization",
        "Information diffusion kernels",
        "Rectifier nonlinearities improve neural network acoustic models",
        "Spherical text embedding",
        "Discovering discrete latent topics with neural variational inference",
        "Neural variational inference for text processing",
        "Distributed representations of words and phrases and their compositionality",
        "Topic modeling with Wasserstein autoencoders",
        "CluBERT: A cluster-based approach for learning sense distributions in multiple languages",
        "GloVe: Global vectors for word representation",
        "Deep contextualized word representations",
        "Language models are unsupervised multitask learners",
        "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
        "Exploring the space of topic coherence measures",
        "Topicocean: An ever-increasing topic model with metalearning",
        "Autoencoding variational inference for topic models",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Attention is all you need",
        "Neural Gibbs Sampling for Joint Event Argument Extraction"
    ],
    "62982a9a5aee126c0f6f5f99": [
        "Diffusion-convolutional neural networks",
        "Spectral networks and locally connected networks on graphs",
        "End-to-end object detection with transformers",
        "Cyclemlp: A mlp-like architecture for dense prediction",
        "Randaugment: Practical automated data augmentation with a reduced search space",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Attention is not all you need: Pure attention loses rank doubly exponentially with depth",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Neural message passing for quantum chemistry",
        "A new model for learning in graph domains",
        "Hire-mlp: Vision mlp via hierarchical rearrangement",
        "Inductive representation learning on large graphs",
        "A survey on vision transformer",
        "Transformer in transformer",
        "Mask r-cnn",
        "Deep residual learning for image recognition",
        "Deep convolutional networks on graph-structured data",
        "Gaussian error linear units (gelus)",
        "Augment your batch: Improving generalization through instance repetition",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Deep networks with stochastic depth",
        "None",
        "Structural-rnn: Deep learning on spatio-temporal graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Imagenet classification with deep convolutional neural networks",
        "Large-scale point cloud semantic segmentation with superpoint graphs",
        "Gradient-based learning applied to document recognition",
        "Deepgcns: Can gcns go as deep as cnns?",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "As-mlp: An axial shifted mlp architecture for vision",
        "Kaiming He, and Piotr Dollár. Focal loss for dense object detection",
        "Microsoft coco: Common objects in context",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Fully convolutional networks for semantic segmentation",
        "Decoupled weight decay regularization",
        "Neural network for graphs: A contextual constructive approach",
        "Learning convolutional neural networks for graphs",
        "Graph neural networks exponentially lose expressive power for node classification",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Faster r-cnn: Towards real-time object detection with region proposal networks",
        "Imagenet large scale visual recognition challenge",
        "The graph neural network model",
        "Collective classification in network data",
        "Bottleneck transformers for visual recognition",
        "Rethinking the inception architecture for computer vision",
        "An image patch is a wave: Phase-aware vision mlp",
        "Mlp-mixer: An all-mlp architecture for vision",
        "Feedforward networks for image classification with data-efficient training",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Patches are all you need?",
        "Attention is all you need",
        "Lipschitz regularity of deep neural networks: analysis and efficient estimation",
        "Comparison of descriptor spaces for chemical compound retrieval and classification",
        "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
        "Dynamic graph cnn for learning on point clouds",
        "Resnet strikes back: An improved training procedure in timm",
        "Cvt: Introducing convolutions to vision transformers",
        "Rethinking and improving relative position encoding for vision transformer",
        "Aggregated residual transformations for deep neural networks",
        "Scene graph generation by iterative message passing",
        "How powerful are graph neural networks?",
        "Spatial temporal graph convolutional networks for skeletonbased action recognition",
        "Graph r-cnn for scene graph generation",
        "Metaformer is actually what you need for vision",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "mixup: Beyond empirical risk minimization",
        "Random erasing data augmentation",
        "Neural architecture search with reinforcement learning"
    ],
    "626f3dd05aee126c0f8f76a7": [
        "Maskgit: Masked generative image transformer",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Cogview: Mastering text-to-image generation via transformers",
        "Learning a deep convolutional network for image super-resolution",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "All nlp tasks are generation tasks: A general pretraining framework",
        "Taming transformers for high-resolution image synthesis",
        "Make-a-scene: Scene-based text-to-image generation with human priors",
        "Mask-predict: Parallel decoding of conditional masked language models",
        "Generative adversarial networks",
        "Vector quantized diffusion model for text-to-image synthesis",
        "Masked autoencoders are scalable vision learners",
        "Deberta: Decoding-enhanced bert with disentangled attention",
        "The curious case of neural text degeneration",
        "Microsoft coco: Common objects in context",
        "Some methods for classification and analysis of multivariate observations",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Glancing transformer for non-autoregressive neural machine translation",
        "Language models are unsupervised multitask learners",
        "Learning transferable visual models from natural language supervision",
        "Do vision transformers see like convolutional neural networks?",
        "Fast generation for convolutional autoregressive models",
        "Zero-shot text-to-image generation",
        "Df-gan: Deep fusion generative adversarial networks for text-to-image synthesis",
        "Neural discrete representation learning",
        "Attention is all you need",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "N\\\" uwa: Visual synthesis pre-training for neural visual world creation",
        "Simmim: A simple framework for masked image modeling",
        "Attngan: Fine-grained text to image generation with attentional generative adversarial networks",
        "The unreasonable effectiveness of deep features as a perceptual metric",
        "M6-ufc: Unifying multi-modal controls for conditional image synthesis",
        "Towards language-free training for text-to-image generation",
        "Dm-gan: Dynamic memory generative adversarial networks for text-to-image synthesis"
    ],
    "628c6264f66cd1000c54e4e9": [
        "Measuring Model Biases in the Absence of Ground Truth",
        "None",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "Multimodal datasets: misogyny, pornography, and malignant stereotypes",
        "Identifying and Reducing Gender Bias in Word-Level Language Models",
        "Large scale gan training for high fidelity natural image synthesis",
        "Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners",
        "Gender shades: Intersectional accuracy disparities in commercial gender classification",
        "Women also snowboard: Overcoming bias in captioning models",
        "Dall-eval: Probing the reasoning skills and social biases of text-to-image generative transformers",
        "PaLM: Scaling Language Modeling with Pathways",
        "Vqgan-clip: Open domain image generation and editing with natural language guidance",
        "Diffusion schrödinger bridge with applications to score-based generative modeling",
        "Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Diffusion models beat gans on image synthesis",
        "Cogview: Mastering text-to-image generation via transformers",
        "Issues in Computer Vision Data Collection: Bias, Consent, and Label Taxonomy",
        "Taming transformers for high-resolution image synthesis",
        "Sex, lies and videotape: deep fakes and free speech delusions",
        "Language-Driven Image Style Transfer",
        "Make-a-scene: Scene-based text-to-image generation with human priors",
        "Datasheets for Datasets",
        "MegaPixels: Origins and endpoints of biometric datasets \"In the Wild",
        "Clipscore: A reference-free evaluation metric for image captioning",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
        "Classifier-free diffusion guidance",
        "Denoising Diffusion Probabilistic Models. NeurIPS",
        "Cascaded diffusion models for high fidelity image generation",
        "Generative adversarial networks-enabled human-artificial intelligence collaborative applications for creative and design industries: A systematic review of current approaches and trends",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "Solving linear inverse problems using the prior implicit in a denoiser",
        "Stochastic solutions for linear inverse problems using the prior implicit in a denoiser",
        "Diffusionclip: Text-guided image manipulation using diffusion models",
        "None",
        "Microsoft COCO: Common Objects in Context",
        "Generating Images from Captions with Attention",
        "A very preliminary analysis of DALL-E 2",
        "Generating High Fidelity Images with Subscale Pixel Networks and Multidimensional Upscaling",
        "Improved denoising diffusion probabilistic models",
        "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
        "On Aliased Resizing and Surprising Subtleties in GAN Evaluation",
        "Data and its (dis)contents: A survey of dataset development and use in machine learning research",
        "Large image datasets: A pyrrhic win for computer vision?",
        "Data cards: Purposeful and transparent dataset documentation for responsible ai",
        "Learning to Generate Reviews and Discovering Sentiment",
        "Improving Language Understanding by Generative Pre-Training",
        "Language Models are Unsupervised Multitask Learners",
        "Learning Transferable Visual Models From Natural Language Supervision",
        "Maribeth Rauh, Po-Sen Huang, and Geoffrey Irving. Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Online and Linear-Time Attention by Enforcing Monotonic Alignments",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Zero-Shot Text-to-Image Generation",
        "Hierarchical Text-Conditional Image Generation with CLIP Latents",
        "Generating diverse high-fidelity images with vq-vae-2",
        "Generative adversarial text to image synthesis",
        "High-Resolution Image Synthesis with Latent Diffusion Models",
        "Palette: Image-to-Image Diffusion Models",
        "Image super-resolution via iterative refinement",
        "Do datasets have politics? disciplinary values in computer vision dataset development",
        "Laion-400m: Open dataset of clip-filtered 400 million image-text pairs",
        "Which faces can AI generate? Normativity, whiteness and lack of diversity in This Person Does Not Exist",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "None",
        "Generative Modeling by Estimating Gradients of the Data Distribution",
        "Score-based generative modeling through stochastic differential equations",
        "Biases in generative art: A causal look from the lens of art history",
        "Image representations learned with unsupervised pre-training contain human-like biases",
        "Deep fusion generative adversarial networks for text-to-image synthesis",
        "Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit",
        "Advances in neural information processing systems",
        "A connection between score matching and denoising autoencoders",
        "High-resolution image synthesis and semantic manipulation with conditional gans",
        "Wsabie: Scaling up to large vocabulary image annotation",
        "Deblurring via stochastic refinement",
        "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks",
        "Attngan: Fine-grained text to image generation with attentional generative adversarial networks",
        "Improving text-to-image synthesis using contrastive learning",
        "Vector-quantized image modeling with improved vqgan",
        "Coca: Contrastive captioners are image-text foundation models",
        "Cross-Modal Contrastive Learning for Text-to-Image Generation",
        "Lafite: Towards language-free training for text-to-image generation",
        "Dm-gan: Dynamic memory generative adversarial networks for text-to-image synthesis",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books"
    ],
    "629c4e2a5aee126c0f6f8d0b": [
        "Generative models for graph-based protein design",
        "ProDCoNN: Protein design using a convolutional neural network",
        "DenseCPD: improving the accuracy of neural-network-based computational protein sequence design with DenseNet",
        "Learning from Protein Structure with Geometric Vector Perceptrons",
        "Fast and flexible protein design using deep graph neural networks",
        "Protein sequence design with a learned potential",
        "CATH-a hierarchic classification of protein domain structures",
        "A deep and tractable density estimator",
        "Highly accurate protein structure prediction with AlphaFold",
        "MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets",
        "Scientific benchmarks for guiding macromolecular energy function improvement",
        "Macromolecular modeling and design in Rosetta: recent methods and frameworks",
        "Accurate prediction of protein structures and interactions using a three-track neural network",
        "lDDT: a local superposition-free score for comparing protein structures and models using distance difference tests",
        "Accurate design of co-assembling multi-component protein nanomaterials",
        "Quadrivalent influenza nanoparticle vaccines induce broad protection",
        "Elicitation of potent neutralizing antibody responses by designed protein nanoparticle vaccines for SARS-CoV-2",
        "Induction of potent neutralizing antibody responses by a designed protein nanoparticle vaccine for respiratory syncytial virus",
        "Design of protein binding proteins from target structure alone",
        "Attention is all you need",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Rethinking the inception architecture for computer vision",
        "TM-align: a protein structure alignment algorithm based on the TM-score",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Neural message passing for quantum chemistry",
        "SNAC-tag for sequence-specific chemical protein cleavage",
        "Xds",
        "Overview of the CCP4 suite and current developments",
        "Phaser crystallographic software",
        "Coot: model-building tools for molecular graphics",
        "PHENIX: a comprehensive Python-based system for macromolecular structure solution",
        "MolProbity: More and better reference data for improved all-atom structure validation"
    ],
    "62aa9fb55aee126c0fa5cbb7": [
        "the 10th SPE Comparative Solution Project, Model 2",
        "Distributed visualization of complex black oil reservoir models",
        "Interaction networks for learning about objects, relations and physics",
        "Surrogate accelerated sampling of reservoir models with complex structures using sparse polynomial chaos expansion",
        "Physics-informed neural networks (PINNs) for fluid mechanics: A review",
        "Development and application of reduced-order modeling procedures for subsurface flow simulation",
        "3D U-Net: learning dense volumetric segmentation from sparse annotation",
        "Application of artificial neural networks in a history matching process",
        "New frontiers in large scale reservoir simulation",
        "Physics Informed Deep Learning for Transport in Porous Media. Buckley Leverett Problem",
        "Limitations of physics informed machine learning for nonlinear two-phase transport in porous media",
        "Gaussian Processes for history-matching: application to an unconventional gas reservoir",
        "Reduced-order modeling for compositional simulation by use of trajectory piecewise linearization",
        "Reduced-order flow modeling and geological parameterization for ensemble-based data assimilation",
        "Reduced-order modeling of CO2 storage operations",
        "Machine learning-accelerated computational fluid dynamics",
        "GeoDIN-Geoscience-Based Deep Interaction Networks for Predicting Flow Dynamics in Reservoir Simulation Models",
        "Flexible neural representation for physics prediction",
        "Learning to simulate complex physics with graph networks",
        "A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems",
        "Solver-in-theloop: Learning from differentiable physics to interact with iterative PDE-solvers",
        "Reducedorder optimal control of water flooding using proper orthogonal decomposition",
        "Group normalization",
        "Non-intrusive subdomain POD-TPWL for reservoir history matching",
        "Fast multiscale reservoir simulations with POD-DEIM model reduction",
        "Bayesian deep convolutional encoderdecoder networks for surrogate modeling and uncertainty quantification"
    ],
    "6260bd7f5aee126c0fc6bbc3": [
        "STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation",
        "Latent dirichlet allocation",
        "Modeling protagonist emotions for emotion-aware storytelling",
        "Reading Wikipedia to answer opendomain questions",
        "Revisiting pretrained models for Chinese natural language processing",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Moral stories: Situated reasoning about norms, intents, actions, and their consequences",
        "Hierarchical neural story generation",
        "Learning narrative structure from annotated folktales",
        "Social chemistry 101: Learning to reason about social and moral norms",
        "An empirical exploration of moral foundations theory in partisan news sources",
        "Convolutional sequence to sequence learning",
        "Deep learning",
        "LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation",
        "A knowledge-enhanced pretraining model for commonsense story generation",
        "UNION: an unreferenced metric for evaluating open-ended story generation",
        "Story ending generation with incremental encoding and commonsense knowledge",
        "Don't stop pretraining: Adapt language models to domains and tasks",
        "Intuitive ethics: How innately prepared intuitions generate culturally variable virtues",
        "Aligning {ai} with shared human values",
        "Moral foundations twitter corpus: A collection of 35k tweets annotated for moral sentiment",
        "Morals, ethics, and integrity: How codes of conduct contribute to ethical adult education practice",
        "Towards machine ethics and norms",
        "Classification of moral foundations in microblog political discourse",
        "Stylized story generation with style-guided planning",
        "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "A diversity-promoting objective function for neural conversation models",
        "ROUGE: A package for automatic evaluation of summaries",
        "Bertgcn: Transductive text classification by combining gcn and bert",
        "Roberta: A robustly optimized bert pretraining approach",
        "Nltk: The natural language toolkit",
        "Deep dungeons and dragons: Learning character-action interactions from role-playing game transcripts",
        "Scruples: A corpus of community ethical judgments on 32, 000 real-life anecdotes",
        "A corpus and cloze evaluation for deeper understanding of commonsense stories",
        "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
        "Bleu: a method for automatic evaluation of machine translation",
        "Morality classification in natural language text",
        "Language models are unsupervised multitask learners",
        "Compressive transformers for long-range sequence modelling",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Plotmachines: Outlineconditioned generation with dynamic plot state tracking",
        "Beyond accuracy: Behavioral testing of NLP models with CheckList",
        "Automatic keyword extraction from individual documents",
        "Social bias frames: Reasoning about social and power implications of language",
        "Long and diverse text generation with planning-based hierarchical variational model",
        "Parsing argumentation structures in persuasive essays",
        "Stories told and lessons learned: Toward a narrative approach to moral development and moral education",
        "Links Number",
        "None",
        "Links Number"
    ],
    "628304515aee126c0f6f0fed": [
        "Findings of the 2021 conference on machine translation (WMT21)",
        "Non-autoregressive transformer by position learning",
        "Non-autoregressive translation by learning target categorical codes",
        "Understanding and improving lexical choice in non-autoregressive translation",
        "Rejuvenating low-frequency words: Making the most of parallel data in non-autoregressive translation",
        "Query lattice for translation retrieval",
        "Order-agnostic cross entropy for non-autoregressive machine translation",
        "Generalizing word lattice translation",
        "Latticebased system combination for statistical machine translation",
        "Mask-predict: Parallel decoding of conditional masked language models",
        "Aligned cross entropy for non-autoregressive machine translation",
        "Semiautoregressive training improves mask-predict decoding",
        "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
        "Fully non-autoregressive neural machine translation: Tricks of the trade",
        "Non-autoregressive neural machine translation",
        "Levenshtein transformer",
        "Non-autoregressive neural machine translation with enhanced decoder input",
        "Jointly masked sequence-tosequence model for non-autoregressive neural machine translation",
        "First-pass large vocabulary continuous speech recognition using bi-directional recurrent dnns",
        "The curious case of neural text degeneration",
        "Nonautoregressive translation with layer-wise prediction and deep supervision",
        "On the learning of non-autoregressive transformers",
        "Improving nonautoregressive translation models without distillation",
        "Fast decoding in sequence models using discrete latent variables",
        "Nonautoregressive machine translation with disentangled context transformer",
        "Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation",
        "Sequence-level knowledge distillation",
        "Open source toolkit for statistical machine translation",
        "Deterministic nonautoregressive neural sequence modeling by iterative refinement",
        "Iterative refinement in the continuous space for non-autoregressive neural machine translation",
        "End-to-end non-autoregressive neural machine translation with connectionist temporal classification",
        "Non-autoregressive conditional sequence generation with generative flow",
        "The alignment template approach to statistical machine translation",
        "URL",
        "A fast, extensible toolkit for sequence modeling",
        "Bleu: a method for automatic evaluation of machine translation",
        "A call for clarity in reporting BLEU scores",
        "Glancing transformer for nonautoregressive neural machine translation",
        "The volctrans GLAT system: Non-autoregressive translation meets WMT21",
        "Latticebased search strategies for large vocabulary speech recognition",
        "Combining outputs from multiple machine translation systems",
        "Nonautoregressive machine translation with latent alignments",
        "Neural machine translation of rare words with subword units",
        "Minimizing the bag-of-ngrams difference for nonautoregressive neural machine translation",
        "Mixture models for diverse machine translation: Tricks of the trade",
        "Latentvariable non-autoregressive neural machine translation with deterministic inference using a delta posterior",
        "An EM approach to non-autoregressive conditional sequence generation",
        "Fast structured decoding for sequence models",
        "Lattice minimum bayes-risk decoding for statistical machine translation",
        "Generation of word graphs in statistical machine translation",
        "Attention is all you need",
        "Imitation learning for non-autoregressive neural machine translation",
        "Posconstrained parallel decoding for non-autoregressive generation",
        "Understanding knowledge distillation in non-autoregressive machine translation"
    ],
    "62c28ae55aee126c0f8a1954": [
        "Encyclopedia of Measurement and Statistics",
        "Validating causal inference models via influence functions",
        "Bayesian inference of individualized treatment effects using multi-task gaussian processes",
        "Counterfactual representation learning with balancing weights",
        "An introduction to propensity score methods for reducing the effects of confounding in observational studies",
        "The netflix prize",
        "Size-invariant graph representations for graph classification extrapolations",
        "Estimating counterfactual treatment outcomes over time through adversarially balanced representations",
        "Fast unfolding of communities in large networks",
        "A multi-scale approach for graph link prediction",
        "Line graph neural networks for link prediction",
        "A survey on network embedding",
        "Hyperspherical variational auto-encoders",
        "Data augmentation for deep graph learning: A survey",
        "Should graph convolution trust neighbors? a simple causal inference method",
        "Fast graph representation learning with pytorch geometric",
        "Stochastic block models: A comparison of variants and inference methods",
        "Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Contrastive multi-view representation learning on graphs",
        "Counterfactual regression with importance sampling weights",
        "Learning disentangled representations for counterfactual regression",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Federated dynamic graph neural networks with secure aggregation for video-based distributed surveillance",
        "Learning representations for counterfactual inference",
        "Stochastic blockmodels and community structure in networks",
        "Simple embedding for link prediction in knowledge graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Variational graph auto-encoders",
        "Treatment effect estimation with data-driven variable decomposition",
        "Treatment effect estimation via differentiated confounder balancing and regression",
        "Counterfactual fairness",
        "Matching on balanced nonlinear representations for treatment effects estimation",
        "Generative causal explanations for graph neural networks",
        "Learning to drop: Robust graph neural network via topological denoising",
        "Automated data augmentations for graph classification",
        "A unified view on graph neural networks as graph signal denoising",
        "Domain adaptation: Learning bounds and algorithms",
        "A survey of link prediction in complex networks",
        "Learning to discover social circles in ego networks",
        "Stochastic blockmodels meet graph neural networks",
        "Link prediction via matrix factorization",
        "Counterfactuals and causal inference",
        "On spectral clustering: Analysis and an algorithm",
        "Metropolis-hastings data augmentation for graph neural networks",
        "Deep structural causal models for tractable counterfactual inference",
        "Online learning of social representations",
        "Link mining: Models, algorithms, and applications",
        "Counterfactual data augmentation using locally factored dynamics",
        "Near linear time algorithm to detect community structures in largescale networks",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "The central role of the propensity score in observational studies for causal effects",
        "Estimating causal effects of treatments in randomized and nonrandomized studies",
        "Causal inference using potential outcomes: Design, modeling, decisions",
        "Estimating individual treatment effect: generalization bounds and algorithms",
        "Intervening on network ties",
        "Cyclical learning rates for training neural networks",
        "Drug response prediction as a link prediction problem",
        "Line: Large-scale information network embedding",
        "Causal effect models for realistic individualized treatment and intention to treat rules",
        "Graph attention networks",
        "Deep graph infomax",
        "Estimation and inference of heterogeneous treatment effects using random forests",
        "Structural deep network embedding",
        "Modeling co-evolution of attributed and structural information in graph sequence",
        "Dynamic attributed graph prediction with conditional normalizing flows",
        "Nodeaug: Semi-supervised node classification with data augmentation",
        "Information theoretic counterfactual learning from missing-not-at-random feedback",
        "Hierarchical grouping to optimize an objective function",
        "Machine learning for treatment assignment: Improving individualized risk attribution",
        "Drugbank 5.0: a major update to the drugbank database for",
        "A comprehensive survey on graph neural networks",
        "Adversarial counterfactual learning and evaluation for recommender system",
        "Representation learning on graphs with jumping knowledge networks",
        "Binarized attributed network embedding",
        "Revisiting semi-supervised learning with graph embeddings",
        "Representation learning for treatment effect estimation from observational data",
        "Estimation of individualized treatment effects using generative adversarial nets",
        "Graph contrastive learning with augmentations",
        "Neo-gnns: Neighborhood overlap-aware graph neural networks for link prediction",
        "Link prediction based on graph neural networks",
        "Revisiting graph neural networks for link prediction",
        "Data augmentation for graph neural networks",
        "Action sequence augmentation for early graph-based anomaly detection",
        "Graph data augmentation for graph machine learning: A survey",
        "Robust graph representation learning via neural sparsification",
        "Deep graph contrastive representation learning",
        "Graph contrastive learning with adaptive augmentation",
        "Neural bellman-ford networks: A general graph neural network framework for link prediction",
        "Each node in this graph represents an FDA-approved or experimental drug and edges represent the existence of unexpected effect when the two drugs are taken together. This dataset does not contain any node features, and it can be downloaded with the dataloader 3 provided by OGB. B. Details on Implementation and Hyperparameters All the experiments",
        "For fair comparison, we set the size of node/link representations to be 256 of all methods. CFLP We use the Adam optimizer with a simple cyclical learning rate scheduler (Smith, 2017), in which the learning rate waves cyclically between the given learning rate (lr) and 1e-4 in every 70 epochs (50 warmup steps and 20 annealing steps)"
    ],
    "620f0e735aee126c0fec46ff": [
        "Graph Clustering",
        "Graph transformer for graph-to-sequence learning",
        "Open catalyst 2020 (oc20) dataset and community challenges",
        "Dwivedi and Bresson, 2020] Vijay Prakash Dwivedi and Xavier Bresson. A generalization of transformer networks to graphs",
        "Neural message passing for quantum chemistry",
        "Time series analysis",
        "Representing long-range context for graph neural networks with global attention",
        "Semi-supervised classification with graph convolutional networks",
        "Provably powerful graph networks",
        "Gr?goire Mialon, Dexiong Chen, Margot Selosse, and Julien Mairal. Graphit: Encoding graph structure in transformers",
        "Masked transformer for neighhourhood-aware click-through rate prediction",
        "Universal graph transformer selfattention networks",
        "Deep learning for audio signal processing",
        "Towards deep graph convolutional networks on node classification",
        "Self-supervised graph transformer on large-scale molecular data",
        "Philipp Dufter, Iryna Gurevych, and Hinrich Sch?tze. Modeling graph structure via relative position for text generation from knowledge graphs",
        "Masked label prediction: Unified message passing model for semi-supervised classification",
        "Vighnesh Shiv and Chris Quirk. Novel positional encodings to enable tree-based transformers",
        "Philipp Th?lke and Gianni de Fabritiis. Equivariant transformers for neural network based molecular potentials",
        "Transformer dissection: A unified understanding of transformer's attention via the lens of kernel",
        "Petar Velivckovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks",
        "Tianming Wang, and Xiaojun Wan. Heterogeneous graph transformer for graph-tosequence learning",
        "Do transformers really perform bad for graph representation? arXiv preprint",
        "Gresnet: Graph residual network for reviving deep gnns from suspended animation",
        "Gophormer: Ego-graph transformer for node classification"
    ],
    "628603bc970707000cbf14a8": [
        "Learning to see by moving",
        "ViViT: A video vision transformer",
        "BEiT: BERT pre-training of image Transformers",
        "Is space-time attention all you need for video understanding",
        "Language models are few-shot learners",
        "A short note about Kinetics-600",
        "A short note on the Kinetics-700 human action dataset",
        "Quo vadis, action recognition? a new model and the kinetics dataset",
        "Generative pretraining from pixels",
        "A simple framework for contrastive learning of visual representations",
        "ELECTRA: Pre-training text encoders as discriminators rather than generators",
        "RandAugment: Practical automated data augmentation with a reduced search space",
        "Histograms of oriented gradients for human detection",
        "ImageNet: A large-scale hierarchical image database",
        "BERT: Pre-training of deep bidirectional Transformers for language understanding",
        "DynamoNet: Dynamic Action and Motion Network",
        "PeCo: Perceptual codebook for BERT pre-training of Vision Transformers",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Multiscale Vision Transformers",
        "X3D: Expanding architectures for efficient video recognition",
        "SlowFast networks for video recognition",
        "A large-scale study on unsupervised spatiotemporal representation learning",
        "Self-supervised video representation learning with odd-one-out networks",
        "Large-scale weakly-supervised pre-training for video action recognition",
        "Unsupervised learning of spatiotemporally coherent metrics",
        "Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: Training ImageNet in 1 hour",
        "The \"something something\" video database for learning and evaluating visual common sense",
        "Bootstrap your own latent -a new approach to self-supervised learning",
        "AVA: A video dataset of spatio-temporally localized atomic visual actions",
        "Video representation learning by dense predictive coding",
        "Masked autoencoders are scalable vision learners",
        "Momentum contrast for unsupervised visual representation learning",
        "Augment your batch: Improving generalization through instance repetition",
        "Deep networks with stochastic depth",
        "The Kinetics human action video dataset",
        "MoviNets: Mobile video networks for efficient video recognition",
        "Backpropagation applied to handwritten zip code recognition",
        "Unsupervised representation learning by sorting sequence",
        "Improved multiscale vision transformers for classification and detection",
        "Swin Transformer v2: Scaling up capacity and resolution",
        "Video Swin Transformer",
        "SGDR: Stochastic gradient descent with warm restarts",
        "Decoupled weight decay regularization",
        "Deep predictive coding networks for video prediction and unsupervised learning",
        "Deep multi-scale video prediction beyond mean square error",
        "Shuffle and learn: Unsupervised learning using temporal order verification",
        "Neural discrete representation learning",
        "Actorcontext-actor relation network for spatio-temporal action localization",
        "Learning features by watching objects move",
        "Context encoders: Feature learning by inpainting",
        "Spatiotemporal contrastive video representation learning",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Zero-shot text-to-image generation",
        "Broaden your views for self-supervised video learning",
        "Faster R-CNN: Towards real-time object detection with region proposal networks",
        "Time-contrastive networks: Self-supervised learning from video",
        "Self-attention with relative position representations",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Unsupervised learning of video representations using LSTMs",
        "Contrastive bidirectional transformer for temporal representation learning",
        "Going deeper with convolutions",
        "Rethinking the inception architecture for computer vision",
        "VIMPAC: Video pre-training via masked token prediction and contrastive learning",
        "VideoMAE: Masked autoencoders are data-efficient learners for self-supervised video pre-training",
        "Attention is all you need",
        "Extracting and composing robust features with denoising autoencoders",
        "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
        "Anticipating visual representations from unlabelled video",
        "Tracking emerges by colorizing videos",
        "An uncertain future: Forecasting from static images using variational autoencoders",
        "BEVT: BERT pretraining of video transformers",
        "Non-local neural networks",
        "Unsupervised learning of visual representations using videos",
        "Learning correspondence from the cycleconsistency of time",
        "Masked feature prediction for self-supervised visual pre-training",
        "Learning and using the arrow of time",
        "Slow feature analysis: Unsupervised learning of invariances",
        "SimMIM: A simple framework for masked image modeling",
        "Self-supervised spatiotemporal learning via video clip order prediction",
        "Multiview transformers for video recognition",
        "A new foundation model for computer",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "Co-training Transformer with videos and images improves action recognition",
        "mixup: Beyond empirical risk minimization"
    ],
    "628ef0495aee126c0f82d966": [
        "On the bottleneck of graph neural networks and its practical implications",
        "Heat kernel estimates for random walks with degenerate weights",
        "Directional graph networks",
        "Longformer: The long-document transformer",
        "Weisfeiler and Lehman go cellular: CW networks",
        "Improving graph neural network expressivity via subgraph isomorphism counting",
        "Groupbert: Enhanced transformer architecture with efficient grouped structures",
        "Structure-aware transformer for graph representation learning",
        "On the equivalence between graph isomorphism testing and function approximation with gnns",
        "From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked transformers",
        "Rethinking attention with performers",
        "Principal neighbourhood aggregation for graph nets",
        "A generalization of transformer networks to graphs",
        "Benchmarking graph neural networks",
        "Graph neural networks with learnable structural and positional representations",
        "Convit: Improving vision transformers with soft convolutional inductive biases",
        "Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions",
        "Fast graph representation learning with PyTorch Geometric",
        "A large-scale database for graph representation learning",
        "Neural message passing for quantum chemistry",
        "Efficiently modeling long sequences with structured state spaces",
        "CMT: Convolutional neural networks meet vision transformers",
        "A survey on vision transformer",
        "Strategies for pre-training graph neural networks",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs. 34th Conference on Neural Information Processing Systems",
        "OGB-LSC: A large-scale challenge for machine learning on graphs",
        "Edge-augmented graph transformers: Global self-attention is enough for graphs",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Representing long-range context for graph neural networks with global attention",
        "Ammus: A survey of transformer-based pretrained models in natural language processing",
        "Semi-supervised classification with graph convolutional networks",
        "Reformer: The efficient transformer",
        "Spectral modification of graphs for improved spectral clustering",
        "Rethinking graph transformers with spectral attention",
        "My body is a cage: the role of morphology in graph-based incompatible control",
        "Sign and basis invariant networks for spectral graph representation learning",
        "Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting",
        "Decoupled weight decay regularization",
        "What graph neural networks cannot learn: depth vs width",
        "Provably powerful graph networks",
        "GraphiT: Encoding graph structure in transformers",
        "Weisfeiler and Leman go neural: Higher-order graph neural networks",
        "Relational pooling for graph representations",
        "Graph neural networks exponentially lose expressive power for node classification",
        "GRPE: Relative positional encoding for graph transformer",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "A survey on the expressive power of graph neural networks",
        "Benchmarking graphormer on large-scale molecular modeling datasets",
        "Long range arena: A benchmark for efficient transformers",
        "Graph learning with 1d convolutions on random walks",
        "Understanding over-squashing and bottlenecks on graphs via curvature",
        "Attention is all you need",
        "Graph attention networks",
        "Linformer: Self-attention with linear complexity",
        "The reduction of a graph to canonical form and the algebra which appears therein",
        "Prediction of physicochemical parameters by atomic contributions",
        "How powerful are graph neural networks?",
        "Breaking the expression bottleneck of graph neural networks",
        "Do transformers really perform badly for graph representation?",
        "First place solution of KDD Cup 2021 &amp; OGB large-scale challenge graph prediction track",
        "Design space for graph neural networks",
        "Big Bird: Transformers for longer sequences",
        "Labeling trick: A theory of using graph neural networks for multi-node representation learning",
        "From stars to subgraphs: Uplifting any GNN with local structure awareness"
    ],
    "628d9e795aee126c0f979247": [
        "Billion-scale pretraining with vision transformers for multi-task visual representations",
        "Uniter: Learning universal image-text representations",
        "An improved data stream summary: the count-min sketch and its applications",
        "Deep neural networks for youtube recommendations",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Pixie: A system for recommending 3+ billion items to 200+ million users in real-time",
        "Detext: A deep text ranking framework with BERT",
        "Deep multimodal representation learning: A survey",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "Heterogeneous graph transformer",
        "Audio-visual deep learning for noise robust speech recognition",
        "Embeddingbased retrieval in Facebook search",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Modeling multimodal clues in a hybrid deep learning framework for video classification",
        "Visualbert: A simple and performant baseline for vision and language",
        "Representation learning using multi-task deep neural networks for semantic classification and information retrieval",
        "Multimodal video classification with stacked contractive autoencoders",
        "Graph-based multilingual product retrieval in e-commerce search",
        "Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs",
        "Multimodal deep learning",
        "Semantic product search",
        "Pinnersage: Multi-modal user embedding framework for recommendations at Pinterest",
        "An overview of multi-task learning in deep neural networks",
        "DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter",
        "Multimodal graph networks for compositional generalization in visual question answering",
        "Hash embeddings for efficient word representations",
        "Lxmert: Learning cross-modality encoder representations from transformers",
        "Progressive layered extraction (PLE): A novel multi-task learning (MTL) model for personalized recommendations",
        "Multimodal deep representation learning for video classification",
        "Lessons learned addressing dataset bias in model-based candidate generation at Twitter",
        "Mixed negative sampling for learning two-tower neural networks in recommendations",
        "Sampling-bias-corrected neural modeling for large corpus item recommendations",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Learning a unified embedding for visual search at Pinterest",
        "Towards personalized and semantic retrieval: An end-to-end solution for e-commerce search via embedding learning",
        "Recommending what video to watch next: A multitask ranking system",
        "Unified vision-language pre-training for image captioning and VQA",
        "PinText"
    ],
    "62bd48b80cd9e8000cfc9dc5": [
        "Bottleneck transformers for visual recognition",
        "Deep learning using rectified linear units (relu)",
        "None",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search",
        "Neural architecture search for global and local image transformer",
        "Autoformer: Searching transformers for visual recognition",
        "Progressive differentiable architecture search: Bridging the depth gap between search and evaluation",
        "Nasvit: Neural architecture search for efficient vison transformers with gradient conflict-aware supernet training",
        "Fair darts: Eliminating unfair advantages in differentiable architecture search",
        "Rethinking evaluation fairness of weight sharing neural architecture search",
        "Convit: Improving vision transformers with soft convolutional inductive biases",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Randaugment: Practical automated data augmentation with a reduced search space",
        "Deep networks with stochastic depth",
        "Single path one-shot neural architecture search with uniform sampling",
        "Cvt: Introducing convolutions to vision transformers",
        "Transformer in transformer",
        "Deep residual learning for image recognition",
        "Gaussian error linear units (gelus)",
        "Going deeper with image transformers",
        "Designing network design spaces",
        "Decoupled weight decay regularization",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "International Conference on Computer Vision",
        "Crafting papers on machine learning",
        "Searching for efficient multi-stage vision transformers",
        "Microsoft coco: Common objects in context",
        "Darts: Differentiable architecture search",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "A convnet for the 2020s",
        "Searching the search space of vision transformer",
        "Imagenet large scale visual recognition challenge",
        "Multi-scale vision longformer: A new vision transformer for high-resolution image encoding",
        "Efficient neural architecture search via parameters sharing",
        "Searching for activation functions",
        "Grad-cam: Visual explanations from deep networks via gradient-based localization",
        "Regularized evolution for image classifier architecture search",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "Vision transformer architecture search",
        "Rethinking the inception architecture for computer vision",
        "Mlp-mixer: An all-mlp architecture for vision",
        "Feedforward networks for image classification with data-efficient training",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Focal loss for dense object detection",
        "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
        "Fbnet: Hardwareaware efficient convnet design via differentiable neural architecture search",
        "Group normalization",
        "Understanding the difficulty of training deep feedforward neural networks",
        "Twins: Revisiting the design of spatial attention in vision transformers",
        "Pc-darts: Partial channel connections for memory-efficient architecture search",
        "Contrastive multiview coding",
        "Bignas: Scaling up neural architecture search with big singlestage models",
        "Metaformer is actually what you need for vision",
        "Incorporating convolution designs into visual transformers"
    ],
    "62bd48b2cb97d2000c50c6a6": [
        "Designing neural network architectures using reinforcement learning",
        "Neural optimizer search with reinforcement learning",
        "Attention enhances synaptic efficacy and the signal-to-noise ratio in neural circuits",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Data: architecture approximation",
        "Searching for efficient multi-scale architectures for dense image prediction",
        "Stabilizing differentiable architecture search via perturbation-based regularization",
        "Backbone search for object detection",
        "Fair darts: Eliminating unfair advantages in differentiable architecture search",
        "Rethinking evaluation fairness of weight sharing neural architecture search",
        "Searching for a robust neural architecture in four gpu hours",
        "Nas-bench-201: Extending the scope of reproducible neural architecture search",
        "Nas-fpn: Learning scalable feature pyramid architecture for object detection",
        "Single path one-shot neural architecture search with uniform sampling",
        "Efficient convolutional neural networks for mobile vision applications",
        "Squeeze-and-excitation networks",
        "A model of saliency-based visual attention for rapid scene analysis. IEEE Transactions on pattern analysis and machine intelligence",
        "Learning efficient, explainable and discriminative representations for pulmonary nodules classification",
        "Nasabn: A neural architecture search framework for attention-based networks",
        "A new measure of rank correlation",
        "Learning multiple layers of features from tiny images",
        "Imagenet classification with deep convolutional neural networks",
        "Sgas: Sequential greedy architecture search",
        "Selective kernel networks",
        "Improved differentiable architecture search with early stopping",
        "Progressive neural architecture search",
        "Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation",
        "Hierarchical representations for efficient architecture search",
        "Darts: Differentiable architecture search",
        "Autopruner: An end-to-end trainable filter pruning method for efficient deep model inference",
        "Recurrent models of visual attention",
        "Att-darts: Differentiable neural architecture search for attention",
        "Efficient neural architecture search via parameters sharing",
        "Large-scale evolution of image classifiers",
        "Regularized evolution for image classifier architecture search",
        "Mnasnet: Platform-aware neural architecture search for mobile",
        "Residual attention network for image classification",
        "Rethinking architecture selection in differentiable nas",
        "Attentionnas: Spatiotemporal attention cell search for video classification",
        "A convolutional neural network pruning method based on attention mechanism",
        "Convolutional block attention module",
        "Fbnet: Hardwareaware efficient convnet design via differentiable neural architecture search",
        "Snas: stochastic neural architecture search",
        "Exploiting operation importance for differentiable neural architecture search",
        "Show, attend and tell: Neural image caption generation with visual attention",
        "Pc-darts: Partial channel connections for memory-efficient architecture search",
        "Frequency principle: Fourier analysis sheds light on deep neural networks. In ICML",
        "Pruning channels with attention statistics for deep network compression",
        "Towards fast one-shot nas with greedy supernet",
        "Understanding and robustifying differentiable architecture search",
        "Neural architecture search with random labels",
        "Bayesnas: A bayesian approach for neural architecture search",
        "Theoryinspired path-regularized differential network architecture search",
        "Neural architecture search with reinforcement learning",
        "Learning transferable architectures for scalable image recognition"
    ],
    "6253cbd75aee126c0f191b95": [
        "The rosetta allatom energy function for macromolecular modeling and design",
        "Unified rational protein engineering with sequence-based deep representation learning",
        "Generative modeling for protein structures",
        "Protein sequence design with a learned potential",
        "Model-based reinforcement learning for biological sequence design",
        "De novo protein design by deep network hallucination",
        "Accurate prediction of protein structures and interactions using a three-track neural network",
        "Learning protein sequence embeddings using information from structure",
        "The protein data bank",
        "Spherical convolutions and their application in molecular modelling",
        "Deep diversification of an aav capsid protein by machine learning",
        "To improve protein sequence profile prediction through image captioning on pairwise residue distance map",
        "Probing the role of packing specificity in protein design",
        "Flip: Benchmark tasks in fitness landscape inference for proteins",
        "De novo protein design: what are we learning?",
        "Understanding back-translation at scale",
        "Ig-vae: generative modeling of immunoglobulin proteins by direct 3d coordinate generation",
        "Prottrans: Towards cracking the language of lifes code through selfsupervised deep learning and high performance computing",
        "Function-guided protein design by deep manifold sampling",
        "High-resolution protein design with backbone freedom",
        "Modeling aspects of the language of life through transfer-learning protein sequences",
        "Comparison of multiple amber force fields and development of improved protein backbone parameters",
        "Pdbflex: exploring flexibility in protein structures",
        "The coming of age of de novo protein design",
        "Generative models for graph-based protein design",
        "Skempi 2.0: an updated benchmark of changes in protein-protein binding energy, kinetics and thermodynamics upon mutation",
        "Iterative refinement graph neural network for antibody sequence-structure co-design",
        "Equivariant graph neural networks for 3d macromolecular structure",
        "Learning from protein structure with geometric vector perceptrons",
        "Improving pre-training by representing and predicting spans",
        "Highly accurate protein structure prediction with alphafold",
        "None",
        "Biotite: a unifying open source computational biology framework in python",
        "Structure of the sars-cov-2 spike receptor-binding domain bound to the ace2 receptor",
        "De novo design of bioactive protein switches",
        "Gene3d: a domain-based resource for comparative genomics, functional annotation and protein network analysis",
        "Predicting changes in protein thermodynamic stability upon point mutation with deep 3d convolutional neural networks",
        "Direct prediction of profiles of sequences compatible with a protein structure by neural networks with fragment-based local and energy-based nonlocal profiles",
        "Progen: Language modeling for protein generation",
        "Deep neural language modeling enables functional protein generation across families",
        "Language models enable zero-shot prediction of the effects of mutations on protein function",
        "Uniclust databases of clustered and deeply annotated protein sequences and alignments",
        "Protein sequence design by conformational landscape optimization",
        "Predicting sequence profiles from protein structures using deep neural networks",
        "Cath-a hierarchic classification of protein domain structures",
        "A fast, extensible toolkit for sequence modeling",
        "Hmmer web server: 2018 update",
        "Densecpd: improving the accuracy of neural-network-based computational protein sequence design with densenet",
        "De novo design of modular and tunable protein biosensors",
        "Evaluating protein transfer learning with tape. Advances in neural information processing systems",
        "A. Msa transformer. bioRxiv",
        "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences",
        "Global analysis of protein folding using massively parallel design, synthesis, and testing",
        "Improved protein structure prediction using potentials from deep learning",
        "Improving neural machine translation models with monolingual data",
        "None",
        "Protein design and variant prediction using autoregressive generative models",
        "Discovery of novel gain-of-function mutations guided by structure-based deep learning",
        "Adalead: A simple and robust adaptive greedy search algorithm for sequence design",
        "Deep mutational scanning of sars-cov-2 receptor binding domain reveals constraints on folding and ace2 binding",
        "Hh-suite3 for fast remote homology detection and deep protein annotation",
        "Computational protein design",
        "Fast and flexible protein design using deep graph neural networks",
        "Uniref clusters: a comprehensive and scalable alternative for improving sequence similarity searches",
        "ATOM3D: tasks on molecules in three dimensions",
        "Efficient generative modeling of protein sequences using simple autoregressive models",
        "Well-read students learn better: On the importance of pre-training compact models",
        "Attention is all you need",
        "Structure, function, and antigenicity of the sars-cov-2 spike glycoprotein",
        "Computational protein design with deep learning neural networks",
        "Deep learning methods for designing proteins scaffolding functional sites",
        "Protein sequence design with deep generative models",
        "Improved protein structure prediction using predicted interresidue orientations",
        "Machine-learningguided directed evolution for protein engineering",
        "Protein design using a convolutional neural network",
        "A generalpurpose protein design framework based on mining sequence-structure relationships in known protein structures"
    ],
    "620c6b655aee126c0fe29013": [
        "Stochastic blockmodel approximation of a graphon: Theory and consistent estimation",
        "Centrality measures for graphons: Accounting for uncertainty in networks",
        "Accurate learning of graph representations with graph multiset pooling",
        "Spectral clustering with graph neural networks for graph pooling",
        "Convergent sequences of dense graphs i: Subgraph frequencies, metric properties and testing",
        "A consistent histogram estimator for exchangeable graph models",
        "Classification and estimation in the stochastic blockmodel based on the empirical degrees",
        "Matrix estimation by universal singular value thresholding",
        "How robust are graph neural networks to structural noise?",
        "Quick approximation to matrices and applications",
        "None",
        "Nonlinear mixup: Out-of-manifold data augmentation for text classification",
        "Augmenting data with mixup for sentence classification: An empirical study",
        "Mixup as locally linear out-of-manifold regularization",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Training graph neural networks by graphon estimation",
        "Adaptive sampling towards fast graph representation learning",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Matrix completion from a few entries",
        "A method for stochastic optimization",
        "Semi-supervised classification with graph convolutional networks",
        "Large networks and graph limits",
        "Limits of dense graph sequences",
        "Rectified linear units improve restricted boltzmann machines",
        "Metropolis-hastings data augmentation for graph neural networks",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Graphon neural networks and the transferability of graph neural networks",
        "Graph and graphon neural network stability",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "Data augmentation for graph convolutional network on semi-supervised classification",
        "Graph attention networks",
        "Manifold mixup: Better representations by interpolating hidden states",
        "Graphmix: Improved training of gnns for semi-supervised learning",
        "The laplacian spectrum of large graphs sampled from graphons",
        "Subgraph cropping for graph classification",
        "Nodeaug: Semi-supervised node classification with data augmentation",
        "Mixup for node and graph classification",
        "A comprehensive survey on graph neural networks",
        "Learning graphons via structured gromov-wasserstein barycenters",
        "How powerful are graph neural networks?",
        "Hierarchical graph representation learning with differentiable pooling",
        "Graph contrastive learning with augmentations",
        "Bringing your own view: Graph contrastive learning without prefabricated data augmentations",
        "mixup: Beyond empirical risk minimization",
        "How does mixup help with robustness and generalization?",
        "An end-toend deep learning architecture for graph classification",
        "Deep learning on graphs: A survey",
        "Data augmentation for graph neural networks",
        "Graph theory and additive combinatorics",
        "Graph neural networks: A review of methods and applications. AI Open",
        "Data augmentation for graph classification"
    ],
    "62d8c4565aee126c0f762dba": [
        "Masked generative image transformer",
        "X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers",
        "Adversarial video generation on complex datasets",
        "Diffusion models beat gans on image synthesis",
        "Cogview: Mastering text-to-image generation via transformers",
        "Taming transformers for high-resolution image synthesis",
        "Vector quantized diffusion model for text-to-image synthesis",
        "Proceedings of the IEEE International Conference on Computer Vision",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
        "Denoising diffusion probabilistic models",
        "Improve Transformer Models with Better Relative Position Embeddings",
        "A method for stochastic optimization",
        "InfinityGAN: Towards Infinite-Pixel Image Synthesis",
        "Infinite Nature: Perpetual View Generation of Natural Scenes From a Single Image",
        "Video swin transformer",
        "Learning Transferable Visual Models From Natural Language Supervision",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Hierarchical text-conditional image generation with clip latents",
        "Zero-Shot Text-to-Image Generation",
        "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
        "Improved techniques for training gans",
        "Aligning latent and image spaces to connect the unconnectable",
        "LocoGAN -Locally convolutional GAN",
        "Towards accurate generative models of video: A new metric &amp; challenges",
        "Attention is all you need",
        "High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks",
        "GIT: A Generative Image-to-text Transformer for Vision and Language",
        "UWA: Visual Synthesis Pre-training for Neural visUal World creAtion",
        "Vector-quantized Image Modeling with Improved VQGAN",
        "Scaling Autoregressive Models for Content-Rich Text-to-Image Generation",
        "M6-ufc: Unifying multi-modal controls for conditional image synthesis"
    ],
    "622eb2495aee126c0f62b12a": [
        "On the surprising behavior of distance metrics in high dimensional space",
        "Considerably improving clustering algorithms using umap dimensionality reduction technique: A comparative study",
        "Top2vec: Distributed representations of topics",
        "Understanding state preferences with text as data: Introducing the un general debate corpus",
        "Raghu Ramakrishnan, and Uri Shaft. 1999. When is \"nearest neighbor\" meaningful?",
        "Pre-training is a hot topic: Contextualized document embeddings improve topic coherence",
        "Debora Nozza, and Elisabetta Fersini. 2020b. Cross-lingual contextualized topic models with zero-shot learning",
        "Dynamic topic models",
        "Latent dirichlet allocation",
        "Normalized (pointwise) mutual information in collocation extraction",
        "A novel neural topic model and its supervised extension",
        "The use of mmr, diversity-based reranking for reordering documents and producing summaries",
        "Chris Tar, et al. 2018. Universal sentence encoder",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Topic modeling in embedding spaces. Transactions of the Association for",
        "Algorithms for nonnegative matrix factorization with the ?divergence",
        "Practical solutions to the problem of diagonal dominance in kernel document clustering",
        "Is automated topic model evaluation broken? the incoherence of coherence",
        "A probabilistic analysis of the rocchio algorithm with tfidf for text categorization",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Newsweeder: Learning to filter netnews",
        "A neural autoregressive topic model",
        "Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality",
        "Distributed representations of sentences and documents",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Tat-Seng Chua, and Maosong Sun",
        "Roberta: A robustly optimized bert pretraining approach",
        "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction",
        "Accelerated hierarchical density based clustering",
        "hdbscan: Hierarchical density based clustering",
        "Umap: Uniform manifold approximation and projection",
        "Improving topic models with latent feature word representations",
        "Systematic review of clustering high-dimensional and large datasets",
        "Topic modeling over short texts by incorporating word embeddings",
        "Sentencebert: Sentence embeddings using siamese bertnetworks",
        "Making monolingual sentence embeddings multilingual using knowledge distillation",
        "We-lda: a word embeddings augmented lda model for web services clustering",
        "Tired of topic models? clusters of pretrained word embeddings make for fast and good topics too! arXiv preprint",
        "Mpnet: Masked and permuted pretraining for language understanding",
        "The challenges of clustering high dimensional data",
        "Octis: Comparing and optimizing topic models is simple",
        "Augmented sbert: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks",
        "Topic modeling with contextualized word representation clusters",
        "Topic modelling meets deep neural networks: A survey"
    ],
    "628c4ce15aee126c0ff597ca": [
        "Layer normalization",
        "Ms marco: A human generated machine reading comprehension dataset",
        "Generative adversarial networks: An overview",
        "Pre-training methods in information retrieval",
        "2021a. Condenser: a pretraining architecture for dense retrieval",
        "2021b. Unsupervised corpus aware language model pre-training for dense passage retrieval",
        "Rethink training of bert rerankers in multi-stage retrieval pipeline",
        "A deep relevance matching model for ad-hoc retrieval",
        "Multi-view cross-lingual structured prediction with minimum supervision",
        "Embedding-based retrieval in facebook search",
        "Dense passage retrieval for open-domain question answering",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Encoder adaptation of dense passage retrieval for open-domain question answering",
        "Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations",
        "Pre-trained language model for web-scale retrieval in baidu search",
        "Roberta: A robustly optimized bert pretraining approach",
        "Ernie-search: Bridging cross-encoder with dual-encoder via self on-the-fly distillation for dense passage retrieval",
        "A statistical approach to mechanized encoding and searching of literary information",
        "B-prop: bootstrapped pre-training with representative words prediction for ad-hoc retrieval",
        "Retrieve-andread: Multi-task learning of information retrieval and reading comprehension",
        "Passage re-ranking with bert",
        "Yes sir! optimizing semantic space of negatives with self-involvement ranker",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Rocketqav2: A joint training method for dense passage retrieval and passage re-ranking",
        "The probabilistic relevance framework: BM25 and beyond",
        "Attention is all you need",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Adversarial retriever-ranker for dense text retrieval"
    ],
    "6292aa4a8c0a46000c95808f": [
        "Object detection and tracking under occlusion for Objectlevel RGB-D video segmentation",
        "Efficient optical flow and stereo vision for velocity estimation and obstacle avoidance on an autonomous pocket drone",
        "Real-time traffic flow parameter estimation from UAV video based on ensemble classifier and optical flow",
        "Obstacle detection and collision avoidance for a UAV with complementary low-cost sensors",
        "Illumination robust video foreground prediction based on color recovering",
        "Video object segmentation via dense trajectories",
        "Vision-Based fingertip tracking utilizing curvature points clustering and hash model representation",
        "Authorized licensed use limited to: Tsinghua University",
        "Flowing convnets for human pose estimation in videos",
        "Online video stream abstraction and stylization",
        "An optical flow-based full reference video quality assessment algorithm",
        "An unsupervised learning model for deformable medical image registration",
        "Video aesthetic quality assessment by temporal integration of photo-and motion-based features",
        "A fast HEVC inter CU selection method based on pyramid motion divergence",
        "Determining optical flow",
        "Illumination invariant optical flow using neighborhood descriptors",
        "Optical flow with semantic segmentation and localized layers",
        "Weighted local intensity fusion method for variational optical flow estimation",
        "Pattern Recognit",
        "Regularization strategies for discontinuity-preserving optical flow methods",
        "Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory",
        "Learning dual convolutional neural networks for lowlevel vision",
        "Velocity estimation from image sequences with second order differential operators",
        "Learning optical flow",
        "The robust estimation of multiple motions: Parametric and piecewise-smooth flow fields",
        "Anisotropic Huber-L 1 optical flow",
        "Motion detail preserving optical flow estimation",
        "High accuracy optic flow estimation based on a theory for warping",
        "A quantitative analysis of current practices in optical flow estimation and the principles behind them",
        "DeepFlow: Large displacement optical flow with deep matching",
        "Fast edge-preserving patchmatch for large displacement optical flow",
        "Large displacement optical flow: Descriptor matching in variational motion estimation",
        "Large displacement optical flow from nearest neighbor fields",
        "Flow fields: Dense correspondence fields for highly accurate large displacement optical flow estimation",
        "Bilateral filtering-based optical flow estimation with occlusion detection",
        "Occlusion-aware optical flow estimation",
        "EpicFlow: Edgepreserving interpolation of correspondences for optical flow",
        "MirrorFlow: Exploiting symmetries in joint optical flow and occlusion estimation",
        "ProbFlow: Joint optical flow and uncertainty estimation",
        "Robust nonlocal TV-L 1 optical flow estimation with occlusion detection",
        "Optical flow with geometric occlusion estimation and fusion of multiple frames",
        "U-net: Convolutional networks for biomedical image segmentation",
        "FlowNet: Learning optical flow with convolutional networks",
        "FlowNet2.0: Evolution of optical flow estimation with deep networks",
        "Optical flow estimation using a spatial pyramid network",
        "LiteFlownet: A lightweight convolutional neural network for optical flow estimation",
        "Optical flow in mostly rigid scenes",
        "PatchBatch: A batch augmented loss for optical flow",
        "Occlusions, motion and depth boundaries with a generic network for disparity, optical flow or scene flow estimation",
        "CNN-based patch matching for optical flow with thresholded hinge embedding loss",
        "Accurate optical flow via direct cost volume processing",
        "KalmanFlow 2.0: Efficient video optical flow estimation via context-aware kalman filtering",
        "PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume",
        "Unsupervised learning of multi-frame optical flow with occlusions",
        "SelFlow: Self-supervised learning of optical flow",
        "Context-aware synthesis for video frame interpolation",
        "Continual occlusion and optical flow estimation",
        "Iterative residual refinement for joint optical flow and occlusion estimation",
        "Unsupervised deep learning for optical flow estimation",
        "Occlusion aware unsupervised learning of optical flow",
        "Densely connected convolutional networks",
        "Residual attention network for image classification",
        "Authorized licensed use limited to: Tsinghua University",
        "Dual attention networks for multimodal reasoning and matching",
        "Residual dense network for image super-resolution",
        "Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness",
        "UnFlow: Unsupervised learning of optical flow with a bidirectional census loss",
        "Fast R-CNN",
        "A naturalistic open source movie for optical flow evaluation",
        "Are we ready for autonomous driving? the kitti vision benchmark suite"
    ],
    "62a013785aee126c0ff695ef": [
        "Tox21 Challenge",
        "Deep Learning using Rectified Linear Units (ReLU)",
        "Layer Normalization",
        "Directional graph networks",
        "Machine learning for molecular and materials science",
        "Molecular fingerprint similarity search in virtual screening",
        "Path-Augmented Graph Transformer Network",
        "Principal Neighbourhood Aggregation for Graph Nets",
        "ESOL: estimating aqueous solubility directly from molecular structure",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "ADMETlab: a platform for systematic ADMET evaluation based on a comprehensively collected ADMET database",
        "Vishrav Chaudhary, et al. 2021. Beyond english-centric multilingual machine translation",
        "GPT-3: Its nature, scope, limits, and consequences. Minds and Machines",
        "The ChEMBL database in 2017",
        "ChEMBL: a large-scale bioactivity database for drug discovery",
        "A data-driven approach to predicting successes and failures of clinical trials",
        "Neural message passing for quantum chemistry",
        "rdkit/rdkit: 2021_09_2 (Q3 2021) Release",
        "Exploring network structure, dynamics, and function using NetworkX",
        "Inductive Representation Learning on Large Graphs",
        "Masked autoencoders are scalable vision learners",
        "Masked Autoencoders Are Scalable Vision Learners",
        "Momentum Contrast for Unsupervised Visual Representation Learning",
        "Gaussian error linear units (gelus)",
        "Strategies for Pre-training Graph Neural Networks",
        "Adam: A Method for Stochastic Optimization",
        "Overcoming catastrophic forgetting in neural networks",
        "Rethinking graph transformers with spectral attention",
        "The SIDER database of drugs and side effects",
        "Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting",
        "N-Gram Graph: Simple Unsupervised Representation for Graphs, with Applications to Molecules",
        "Pre-training Molecular Graph Representation with 3D Geometry",
        "Swin Transformer V2: Scaling Up Capacity and Resolution",
        "A Bayesian approach to in silico blood-brain barrier penetration modeling",
        "Molecule Attention Transformer",
        "Graphit: Encoding graph structure in transformers",
        "FreeSolv: a database of experimental and calculated hydration free energies, with input files",
        "Mordred: a molecular descriptor calculator",
        "Automatic differentiation in PyTorch",
        "MetStabOn-online platform for metabolic stability predictions",
        "Deep Learning for the Life Sciences",
        "ToxCast chemical landscape: paving the road to 21st century toxicology",
        "Extended-connectivity fingerprints",
        "Self-Supervised Graph Transformer on Large-Scale Molecular Data",
        "Self-Attention with Relative Position Representations",
        "Stephan G?nnemann, and Pietro Li?. 2021. 3D Infomax improves GNNs for Molecular Property Prediction",
        "Computational modeling of ?-secretase 1 (BACE-1) inhibitors using ligand based approaches",
        "Machine learning for chemical discovery",
        "ADMET in silico modelling: towards prediction paradise?",
        "Attention is All you Need",
        "Deep Graph Infomax",
        "Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks",
        "MolCLR: molecular contrastive learning of representations via graph neural networks",
        "A compact review of molecular property prediction with graph neural networks",
        "MoleculeNet: a benchmark for molecular machine learning",
        "Pushing the boundaries of molecular representation for drug discovery with the graph attention mechanism",
        "How Powerful are Graph Neural Networks?",
        "Selfsupervised Graph-level Representation Learning with Local and Global Structure",
        "Molecular descriptors in chemoinformatics, computational combinatorial chemistry, and virtual screening",
        "Analyzing learned molecular representations for property prediction",
        "Do Transformers Really Perform Badly for Graph Representation?",
        "Graph Contrastive Learning Automated",
        "Graph Contrastive Learning with Augmentations",
        "Graph neural networks: A review of methods and applications"
    ],
    "62e744545aee126c0f33c1ec": [
        "Graph convolutional matrix completion",
        "Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention",
        "Revisiting Graph Based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach",
        "Curriculum meta-learning for next POI recommendation",
        "Debiasing grid-based product search in e-commerce",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Neural collaborative filtering",
        "Recent advances in heterogeneous relation learning for recommendation",
        "Xiaoping Lai, and Yanfang Ye. 2021. Knowledge-aware coupled graph neural network for social recommendation",
        "Self-supervised auxiliary learning with meta-paths for heterogeneous graphs",
        "Dual channel hypergraph collaborative filtering",
        "Contragan: Contrastive learning for conditional image generation",
        "Matrix factorization techniques for recommender systems",
        "An adversarial approach to improve long-tail performance in neural collaborative filtering",
        "Variational autoencoders for collaborative filtering",
        "Self-supervised learning: Generative or contrastive",
        "Concept-Aware Denoising Graph Neural Network for Micro-Video Recommendation",
        "Graph representation learning via graphical mutual information maximization",
        "Sequential recommendation with self-attentive multi-adversarial network",
        "Neural collaborative filtering vs. matrix factorization revisited",
        "Autorec: Autoencoders meet collaborative filtering",
        "Rec: Sequential recommendation with bidirectional encoder representations from transformer",
        "Deep Graph Infomax.. In ICLR",
        "LexFit: Lexical fine-tuning of pretrained language models",
        "Next-item recommendation with sequential hypergraphs",
        "Neural Graph Collaborative Filtering",
        "Heterogeneous graph attention network",
        "Disentangled graph collaborative filtering",
        "Disenhan: Disentangled heterogeneous graph attention network for recommendation",
        "Simplifying graph convolutional networks",
        "Self-supervised graph learning for recommendation",
        "Knowledge-enhanced hierarchical graph transformer network for multi-behavior recommendation",
        "Hypergraph Contrastive Collaborative Filtering",
        "Graph meta network for multi-behavior recommendation",
        "Hyper Meta-Path Contrastive Learning for Multi-Behavior Recommendation",
        "Knowledge Graph Contrastive Learning for Recommendation",
        "Self-supervised Learning for Large-scale Item Recommendations",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Nguyen Quoc Viet Hung, and Xiangliang Zhang. 2021. Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation",
        "Star-gcn: Stacked and reconstructed graph convolutional networks for recommender systems",
        "A model of two tales: Dual transfer learning framework for improved long-tail item recommendation",
        "Causal intervention for leveraging popularity bias in recommendation"
    ],
    "623be1965aee126c0f37abe2": [
        "Intent classification and slot filling for privacy policies",
        "Automatic extraction of facts from press releases to generate news stories",
        "Autoregressive entity retrieval",
        "Detecting and reading text in natural scenes",
        "Unifying vision-and-language tasks via text generation",
        "Unsupervised cross-lingual representation learning at scale",
        "Template-based named entity recognition using BART",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Event extraction by answering (almost) natural questions",
        "Twenty-five years of information extraction",
        "Message Understanding Conference-6: A brief history",
        "Fewshot named entity recognition: An empirical baseline study",
        "Knowledge base population: Successful approaches and challenges",
        "Adam: A method for stochastic optimization",
        "Identity and necessity",
        "Neural architectures for named entity recognition",
        "End-to-end neural coreference resolution",
        "Zero-shot relation extraction via reading comprehension",
        "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Generating templates of entity summaries with an entityaspect model and pattern mining",
        "2021a. Documentlevel event argument extraction by conditional generation",
        "2021b. UNIMO: Towards unified-modal understanding and generation via cross-modal contrastive learning",
        "A unified MRC framework for named entity recognition",
        "Nugget proposal networks for Chinese event detection",
        "Sequence-to-nuggets: Nested entity mention detection via anchor-region networks",
        "A joint neural model for information extraction with global features",
        "Fine-grained entity typing via label reasoning",
        "Roberta: A robustly optimized BERT pretraining approach",
        "End-to-end neural event coreference resolution",
        "Text2Event: Controllable sequence-tostructure generation for end-to-end event extraction",
        "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
        "Exploring sequence-tosequence learning in aspect term extraction",
        "Coarse-to-Fine Pre-training for Named Entity Recognition",
        "From information retrieval to information extraction",
        "None",
        "Issues and methodology for template design for information extraction",
        "RISHITA ANUBHAI, Cicero Nogueira dos Santos, Bing Xiang, and Stefano Soatto. 2021. Structured prediction as translation between augmented natural languages",
        "SemEval-2016 task 5: Aspect based sentiment analysis",
        "SemEval-2015 task 12: Aspect based sentiment analysis",
        "SemEval-2014 task 4: Aspect based sentiment analysis",
        "ERICA: Improving entity and relation understanding for pre-trained language models via contrastive learning",
        "Exploring the limits of transfer learning with a unified text-totext transformer",
        "Sequence level training with recurrent neural networks",
        "HySPA: Hybrid span generation for scalable text-to-graph extraction",
        "Modeling relations and their mentions without labeled text",
        "A linear programming formulation for global inference in natural language tasks",
        "Casie: Extracting cybersecurity event information from text",
        "Deep exhaustive model for nested named entity recognition",
        "An open multilingual graph of general knowledge",
        "Neural architectures for nested NER through linearization",
        "Joint entity and relation extraction with set prediction networks",
        "Let's Stop Incorrect Comparisons in End-to-end Relation Extraction",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "Entity, relation, and event extraction with contextualized span representations",
        "Ace 2005 multilingual training corpus",
        "Two are better than one: Joint entity and relation extraction with tablesequence encoders",
        "2021a. Improving named entity recognition by external context retrieving and cooperative learning",
        "TPLinker: Single-stage joint extraction of entities and relations through token pair linking",
        "CLEVE: Contrastive Pre-training for Event Extraction",
        "Learning span-level interactions for aspect sentiment triplet extraction",
        "Position-aware tagging for aspect sentiment triplet extraction",
        "Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer",
        "2021a. A unified generative framework for aspect-based sentiment analysis",
        "Zheng Zhang, and Xipeng Qiu. 2021b. A unified genera-tive framework for various NER subtasks",
        "Joint extraction of entities and relations based on a novel decomposition strategy",
        "Extracting relational facts by an end-to-end neural model with copy mechanism",
        "Minimize exposure bias of Seq2Seq models in joint entity and relation extraction",
        "Towards generative aspect-based sentiment analysis",
        "PRGC: Potential relation and global correspondence based joint relational triple extraction",
        "Joint extraction of entities and relations based on a novel tagging scheme",
        "A frustratingly easy approach for entity and relation extraction",
        "For nested entity extraction datasets ACE04 and ACE05-Ent, we follow the pre-processing steps and data split of previous works"
    ],
    "6281b2a35aee126c0ffd514a": [
        "Beit: Bert pre-training of image transformers",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "Vggface2: A dataset for recognising faces across pose and age",
        "Maskgit: Masked generative image transformer",
        "Progressive semantic-aware style transformation for blind face restoration",
        "Fsrnet: End-to-end learning face superresolution with facial priors",
        "Arcface: Additive angular margin loss for deep face recognition",
        "Exemplar guided face image super-resolution without facial landmarks",
        "Learning a deep convolutional network for image super-resolution",
        "Peco: Perceptual codebook for bert pre-training of vision transformers",
        "Taming transformers for high-resolution image synthesis",
        "Swagan: A style-based wavelet-driven generative model",
        "Image style transfer using convolutional neural networks",
        "Image processing using multi-code gan prior",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems",
        "Image-to-image translation with conditional adversarial networks",
        "Perceptual losses for real-time style transfer and superresolution",
        "A style-based generator architecture for generative adversarial networks",
        "Analyzing and improving the image quality of stylegan",
        "Adam: A method for stochastic optimization",
        "Deblurgan: Blind motion deblurring using conditional adversarial networks",
        "Robust training of vector quantized bottleneck models",
        "Blind face restoration via deep multiscale component dictionaries",
        "Learning warped guidance for blind face restoration",
        "Enhanced deep residual networks for single image super-resolution",
        "Pulse: Self-supervised photo upsampling via latent space exploration of generative models",
        "Making a \"completely blind\" image quality analyzer",
        "Generating diverse high-fidelity images with vq-vae-2",
        "Deep semantic face deblurring",
        "Very deep convolutional networks for large-scale image recognition",
        "Advances in neural information processing systems",
        "Bringing old photos back to life",
        "Towards real-world blind face restoration with generative facial prior",
        "Restoreformer: High-quality blind face restoration from undegraded key-value pairs",
        "N\\\" uwa: Visual synthesis pre-training for neural visual world creation",
        "Hifacegan: Face renovation via collaborative suppression and replenishment",
        "Gan prior embedded network for blind face restoration in the wild",
        "Vector-quantized image modeling with improved vqgan",
        "Face super-resolution guided by facial component heatmaps",
        "Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising",
        "The unreasonable effectiveness of deep features as a perceptual metric",
        "The unreasonable effectiveness of deep features as a perceptual metric",
        "Deformable convnets v2: More deformable, better results"
    ],
    "624802f36750f84d00082030": [
        "Survey Results",
        "Amazon 'thwarts largest ever DDoS cyber-attack",
        "NET SCOUT THREAT INTELLIGENCE REPORT",
        "Rate-limiting state",
        "MANRS",
        "Rfc3704: Ingress filtering for multihomed networks",
        "Network hygiene, incentives, and regulation: Deployment of source address validation in the internet",
        "Effective notification campaigns on the web: A matter of trust, framing, and support",
        "Heartbleed 101",
        "The matter of heartbleed",
        "You've got vulnerability: Exploring effective vulnerability notifications",
        "Amplification Hell: Revisiting Network Protocols for DDoS Abuse",
        "Saving the internet: Explaining the adoption of source address validation by internet service providers",
        "The Spoofer Project",
        "The cox model",
        "Challenges in inferring spoofed traffic at IXPs",
        "Detection, Classification, and Analysis of Inter-domain Traffic with Spoofed Source IP Addresses",
        "Don't Forget to Lock the Front Door! Inferring the Deployment of Source Address Validation of Inbound Traffic",
        "Inferring the deployment of inbound source address validation using dns resolvers",
        "Understanding the Efficacy of Deployed Internet Source Address Validation Filtering",
        "The Spoofer Project: Inferring the Extent of Source Address Filtering on the Internet",
        "Exit from Hell? Reducing the Impact of Amplification DDoS Attacks",
        "Using Loops Observed in Traceroute to Infer the Ability to Spoof",
        "Tell me you fixed it: Evaluating vulnerability notifications via quarantine networks",
        "RDAP Client",
        "Didn't you hear me?-towards more successful web vulnerability notifications",
        "Hey, you have a problem: On the feasibility of large-scale web vulnerability notification",
        "Understanding the role of sender reputation in abuse reporting and cleanup",
        "Make notifications great again: learning how to notify in the age of large-scale vulnerability scanning",
        "Libertarian paternalism",
        "Nudge improving decisions about health, wealth and happiness",
        "Nudging: a very short guide",
        "Nudge me right: Personalizing online security nudges to people's decision-making styles",
        "A promise is a promise: The effect of commitment devices on computer security intentions",
        "Nudges for privacy and security: Understanding and assisting users' choices online",
        "Social nudges: their mechanisms and justification",
        "Do the effects of social nudges persist? theory and evidence from 38 natural field experiments",
        "Crimes of obedience: Toward a social psychology of authority and responsibility",
        "The psychology of persuasion",
        "The science of persuasion",
        "A theory of reciprocity",
        "The norm of reciprocity: A preliminary statement",
        "Trust, reciprocity, and social history",
        "Fairness and retaliation: The economics of reciprocity",
        "Evolution of indirect reciprocity",
        "Social status and group norms: Indirect reciprocity in a repeated helping experiment",
        "Spoofing ASNs",
        "None",
        "PeeringDB",
        "Incident Response and S. Teams",
        "Going Wild: Large-Scale Classification of Open DNS Resolvers",
        "Using peeringdb to understand the peering ecosystem",
        "Looking for hypergiants in peeringdb",
        "The framing of decisions: A new look at old problems",
        "Positive versus negative framing of a hypothetical infant immunization: the influence of involvement",
        "Health warnings promote healthier dietary decision making: Effects of positive versus negative message framing and graphic versus text-based warnings",
        "A note on stratifying versus complete random assignment in clinical trials",
        "Ethics and internet measurements",
        "The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research",
        "Understanding Relative Risk, Odds Ratio and Related Terms",
        "Manrs for network operators",
        "University of Oregon Route Views Project",
        "None",
        "Macroscopic Internet Topology Data Kit (ITDK)",
        "Internet-scale ipv4 alias resolution with midar",
        "Pushing the boundaries with bdrmapit: Mapping router ownership at internet scale",
        "AS relationships: Inference and Validation",
        "MANRS Implementation Guide",
        "RIPE 81",
        "None",
        "NANOG75",
        "Compton Ebgp Flowspec Peering v1",
        "Do malware reports expedite cleanup? an experimental study",
        "Measuring the impact of sharing abuse data with web hosting providers",
        "Feasibility of large-scale vulnerability notifications after gdpr",
        "Fixing https misconfigurations at scale: An experiment with security notifications",
        "RIPE IP Anti-Spoofing Task Force",
        "NANOG75",
        "BGP hijacker booted off the Internet's backbone",
        "To coerce or not to coerce? a quantitative investigation on cybersecurity and cybercrime legislations towards large-scale vulnerability notifications",
        "not sure Q2: How did you discover the issue with IP spoofing? Choose all that apply. 1) I ran a Spoofer test 2) I received a notification from NOG",
        "I received a notification from CERT (Computer Emergency Response Team)",
        "I received a notification from security researchers 5) Other (please specify) Q3: Are you the person responsible for the implementation of Source Address Validation (SAV)",
        "I don't know what SAV means Q4: Have you escalated the issue with IP spoofing to the person/team responsible for SAV implementation? 1) Yes",
        "Have you implemented SAV in your network? 1) Yes, on the entire network 2) Yes, but only in the segment of our network 3) No, we haven't implemented SAV in our network at all 4) I'm not sure Q6: What kind of filtering of origin IPs do you perform? Choose all that apply. 1) Filter private address space",
        "Perform SAV on customer facing interfaces 3) Perform SAV on stub AS 4) Other (please specify) Q7: Why didn't you implement SAV in your network? Choose all that apply",
        "I lack technical knowledge to implement SAV 2) I am concerned that SAV implementation may cause network downtime/performance",
        "I don't think SAV is effective in addressing IP spoofing issues",
        "Other (please specify) Q8: Are you planning to implement SAV in your network? 1) Yes",
        "Q10:What information, necessary for implementing SAV, is missing in MANRS guidelines? Please, provide as much details as you can"
    ],
    "63034ea190e50fcafd73e0b0": [
        "Music Outdoors Arts Toy 5-way 10-way 5-way 10-way 5-way 10-way 5-way 10-way 3-shot node2vec",
        "None",
        "None",
        "None",
        "Metagraph: Few shot link prediction via meta learning",
        "Graph prototypical networks for few-shot learning on attributed networks",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "Metanorm: Learning to normalize few-shot batches across domains",
        "Model-agnostic metalearning for fast adaptation of deep networks",
        "Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning",
        "node2vec: Scalable feature learning for networks",
        "Few-Shot Graph Learning for Molecular Property Prediction",
        "Inductive representation learning on large graphs",
        "Graph Meta Learning via Local Subgraphs",
        "Self-supervised Learning on Graphs: Deep Insights and New Direction",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Learning to generalize: Meta-learning for domain generalization",
        "Feature-critic networks for heterogeneous domain generalization",
        "Meta-sgd: Learning to learn quickly for few-shot learning",
        "Learning to propagate for graph meta-learning",
        "Self-supervised learning: Generative or contrastive",
        "Relative and absolute location embedding for few-shot node classification on graph",
        "Are we really making much progress? Revisiting, benchmarking and refining heterogeneous graph neural networks",
        "Inferring networks of substitutable and complementary products",
        "Modeling relational data with graph convolutional networks",
        "Generalizing across domains via cross-gradient training",
        "Adversarial deep network embedding for cross-network node classification",
        "Network together: Node classification via cross-network deep network embedding",
        "A survey of heterogeneous information network analysis",
        "Prototypical networks for few-shot learning",
        "Pathsim: Meta path-based top-k similarity search in heterogeneous information networks",
        "Aminer: Toward understanding big scholar data",
        "Transfer learning to infer social ties across heterogeneous networks",
        "Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation",
        "Generalizing to Unseen Domains: A Survey on Domain Generalization",
        "Graph Few-shot Learning with Attribute Matching",
        "Heterogeneous graph attention network",
        "Simplifying graph convolutional networks",
        "One-Shot Relational Learning for Knowledge Graphs",
        "Domain Adaptive Classification on Heterogeneous Information Networks",
        "Domain adaptive classification on heterogeneous information networks",
        "Graph few-shot learning via knowledge transfer",
        "Few-Shot Learning on Graphs",
        "Heterogeneous graph neural network",
        "Few-shot knowledge graph completion",
        "HG-Meta: Graph Meta-learning over Heterogeneous Graphs",
        "DANE: domain adaptive network embedding",
        "Meta-gnn: On few-shot node classification in graph meta-learning"
    ],
    "62c2a9595aee126c0fcf0a32": [
        "Mixhop: Higher-order Graph Convolutional Architectures via Sparsified Neighborhood Mixing",
        "Relational Inductive Biases, Deep Learning, and Graph Networks",
        "Understanding Structural Vulnerability in Graph Convolutional Networks",
        "A Simple Framework for Contrastive Learning of Visual Representations",
        "Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings",
        "Adaptive Universal Generalized Pagerank Graph Neural Network",
        "Adversarial Attack on Graph Structured Data",
        "All You Need is Low (rank) Defending Against Adversarial Attacks on Graphs",
        "SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks",
        "Single-Node Attack for Fooling Graph Neural Networks",
        "Exploring Structure-adaptive Graph Learning for Robust Semi-supervised Classification",
        "Learning Graph Representations With Embedding Propagation",
        "Reliable Graph Neural Networks via Robust Aggregation",
        "Inductive Representation Learning on Large Graphs",
        "Contrastive Multi-view Representation Learning on Graphs",
        "Learning Deep Representations by Mutual Information Estimation and Maximization",
        "Measuring and Improving The Use of Graph Information in Graph Neural Networks",
        "AUC-oriented Graph Neural Network for Fraud Detection",
        "Scaling Personalized Web Search",
        "Node Similarity Preserving Graph Convolutional Networks",
        "Adversarial Attacks and Defenses on Graphs: A Review, A Tool and Empirical Studies",
        "Graph Structure Learning for Robust Graph Neural Networks",
        "Variational Graph Auto-Encoders",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Adaptive Graph Convolutional Neural Networks",
        "Deeprobust: A Pytorch Library for Adversarial Attacks and Defenses",
        "Gated Graph Sequence Neural Networks",
        "Elastic Graph Neural Networks",
        "Pick and Choose: A GNN-based Imbalanced Learning Approach for Fraud Detection",
        "Learning to Drop: Robust Graph Neural Network via Topological Denoising",
        "Birds of a Feather: Homophily in Social Networks",
        "Graph Representation Learning via Graphical Mutual Information Maximization",
        "Deepwalk: Online Learning of Social Representations",
        "Infograph: Unsupervised and Semi-supervised Graph-level Representation Learning via Mutual Information maximization",
        "Graph Attention Networks",
        "Deep Graph Infomax",
        "Am-gcn: Adaptive Multi-channel Graph Convolutional Networks",
        "Hiding Individuals and Communities in A Social Network",
        "Taylan Cemgil, et al. 2022. A Fine-grained Analysis on Distribution Shift",
        "Adversarial Examples on Graph Data: Deep Insights Into Attack and Defense",
        "Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective",
        "How Powerful Are Graph Neural Networks?",
        "Graph Contrastive Learning With Augmentations",
        "Graph-revised Convolutional Network",
        "GNNGuard: Defending Graph Neural Networks Against Adversarial Attacks",
        "Deep learning on graphs: A survey",
        "Data Augmentation for Graph Neural Networks",
        "Graph Neural Networks: A Review of Methods and Applications",
        "Robust Graph Convolutional Networks Against Adversarial Attacks",
        "Qing He, and Jianping Li. 2021. Intelligent financial fraud detection practices in post-pandemic era",
        "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection",
        "Deep Graph Structure Learning for Robust Representations: A Survey",
        "Deep Graph Contrastive Representation Learning",
        "Adversarial Attacks on Neural Networks for Graph Data",
        "Adversarial Attacks on Graph Neural Networks via Meta Learning"
    ],
    "62f07ec290e50fcafde5ad10": [
        "Autoregressive search engines: Generating substrings as document identifiers",
        "Improving language models by retrieving from trillions of tokens",
        "Language models are few-shot learners",
        "Autoregressive entity retrieval",
        "Extracting training data from large language models",
        "Reading Wikipedia to answer open-domain questions",
        "Scaling language modeling with pathways",
        "Simple and effective multi-paragraph reading comprehension",
        "Think you have solved question answering? try arc, the ai2 reasoning challenge",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Time-aware language models as temporal knowledge bases",
        "Wizard of wikipedia: Knowledge-powered conversational agents",
        "Documenting large webtext corpora: A case study on the colossal clean crawled corpus",
        "A large scale alignment of natural language with knowledge base triples",
        "R2-D2: A modular baseline for open-domain question answering",
        "Object classification from a single example utilizing class relevance metrics",
        "Making pre-trained language models better few-shot learners",
        "Md Faisal Mahbub Chowdhury, Ankita Rajaram Naik, Pengshan Cai, and Alfio Gliozzo. Re2g: Retrieve, rerank, generate",
        "Unbounded cache model for online language modeling with open vocabulary",
        "Improving neural language models with a continuous cache",
        "Realm: Retrieval-augmented language model pre-training",
        "Momentum contrast for unsupervised visual representation learning",
        "Measuring massive multitask language understanding",
        "Robust disambiguation of named entities in text",
        "Training compute-optimal large language models",
        "Multi-task retrieval-augmented text generation with relevance sampling",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Distilling knowledge from reader to retriever for question answering",
        "Unsupervised dense information retrieval with contrastive learning",
        "How can we know what language models know?",
        "A statistical interpretation of term specificity and its application in retrieval",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "Scaling laws for neural language models",
        "Dense passage retrieval for open-domain question answering",
        "Generalization through memorization: Nearest neighbor language models",
        "UNIFIEDQA: Crossing format boundaries with a single QA system",
        "Proofver: Natural logic theorem proving for fact verification",
        "Natural questions: A benchmark for question answering research",
        "RACE: Large-scale ReAding comprehension dataset from examinations",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "How many data points is a prompt worth?",
        "You only need one model for open-domain question answering",
        "Latent retrieval for weakly supervised open domain question answering",
        "The power of scale for parameter-efficient prompt tuning",
        "Zero-shot relation extraction via reading comprehension",
        "Retrieval-augmented generation for knowledgeintensive nlp tasks",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Jurassic-1: Technical details and evaluation",
        "Cutting down on prompts and parameters: Simple few-shot learning with language models",
        "Can a suit of armor conduct electricity? a new dataset for open book question answering",
        "Ambigqa: Answering ambiguous open-domain questions",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Hindsight: Posterior-guided training of retrievers for improved open-ended generation",
        "How context affects language models' factual predictions",
        "Improving wikipedia verifiability with ai",
        "The web is your oysterknowledge-intensive nlp against a very large web corpus",
        "Language models are unsupervised multitask learners",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Learning to retrieve passages without supervision",
        "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
        "Okapi at TREC-3. NIST Special Publication Sp",
        "End-to-end training of multi-document reader and retriever for open-domain question answering",
        "It's not just size that matters: Small language models are also few-shot learners",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Few-shot text generation with natural language instructions",
        "Learning semantic representations using convolutional neural networks for web search",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "Retrieval augmentation reduces hallucination in conversation",
        "Language models that seek for knowledge: Modular search &amp; generation for dialogue and prompt completion",
        "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
        "Improving and simplifying pattern exploiting training",
        "Language models for dialog applications",
        "Fever: a large-scale dataset for fact extraction and verification",
        "Learning to Learn: Introduction and Overview",
        "Matching networks for one shot learning",
        "The TREC-8 question answering track report",
        "Multi-passage BERT: A globally normalized BERT model for open-domain question answering",
        "Emergent abilities of large language models",
        "CCNet: Extracting high quality monolingual datasets from web crawl data",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
        "Pretrained Transformers for Text Ranking: BERT and Beyond",
        "Learning Discriminative Projections for Text Similarity Measures",
        "Adaptive semiparametric language models"
    ],
    "628464625aee126c0faca44e": [
        "Tensor factorization for knowledge graph completion",
        "Translating embeddings for modeling multi-relational data",
        "LibKGE -a knowledge graph embedding library for reproducible research",
        "A standard database for drug repositioning",
        "Building a knowledge graph to enable precision medicine",
        "Efficient cost-aware cascade ranking in multi-stage retrieval",
        "Inductive entity representations from text via link prediction",
        "Convolutional 2d knowledge graph embeddings",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Predicting completeness knowledge bases",
        "An open challenge for inductive link prediction on knowledge graphs",
        "Joint optimization of cascade ranking models",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring",
        "A survey on knowledge graphs: Representation, acquisition and applications",
        "Dense passage retrieval for open-domain question answering",
        "Efficient and effective passage search via contextualized late interaction over bert",
        "Multi-task learning for knowledge graph completion with pre-trained language models",
        "URL",
        "Knowledge base completion meets transfer learning",
        "Quantile regression",
        "Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy",
        "Pretrained transformers for text ranking: Bert and beyond",
        "dense, and attentional representations for text retrieval",
        "Reranking for efficient transformerbased answer selection",
        "Scientific language models for biomedical knowledge base completion: An empirical study",
        "A three-way model for collective learning on multi-relational data",
        "A review of relational machine learning for knowledge graphs",
        "Multi-stage document ranking with bert",
        "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
        "You can teach an old dog new tricks! on training knowledge graph embeddings",
        "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "Observed versus latent features for knowledge base and text inference",
        "Representing text for joint embedding of text and knowledge bases",
        "Compositional learning of embeddings for relation paths in knowledge base and text",
        "Complex embeddings for simple link prediction",
        "Attention is all you need",
        "Rapid object detection using a boosted cascade of simple features",
        "Structure-augmented text representation learning for efficient knowledge graph completion",
        "A cascade ranking model for efficient ranked retrieval",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Wisdom of committees: An overlooked approach to faster and more accurate models",
        "Machine knowledge: Creation and curation of comprehensive knowledge bases",
        "Transformers: State-of-theart natural language processing",
        "Representation learning of knowledge graphs with entity descriptions",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Kg-bert: Bert for knowledge graph completion",
        "Neural bellman-ford networks: A general graph neural network framework for link prediction"
    ],
    "6303545e90e50fcafd7d3b71": [
        "JKNet",
        "None",
        "None",
        "Simple and deep graph convolutional networks",
        "Adaptive Universal Generalized PageRank Graph Neural Network",
        "Principal Neighbourhood Aggregation for Graph Nets",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Graph Neural Architecture Search",
        "Neural message passing for quantum chemistry",
        "AutoAttend: Automated Attention Representation Search",
        "Inductive Representation Learning on Large Graphs",
        "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein Approximation",
        "Long short-term memory",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs. Neural Information Processing Systems (NeurIPS)",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Policy-GNN: Aggregation Optimization for Graph Neural Networks",
        "Predicting positive and negative links in online social networks",
        "Graphs over time: densification laws, shrinking diameters and possible explanations",
        "Geometry-Aware Gradient Algorithms for Neural Architecture Search",
        "One-shot Graph Neural Architecture Search with Dynamic Search Space",
        "DARTS: Differentiable Architecture Search",
        "Geniepath: Graph neural networks with adaptive receptive paths",
        "Is Homophily a Necessity for Graph Neural Networks",
        "Geom-GCN: Geometric Graph Convolutional Networks",
        "DropEdge: Towards Deep Graph Convolutional Networks on Node Classification",
        "Breaking the Limit of Graph Neural Networks by Improving the Assortativity of Graphs with Local Mixing Patterns",
        "Policy gradient methods for reinforcement learning with function approximation",
        "Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous GNNs",
        "Graph attention networks",
        "AutoGEL: An Automated Graph Neural Network with Explicit Link Information",
        "A Comprehensive Survey on Graph Neural Networks",
        "When Do GNNs Work: Understanding and Improving Neighborhood Aggregation",
        "How Powerful are Graph Neural Networks",
        "Representation Learning on Graphs with Jumping Knowledge Networks",
        "GNNExplainer: Generating Explanations for Graph Neural Networks",
        "Design space for graph neural networks",
        "Automated Machine Learning on Graphs: A Survey",
        "Search to aggregate neighborhood for graph neural network",
        "Auto-gnn: Neural architecture search of graph neural networks",
        "Predicting multicellular function through multi-layer tissue networks"
    ],
    "62d16f8d5aee126c0fd82ddd": [
        "Clang c language family frontend for llvm",
        "Github akopytov/sysbench: Scriptable database and system performance benchmark",
        "Github -antirez/mc-benchmark: Memcache port of redis benchmark",
        "Github -benchmarking tools: facebook/rocksdb wiki",
        "Optimizing linux kernel with bolt",
        "Memory hierarchy for web search",
        "Asmdb: understanding and mitigating front-end stalls in warehouse-scale computers",
        "System-wide compaction and specialization of the linux kernel",
        "Autofdo: Automatic feedback-directed optimization for warehouse-scale applications",
        "Clearing the clouds: a study of emerging scale-out workloads on modern hardware",
        "Propeller: Profile guided optimizing large scale llvm-based relinker",
        "Profile inference revisited",
        "Profiling a warehouse-scale computer",
        "Ripple: Profile-guided instruction cache replacement for data center applications",
        "Codestitcher: inter-procedural basic block layout optimization",
        "An application-oriented linux kernel customization for embedded systems",
        "Lightweight feedback-directed cross-module optimization",
        "Ispike: a post-link optimizer for the intel/spl reg/itanium/spl reg/architecture",
        "Vespa: static profiling for binary optimization",
        "Hhvm jit: A profile-guided, regionbased compiler for php and hack",
        "Hhvm jump-start: Boosting both warmup and steady-state performance at scale",
        "Optimizing function placement for large-scale data-center applications",
        "Bolt: a practical binary optimizer for data centers and beyond",
        "Lightning bolt: powerful, fast, and scalable binary optimization",
        "Profile-guided specialization of an operating system kernel",
        "Profile guided code positioning",
        "Binary rewriting of an operating system kernel",
        "Softsku: Optimizing server architectures for microservice diversity@ scale",
        "Predicting program behavior using real or estimated profiles",
        "Apachebench -Wikipedia, the free encyclopedia",
        "Leveldb -Wikipedia, the free encyclopedia",
        "(Linux)&amp;oldid= 1035926020",
        "Apache http server -Wikipedia, the free encyclopedia",
        "Gcov -Wikipedia, the free encyclopedia",
        "Wikipedia contributors. Memcached -Wikipedia, the free encyclopedia",
        "Wikipedia contributors. Mysql -Wikipedia, the free encyclopedia",
        "Nginx -Wikipedia, the free encyclopedia",
        "Wikipedia contributors. Postgresql -Wikipedia, the free encyclopedia",
        "Redis -Wikipedia, the free encyclopedia",
        "Rocksdb -Wikipedia, the free encyclopedia",
        "Experiences in profile-guided operating system kernel optimization",
        "Rethinking compiler optimizations for the linux kernel: An explorative study",
        "Building application-specific operating systems: a profile-guided approach",
        "Profmig: A framework for flexible migration of program profiles across software versions",
        "On the impact of instruction address translation overhead"
    ],
    "62393e7f5aee126c0f12607f": [
        "Matching the blanks: Distributional similarity for relation learning",
        "HacRED: A largescale relation extraction dataset toward hard cases in practical applications",
        "Unsupervised cross-lingual representation learning at scale",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Reinforcement learning for relation classification from noisy data",
        "Mrn: A locally and globally mention-based reasoning network for documentlevel relation extraction",
        "Focal loss for dense object detection",
        "Roberta: A robustly optimized bert pretraining approach",
        "Decoupled weight decay regularization",
        "Reasoning with latent structure refinement for document-level relation extraction",
        "Learning from context or names? An empirical study on neural relation extraction",
        "Cross-sentence n-ary relation extraction with graph lstms",
        "DSGAN: Generative adversarial training for distant supervision relation extraction",
        "Distant supervision for relation extraction beyond the sentence boundary",
        "The graph neural network model",
        "HIN: hierarchical inference network for documentlevel relation extraction",
        "Attention is all you need",
        "Simultaneously self-attending to all mentions for full-abstract biological relation extraction",
        "Wikidata: a free collaborative knowledgebase",
        "Fine-tune BERT for DocRED with two-step process",
        "Axial-deeplab: Stand-alone axial-attention for panoptic segmentation",
        "Transformers: State-of-theart natural language processing",
        "Entity structure within and throughout: Modeling mention dependencies for document-level relation extraction",
        "DocRED: a large-scale document-level relation extraction dataset",
        "Coreferential reasoning learning for language representation",
        "SIRE: Separate intra-and inter-sentential reasoning for document-level relation extraction",
        "Double graph based reasoning for documentlevel relation extraction",
        "Document-level relation extraction as semantic segmentation",
        "Graph convolution over pruned dependency trees improves relation extraction",
        "Positionaware attention and supervised data improve slot filling",
        "Document-level relation extraction with adaptive thresholding and localized context pooling"
    ],
    "6293c3025d72d8000db42919": [
        "Inter MKL-DNN",
        "NVIDIA, CUBLAS Library",
        "Tensorflow: A system for large-scale machine learning",
        "Best of both worlds: Automl co-design of a cnn and its hardware accelerator",
        "Neuromorphic computing across the stack: Devices, circuits and architectures",
        "A pipelined and scalable dataflow implementation of convolutional neural networks on FPGA",
        "Understanding and simplifying one-shot architecture search",
        "Once-for-all: Train one network and specialize it for efficient deployment",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems",
        "{TVM}: An automated end-to-end optimizing compiler for deep learning",
        "Learning to Optimize Tensor Programs",
        "You only search once: A fast automation framework for single-stage DNN/Accelerator co-design",
        "Using dataflow to optimize energy efficiency of deep neural network accelerators",
        "Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices",
        "Efficient primitives for deep learning",
        "Intel ngraph: An intermediate representation, compiler, and executor for deep learning",
        "Energy-aware task mapping and scheduling for reliable embedded computing systems",
        "Reliability and energy-aware mapping and scheduling of multimedia applications on multiprocessor systems",
        "CoCoPIE: Enabling real-time AI on off-the-shelf mobile devices via compression-compilation co-design",
        "Accelerator-aware neural network design using AutoML",
        "FPGA/DNN co-design: An efficient design methodology for IoT intelligence on the edge",
        "Searching for mobilenetv3",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 0.5 MB model size",
        "Caffe: Convolutional architecture for fast feature embedding",
        "Accuracy vs. efficiency: Achieving both through FPGA-implementation aware neural architecture search",
        "Understanding reuse, performance, and hardware cost of dnn dataflow: A data-centric approach",
        "Co-design of deep neural nets and neural net accelerators for embedded vision applications",
        "Edd: Efficient differentiable dnn architecture and implementation co-search for embedded ai solutions",
        "Mcunet: Tiny deep learning on iot devices",
        "Darts: Differentiable architecture search",
        "On neural architecture search for resourceconstrained hardware platforms",
        "Pconv: The missing but desirable sparsity in dnn weight pruning for real-time execution on mobile devices",
        "Optimizing loop operation and dataflow in FPGA acceleration of deep convolutional neural networks",
        "Hardware-aware machine learning: Modeling and optimization",
        "Polymage: Automatic optimization for image processing pipelines",
        "Patdnn: Achieving real-time dnn execution on mobile devices with pattern-based weight pruning",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Efficient neural architecture search via parameters sharing",
        "Designing network design spaces",
        "Halide: A language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Mnasnet: Platform-aware neural architecture search for mobile",
        "Tensor comprehensions: Framework-agnostic highperformance machine learning abstractions",
        "SWIRL: High-performance manycore CPU code generation for deep neural networks",
        "DeepBurning: Automatic generation of FPGA-based learning accelerators for the neural network family",
        "Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search",
        "Exploring heterogeneous algorithms for accelerating deep convolutional neural networks on FPGAs",
        "Latency-aware differentiable neural architecture search",
        "Co-exploration of neural architectures and heterogeneous asic accelerator designs targeting multiple tasks",
        "Synetgy: Algorithm-hardware co-design for ConvNet accelerators on embedded FPGAs",
        "DeepBurning: Automatic generation of FPGA-based learning accelerators for the neural network family",
        "Shufflenet: An extremely efficient convolutional neural network for mobile devices",
        "Ansor: Generating high-performance tensor programs for deep learning",
        "Flextensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "BayesNAS: A Bayesian approach for neural architecture search",
        "Rethinking co-design of neural architectures and hardware accelerators",
        "Neural architecture search with reinforcement learning"
    ],
    "62de84a55aee126c0f96fbb9": [
        "Learning representations by maximizing mutual information across views",
        "Graph convolutional matrix completion",
        "Kernel density estimation via diffusion",
        "Bias and debias in recommender system: A survey and future directions",
        "A simple framework for contrastive learning of visual representations",
        "Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions",
        "SimCSE: Simple Contrastive Learning of Sentence Embeddings",
        "Explaining and harnessing adversarial examples",
        "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",
        "MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems",
        "A survey on contrastive self-supervised learning",
        "Supervised Contrastive Learning",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Bootstrapping User and Item Representations for One-Class Collaborative Filtering",
        "Variational autoencoders for collaborative filtering",
        "Self-supervised learning: Generative or contrastive",
        "Disentangled Self-Supervision in Sequential Recommenders",
        "Representation learning with contrastive predictive coding",
        "Memory Augmented Multi-Instance Contrastive Predictive Coding for Sequential Recommendation",
        "Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation",
        "BPR: Bayesian personalized ranking from implicit feedback",
        "Sparsity, scalability, and distribution in recommender systems",
        "Visualizing data using t-SNE",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Neural graph collaborative filtering",
        "Contrastive learning for cold-start recommendation",
        "Simplifying graph convolutional networks",
        "Self-supervised graph learning for recommendation",
        "Graph Neural Networks in Recommender Systems: A Survey",
        "A comprehensive survey on graph neural networks",
        "Self-Supervised Graph Co-Training for Session-based Recommendation",
        "Self-Supervised Hypergraph Convolutional Networks for Sessionbased Recommendation",
        "Bolin Ding, and Bin Cui",
        "Self-supervised Learning for Large-scale Item Recommendations",
        "Graph Contrastive Learning with Augmentations",
        "Adaptive Implicit Friends Identification over Heterogeneous Network for Social Recommendation",
        "Generating reliable friends via adversarial training to improve social recommendation",
        "Socially-Aware Self-Supervised Tri-Training for Recommendation",
        "Enhance Social Recommendation with Adversarial Graph Convolutional Networks",
        "Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation",
        "Self-Supervised Learning for Recommender Systems: A Survey",
        "Graph convolutional network for recommendation with low-pass collaborative filters",
        "Double-Scale Self-Supervised Hypergraph Learning for Group Recommendation",
        "Contrastive learning for debiased candidate generation in large-scale recommender systems",
        "Sˆ3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization",
        "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering"
    ],
    "63180bf590e50fcafded784e": [
        "A survey on contrastive self-supervised learning",
        "Self-supervised learning: Generative or contrastive",
        "Self-supervised learning for recommender systems: A survey",
        "Graph contrastive learning with augmentations",
        "A simple framework for contrastive learning of visual representations",
        "Simcse: Simple contrastive learning of sentence embeddings",
        "Momentum contrast for unsupervised visual representation learning",
        "Bootstrap your own latent: A new approach to selfsupervised learning",
        "Scalability and sparsity issues in recommender datasets: a survey",
        "Retaining data from streams of social platforms with minimal regret",
        "Sequence-aware factorization machines for temporal predictive analytics",
        "Selfsupervised graph learning for recommendation",
        "Selfsupervised multi-channel hypergraph convolutional network for social recommendation",
        "Selfsupervised hypergraph convolutional networks for session-based recommendation",
        "S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization",
        "Contrastive learning for debiased candidate generation in large-scale recommender systems",
        "Socially-aware self-supervised tri-training for recommendation",
        "Improving graph collaborative filtering with neighborhood-enriched contrastive learning",
        "Learning representations by maximizing mutual information across views",
        "Selfcf: A simple framework for self-supervised collaborative filtering",
        "Bootstrapping user and item representations for one-class collaborative filtering",
        "Representation learning with contrastive predictive coding",
        "Bias and debias in recommender system: A survey and future directions",
        "Are graph augmentations necessary? simple graph contrastive learning for recommendation",
        "Contrastive learning for sequential recommendation",
        "Double-scale self-supervised hypergraph learning for group recommendation",
        "Self-supervised learning for large-scale item recommendations",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Bpr: Bayesian personalized ranking from implicit feedback",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Visualizing data using t-sne",
        "Kernel density estimation via diffusion",
        "Challenging the long tail recommendation",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Explaining and harnessing adversarial examples",
        "Learning spreadout local feature descriptors",
        "What makes for good views for contrastive learning?",
        "Mixgcf: An improved training method for graph neural network-based recommender systems",
        "Disentangled graph collaborative filtering",
        "Graph neural networks for recommender system",
        "Graph neural networks in recommender systems: a survey",
        "Enhance social recommendation with adversarial graph convolutional networks",
        "Session-based recommendation with graph neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "Neural graph collaborative filtering",
        "Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach",
        "Graph convolutional network for recommendation with low-pass collaborative filters",
        "Simplifying graph convolutional networks",
        "Adaptive implicit friends identification over heterogeneous network for social recommendation",
        "Disentangled self-supervision in sequential recommenders",
        "Contrastive learning for cold-start recommendation",
        "Attention is all you need",
        "Contrastive learning for representation degeneration problem in sequential recommendation",
        "Social recommendation with self-supervised metagraph informax network",
        "Contrastive cross-domain recommendation in matching",
        "Crosscbr: Crossview contrastive learning for bundle recommendation",
        "Self-supervised graph co-training for session-based recommendation",
        "Currently, he is a final-year Ph.D. candidate at the School of Information Technology and Electrical Engineering, the University of Queensland. His research interests include recommender systems, social media analytics, and self-supervised learning"
    ],
    "628c4ce25aee126c0ff59b39": [
        "The surprising power of graph neural networks with random node initialization",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Graph neural networks with convolutional ARMA filters",
        "Fast learning with graph convolutional networks via importance sampling",
        "On graph neural networks versus graph-augmented mlps",
        "Scalable graph neural networks via bidirectional propagation",
        "On the equivalence between graph isomorphism testing and function approximation with gnns",
        "Can graph neural networks count substructures?",
        "Adaptive universal generalized pagerank graph neural network",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "The rank of a random matrix",
        "Protein interface prediction using graph convolutional networks",
        "Generalization and representational limits of graph neural networks",
        "Bernnet: Learning arbitrary graph spectral filters via bernstein approximation",
        "Universal invariant and equivariant graph neural networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Diffusion improves graph learning",
        "Distance encoding: Design provably more powerful neural networks for graph representation learning",
        "What graph neural networks cannot learn: depth vs width",
        "Polynomial least squares fitting in the bernstein basis",
        "Provably powerful graph networks",
        "On the universality of invariant networks",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Numerical Optimization",
        "The pagerank citation ranking: Bringing order to the web",
        "Geom-gcn: Geometric graph convolutional networks",
        "Multi-scale attributed node embedding",
        "Approximation ratios of graph neural networks for combinatorial problems",
        "Random features strengthen graph neural networks",
        "Pitfalls of graph neural network evaluation",
        "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains",
        "The reduction of a graph to canonical form and the algebra which appears therein",
        "Simplifying graph convolutional networks",
        "A comprehensive survey on graph neural networks",
        "How powerful are graph neural networks?",
        "Optimization of graph neural networks: Implicit acceleration by skip connections and more depth",
        "Revisiting semi-supervised learning with graph embeddings",
        "Graph convolutional networks for text classification",
        "Position-aware graph neural networks",
        "Link prediction based on graph neural networks",
        "Interpreting and unifying graph neural networks with an optimization framework"
    ],
    "62c28ae45aee126c0f8a182f": [
        "Diffusion-convolutional neural networks",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Directional graph networks",
        "Beyond lowfrequency information in graph convolutional networks",
        "Improving graph neural network expressivity via subgraph isomorphism counting",
        "Residual gated graph convnets",
        "Graph convolutions that can finally model local structure",
        "Graphnorm: A principled approach to accelerating graph neural network training",
        "Adaptive universal generalized pagerank graph neural network",
        "Principal neighbourhood aggregation for graph nets",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Benchmarking graph neural networks",
        "Message passing in graph convolution networks via adaptive filter banks",
        "Neural message passing for quantum chemistry",
        "Inductive representation learning on large graphs",
        "Wavelets on graphs via spectral graph theory",
        "Learning arbitrary graph spectral filters via bernstein approximation",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Tackling over-smoothing for general graph convolutional networks",
        "Anonymous walk embeddings",
        "Towards feature overcorrelation in deeper graph neural networks",
        "Benchmark data sets for graph kernels",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Diffusion improves graph learning",
        "Rethinking graph transformers with spectral attention",
        "Graph convolutional neural networks with complex rational spectral filters",
        "Deepergcn: All you need to train deeper gcns",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Towards deeper graph neural networks",
        "Simple and deep graph convolutional networks",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "When spectral domain meets spatial domain in graph neural networks",
        "Janossy pooling: Learning deep permutation-invariant functions for variable-size inputs",
        "Propagation kernels: efficient graph kernels from propagated information",
        "Learning convolutional neural networks for graphs",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Graph neural networks exponentially lose expressive power for node classification",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Efficient graphlet kernels for large graph comparison",
        "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains",
        "Dynamic edgeconditioned filters in convolutional neural networks on graphs",
        "Spectral graph theory and its applications",
        "Graph Attention Networks. International Conference on Learning Representations",
        "Hunt for the unique, stable, sparse and fast feature learning on graphs",
        "Graph kernels",
        "Simplifying graph convolutional networks",
        "Capsule graph neural network",
        "Representation learning on graphs with jumping knowledge networks",
        "How powerful are graph neural networks?",
        "Deep graph kernels",
        "Do transformers really perform bad for graph representation?",
        "Hierarchical graph representation learning with differentiable pooling",
        "An end-toend deep learning architecture for graph classification",
        "Lite geometry enhanced molecular representation learning for quantum property prediction",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Simple spectral graph convolution",
        "Interpreting and unifying graph neural networks with an optimization framework"
    ],
    "62d0db155aee126c0f9f111a": [
        "Modeling of the question answering task in the yodaqa system",
        "Semantic parsing on freebase from question-answer pairs",
        "Bridging the lexical chasm: statistical approaches to answer-finding",
        "SIGIR 2000: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "Language models are few-shot learners",
        "Reading wikipedia to answer opendomain questions",
        "Out-of-domain semantics to the rescue! zero-shot hybrid retrieval models",
        "European Conference on Information Retrieval",
        "SPECTER: document-level representation learning using citation-informed transformers",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Retrieve fast, rerank smart: Cooperative and joint approaches for improved cross-modal retrieval",
        "On calibration of modern neural networks",
        "Retrieval augmented language model pre-training",
        "Pre-trained models: Past, present and future",
        "Efficiently teaching an effective dense retriever with balanced topic aware sampling",
        "Parameter-efficient transfer learning for NLP",
        "Lora: Low-rank adaptation of large language models",
        "Towards unsupervised dense information retrieval with contrastive learning",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "Dense passage retrieval for open-domain question answering",
        "Colbert: Efficient and effective passage search via contextualized late interaction over BERT",
        "Natural questions: a benchmark for question answering research",
        "The power of scale for parameter-efficient prompt tuning",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Parameter-efficient neural reranking for cross-lingual and multilingual retrieval",
        "2021a. Generalizing discriminative retrieval models using generative tasks",
        "Challenges in generalization in open domain question answering",
        "P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks",
        "None",
        "Roberta: A robustly optimized bert pretraining approach",
        "Obtaining well calibrated probabilities using bayesian binning",
        "MS MARCO: A human generated machine reading comprehension dataset",
        "Large dual encoders are generalizable retrievers",
        "From doc2query to doctttttquery",
        "On the calibration and uncertainty of neural learning to rank models for conversational search",
        "KILT: a benchmark for knowledge intensive language tasks",
        "Adapterhub: A framework for adapting transformers",
        "Squad: 100, 000+ questions for machine comprehension of text",
        "Colbertv2: Effective and efficient retrieval via lightweight late interaction",
        "Arnetminer: extraction and mining of academic social networks",
        "BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models",
        "Fever: a large-scale dataset for fact extraction and verification",
        "Attention is all you need",
        "None",
        "Trec-covid: constructing a pandemic information retrieval test collection",
        "Fact or fiction: Verifying scientific claims",
        "On calibration and out-of-domain generalization. Advances in neural information processing systems",
        "Microsoft academic graph: When experts are not enough",
        "Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "A unified pretraining framework for passage ranking and expansion",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "OAG: toward linking large-scale heterogeneous entity graphs"
    ],
    "628749345aee126c0ffeb827": [
        "Modeling Frames in Argumentation",
        "Toward audience-aware argument generation",
        "Valuebased argumentation",
        "On flat versus hierarchical classification in large-scale taxonomies",
        "From arguments to key points: Towards automatic argument summarization",
        "Persuasion in practical argument using value-based argumentation frameworks",
        "Audiences and argument strength",
        "Life values inventory facilitator's guide",
        "Seeing things from a different angle:discovering diverse perspectives about claims",
        "Controlled neural sentencelevel reframing of news articles",
        "Developing a meta-inventory of human values",
        "News framing: Theory and typology. Information design journal &amp; document design",
        "On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games",
        "Summarising the points made in online political debates",
        "Personal value systems of american managers",
        "Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory",
        "Personal values and moral foundations: Examining relations and joint prediction of moral variables. Social Psychological and Personality",
        "Overview of KPA-2021 shared task: Key point based quantitative summarization",
        "A large-scale dataset for argument quality ranking: Construction and analysis",
        "World values survey",
        "The righteous mind: Why good people are divided by politics and religion",
        "Learning whom to trust with mace",
        "Changes in social values in the united states during the past decade",
        "The Meant, the Said, and the Understood: Conversational Argument Search and Cognitive Biases",
        "Exploring morality in argumentation",
        "Measuring the reliability of qualitative text analysis data",
        "Learning rules for multi-label classification: a stacking and a separate-and-conquer approach",
        "A societal sentiment analysis: Predicting the values and ethics of individuals by analysing social media content",
        "Measuring the similarity of sentential arguments in dialogue",
        "Argumentation mining in parliamentary discourse",
        "The nature of human values",
        "Aspect-controlled neural argument generation",
        "Are there universal aspects in the structure and contents of human values?",
        "Refining the theory of basic individual values",
        "Rationality in action",
        "Practical reasoning using values: an argumentative approach based on a hierarchy of values",
        "Aspect-based argument mining",
        "Practical reasoning using values",
        "Statistics for the Social Sciences"
    ],
    "621635aa91e011b46d7ce129": [
        "Distributed large-scale natural graph factorization",
        "A semi-NMF-PCA unified framework for data clustering",
        "Simultaneous spectral data embedding and clustering",
        "Variational autoencoder based anomaly detection using reconstruction probability",
        "Graph Clustering with Graph Neural Networks",
        "Self-labelling via simultaneous clustering and representation learning",
        "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation",
        "Adaptive graph encoder for attributed graph embedding",
        "K-means clustering in a lowdimensional Euclidean space",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Weighted Graph Cuts without Eigenvectors A Multilevel Approach",
        "Graph Neural Networks for Social Recommendation",
        "Deep k-means: Jointly clustering with k-means and learning representations",
        "Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization",
        "node2vec: Scalable feature learning for networks",
        "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions",
        "Representation Learning on Graphs: Methods and Applications",
        "Spherical k-Means Clustering",
        "VAIN: Attentional Multi-agent Predictive Modeling",
        "Deep learning-based clustering approaches for bioinformatics",
        "Convolutional Embedded Networks for Population Scale Clustering and Bio-ancestry Inferencing",
        "Variational Graph Auto-Encoders",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Efficient regularized spectral data embedding",
        "Least squares quantization in PCM",
        "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling",
        "Graph InfoClust: Maximizing Coarse-Grain Mutual Information in Graphs",
        "On Spectral Clustering: Analysis and an Algorithm",
        "DeepWalk: online learning of social representations",
        "3D Graph Neural Networks for RGBD Semantic Segmentation",
        "Gemsec: Graph embedding with self clustering",
        "Social regularized von Mises-Fisher mixture model for item recommendation",
        "Simple and Effective Graph Autoencoders with One-Hop Linear Models",
        "Graph networks as learnable physics engines for inference and control",
        "Few-Shot Learning with Graph Neural Networks",
        "Collective classification in network data",
        "A Graph-to-Sequence Model for AMR-to-Text Generation",
        "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization",
        "Visualizing High-Dimensional Data Using t-SNE",
        "Deep Graph Infomax. ICLR (Poster)",
        "Structural deep network embedding",
        "Simplifying graph convolutional networks",
        "A general formulation of cluster analysis with dimension reduction and subspace separation",
        "Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering",
        "Network Representation Learning with Rich Text Information",
        "Graph R-CNN for Scene Graph Generation",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Attributed Graph Clustering via Adaptive Graph Convolution",
        "Simple Spectral Graph Convolution",
        "Deep learning for learning graph representations"
    ],
    "62feff8d90e50fcafd599888": [
        "The unfairness of popularity bias in recommendation",
        "Graph convolutional matrix completion",
        "Debiased Explainable Pairwise Ranking from Implicit Feedback",
        "Offline evaluation to make decisions about playlist recommendation algorithms",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Neural collaborative filtering",
        "Fast matrix factorization for online recommendation with implicit feedback",
        "Weighted average importance sampling and defensive mixture distributions",
        "Unbiased learning-to-rank with biased feedback",
        "Fism: factored item similarity models for top-n recommender systems",
        "Adam: A method for stochastic optimization",
        "Grouplens: Applying collaborative filtering to usenet news",
        "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
        "Feedback loop and bias amplification in recommender systems",
        "BPR: Bayesian personalized ranking from implicit feedback",
        "Grouplens: An open architecture for collaborative filtering of netnews",
        "Unbiased Pairwise Learning from Implicit Feedback",
        "Unbiased recommender learning from missing-not-at-random implicit feedback",
        "Recommendations as treatments: Debiasing learning and evaluation",
        "The self-normalized estimator for counterfactual learning",
        "Learning to rank with selection bias in personal search",
        "Neural graph collaborative filtering",
        "Unbiased offline recommender evaluation for missing-not-atrandom implicit feedback",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Causal Intervention for Leveraging Popularity Bias in Recommendation. SIGIR"
    ],
    "62cce6795aee126c0f2a7fcc": [
        "Tensorflow: A system for large-scale machine learning",
        "Learning to optimize halide with tree search and random programs",
        "ARM Compute Library",
        "Exploring the Arm dot product instructions",
        "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code",
        "Automatic kernel generation for volta tensor cores",
        "XGBoost: A Scalable Tree Boosting System",
        "Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems",
        "{TVM}: An automated end-to-end optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "Efficient primitives for deep learning",
        "Automatic Generation of Efficient Sparse Tensor Format Conversion Routines",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Cortex: A Compiler for Recursive Deep Learning Models",
        "The Hierarchically Tiled Arrays Programming Approach",
        "Fireiron: A Data-Movement-Aware Scheduling Language for GPUs",
        "Deep residual learning for image recognition",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Intel? Math Kernel Library for Deep Learning Networks",
        "Introduction to Intel? Deep Learning Boost on Second Generation Intel? Xeon? Scalable Processors",
        "CUTLASS",
        "The Tensor Algebra Compiler",
        "When polyhedral transformations meet SIMD code generation",
        "Mlir: Scaling compiler infrastructure for domain specific computation",
        "Continuous control with deep reinforcement learning",
        "QNNPACK: Open source library for optimized mobile deep learning",
        "Playing atari with deep reinforcement learning",
        "VTA: an open hardware-software stack for deep learning",
        "None",
        "NVIDIA TensorRT: Programmable Inference Accelerator",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Language models are unsupervised multitask learners",
        "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Loop-aware SLP in GCC",
        "Proximal policy optimization algorithms",
        "A Sparse Iteration Space Transformation Framework for Sparse Tensor Algebra",
        "Very deep convolutional networks for large-scale image recognition",
        "Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations",
        "Polyhedral code generation in the real world",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "Attention is all you need",
        "UNIT: Unifying tensorized instruction compilation",
        "Stripe: Tensor compilation via the nested polyhedral model",
        "AKG: automatic kernel generation for neural processing units using polyhedral transformations",
        "Ansor: generating high-performance tensor programs for deep learning",
        "AMOS: enabling automatic mapping for tensor computations on spatial accelerators with hardware abstraction",
        "Flex-Tensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System"
    ],
    "628749495aee126c0fff087a": [
        "Learning to retrieve reasoning paths over wikipedia graph for question answering",
        "Reading Wikipedia to answer opendomain questions",
        "Multi-hop question answering via reasoning chains",
        "Simple and effective multi-paragraph reading comprehension",
        "Electra: Pretraining text encoders as discriminators rather than generators",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
        "Co-search: COVID-19 information retrieval with semantic search, question answering, and abstractive summarization",
        "ELI5: long form question answering",
        "IIRC: A dataset of incomplete information reading comprehension questions",
        "Retrieval augmented language model pre-training",
        "Accurate supervised and semisupervised machine reading for long documents",
        "A simple language model for task-oriented dialogue",
        "Niranjan Balasubramanian, and Kentaro Inui. 2021. Summarize-then-answer: Generating concise explanations for multi-hop reading comprehension",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Dense passage retrieval for open-domain question answering",
        "Natural questions: A benchmark for question answering research",
        "Latent retrieval for weakly supervised open domain question answering",
        "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Tim Rockt?schel, Sebastian Riedel, and Douwe Kiela. 2020b. Retrieval-augmented generation for knowledgeintensive nlp tasks",
        "Hopretriever: Retrieve hops over wikipedia to answer complex questions",
        "Dense hierarchical retrieval for open-domain question answering",
        "A discrete hard EM approach for weakly supervised question answering",
        "AmbigQA: Answering ambiguous open-domain questions",
        "Neural assistant: Joint action prediction, response generation, and latent knowledge reasoning",
        "Revealing the importance of semantic retrieval for machine reading at scale",
        "Answering while summarizing: Multi-task learning for multi-hop QA with evidence extraction",
        "Soloist: Building task bots at scale with transfer learning and machine teaching",
        "Retrieve, read, rerank, then iterate: Answering open-domain questions of varying reasoning steps from text",
        "Answering complex open-domain questions through iterative query generation",
        "Dynamically fused graph network for multi-hop reasoning",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "How much knowledge can you pack into the parameters of a language model?",
        "Memory augmented sequential paragraph retrieval for multi-hop question answering",
        "The web as a knowledge-base for answering complex questions",
        "Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents",
        "The trec-8 question answering track report",
        "Constructing datasets for multi-hop reading comprehension across documents",
        "Huggingface's transformers: State-of-the-art natural language processing",
        "Answering complex open-domain questions with multi-hop dense retrieval",
        "Simple yet effective bridge reasoning for open-domain multi-hop question answering",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "Covidex: Neural ranking models and keyword search infrastructure for the COVID-19 open research dataset",
        "Transformer-xh: Multi-evidence reasoning with extra hop attention"
    ],
    "62bbc3865aee126c0fa68605": [
        "Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Accurate learning of graph representations with graph multiset pooling",
        "Spectral clustering with graph neural networks for graph pooling",
        "The spread of behavior in an online social network experiment",
        "Fastgcn: Fast learning with graph convolutional networks via importance sampling",
        "Simple and deep graph convolutional networks",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "A fair comparison of graph neural networks for graph classification",
        "Graph u-nets",
        "Inductive representation learning on large graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Self-attention graph pooling",
        "Structural information and dynamical complexity of networks",
        "Resistance and security index of networks: structural information perspective of network security",
        "Three-dimensional gene maps of cancer cell types: Structural entropy minimisation principle for defning tumour subtypes",
        "Decoding topologically associating domains with ultra-low resolution hi-c data by graph structural entropy",
        "Graph convolutional networks with eigenpooling",
        "Rethinking pooling in graph neural networks",
        "Tudataset: A collection of benchmark datasets for learning with graphs",
        "Adaptive structure aware pooling for learning hierarchical graph representations",
        "Collective classification in network data",
        "A mathematical theory of communication",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Graph attention networks",
        "Deep graph infomax",
        "Order matters: Sequence to sequence for sets",
        "Simplifying graph convolutional networks",
        "A simple yet effective method for graph classification",
        "How powerful are graph neural networks?",
        "Hierarchical graph representation learning with differentiable pooling",
        "Structured graph pooling via conditional random fields",
        "Link prediction based on graph neural networks",
        "An end-toend deep learning architecture for graph classification",
        "Simple spectral graph convolution"
    ],
    "630359f590e50fcafd88dc06": [
        "Invariant risk minimization",
        "Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples",
        "Invariance, causality and robustness",
        "Towards evaluating the robustness of neural networks",
        "Unlabeled data improves adversarial robustness",
        "Invariant rationalization",
        "Robust overfitting may be mitigated by properly learned smoothening",
        "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
        "Learning to confuse: generating training time adversarial data with auto-encoder",
        "Adversarial examples make strong poisons",
        "Witches' brew: Industrial scale data poisoning via gradient matching",
        "Causal inference in statistics: A primer",
        "Explaining and Harnessing Adversarial Examples",
        "A theory of causal learning in children: causal maps and Bayes nets",
        "Deep residual learning for image recognition",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Densely connected convolutional networks",
        "Unlearnable examples: Making personal data unexploitable",
        "Metapoison: Practical general-purpose clean-label data poisoning",
        "Variational autoencoders and nonlinear ica: A unifying framework",
        "Bridging adversarial robustness and gradient interpretability",
        "Learning multiple layers of features from tiny images",
        "Out-ofdistribution generalization via risk extrapolation (rex)",
        "Learning causal semantic representation for out-ofdistribution prediction",
        "Towards deep learning models resistant to adversarial attacks",
        "Representation learning via invariant causal mechanisms",
        "Robustness to adversarial perturbations in learning from incomplete data",
        "Improving adversarial robustness via promoting ensemble diversity",
        "Bag of tricks for adversarial training",
        "Causality",
        "Interpretation and identification of causal mediation",
        "Causal inference by using invariant prediction: identification and confidence intervals",
        "Elements of causal inference: foundations and learning algorithms",
        "Learning to learn single domain generalization",
        "Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond",
        "Overfitting in adversarially robust deep learning",
        "Adversarially robust generalization requires more data",
        "On causal and anticausal learning",
        "Very deep convolutional networks for large-scale image recognition",
        "Is Robustness the Cost of Accuracy?-A Comprehensive Study on the Robustness of 18 Deep Image Classification Models",
        "Recovering Latent Causal Factor for Generalization to Distributional Shifts",
        "Going deeper with convolutions",
        "Intriguing properties of neural networks",
        "Better safe than sorry: Preventing delusive adversaries with adversarial training",
        "On adaptive attacks to adversarial example defenses",
        "Ensemble adversarial training: Attacks and defenses",
        "Robustness may be at odds with accuracy",
        "High-frequency component helps explain the generalization of convolutional neural networks",
        "Causal attention for unbiased visual recognition",
        "Improving adversarial robustness requires revisiting misclassified examples",
        "Handling Distribution Shifts on Graphs: An Invariance Perspective",
        "Show, attend and tell: Neural image caption generation with visual attention",
        "Causal attention for vision-language tasks",
        "A closer look at accuracy vs. robustness",
        "Wide residual networks",
        "A causal view on robustness of neural networks",
        "Causal intervention for weakly-supervised semantic segmentation",
        "mixup: Beyond empirical risk minimization",
        "Theoretically principled trade-off between robustness and accuracy",
        "Geometry-aware instance-reweighted adversarial training",
        "Adversarial robustness through the lens of causality"
    ],
    "628748bc5aee126c0ffc3ecd": [
        "Signature verification using a \"siamese\" time delay neural network",
        "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER",
        "Named entity recognition with bidirectional LSTM-CNNs",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Entity projection via machine translation for cross-lingual NER",
        "Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER",
        "Siamese neural networks for one-shot image recognition",
        "Neural architectures for named entity recognition",
        "Reinforced iterative knowledge distillation for crosslingual named entity recognition",
        "Cheap translation for cross-lingual named entity recognition",
        "Learning text similarity with Siamese recurrent networks",
        "Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection",
        "Crosslingual name tagging and linking for 282 languages",
        "Transfer learning in natural language processing",
        "Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition",
        "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
        "Cross-lingual named entity recognition via wikification",
        "Single-/multisource cross-lingual NER via teacher-student learning on unlabeled data in target language",
        "Unitrans : Unifying model transfer and data transfer for cross-lingual named entity recognition with unlabeled data",
        "Enhanced meta-learning for cross-lingual named entity recognition with minimal resources",
        "Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT",
        "Neural crosslingual named entity recognition with minimal resources",
        "Target-oriented fine-tuning for zero-resource named entity recognition"
    ],
    "62bab8f95aee126c0f6afb82": [
        "Unsupervised learning by predicting noise",
        "Efficient Neural Matrix Factorization without Sampling for Recommendation",
        "Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention",
        "Deep neural networks for youtube recommendations",
        "SimCSE: Simple Contrastive Learning of Sentence Embeddings",
        "Bootstrap your own latent: A new approach to self-supervised learning",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Neural collaborative filtering",
        "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
        "Matrix factorization techniques for recommender systems",
        "On sampled metrics for item recommendation",
        "Bootstrapping User and Item Representations for One-Class Collaborative Filtering",
        "Modeling user exposure in recommendation",
        "Variational autoencoders for collaborative filtering",
        "Contrastive Learning for Recommender System",
        "SimpleX: A Simple and Strong Baseline for Collaborative Filtering",
        "Image-based recommendations on styles and substitutes",
        "Improving pairwise learning for item recommendation from implicit feedback",
        "BPR: Bayesian personalized ranking from implicit feedback",
        "Collaborative filtering recommender systems",
        "Recvae: A new variational autoencoder for top-n recommendations with implicit feedback",
        "A survey of collaborative filtering techniques",
        "Sequential Recommendation with Multiple Contrast Signals",
        "Toward Dynamic User Intention: Temporal Evolutionary Effects of Item Relations in Sequential Recommendation",
        "Make It a Chrous: Knowledge-and Time-aware Item Modeling for Sequential Recommendation",
        "Modeling Item-Specific Temporal Dynamics of Repeat Consumption for Recommender Systems",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Neural graph collaborative filtering",
        "Disentangled graph collaborative filtering",
        "Session-based recommendation with graph neural networks",
        "Barlow twins: Self-supervised learning via redundancy reduction",
        "Deep learning based recommender system: A survey and new perspectives",
        "RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms",
        "Contrastive learning for debiased candidate generation in large-scale recommender systems"
    ],
    "628749125aee126c0ffe0f2d": [
        "Learning to retrieve reasoning paths over wikipedia graph for question answering",
        "Reading Wikipedia to answer opendomain questions",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Bottom-up abstractive summarization",
        "Non-autoregressive neural machine translation",
        "Incorporating copying mechanism in sequenceto-sequence learning",
        "Distilling knowledge from reader to retriever for question answering",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Dense passage retrieval for opendomain question answering",
        "Natural questions: A benchmark for question answering research",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Question and answer test-train overlap in opendomain question answering datasets",
        "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "Fixing weight decay regularization in adam",
        "Addressing the rare word problem in neural machine translation",
        "On faithfulness and factuality in abstractive summarization",
        "Yashar Mehdad",
        "Joint passage ranking for diverse multi-answer retrieval",
        "AmbigQA: Answering ambiguous open-domain questions",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension",
        "Get to the point: Summarization with pointergenerator networks",
        "Pointer networks",
        "The TREC-8 question answering track report",
        "Training adaptive computation for open-domain question answering with computational constraints",
        "Efficient passage retrieval with hashing for open-domain question answering",
        "End-to-end open-domain question answering with BERTserini",
        "Detecting hallucinated content in conditional neural sequence generation"
    ],
    "62cce67a5aee126c0f2a86f3": [
        "Author name disambiguation using vector space model and hybrid similarity measures",
        "A joint model for word embedding and word morphology",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Distributed representations of tuples for entity resolution",
        "On graph-based name disambiguation",
        "A brief survey of automatic methods for author name disambiguation",
        "Effective self-training author name disambiguation in scholarly digital libraries",
        "Name2vec: Personal names embeddings",
        "node2vec: Scalable feature learning for networks",
        "Two supervised learning approaches for name disambiguation in author citations",
        "Collective entity linking in web text: a graph-based method",
        "Entity disambiguation in anonymized graphs using graph kernels",
        "Robust disambiguation of named entities in text",
        "Using deep learning word embeddings for citations similarity in academic papers",
        "A survey of author name disambiguation techniques",
        "Large scale author name disambiguation in digital libraries",
        "Online person name disambiguation with constraints",
        "Learning cnf blocking for large-scale author name disambiguation",
        "A web service for author name disambiguation in scholarly databases",
        "Symmetric nonnegative matrix factorization for graph clustering",
        "Author name disambiguation for p ub m ed",
        "Ethnicity sensitive author disambiguation using semi-supervised learning",
        "Semantic author name disambiguation with word embeddings",
        "Deepwalk: Online learning of social representations",
        "Combining machine learning and human judgment in author disambiguation",
        "Dynamic author name disambiguation for growing digital libraries",
        "Detecting ambiguous author names in crowdsourced scholarly data",
        "Pte: Predictive text embedding through large-scale heterogeneous text networks",
        "Line: Large-scale information network embedding",
        "Author name disambiguation by using deep neural network",
        "Unsupervised author disambiguation using dempster-shafer theory",
        "A network-embedding based method for author disambiguation",
        "Author name disambiguation in citations",
        "Name disambiguation in anonymized graphs using network embedding",
        "Bayesian non-exhaustive classification a case study: Online name disambiguation using temporal record streams",
        "Name disambiguation in aminer: Clustering, maintenance, and human in the loop",
        "A semi-supervised approach for author disambiguation in kdd cup 2013"
    ],
    "62f3220a90e50fcafd115bd6": [
        "Layer normalization",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "The automatic content extraction (ACE) program -tasks, data, and evaluation",
        "Deep biaffine attention for neural dependency parsing",
        "Span-based joint entity and relation extraction with transformer pre-training",
        "Rethinking boundaries: End-to-end recognition of discontinuous mentions with pointer networks",
        "Bridging nonlinearities and stochastic regularizers with gaussian error linear units",
        "Bidirectional LSTM-CRF models for sequence tagging",
        "Nested named entity recognition revisited",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Unified named entity recognition as wordword relation classification",
        "A unified MRC framework for named entity recognition",
        "Joint mention extraction and classification with mention hypergraphs",
        "Unified structure generation for universal information extraction",
        "End-to-end sequence labeling via bi-directional lstm-cnns-crf",
        "Learning to recognize discontiguous entities",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Neural architectures for nested NER through linearization",
        "Sequence to sequence learning with neural networks",
        "Walker and Linguistic Data Consortium",
        "Nested named entity recognition with span-level graphs",
        "Neural segmental hypergraphs for overlapping mention recognition",
        "Transformers: State-of-the-art natural language processing",
        "TENER: adapting transformer encoder for named entity recognition",
        "A unified generative framework for various NER subtasks",
        "Named entity recognition as dependency parsing",
        "Fusing heterogeneous factors with triaffine mechanism for nested named entity recognition",
        "Boundary smoothing for named entity recognition",
        "None"
    ],
    "628748e05aee126c0ffd1130": [
        "Syntaxbert: Improving pre-trained transformers with syntax trees",
        "Minimum hellinger distance estimates for parametric models. The annals of Statistics",
        "Enhancing machine translation with dependency-aware self-attention",
        "Ultra-fine entity typing",
        "Generating typed dependency parses from phrase structure parses",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "A new metric for probability distributions",
        "Constituency and the grammar. The language of turn and sequence",
        "Noisecontrastive estimation: A new estimation principle for unnormalized statistical models",
        "Momentum contrast for unsupervised visual representation learning",
        "A structural probe for finding syntax in word representations",
        "What does bert learn about the structure of language",
        "Supervised contrastive learning",
        "Are pre-trained language models aware of phrases? simple but strong baselines for grammar induction",
        "Revealing the dark secrets of bert",
        "On information and sufficiency. The annals of mathematical statistics",
        "A unified mrc framework for named entity recognition",
        "Improving bert with syntax-aware local attention",
        "Assessing the ability of lstms to learn syntax-sensitive dependencies",
        "Roberta: A robustly optimized bert pretraining approach",
        "From balustrades to pierre vinken: Looking for syntax in transformer self-attentions",
        "Comparison of the predicted and observed secondary structure of t4 phage lysozyme",
        "Syntactic data augmentation increases robustness to inference heuristics",
        "Tree-structured attention with hierarchical accumulation",
        "Language models are unsupervised multitask learners",
        "Jointly learning to label sentences and tokens",
        "Do syntax trees help pretrained transformers extract information?",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "Linguisticallyinformed self-attention for semantic role labeling",
        "Bert rediscovers the classical nlp pipeline",
        "Attention is all you need",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "K-adapter: Infusing knowledge into pre-trained models with adapters",
        "Kepler: A unified model for knowledge embedding and pre-trained language representation",
        "Tree transformer: Integrating tree structures into self-attention",
        "Blimp: The benchmark of linguistic minimal pairs for english",
        "Neural network acceptability judgments",
        "Structural supervision improves learning of non-local grammatical dependencies",
        "Unsupervised feature learning via non-parametric instance discrimination",
        "Syntax-enhanced pre-trained model",
        "Luke: Deep contextualized entity representations with entityaware self-attention",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "A new dataset and method for automatically grading esol texts",
        "Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach",
        "Sg-net: Syntax-guided machine reading comprehension",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books"
    ],
    "628afb4c5aee126c0f04e3aa": [
        "Hindsight experience replay",
        "Model-based offline planning",
        "Structured denoising diffusion models in discrete state-spaces",
        "Structured agents for physical construction",
        "The cross-entropy method for optimization",
        "TransDreamer: Reinforcement learning with transformer world models",
        "Decision transformer: Reinforcement learning via sequence modeling",
        "Estimating gradients for waveform generation",
        "Deep reinforcement learning in a handful of trials using probabilistic dynamics models",
        "Diffusion models beat GANs on image synthesis",
        "Modelbased reinforcement learning for semi-markov decision processes with neural odes",
        "Model based planning with energy based models",
        "Compositional visual generation with energy based models",
        "Mismatched no more: Joint modelpolicy optimization for model-based rl",
        "Valueaware loss function for model-based reinforcement learning",
        "Datasets for deep data-driven reinforcement learning",
        "Off-policy deep reinforcement learning without exploration",
        "Integrating symbolic planners and blackbox samplers via optimistic adaptive planning",
        "Learning the stein discrepancy for training and evaluating energy-based models without sampling",
        "Recurrent world models facilitate policy evolution",
        "Learning latent dynamics for planning from pixels",
        "Mastering atari with discrete world models",
        "Array programming with NumPy",
        "Denoising diffusion probabilistic models",
        "Estimation of non-normalized statistical models by score matching",
        "γ-models: Generative temporal difference learning for infinitehorizon prediction",
        "Offline reinforcement learning as one big sequence modeling problem",
        "Model based reinforcement learning for atari",
        "Modeling the long term future in model-based reinforcement learning",
        "An introduction to trajectory optimization: How to do your own direct collocation",
        "MOReL: Model-based offline reinforcement learning",
        "A method for stochastic optimization",
        "Offline reinforcement learning with implicit Q-learning",
        "Conservative Q-learning for offline reinforcement learning",
        "A tutorial on energy-based learning",
        "Reinforcement learning and control as probabilistic inference: Tutorial and review",
        "A. 3d neural scene representations for visuomotor control",
        "Mish: A self regularized non-monotonic neural activation function",
        "Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning",
        "Accelerating online reinforcement learning with offline datasets",
        "Improved denoising diffusion probabilistic models",
        "Learning non-convergent non-persistent short-run MCMC toward energy-based model",
        "Value prediction network",
        "Vector quantized models for planning",
        "An imperative style, high-performance deep learning library",
        "A direct method for trajectory optimization of rigid bodies through contact",
        "Deep imitative models for flexible inference, planning, and control",
        "Graph networks as learnable physics engines for inference and control",
        "Mastering atari, go, chess and shogi by planning with a learned model",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Denoising diffusion implicit models",
        "Generative modeling by estimating gradients of the data distribution",
        "Integrated architectures for learning, planning, and reacting based on approximating dynamic programming",
        "Model regularization for stable sample rollouts",
        "Value iteration networks",
        "Synthesis and stabilization of complex behaviors through online trajectory optimization",
        "Implementation of denoising diffusion probabilistic models in pytorch",
        "Benchmarking model-based reinforcement learning",
        "Model predictive path integral control using covariance variable importance sampling",
        "Spacetime constraints",
        "Group normalization",
        "3D shape generation and completion through point-voxel diffusion",
        "Timestep embeddings are produced by a single fully-connected layer and added to the activations of the first temporal convolution within each block",
        "We train the model using the Adam optimizer (Kingma &amp; Ba, 2015) with a learning rate of 4e−05 and batch size of 32. We train the models for 500k steps",
        "The return predictor J has the structure of the first half of the U-Net used for the diffusion model",
        "We use a planning horizon T of 100 in all locomotion tasks, 128 for blocking stacking",
        "We use N = 100 diffusion steps",
        "We use a guide scale of α = 0",
        "We tuned over discount factors for the return prediction J φ , but found that above γ = 0.99 planning was insensitive to changes in discount factor. We found that control performance was not substantially affected by the choice of predicting noise versus uncorrupted data τ 0 with the diffusion model"
    ],
    "6344dede90e50fcafd24ceec": [
        "The nonstochastic multiarmed bandit problem",
        "Longformer: The long-document transformer",
        "Contextual bandit algorithms with supervised learning guarantees",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "Adaptive universal generalized pagerank graph neural network. ICLR",
        "Adaptive universal generalized pagerank graph neural network",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "A generalization of transformer networks to graphs",
        "Community structure in social and biological networks",
        "Inductive representation learning on large graphs",
        "Adaptive transfer learning on graph neural networks",
        "Joint identification of network communities and semantics via integrative modeling of network topologies and node contents",
        "Active learning by learning",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Adaptive sampling towards fast graph representation learning",
        "Scaling up graph neural networks via graph coarsening",
        "Semi-supervised classification with graph convolutional networks",
        "Reformer: The efficient transformer. ICLR",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Rethinking graph transformers with spectral attention",
        "Sac: Accelerating and structuring self-attention via sparse adaptive connection",
        "Transformer with memory replay",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Bandit samplers for training graph neural networks",
        "Graph reduction with spectral and cut guarantees",
        "The pagerank citation ranking: Bringing order to the web",
        "Geom-gcn: Geometric graph convolutional networks",
        "Relaxation-based coarsening and multiscale graph organization",
        "Efficient content-based sparse attention with routing transformers",
        "Towards an optimal asymmetric graph structure for robust semi-supervised node classification",
        "Efficient transformers: A survey",
        "Attention is all you need",
        "Graph attention networks",
        "Linformer: Self-attention with linear complexity",
        "Representation learning on graphs with jumping knowledge networks",
        "Focal self-attention for local-global interactions in vision transformers",
        "Do transformers really perform bad for graph representation?",
        "Performanceadaptive sampling strategy towards fast and accurate graph neural networks",
        "A transformer-based framework for multivariate time series representation learning",
        "Graph-bert: Only attention is needed for learning graph representations",
        "Model inversion attacks against graph neural networks",
        "Motif-based graph self-supervised learning for molecular property prediction",
        "Protgnn: Towards self-explaining graph neural networks",
        "Graph self-supervised learning for optoelectronic properties of organic semiconductors",
        "Gophormer: Ego-graph transformer for node classification",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Layerdependent importance sampling for training deep and large graph convolutional networks",
        "Did you describe the limitations of your work",
        "Did you discuss any potential negative social impacts of your work",
        "Have you read the ethics review guidelines and ensured that your paper conforms to them",
        "Did you state the full set of assumptions of all theoretical results",
        "Did you include complete proofs of all theoretical results",
        "Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen",
        "Did you report error bars (e.g., with respect to the random seed after running experiments multiple times",
        "Did you include the total amount of computing and the type of resources used (e.g., type of GPUs, internal cluster",
        "If your work uses existing assets",
        "Did you discuss whether and how consent was obtained from people whose data you're using",
        "Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content",
        "Did you include the full text of instructions given to participants and screenshots",
        "Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals",
        "Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation"
    ],
    "628749415aee126c0ffee49c": [
        "Fine-grained entity type classification by jointly learning representations and label embeddings",
        "Fine-grained named entity typing over distantly supervised data based on refined representations",
        "Improving distantly-supervised entity typing with compact latent space clustering",
        "Hierarchical entity typing via multi-level learning to rank",
        "An empirical study on multiple information sources for zero-shot fine-grained entity typing",
        "A question-answering based framework for relation extraction validation",
        "Ultra-fine entity typing",
        "Insrl: A multi-view learning framework fusing multiple information sources for distantly-supervised relation extraction",
        "Fast graph representation learning with PyTorch Geometric",
        "Improving event representation via simultaneous weakly supervised contrastive learning and clustering",
        "Contextdependent fine-grained entity type tagging",
        "Complex relation extraction: Challenges and opportunities",
        "Surface pattern-enhanced relation extraction with global constraints",
        "Explaining a bag of words with hierarchical conceptual labels",
        "Fine-grained entity typing via hierarchical multi graph convolutional networks",
        "Semi-supervised classification with graph convolutional networks",
        "Empirical analysis of unlabeled entity problem in named entity recognition",
        "Targetadaptive graph for cross-target stance detection",
        "Aspect-based sentiment analysis via affective knowledge enhanced graph convolutional networks",
        "No noun phrase left behind: detecting and typing unlinkable entities",
        "An attentive fine-grained entity typing model with latent type representation",
        "Fine-grained entity recognition",
        "TexSmart: A system for enhanced natural language understanding",
        "Texsmart: A system for enhanced natural language understanding",
        "Modeling fine-grained entity types with box embeddings",
        "Learning to denoise distantly-labeled data for entity typing",
        "Fine-grained entity typing for domain independent entity linking",
        "Deep contextualized word representations",
        "Fine-grained entity typing without knowledge base",
        "Afet: Automatic finegrained entity typing by hierarchical partial-label embedding",
        "An attentive neural architecture for fine-grained entity type classification",
        "Neural architectures for fine-grained entity type classification",
        "Graph attention networks",
        "Heterogeneous graph attention network",
        "Bbn pronoun coreference and entity type corpus. Linguistic Data Consortium",
        "Improving neural fine-grained entity typing with knowledge attention",
        "Imposing label-relational inductive bias for extremely fine-grained entity typing",
        "How powerful are graph neural networks?",
        "Neural finegrained entity type classification with hierarchyaware loss",
        "Texsmart: A text understanding system for fine-grained NER and enhanced semantic analysis",
        "Texsmart: A text understanding system for finegrained ner and enhanced semantic analysis",
        "Learning with noise: Improving distantlysupervised fine-grained entity typing via automatic relabeling",
        "Fine-grained entity typing through increased discourse context and adaptive classification thresholds"
    ],
    "623004305aee126c0f9b3299": [
        "Mixhop: Higher-order graph convolution architectures via sparsified neighborhood mixing",
        "Local graph partitioning using pagerank vectors",
        "Fast Bidirectional Probability Estimation in Markov Models",
        "MixMatch: A Holistic Approach to Semi-Supervised Learning",
        "Scaling graph neural networks with approximate pagerank",
        "Semi-supervised learning",
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Scalable Graph Neural Networks via Bidirectional Propagation",
        "Simple and deep graph convolutional networks",
        "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks",
        "Semi-supervised learning on graphs with generative adversarial nets",
        "Graph Random Neural Network for Semi-Supervised Learning on Graphs",
        "Accurate, large minibatch sgd: Training imagenet in 1 hour",
        "Inductive representation learning on large graphs",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima",
        "FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. NeurIPS",
        "Adam: A Method for Stochastic Optimization",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Diffusion improves graph learning",
        "Optimizing generalized pagerank methods for seed-expansion community detection",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "On the difficulty of training recurrent neural networks",
        "Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM",
        "An Overview of Microsoft Academic Service (MAS) and Applications",
        "Arnetminer: extraction and mining of academic social networks",
        "Graph Attention Networks. ICLR",
        "Simplifying graph convolutional networks",
        "Revisiting semi-supervised learning with graph embeddings",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "Learning with local and global consistency",
        "Semi-supervised learning using gaussian fields and harmonic functions",
        "Layer-dependent importance sampling for training deep and large graph convolutional networks"
    ],
    "629587485aee126c0fe15059": [
        "Interactive Exploration and Refinement of Facial Expression Using Manifold Learning",
        "An expressive text-driven 3D talking head",
        "Look, listen and learn",
        "Voice puppetry",
        "Video rewrite: Driving visual speech with audio",
        "Video Rewrite: Driving Visual Speech with Audio",
        "Neural head reenactment with latent pose descriptors",
        "Crema-d: Crowd-sourced emotional multimodal actors dataset",
        "What makes fake images detectable? understanding properties that generalize",
        "Hierarchical cross-modal talking face generation with dynamic pixel-wise loss",
        "Hierarchical cross-modal talking face generation with dynamic pixel-wise loss",
        "Puppeteergan: Arbitrary portrait animation with semantic-aware appearance transformation",
        "None",
        "Lip reading in the wild",
        "Out of time: automated lip sync in the wild",
        "Synthesizing normalized faces from facial identity features",
        "JALI: an animatorcentric viseme model for expressive lip synchronization",
        "Text-based editing of talking-head video",
        "Deepfake video detection using recurrent neural networks",
        "Towards fast, accurate and stable 3d dense face alignment",
        "Long short-term memory",
        "Learning Identity-Invariant Motion Representations for Cross-ID Face Reenactment",
        "Arbitrary style transfer in real-time with adaptive instance normalization",
        "Image-to-image translation with conditional adversarial networks",
        "Audio-driven emotional video portraits",
        "Perceptual losses for real-time style transfer and super-resolution",
        "Audiodriven facial animation by joint end-to-end learning of pose and emotion",
        "Neural style-preserving visual dubbing",
        "Deep video portraits",
        "Cooperative learning of audio and video models from self-supervised synchronization",
        "Face x-ray for more general face forgery detection",
        "Write-a-speaker: Text-based Emotional and Rhythmic Talkinghead Generation",
        "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English",
        "Mel frequency cepstral coefficients for music modeling",
        "Live Speech Portraits: Real-Time Photorealistic Talking-Head Animation",
        "The Chicago face database: A free stimulus set of faces and norming data",
        "Frame attention networks for facial expression recognition in videos",
        "Nerf: Representing scenes as neural radiance fields for view synthesis",
        "Animating face using disentangled audio representations",
        "Ambient sound provides supervision for visual learning",
        "A lip sync expert is all you need for speech to lip generation in the wild",
        "Audio-and gaze-driven facial animation of codec avatars",
        "Speech-driven expressive talking lips with conditional sequential generative adversarial networks",
        "Animating arbitrary objects via deep motion transfer",
        "First order motion model for image animation",
        "Synthesizing obama: learning lip sync from audio",
        "Ayush Tewari, Christian Theobalt, and Matthias Nießner",
        "Face2face: Real-time face capture and reenactment of rgb videos",
        "FACEGAN: Facial Attribute Controllable rEenactment GAN",
        "End-to-end speechdriven facial animation with temporal gans",
        "Realistic speechdriven facial animation with gans",
        "Mead: A large-scale audio-visual dataset for emotional talking-face generation",
        "High quality lip-sync animation for 3D photo-realistic talking head",
        "Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion",
        "Cnn-generated images are surprisingly easy to spot... for now",
        "One-shot free-view neural talking-head synthesis for video conferencing",
        "Image quality assessment: from error visibility to structural similarity",
        "Reenactgan: Learning to reenact faces via boundary transfer",
        "Mesh guided one-shot face reenactment using graph convolutional networks",
        "Iterative text-based editing of talking-heads using neural retargeting",
        "Attributing fake images to gans: Learning and analyzing gan fingerprints",
        "Fast bi-layer neural synthesis of one-shot realistic head avatars",
        "Freenet: Multi-identity face reenactment",
        "Talking face generation by adversarially disentangled audio-visual representation",
        "Pose-controllable talking face generation by implicitly modularized audio-visual representation",
        "MakeltTalk: speaker-aware talking-head animation",
        "Joint Audio-Visual Deepfake Detection",
        "Visemenet: Audio-driven animator-centric speech animation",
        "State of the art on monocular 3D face reconstruction, tracking, and applications"
    ],
    "634d809490e50fcafd4e683f": [
        "Renovating Assessment for the Future: Design-Based Implementation Research for a Learning-in-Class Monitoring System Based on the Learning Sciences",
        "IBM Cloud API Docs / Speech to Text",
        "Multiple emitter location and signal parameter estimation",
        "Sound Source Localization and Separation in Near Field",
        "Microphone Array Position Self-Calibration from Reverberant Speech Input",
        "Multiple sound source localization with iterative updates of DOA permutations in distributed microphone arrays",
        "Multi-talker Speech Recognition Based on Blind Source Separation with Ad Hoc Microphone Array Using Smartphones and Cloud Storage",
        "Amplitude-based Speech Enhancement with Nonnegative Matrix Factorization for Asynchronous Distributed Recording",
        "Meeting Recognition with Asynchronous Distributed Microphone Array Using Block-Wise Refinement of Mask-Based MVDR Beamformer",
        "Watermarked Movie Soundtrack Finds the Position of the Camcorder in a Theater",
        "Meeting Recognition with Asynchronous Distributed Microphone Array",
        "Discourse parsing: a decision tree approach",
        "An empirical investigation of the relation between discourse structure and coreference",
        "A model of coherence based on distributed sentence representation",
        "Acoustic Event Localization Using a Crosspower-Spectrum Phase Based Technique",
        "A statistical model-based voice activity detection",
        "A simple but efficient real-time Voice Activity Detection algorithm",
        "Multi-Channel VAD for Transcription of Group Discussion",
        "A tutorial on spectral clustering"
    ],
    "630359ec90e50fcafd88ceba": [
        "A Review of Uncertainty Quantification in Deep Learning: Techniques, Applications and Challenges. Information Fusion",
        "Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions",
        "Predictive Inference with the Jackknife+",
        "Spectral Networks and Locally Connected Networks on Graphs",
        "Active Learning for Graph Embedding",
        "Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts",
        "Gated Residual Recurrent Graph Neural Networks for Traffic Prediction",
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Residuals and Influence in Regression",
        "Node Classification in Uncertain Graphs",
        "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering",
        "Few-Shot Network Anomaly detection via cross-network meta-learning",
        "Jackknife-After-Bootstrap Standard Errors and Influence Functions",
        "On the Evolution of Random Graphs",
        "The Power of Certainty: A Dirichlet-Multinomial Model for Belief Propagation",
        "Von Mises Calculus for Statistical Functionals",
        "Dropout as A Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
        "Active Discriminative Network Representation Learning",
        "Utilizing Graph Machine Learning within Drug Discovery and Development",
        "Inductive Representation Learning on Large Graphs",
        "Bayesian Graph Neural Networks with Adaptive Connection Sampling",
        "Stochastic Blockmodels: First Steps",
        "On Embedding Uncertain Graphs",
        "Graph policy network for transferable active learning on graphs",
        "Rawls-GCN: Towards Rawlsian Difference Principle on Graph Convolutional Network",
        "Adam: A Method for Stochastic Optimization",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Understanding Black-Box Predictions via Influence Functions",
        "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
        "Uncertainty Aware Graph Gaussian Process for Semi-Supervised Learning",
        "Σ-Optimality for Active Learning on Gaussian Random Fields",
        "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
        "Predictive Uncertainty Estimation via Prior Networks",
        "The Jackknife-A Review",
        "Query-Driven Active Surveying for Collective Classification",
        "Bayesian Semi-Supervised Learning with Graph Gaussian Processes",
        "DropEdge: Towards Deep Graph Convolutional Networks on Node Classification",
        "Collective Classification in Network Data. AI Magazine",
        "Active Learning for Convolutional Neural Networks: A Core-set Approach",
        "Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification",
        "Bias and Confidence in Not-Quite Large Sample",
        "Uncertainty Estimation Using a Single Deep Deterministic Neural Network",
        "Graph Attention Networks",
        "Algorithmic Learning in a Random World",
        "A Semi-Supervised Graph Attentive Network for Financial Fraud Detection",
        "Neural Graph Collaborative Filtering",
        "Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration",
        "Bayesian Graph Convolutional Neural Networks for Semi-supervised Classification",
        "Uncertainty Aware Semi-Supervised Learning on Graph Data",
        "Graph Neural Networks: A Review of Methods and Applications",
        "Towards Real Time Team Optimization",
        "Attent: Active attributed network alignment"
    ],
    "629435a05aee126c0f2fe317": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Graph neural networks with convolutional arma filters",
        "Beyond low-frequency information in graph convolutional networks",
        "Spectral networks and locally connected networks on graphs",
        "Structural balance: a generalization of heider's theory",
        "Simple and deep graph convolutional networks",
        "When does a spectral graph neural network fail in node classification",
        "Adaptive universal generalized pagerank graph neural network",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Contextual stochastic block models",
        "All you need is low (rank): Defending against adversarial attacks on graphs",
        "Fast graph representation learning with pytorch geometric",
        "Inductive representation learning on large graphs",
        "Bernnet: Learning arbitrary graph spectral filters via bernstein approximation",
        "Graph structure learning for robust graph neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Combining neural networks with personalized pagerank for classification on graphs",
        "Deeprobust: A pytorch library for adversarial attacks and defenses",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "Revisiting graph neural networks",
        "Geom-gcn: Geometric graph convolutional networks",
        "Multi-scale attributed node embedding",
        "Collective classification in network data",
        "Social influence analysis in large-scale networks",
        "Graph attention networks",
        "Heterogeneous graph attention network",
        "Hiding individuals and communities in a social network",
        "Simplifying graph convolutional networks",
        "Adversarial examples for graph data: Deep insights into attack and defense",
        "Topology attack and defense for graph neural networks: An optimization perspective",
        "Graph neural networks inspired by classical iterative algorithms",
        "Revisiting semi-supervised learning with graph embeddings",
        "Gnnguard: Defending graph neural networks against adversarial attacks",
        "Robust graph convolutional networks against adversarial attacks",
        "On the relationship between heterophily and robustness of graph neural networks",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Adversarial attacks on graph neural networks via meta learning"
    ],
    "626754c85aee126c0fbcdd75": [
        "Hpatches: A benchmark and evaluation of handcrafted and learned local descriptors",
        "Longformer: The long-document transformer",
        "None",
        "Neural-guided ransac: Learning where to sample model hypotheses",
        "Endto-end object detection with transformers",
        "Learning to match features with seeded graph matching network",
        "Generating long sequences with sparse transformers",
        "Masked language modeling for proteins via linearly scalable long-context transformers",
        "Rethinking attention with performers",
        "Sinkhorn distances: Lightspeed computation of optimal transport",
        "Superpoint: Self-supervised interest point detection and description",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "D2-net: A trainable cnn for joint detection and description of local features",
        "Direct sparse odometry",
        "Deep graph matching consensus",
        "Reformer: The efficient transformer",
        "Megadepth: Learning singleview depth prediction from internet photos",
        "Distinctive image features from scaleinvariant keypoints",
        "Aslfeat: Learning local features of accurate shape and localization",
        "Orbslam: A versatile and accurate monocular slam system",
        "Lf-net: Learning local features from images",
        "Image transformer",
        "Blockwise self-attention for long document understanding",
        "Revisiting oxford and paris: Large-scale image retrieval benchmarking",
        "repeatable and reliable detector and descriptor",
        "Neighbourhood consensus networks",
        "Efficient content-based sparse attention with routing transformers",
        "Orb: An efficient alternative to sift or surf",
        "From coarse to fine: Robust hierarchical localization at large scale",
        "Superglue: Learning feature matching with graph neural networks",
        "Image retrieval for image-based localization revisited",
        "Structurefrom-motion revisited",
        "Pixelwise view selection for unstructured multi-view stereo",
        "None",
        "Concerning nonnegative matrices and doubly stochastic matrices",
        "Detector-free local feature matching with transformers",
        "Acne: Attentive context normalization for robust permutation-equivariant learning",
        "Inloc: Indoor visual localization with dense matching and view synthesis",
        "Yfcc100m: The new data in multimedia research",
        "Long-term visual localization revisited",
        "Attention is all you need",
        "Learning combinatorial embedding networks for deep graph matching",
        "Linformer: Self-attention with linear complexity",
        "Towards linear-time incremental structure from motion",
        "Learning to find good correspondences",
        "Learning two-view correspondences and geometry using order-aware network",
        "Reference pose generation for visual localization via learned features and view synthesis",
        "Patch2pix: Epipolar-guided pixel-level correspondences",
        "To learn or not to learn: Visual localization from essential matrices"
    ],
    "634f6ae390e50fcafdcb62af": [
        "On the opportunities and risks of foundation models",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Language models are few-shot learners",
        "Deep contextualized word representations",
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Wikidata: A free collaborative knowledgebase",
        "An open multilingual graph of general knowledge",
        "QA-GNN: Reasoning with language models and knowledge graphs for question answering",
        "Greaselm: Graph reasoning enhanced language models for question answering",
        "Query2box: Reasoning over knowledge graphs in vector space using box embeddings",
        "Latent execution-guided reasoning for multi-hop question answering on knowledge graphs",
        "Ernie: Enhanced language representation with informative entities",
        "Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model",
        "Kepler: A unified model for knowledge embedding and pre-trained language representation",
        "Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training",
        "Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation",
        "The unified medical language system (UMLS): Integrating biomedical terminology",
        "A robustly optimized bert pretraining approach",
        "LinkBERT: Pretraining language models with document links",
        "Realm: Retrieval-augmented language model pre-training",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Improving language models by retrieving from trillions of tokens",
        "Knowledge enhanced contextual word representations",
        "Knowledge-aware language model pretraining",
        "Exploiting structured knowledge in text via graph-guided representation learning",
        "Self-alignment pretraining for biomedical entity representations",
        "Jaket: Joint pre-training of knowledge graph and language understanding",
        "Jointgt: Graph-text joint representation learning for text generation from knowledge graphs",
        "K-bert: Enabling language representation with knowledge graph",
        "Colake: Contextualized language and knowledge embedding",
        "Integrating graph contextualized knowledge into pre-trained language models",
        "Kagnet: Knowledge-aware graph networks for commonsense reasoning",
        "Scalable multi-hop relational reasoning for knowledge-aware question answering",
        "Graph-based reasoning over heterogeneous external knowledge for commonsense question answering",
        "Gnn is a counter? revisiting gnn for question answering",
        "Knowledgeable reader: Enhancing cloze-style reading comprehension with external commonsense knowledge",
        "Enhancing pre-trained language representations with rich knowledge for machine reading comprehension",
        "Open domain question answering using early fusion of knowledge bases and text",
        "Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text",
        "Nedim Lipka, and Xiang Ren. Learning contextualized knowledge structures for commonsense reasoning",
        "Jointlk: Joint reasoning with language models and knowledge graphs for commonsense question answering",
        "Human parity on commonsenseqa: Augmenting self-attention with external attention",
        "Complex embeddings for simple link prediction",
        "Simple embedding for link prediction in knowledge graphs",
        "Translating embeddings for modeling multi-relational data",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "Relation extraction with matrix factorization and universal schemas",
        "Representing text for joint embedding of text and knowledge bases",
        "Representation learning of knowledge graphs with entity descriptions",
        "Kg-bert: Bert for knowledge graph completion",
        "Multi-task learning for knowledge graph completion with pre-trained language models",
        "Multi-task pre-training language model for semantic network completion",
        "Attention is all you need",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
        "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
        "Can a suit of armor conduct electricity? a new dataset for open book question answering",
        "Riddlesense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge",
        "Think you have solved question answering? try arc, the ai2 reasoning challenge",
        "Cosmos qa: Machine reading comprehension with contextual commonsense reasoning",
        "Hellaswag: Can a machine really finish your sentence?",
        "Piqa: Reasoning about physical commonsense in natural language",
        "Socialiqa: Commonsense reasoning about social interactions",
        "Abductive commonsense reasoning",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "The medical dictionary for regulatory activities (meddra)",
        "Medical subject headings (mesh)",
        "Modeling polypharmacy side effects with graph convolutional networks",
        "Gene ontology: tool for the unification of biology",
        "Drugbank 5.0: a major update to the drugbank database for 2018",
        "Identification of disease treatment mechanisms through the multiscale interactome",
        "None",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "Pubmedqa: A dataset for biomedical research question answering",
        "Results of the seventh edition of the bioasq challenge",
        "A survey of knowledge-enhanced text generation",
        "Towards controllable biases in language generation",
        "Ethical and social risks of harm from language models",
        "Realtoxicityprompts: Evaluating neural toxic degeneration in language models",
        "Lawyers are dishonest? quantifying representational harms in commonsense knowledge resources"
    ],
    "6369c8cd90e50fcafde87ef2": [
        "Do not have enough data? deep learning to the rescue! In AAAI",
        "Learning to learn by gradient descent by gradient descent",
        "What size net gives valid generalization",
        "Climbing towards NLU: On meaning, form, and understanding in the age of data",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "The fifth pascal recognizing textual entailment challenge",
        "Language models are few-shot learners",
        "CoCon: A self-supervised approach for controlled text generation",
        "Linguistically-informed interpolation of hidden space for semi-supervised text classification",
        "ELECTRA: Pre-training text encoders as discriminators rather than generators",
        "Prototypical verbalizer for prompt-based few-shot tuning",
        "The pascal recognising textual entailment challenge",
        "Plug and play language models: A simple approach to controlled text generation",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Automatically constructing a corpus of sentential paraphrases",
        "Model-agnostic meta-learning for fast adaptation of deep networks",
        "Bilevel programming for hyperparameter optimization and meta-learning",
        "Making pre-trained language models better few-shot learners",
        "RealToxi-cityPrompts: Evaluating neural toxic degeneration in language models",
        "The third pascal recognizing textual entailment challenge",
        "The second pascal recognising textual entailment challenge",
        "WARP: Word-level adversarial reprogramming",
        "DeBERTa: Decoding-enhanced BERT with disentangled attention",
        "Using trusted data to train deep networks on labels corrupted by severe noise",
        "Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification",
        "Toward controlled generation of text",
        "Marian: Fast neural machine translation in C++",
        "CTRL: A conditional transformer language model for controllable generation",
        "A distributional approach to controlled text generation",
        "Adam: A method for stochastic optimization",
        "Overcoming catastrophic forgetting in neural networks",
        "GeDi: Generative discriminator guided sequence generation",
        "Controlled text generation as continuous optimization with multiple constraints",
        "Data augmentation using pre-trained transformer models",
        "Temporal ensembling for semi-supervised learning",
        "Neural data augmentation via example extrapolation",
        "The power of scale for parameter-efficient prompt tuning",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "DExperts: Decoding-time controlled text generation with experts and anti-experts",
        "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning",
        "What makes good in-context examples for GPT-3?",
        "GPT understands",
        "A robustly optimized BERT pretraining approach",
        "Cutting down on prompts and parameters: Simple few-shot learning with language models",
        "PowerTransformer: Unsupervised controllable revision for biased language correction",
        "Weakly-supervised neural text classification",
        "Weakly-supervised hierarchical text classification",
        "COCO-LM: Correcting and contrasting text sequences for language model pretraining",
        "Generating training data with language models: Towards zero-shot language understanding",
        "Pretraining text encoders with adversarial mixture of training signal generators",
        "Noisy channel language model prompting for few-shot text classification",
        "Adversarial training methods for semisupervised text classification",
        "SELF: Learning to filter noisy labels with self-ensembling",
        "Understanding factuality in abstractive summarization with FRANK: A benchmark for factuality metrics",
        "A plug-andplay method for controlled text generation",
        "True few-shot learning with language models",
        "Style transfer through back-translation",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Learning to reweight examples for robust deep learning",
        "How many data points is a prompt worth",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Few-shot text generation with natural language instructions",
        "Generating datasets with pretrained language models",
        "It's not just size that matters: Small language models are also few-shot learners",
        "First Quora dataset release: Question pairs",
        "Eliciting knowledge from language models using automatically generated prompts",
        "Meta-weightnet: Learning an explicit mapping for sample weighting",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Rethinking the inception architecture for computer vision",
        "Improving and simplifying pattern exploiting training",
        "Attention is all you need",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "SuperGLUE: A stickier benchmark for general-purpose language understanding systems",
        "Learning to model the tail",
        "Towards zero-label language learning",
        "Neural network acceptability judgments",
        "EDA: Easy data augmentation techniques for boosting performance on text classification tasks",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Learning to teach with dynamic loss functions",
        "Unsupervised data augmentation for consistency training",
        "FUDGE: Controlled text generation with future discriminators",
        "G-daug: Generative data augmentation for commonsense reasoning",
        "Zerogen: Efficient zero-shot learning via dataset generation",
        "GPT3Mix: Leveraging large-scale language models for text augmentation",
        "Differentiable prompt makes pre-trained language models better few-shot learners",
        "Calibrate before use: Improving few-shot performance of language models",
        "Factual probing is [mask]: Learning vs. learning to recall",
        "Fine-tuning language models from human preferences"
    ],
    "6304456b90e50fcafd12fe4b": [
        "A theory of learning from different domains",
        "Curriculum learning",
        "GRAM: Graph-based Attention Model for Healthcare Representation Learning",
        "Graph analysis of functional brain networks: practical issues in translational neuroscience",
        "New Frontiers of Multi-Network Mining: Recent Developments and Future Trend",
        "Convolutional Networks on Graphs for Molecular Fingerprints",
        "On random graphs I",
        "Learning to Teach",
        "Adversarial Graph Contrastive Learning with Information Regularization",
        "Meta-Learned Metrics over Multi-Evolution Temporal Graphs",
        "DPPIN: A biological repository of dynamic protein-protein interaction network data",
        "A View-Adversarial Framework for Multi-View Network Embedding",
        "Neural Message Passing for Quantum Chemistry",
        "Armin Moharrer, Jennifer Dy, and Stratis Ioannidis. 2021. Graph Transfer Learning",
        "Graph theoretical analysis of structural and functional connectivity MRI in normal and pathological brain networks",
        "Representation Learning on Graphs: Methods and Applications",
        "Inductive Representation Learning on Large Graphs",
        "Loyalty in Online Communities",
        "Adaptive Transfer Learning on Graph Neural Networks",
        "Graph Policy Network for Transferable Active Learning on Graphs",
        "Strategies for Pre-training Graph Neural Networks",
        "GPT-GNN: Generative Pre-Training of Graph Neural Networks",
        "Self-Paced Curriculum Learning",
        "Men-torNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
        "Pre-training on Large-Scale Heterogeneous Graph",
        "Contrastive Pre-Training of GNNs on Heterogeneous Graphs",
        "HDMI: High-order Deep Multiplex Infomax",
        "Graph-MVP: Multi-View Prototypical Contrastive Learning for Multiplex Graphs",
        "COIN: Co-Cluster Infomax for Bipartite Graphs",
        "Supervised Contrastive Learning",
        "Adam: A Method for Stochastic Optimization",
        "Variational Graph Auto-Encoders",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Self-Paced Learning for Latent Variable Models",
        "Transferability of Spectral Graph Convolutional Neural Networks",
        "Graph Communal Contrastive Learning",
        "Learning Invariant Representations and Risks for Semi-Supervised Domain Adaptation",
        "Disentangled Contrastive Learning on Graphs",
        "Pre-training Molecular Graph Representation with 3D Geometry",
        "Neural subgraph isomorphism counting",
        "Link-based Classification",
        "Learning to Pre-train Graph Neural Networks",
        "Progressive Graph Learning for Open-Set Domain Adaptation",
        "Supervised Domain Adaptation using Graph Embedding",
        "Querydriven active surveying for collective classification",
        "Pretraining Graph Neural Networks with Kernels",
        "GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training",
        "To transfer or not to transfer",
        "Learning to Simulate Complex Physics with Graph Networks",
        "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization",
        "LINE: Large-scale Information Network Embedding",
        "Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
        "Convergence of a block coordinate descent method for nondifferentiable minimization",
        "Visualizing data using t-SNE",
        "Graph Attention Networks",
        "Deep Graph Infomax",
        "Dynamic protein interaction network construction and applications",
        "Curgraph: Curriculum learning for graph classification",
        "Unsupervised Domain Adaptive Graph Convolutional Networks",
        "InfoGCL: Information-Aware Graph Contrastive Learning",
        "How Powerful are Graph Neural Networks?",
        "Dynamic knowledge graph alignment",
        "Bright: A bridging algorithm for network alignment",
        "Hierarchical Graph Representation Learning with Differentiable Pooling",
        "FINAL: Fast Attributed Network Alignment",
        "On Learning Invariant Representations for Domain Adaptation",
        "Tackling oversmoothing of gnns with contrastive learning",
        "Contrastive Learning with Complex Heterogeneity",
        "Heterogeneous Contrastive Learning",
        "SPARC: Self-Paced Network Representation for Few-Shot Rare Category Characterization",
        "A Local Algorithm for Structure-Preserving Graph Cut",
        "High-Order Structure Exploration on Massive Graphs: A Local Graph Clustering Perspective",
        "A data-driven graph generative model for temporal interaction networks",
        "Misc-GAN: A multi-scale generative model for graphs",
        "Unlearn What You Have Learned: Adaptive Crowd Teaching with Exponentially Decayed Memory Learners",
        "Crowd Teaching with Imperfect Labels",
        "Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization",
        "Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education"
    ],
    "637aec2590e50fcafd929667": [
        "Model OPT-13B OPT-30B",
        "None",
        "None",
        "Piqa: Reasoning about physical commonsense in natural language",
        "Language models are few-shot learners",
        "Language models are few-shot learners",
        "Palm: Scaling language modeling with pathways",
        "-bit matrix multiplication for transformers at scale",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Glam: Efficient scaling of language models with mixture-of-experts",
        "The pile: An 800gb dataset of diverse text for language modeling",
        "Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding",
        "Measuring massive multitask language understanding",
        "Quantization and training of neural networks for efficient integer-arithmetic-only inference",
        "2021. I-bert: Integeronly bert quantization",
        "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Mcunet: Tiny deep learning on iot devices",
        "Post-training quantization for vision transformer",
        "Pointer sentinel mixture models",
        "Can a suit of armor conduct electricity? a new dataset for open book question answering",
        "Data-free quantization through weight equalization and bias correction",
        "The LAMBADA dataset: Word prediction requiring a broad discourse context",
        "Quantized matmul for efficient inference of large-scale generative language models",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Choice of plausible alternatives: An evaluation of commonsense causal reasoning",
        "Winogrande: An adversarial winograd schema challenge at scale",
        "Bloom: A 176b-parameter open-access multilingual language model",
        "Q-bert: Hessian based ultra low precision quantization of bert",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
        "Attention is all you need. Advances in neural information processing systems",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "HAQ: Hardware-Aware Automated Quantization with Mixed Precision",
        "Outlier suppression: Pushing the limit of low-bit transformer language models",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Zeroquant: Efficient and affordable post-training quantization for large-scale transformers",
        "Hellaswag: Can a machine really finish your sentence?",
        "Glm-130b: An open bilingual pre-trained model",
        "None",
        "Improving neural network quantization without retraining using outlier channel splitting"
    ],
    "6350bc6d90e50fcafdecf145": [
        "None",
        "Label-gcn: An effective method for adding label propagation to graph convolutional networks",
        "Deep clustering for unsupervised learning of visual features",
        "Node feature extraction by self-supervised multi-scale neighborhood prediction",
        "Evaluating modules in graph contrastive learning",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "Understanding the difficulty of training deep feedforward neural networks",
        "Contrastive multi-view representation learning on graphs",
        "Learning deep representations by mutual information estimation and maximization",
        "Self-supervised speech representation learning by masked prediction of hidden units",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "Heterogeneous graph transformer",
        "Maru: Meta-context aware random walks for heterogeneous network representation learning",
        "Pre-training on large-scale heterogeneous graph",
        "Contrastive pre-training of gnns on heterogeneous graphs",
        "Hdmi: High-order deep multiplex infomax",
        "Semi-supervised classification with graph convolutional networks",
        "Visualizing data using t-sne",
        "Unsupervised attributed multiplex network embedding",
        "Graph representation learning via graphical mutual information maximization",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Near linear time algorithm to detect community structures in large-scale networks",
        "Asap: Adaptive structure aware pooling for learning hierarchical graph representations",
        "Heterogeneous deep graph infomax",
        "Masked label prediction: Unified message passing model for semi-supervised classification",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Multi-stage self-supervised learning for graph convolutional networks on graphs with few labeled nodes",
        "Pathsim: Meta path-based topk similarity search in heterogeneous information networks",
        "Ranking-based clustering of heterogeneous information networks with star network schema",
        "Deep graph infomax",
        "Augmentation-free graph contrastive learning",
        "Unifying graph convolutional neural networks and label propagation",
        "Heterogeneous graph attention network",
        "Self-supervised heterogeneous graph neural network with co-contrastive learning",
        "Self-supervised learning on graphs: Contrastive, generative, or predictive",
        "Simgrace: A simple framework for graph contrastive learning without data augmentation",
        "Infogcl: Information-aware graph contrastive learning",
        "Xiaochun Cao, and Yuanfang Guo. Heterogeneous graph information bottleneck",
        "Interpretable and efficient heterogeneous graph convolutional network",
        "Hierarchical graph representation learning with differentiable pooling",
        "Graph contrastive learning automated",
        "Graph contrastive learning with augmentations",
        "Graph transformer networks",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "6346f67490e50fcafd950453": [
        "Frontswap",
        "Gen-Z Core Specification",
        "Compute Express Link Specification",
        "Connectx-6 single/dual-port adapter supporting 200Gb/s with VPI",
        "Linux Block Ram Disk",
        "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines",
        "Thermostat: Applicationtransparent page management for two-tiered main memory",
        "Remote memory in the age of fast networks",
        "Effectively Prefetching Remote Memory with Leap",
        "Can far memory improve job throughput",
        "Workload analysis of a large-scale key-value store",
        "A study of replacement algorithms for a virtualstorage computer",
        "Intel® Omni-path architecture: Enabling scalable, high performance fabrics",
        "Understanding the Linux Kernel: from I/O ports to process management",
        "Rethinking software runtimes for disaggregated memory",
        "CCIX Base Specification Revision 1.1. Version 1.0",
        "Ippokratis Pandis, and Radu Stoica",
        "AutoNUMA: the other approach to NUMA scheduling",
        "System software for persistent memory",
        "Data tiering in heterogeneous memory systems",
        "Distributed caching with memcached",
        "Network Requirements for Resource Disaggregation",
        "Large pages may be harmful on NUMA systems",
        "Efficient Memory Disaggregation with Infiniswap",
        "Intel® 64 and ia-32 architectures software developer's manual",
        "Heterovisor: Exploiting resource heterogeneity to enhance the elasticity of cloud platforms",
        "Basic performance measurements of the intel optane DC persistent memory module",
        "Heteroos: Os design for heterogeneous memory management in datacenter",
        "Radiant: efficient page table management for tiered memory systems",
        "Coordinated and efficient huge page management with ingens",
        "Mutilate: high-performance memcached load generator",
        "Utility-based hybrid memory management",
        "Disaggregated memory for expansion and sharing in blade servers",
        "Pin: building customized program analysis tools with dynamic instrumentation",
        "Introducing the graph 500",
        "Welcome to zombieland: Practical and energy-efficient memory disaggregation in a datacenter",
        "Scale-out NUMA",
        "Hawkeye: Efficient fine-grained os support for huge pages",
        "Making huge pages actually useful",
        "Data cache management using frequency-based replacement",
        "AIFM: High-Performance, Application-Integrated Far Memory",
        "LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation",
        "Shoal: A network architecture for disaggregated racks",
        "Ligra: a lightweight graph processing framework for shared memory",
        "The VoltDB Main Memory DBMS",
        "Intel memory latency checker. Intel Corporation",
        "Semeru: A Memory-Disaggregated Managed Runtime",
        "Nimble Page Management for Tiered Memory Systems",
        "An empirical guide to the behavior and use of scalable persistent memory"
    ],
    "6344dedd90e50fcafd24cdcd": [
        "Hypergraph neural networks",
        "Hypergcn: A new method for training graph convolutional networks on hypergraphs",
        "You are allset: A multiset function framework for hypergraph neural networks",
        "Hypergraph theory. An introduction. Mathematical Engineering",
        "Dual channel hypergraph collaborative filtering",
        "Self-supervised multi-channel hypergraph convolutional network for social recommendation",
        "Spatiotemporal hypergraph convolution network for stock movement forecasting",
        "Cross-modality and self-supervised protein embedding for compound-protein affinity and contact prediction",
        "Multiscale and integrative single-cell hi-c analysis with higashi",
        "Generating 3d molecules for target protein binding",
        "Scaling and benchmarking self-supervised visual representation learning",
        "A simple framework for contrastive learning of visual representations",
        "Strategies for pre-training graph neural networks",
        "Graph contrastive learning with augmentations",
        "When does self-supervision help graph convolutional networks?",
        "Self-supervised learning on graphs: Deep insights and new direction",
        "Self-supervised learning of graph neural networks: A unified review",
        "Deep graph infomax. ICLR (Poster)",
        "Graph contrastive learning automated",
        "Bringing your own view: Graph contrastive learning without prefabricated data augmentations",
        "Deep graph contrastive representation learning",
        "Augmentations in graph contrastive learning: Current methodological flaws &amp; towards better practices",
        "Augmentation-free graph contrastive learning",
        "Adversarial graph contrastive learning with information regularization",
        "Group contrastive self-supervised learning on graphs",
        "Hypergraph contrastive collaborative filtering",
        "Hypergraph contrastive learning for electronic health records",
        "Categorical reparameterization with gumbel-softmax",
        "Hyper-sagnn: a self-attention based graph neural network for hypergraphs",
        "Hypergraph convolution and hypergraph attention",
        "Unignn: a unified framework for graph and hypergraph neural networks",
        "Generalizing inductive representation learning on hypergraphs",
        "Deep sets. Advances in neural information processing systems",
        "Momentum contrast for unsupervised visual representation learning",
        "Bootstrap your own latent-a new approach to self-supervised learning",
        "Self-supervised hypergraph convolutional networks for session-based recommendation",
        "Hypergraph pre-training with graph neural networks",
        "Neural collaborative filtering",
        "Model-agnostic counterfactual reasoning for eliminating popularity bias in recommender system",
        "Comprehensive fair meta-learned recommender system",
        "Causal intervention for leveraging popularity bias in recommendation",
        "None",
        "Variational graph auto-encoders",
        "An introduction to variational autoencoders",
        "Bayesian modeling and uncertainty quantification for learning to optimize: What, why, and how",
        "Adversarial attacks on graph neural networks via meta learning",
        "Adversarial attacks on neural networks for graph data",
        "Uci machine learning repository",
        "The effect of race/ethnicity on sentencing: Examining sentence type, jail length, and prison length",
        "The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert systems with applications"
    ],
    "633e476490e50fcafde590a1": [
        "Get to the point: Summarization with pointer-generator networks",
        "A unified model for extractive and abstractive summarization using inconsistency loss",
        "Global encoding for abstractive summarization",
        "Text summarization with pretrained encoders",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Evaluating the factual consistency of abstractive text summarization",
        "Questeval: Summarization asks for fact-based evaluation",
        "Feqa: A question answering evaluation framework for faithfulness assessment in abstractive summarization",
        "Bass: Boosting abstractive summarization with unified semantic graph",
        "Cliff: Contrastive learning for improving faithfulness and factuality in abstractive summarization",
        "Towards a human-like open-domain chatbot",
        "Teaching machines to read and comprehend",
        "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
        "Learning towards abstractive timeline summarization",
        "Capturing relations between scientific papers: An abstractive model for related work section generation",
        "Generative adversarial network for abstractive text summarization",
        "How to write summaries with patterns? learning towards abstractive summarization through prototype editing",
        "Vmsmo: Learning to generate multimodal summary for video-based news articles",
        "Entity-aware abstractive multidocument summarization",
        "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
        "Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Semsum: Semantic dependency guided neural abstractive summarization",
        "Faithful to the original: Fact aware neural abstractive summarization",
        "Ensure the correctness of the summary: Incorporate entailment knowledge into abstractive sentence summarization",
        "Enhancing factual consistency of abstractive summarization",
        "Focus attention: Promoting faithfulness and diversity in summarization",
        "Multitask learning. Machine learning",
        "A transition-based system for joint part-of-speech tagging and labeled non-projective dependency parsing",
        "Incremental joint approach to word segmentation, pos tagging, and dependency parsing in chinese",
        "Joint optimization for chinese pos tagging and dependency parsing",
        "Recurrent neural network for text classification with multi-task learning",
        "Attention is all you need",
        "Text generation from knowledge graphs with graph transformers",
        "Graph attention networks",
        "Handling divergent reference texts when evaluating table-to-text generation",
        "On faithfulness and factuality in abstractive summarization",
        "Towards enhancing faithfulness for neural machine translation",
        "Prevent the language model from being overconfident in neural machine translation",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Gsum: A general framework for guided neural abstractive summarization",
        "Simcls: A simple framework for contrastive learning of abstractive summarization",
        "Transformers: State-ofthe-art natural language processing",
        "Rouge: A package for automatic evaluation of summaries",
        "Bertscore: Evaluating text generation with bert"
    ],
    "632812a590e50fcafd1a6a98": [
        "Small molecules and their impact in drug discovery: A perspective on the occasion of the 125th anniversary of the bayer chemical research laboratory",
        "rzmlp-dta: gmlp network with rezero for sequence-based drug-target affinity prediction",
        "Structure-based protein-drug affinity prediction with spatial attention mechanisms",
        "Edge-gated graph neural network for predicting proteinligand binding affinities",
        "omics\"-informed drug and biomarker discovery: opportunities, challenges and future perspectives",
        "The significance of acid/base properties in drug discovery",
        "Quantum chemical studies of some pyridine derivatives as corrosion inhibitors",
        "Perspective on density functional theory",
        "Ogb-lsc: A large-scale challenge for machine learning on graphs",
        "Geometry-enhanced molecular representation learning for property prediction",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Improving language understanding with unsupervised learning",
        "Smiles-bert: large scale unsupervised pre-training for molecular property prediction",
        "Chemberta: large-scale self-supervised pretraining for molecular property prediction",
        "Pure transformers are powerful graph learners",
        "Attention is all you need",
        "How powerful are graph neural networks?",
        "Graph attention networks",
        "Neural passing for quantum chemistry",
        "Deepergcn: All you need to train deeper gcns",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "cosformer: Rethinking softmax in attention",
        "Semi-supervised classification with graph convolutional networks",
        "Pure transformers are powerful graph learners",
        "Grpe: Relative positional encoding for graph transformer",
        "Edgeaugmented graph transformers: Global self-attention is enough for graphs",
        "Do transformers really perform badly for graph representation?",
        "Visualizing data using t-sne",
        "Scikit-learn: Machine learning in Python"
    ],
    "634e194790e50fcafd24f33e": [
        "None",
        "Víctor Valdés, Amir Sadik, et al. Deepmind lab",
        "Tinytl: Reduce memory, not parameters for efficient on-device learning",
        "MMDetection: Open mmlab detection toolbox and benchmark",
        "Adaptformer: Adapting vision transformers for scalable visual recognition",
        "On self modulation for generative adversarial networks",
        "Remote sensing image scene classification: Benchmark and state of the art",
        "Describing textures in the wild",
        "MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark",
        "Coatnet: Marrying convolution and attention for all data sizes",
        "Modulating early visual processing by language",
        "Imagenet: A large-scale hierarchical image database",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Repmlp: Re-parameterizing convolutions into fully-connected layers for image recognition",
        "Repvgg: Making vgg-style convnets great again",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "One-shot learning of object categories",
        "Finegrained car detection for visual census estimation",
        "Vision meets robotics: The kitti dataset",
        "An evolutionary approach to dynamic introduction of tasks in large-scale multitask learning systems",
        "munet: Evolving pretrained deep neural networks into scalable auto-tuning multitask systems",
        "Kaggle diabetic retinopathy detection competition report",
        "Spottune: transfer learning through adaptive fine-tuning",
        "Single path one-shot neural architecture search with uniform sampling",
        "Masked autoencoders are scalable vision learners",
        "Momentum contrast for unsupervised visual representation learning",
        "Rethinking imagenet pre-training",
        "Mask R-CNN",
        "Deep residual learning for image recognition",
        "Parameterefficient fine-tuning for vision transformers",
        "Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification",
        "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "Benchmarking neural network robustness to common corruptions and perturbations",
        "Natural adversarial examples",
        "Vision permutator: A permutable mlp-like architecture for visual recognition",
        "Parameter-efficient transfer learning for nlp",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Lora: Low-rank adaptation of large language models",
        "Densely connected convolutional networks",
        "Arbitrary style transfer in real-time with adaptive instance normalization",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Quantization and training of neural networks for efficient integer-arithmetic-only inference",
        "Spatial transformer networks",
        "Visual prompt tuning",
        "Clevr: A diagnostic dataset for compositional language and elementary visual reasoning",
        "Novel dataset for fine-grained image categorization: Stanford dogs",
        "Learning multiple layers of features from tiny images",
        "Learning methods for generic object recognition with invariance to pose and lighting",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "As-mlp: An axial shifted mlp architecture for vision",
        "Towards fast adaptation of neural architectures with meta learning",
        "Microsoft COCO: Common objects in context",
        "Darts: Differentiable architecture search",
        "Overcoming catastrophic forgetting in graph neural networks",
        "Dynast: Dynamic sparse transformer for exemplar-guided image generation",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "A convnet for the 2020s",
        "Video swin transformer",
        "Decoupled weight decay regularization",
        "Compacter: Efficient low-rank hypercomplex adapter layers",
        "Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks",
        "dsprites: Disentanglement testing sprites dataset",
        "Reading digits in natural images with unsupervised feature learning",
        "Automated flower classification over a large number of classes",
        "Cats and dogs",
        "Film: Visual reasoning with a general conditioning layer",
        "Efficient neural architecture search via parameters sharing",
        "Learning transferable visual models from natural language supervision",
        "Shunted selfattention via multi-scale token aggregation",
        "Very deep convolutional networks for large-scale image recognition",
        "Return of frustratingly easy domain adaptation",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "MLP-Mixer: An all-mlp architecture for vision",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Three things everyone should know about vision transformers",
        "Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection",
        "Attention is all you need",
        "Rotation equivariant cnns for digital pathology",
        "The caltech-ucsd birds-200-2011 dataset",
        "Group normalization",
        "Sun database: Large-scale scene recognition from abbey to zoo",
        "Unified perceptual parsing for scene understanding",
        "Aggregated residual transformations for deep neural networks",
        "Factorizing knowledge in neural networks",
        "Factorizable graph convolutional networks",
        "Distilling knowledge from graph convolutional networks",
        "Learning with recoverable forgetting",
        "Metaformer is actually what you need for vision",
        "Diracnets: Training very deep neural networks without skip-connections",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "A large-scale study of representation learning with the visual task adaptation benchmark",
        "None",
        "Scene parsing through ade20k dataset",
        "Qibin Hou, and Jiashi Feng. DeepViT: Towards deeper vision transformer",
        "Understanding the robustness in vision transformers",
        "Learning to prompt for vision-language models"
    ],
    "62982a9a5aee126c0f6f5ecb": [
        "Cormorant: Covariant molecular neural networks",
        "The shattered gradients problem: If resnets are the answer, then what is the question?",
        "Coupled-cluster theory in quantum chemistry",
        "Interaction networks for learning about objects, relations and physics",
        "Relational inductive biases, deep learning, and graph networks",
        "Se(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials",
        "Training with noise is equivalent to tikhonov regularization",
        "JAX: composable transformations of Python+NumPy programs",
        "Geometric and physical quantities improve e (3) equivariant message passing",
        "Geometric deep learning: going beyond euclidean data",
        "Language models are few-shot learners",
        "A note on over-smoothing for graph neural networks",
        "Open catalyst 2020 (oc20) dataset and community challenges",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Semi-supervised sequence learning",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Graph convolutional neural networks with node transition probability-based message passing and dropnode regularization",
        "Quantum chemical benchmark databases of gold-standard dimer interaction energies",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data",
        "Se(3)-transformers: 3d rototranslation equivariant attention networks",
        "Jraph: A library for graph neural networks in jax",
        "Simple GNN regularisation for 3d molecular property prediction and beyond",
        "Haiku: Sonnet for JAX",
        "Denoising diffusion probabilistic models",
        "Equivariant diffusion for molecule generation in 3d",
        "Strategies for pre-training graph neural networks. arXiv: Learning",
        "GPT-GNN: generative pre-training of graph neural networks",
        "Lietransformer: Equivariant self-attention for lie groups",
        "None",
        "Variational graph auto-encoders",
        "Fast and uncertainty-aware directional message passing for non-equilibrium molecules",
        "Directional message passing for molecular graphs",
        "Gemnet: Universal directional graph neural networks for molecules",
        "Covariant compositional networks for learning graphs",
        "N-gram graph: Simple unsupervised representation for graphs, with applications to molecules",
        "Pre-training molecular graph representation with 3d geometry",
        "Spherical message passing for 3d graph networks",
        "Graph self-supervised learning: A survey",
        "Rapid training of deep neural networks without skip connections or normalization layers using deep kernel shaping",
        "Relevance of rotationally equivariant convolutions for predicting molecular properties",
        "Pubchemqc project: A large-scale first-principles electronic structure database for data-driven chemistry",
        "Density-Functional Theory of Atoms and Molecules",
        "Carbon emissions and large neural network training",
        "Learning mesh-based simulation with graph networks",
        "Quantum chemistry structures and properties of 134 kilo molecules",
        "The truly deep graph convolutional networks for node classification",
        "Self-supervised graph transformer on large-scale molecular data",
        "Graph networks as learnable physics engines for inference and control",
        "Learning to simulate complex physics with graph networks",
        "Random features strengthen graph neural networks",
        "E(n) equivariant graph neural networks",
        "The graph neural network model",
        "Automap: Towards ergonomic automated parallelism for ML models",
        "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions",
        "Equivariant message passing for the prediction of tensorial properties and molecular spectra",
        "Learning gradient fields for molecular conformation generation",
        "Rotation invariant graph neural networks using spin convolutions",
        "Creating artificial neural networks that generalize",
        "Very deep convolutional networks for large-scale image recognition",
        "Generative Modeling by Estimating Gradients of the Data Distribution",
        "Improved techniques for training score-based generative models",
        "Towards training billion parameter graph neural networks for atomic simulations",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Bootstrapped representation learning on graphs",
        "Torchmd-net: Equivariant transformers for neural network based molecular potentials",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "Physnet: A neural network for predicting energies, forces, dipole moments, and partial charges",
        "Deep Graph Infomax",
        "A connection between score matching and denoising autoencoders",
        "Extracting and composing robust features with denoising autoencoders",
        "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
        "3d steerable cnns: Learning rotationally equivariant features in volumetric data",
        "Dynamical isometry and a mean field theory of cnns: How to train 10,000-layer vanilla convolutional neural networks",
        "Self-supervised learning of graph neural networks: A unified review",
        "Geodiff: A geometric diffusion model for molecular conformation generation",
        "Revisiting\" over-smoothing\" in deep gcns",
        "Do transformers really perform bad for graph representation?",
        "Graph contrastive learning with augmentations",
        "Deep learning without shortcuts: Shaping the kernel with tailored rectifiers",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Effective training strategies for deep graph neural networks"
    ],
    "63520de890e50fcafd60f43e": [
        "Language models are few-shot learners",
        "The PASCAL recognising textual entailment challenge",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models",
        "Automatically constructing a corpus of sentential paraphrases",
        "Making pre-trained language models better few-shot learners",
        "Deberta: decoding-enhanced bert with disentangled attention",
        "Parameter-efficient transfer learning for NLP",
        "LoRA: Low-rank adaptation of large language models",
        "Instance-aware prompt learning for language understanding and generation",
        "The power of scale for parameter-efficient prompt tuning",
        "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Xiangyang Liu, and Xipeng Qiu. 2021. A survey of transformers",
        "Xuanjing Huang, and Xipeng Qiu. 2022a. Towards efficient NLP: A standard evaluation and A strong baseline",
        "2022b. P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks",
        "GPT understands",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Decoupled weight decay regularization",
        "Compacter: Efficient low-rank hypercomplex adapter layers",
        "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts",
        "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Pre-trained models for natural language processing: A survey",
        "Language models are unsupervised multitask learners",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Squad: 100, 000+ questions for machine comprehension of text",
        "Adapterdrop: On the efficiency of adapters in transformers",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Xipeng Qiu, and Xuan-Jing Huang. 2022a. Paradigm shift in natural language processing",
        "Xuanjing Huang, and Xipeng Qiu. 2022b. Black-box tuning for language-model-as-a-service",
        "Context-tuning: Learning contextualized prompts for natural language generation",
        "Attention is all you need",
        "Building a question answering test collection",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "titan: Exploring larger-scale knowledge enhanced pre-training for language understanding and generation",
        "List: Lite prompted self-training makes parameter-efficient few-shot learners",
        "Revisiting locally supervised learning: an alternative to end-to-end training",
        "Annotating expressions of opinions and emotions in language",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Transformers: State-of-the-art natural language processing",
        "IDPG: an instance-dependent prompt generation method",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "Beyond fully-connected layers with quaternions: Parameterization of hypercomplex multiplications with 1/n parameters"
    ],
    "6327dda690e50fcafd67dfe7": [
        "Emergence of invariance and disentanglement in deep representations",
        "Deep Variational Information Bottleneck",
        "Representation Learning: A Review and New Perspectives",
        "Size-invariant graph representations for graph classification extrapolations",
        "ICML",
        "A Simple Framework for Contrastive Learning of Visual Representations",
        "Intriguing properties of contrastive losses",
        "Elements of information theory",
        "Learning robust representations via multi-view information bottleneck",
        "Shortcut learning in deep neural networks",
        "node2vec: Scalable Feature Learning for Networks",
        "Inductive Representation Learning on Large Graphs",
        "Representation learning on graphs: Methods and applications",
        "Contrastive Multi-View Representation Learning on Graphs",
        "Contrastive multi-view representation learning on graphs",
        "Learning to Decompose and Disentangle Representations for Video Prediction",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "Strategies for pre-training graph neural networks",
        "Variational Graph Auto-Encoders",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Disentangled Contrastive Learning on Graphs",
        "Let invariant rationale discovery inspire graph contrastive learning",
        "Independence promoted graph disentangled networks",
        "Disentangled Graph Convolutional Networks",
        "Towards deep learning models resistant to adversarial attacks",
        "Automatic shortcut removal for self-supervised representation learning",
        "TUDataset: A collection of benchmark datasets for learning with graphs",
        "Learning Distributed Representations of Graphs",
        "GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training",
        "Can contrastive learning avoid shortcut solutions? In NeurIPS",
        "Opening the Black Box of Deep Neural Networks via Information",
        "GraphVAE: Towards generation of small graphs using variational autoencoders",
        "InfoGraph: Unsupervised and Semisupervised Graph-Level Representation Learning via Mutual Information Maximization",
        "On mutual information maximization for representation learning",
        "Representation Learning with Contrastive Predictive Coding. arXiv e-prints",
        "Graph Attention Networks",
        "Deep Graph Infomax",
        "Handling distribution shifts on graphs: An invariance perspective",
        "Graph Information Bottleneck",
        "Xiangnan He, and Tat seng Chua. Discovering invariant rationales for graph neural networks",
        "Moleculenet: a benchmark for molecular machine learning",
        "Unsupervised Feature Learning via Non-Parametric Instance Discrimination",
        "InfoGCL: Information-Aware Graph Contrastive Learning",
        "How Powerful are Graph Neural Networks? In ICLR",
        "Self-supervised graph-level representation learning with local and global structure",
        "Graph Adversarial Self-Supervised Learning",
        "Towards a theoretical framework of out-of-distribution generalization",
        "Graph Contrastive Learning with Augmentations",
        "Learning View-Disentangled Human Pose Representation by Contrastive Cross-View Mutual Information Maximization",
        "An Empirical Study of Graph Contrastive Learning"
    ],
    "63896cd690e50fcafde7a0f0": [
        "Cross-Lingual Abstractive Summarization with Limited Parallel Resources",
        "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments",
        "Longformer: The longdocument transformer",
        "Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization",
        "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents",
        "MSAMSum: Towards Benchmarking Multi-lingual Dialogue Summarization",
        "Efficient Attentions for Long Document Summarization",
        "Index term weighting. Information storage and retrieval",
        "Wik-iLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization",
        "Cross-lingual C*ST*RD: English access to Hindi information",
        "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
        "A Variational Hierarchical Model for Neural Cross-Lingual Summarization",
        "ROUGE: A Package for Automatic Evaluation of Summaries",
        "TextRank: Bringing Order into Text",
        "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents",
        "Global Voices: Crossing Borders in Automatic News Summarization",
        "Evaluation of a Crosslingual Romanian-English Multi-document Summariser",
        "A Robust Abstractive System for Cross-Lingual Summarization",
        "Bleu: a Method for Automatic Evaluation of Machine Translation",
        "Models and Datasets for Cross-Lingual Summarisation",
        "Get To The Point: Summarization with Pointer-Generator Networks",
        "BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization",
        "LayerConnect: Hypernetwork-Assisted Inter-Layer Connector to Enhance Parameter Efficiency",
        "Multilingual Translation from Denoising Pre-Training",
        "Efficient Transformers: A Survey",
        "OPUS-MT -Building open translation services for the World",
        "CIDEr: Consensus-based image description evaluation",
        "Using Bilingual Information for Cross-Language Document Summarization",
        "Cross-Language Document Summarization Based on Machine Translation Quality Prediction",
        "SportsSum2.0: Generating High-Quality Sports News from Live Text Commentary",
        "Knowledge Enhanced Sports Game Summarization",
        "Clidsum: A benchmark dataset for cross-lingual dialogue summarization",
        "A survey on cross-lingual summarization",
        "GOAL: Towards Benchmarking Few-Shot Sports Game Summarization",
        "Incorporating Commonsense Knowledge into Story Ending Generation via Heterogeneous Graph Networks",
        "Mixed-Lingual Pre-training for Cross-lingual Summarization",
        "Phrase-based Compressive Cross-Language Summarization",
        "Abstractive Cross-Language Summarization via Translation Model Enhanced Predicate Argument Structure Fusing",
        "BERTScore: Evaluating Text Generation with BERT",
        "Sentence Centrality Revisited for Unsupervised Summarization",
        "NCLS: Neural Cross-Lingual Summarization"
    ],
    "62a165475aee126c0f509e38": [
        "Monophily in social networks introduces similarity among friends-of-friends",
        "Beyond low-frequency information in graph convolutional networks",
        "Translating embeddings for modeling multi-relational data",
        "Exploiting domain-specific features to enhance domain generalization",
        "Simple and deep graph convolutional networks",
        "Adaptive universal generalized pagerank graph neural network",
        "How well do self-supervised models transfer?",
        "Learning robust representations via multi-view information bottleneck",
        "Unsupervised representation learning by predicting image rotations",
        "Bootstrap your own latent-a new approach to self-supervised learning",
        "node2vec: Scalable feature learning for networks",
        "Graphite: Iterative generative modeling of graphs",
        "Inductive representation learning on large graphs",
        "Representation learning on graphs: Methods and applications",
        "Contrastive multi-view representation learning on graphs",
        "Momentum contrast for unsupervised visual representation learning",
        "Strategies for pre-training graph neural networks",
        "Categorical reparameterization with gumbel-softmax",
        "Universal graph convolutional networks",
        "Selfsupervised learning on graphs: Deep insights and new direction",
        "Node similarity preserving graph convolutional networks",
        "Adam: A method for stochastic optimization",
        "Auto-encoding variational bayes",
        "Variational graph auto-encoders",
        "Semi-supervised classification with graph convolutional networks",
        "Disentangled contrastive learning on graphs",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "New benchmarks for learning on nonhomophilous graphs",
        "Independence promoted graph disentangled networks",
        "Disentangled graph convolutional networks",
        "Netprobe: a fast and scalable system for fraud detection in online auction networks",
        "Geom-gcn: Geometric graph convolutional networks",
        "Graph representation learning via graphical mutual information maximization",
        "Deepwalk: Online learning of social representations",
        "On variational bounds of mutual information",
        "struc2vec: Learning node representations from structural identity",
        "Multi-scale attributed node embedding",
        "Collective classification in network data",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "Line: Large-scale information network embedding",
        "Large-scale representation learning on graphs via bootstrapping",
        "Elements of information theory",
        "Augmentations in graph contrastive learning: Current methodological flaws &amp; towards better practices",
        "Demystifying self-supervised learning: An information-theoretical framework",
        "Graph attention networks",
        "Deep graph infomax",
        "Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance",
        "Unsupervised feature learning via nonparametric instance discrimination",
        "Learning how to propagate messages in graph neural networks",
        "Representation learning on graphs with jumping knowledge networks",
        "Diverse message passing for attribute with heterophily",
        "Factorizable graph convolutional networks",
        "Graph contrastive learning with augmentations",
        "When does self-supervision help graph convolutional networks?",
        "From canonical correlation analysis to self-supervised graph neural networks",
        "Exploring edge disentanglement for node classification",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "An empirical study of graph contrastive learning",
        "Graph contrastive learning with adaptive augmentation",
        "Prioritizing network communities"
    ],
    "62393e7f5aee126c0f1260e9": [
        "MSCOCO WikiAns",
        "q sem ↑ q syn ↑ q lex ↑ Self-BLEU↓ q sem ↑ q syn ↑ q lex ↑ Self-BLEU↓ q sem ↑ q syn ↑ q lex ↑ Self-BLEU↓ Gold",
        "Generating sentences from disentangled syntactic and semantic spaces",
        "Controllable paraphrase generation with a syntactic exemplar",
        "Electra: Pre-training text encoders as discriminators rather than generators",
        "Applied nonparametric statistics pws",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Open question answering over curated and extracted knowledge bases",
        "Open Question Answering Over Curated and Extracted Knowledge Bases",
        "Unsupervised contextual paraphrase generation using lexical control and reinforcement learning",
        "Neural syntactic preordering for controlled paraphrase generation",
        "Effective parallel corpus mining using bilingual sentence embeddings",
        "A deep generative framework for paraphrase generation",
        "Factorising meaning and form for intent-preserving paraphrasing",
        "Large-scale, diverse, paraphrastic bitexts via sampling and clustering",
        "Adversarial example generation with syntactically controlled paraphrase networks",
        "Transformers to learn hierarchical contexts in multiparty dialogue for span-based question answering",
        "Decomposable neural paraphrase generation",
        "Microsoft coco: Common objects in context",
        "Unsupervised paraphrasing by simulated annealing",
        "Unsupervised paraphrasing by simulated annealing",
        "The natural language decathlon: Multitask learning as question answering",
        "The components of paraphrase evaluations",
        "Unsupervised paraphrase generation via dynamic blocking",
        "Bleu: a method for automatic evaluation of machine translation",
        "Paraphrase diversification using counterfactual debiasing",
        "Exploring diverse expressions for paraphrase generation",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
        "Making monolingual sentence embeddings multilingual using knowledge distillation",
        "A neural attention model for abstractive sentence summarization",
        "BLEURT: Learning robust metrics for text generation"
    ],
    "630ed16690e50fcafd793a2d": [
        "Cnvlutin: Ineffectual-neuron-free deep neural network computing",
        "Post training 4-bit quantization of convolutional networks for rapid-deployment",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "Efficient 8-bit quantization of transformer neural machine language translation model",
        "Language models are few-shot learners",
        "Zeroq: A novel zero shot quantization framework",
        "Rethinking differentiable search for mixed-precision neural networks",
        "A dynamically configurable coprocessor for convolutional neural networks",
        "Prophet: Precise qos prediction on non-preemptive accelerators to improve utilization in warehouse-scale computers",
        "Baymax: Qos awareness and increased utilization for non-preemptive accelerators in warehouse scale computers",
        "TVM: an automated end-to-end optimizing compiler for deep learning",
        "Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning",
        "Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks",
        "Dadiannao: A machinelearning supercomputer",
        "Pact: Parameterized clipping activation for quantized neural networks",
        "Lazy batching: An slaaware batching system for cloud machine learning inference",
        "Lowbit quantization of neural networks for efficient inference",
        "Natural language processing",
        "Ebird: Elastic batch for improving responsiveness and throughput of deep learning services",
        "DVABatch: Diversity-aware Multi-Entry Multi-Exit batching for efficient processing of DNN services on GPUs",
        "Imagenet: A large-scale hierarchical image database",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Hawq-v2: Hessian aware trace-weighted quantization of neural networks",
        "Hawq: Hessian aware quantization of neural networks with mixed-precision",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Shidiannao: Shifting vision processing closer to the sensor",
        "Lowlatency proactive continuous vision",
        "Ptolemy: Architecture support for robust deep learning",
        "Ai and memory wall",
        "A 240 g-ops/s mobile coprocessor for deep neural networks",
        "How far does bert look at: Distance-based clustering and analysis of bert s attention",
        "Transkimmer: Transformer learns to layer-wise skim",
        "Block-skim: Efficient question answering for transformer",
        "Accelerating sparse dnn models without hardware-support via tile-wise sparsity",
        "SQuant: On-the-fly data-free quantization via diagonal hessian approximation",
        "Balancing Efficiency and Flexibility for DNN Acceleration via Temporal GPU-Systolic Array Integration",
        "Deep learning with limited numerical precision",
        "Beating floating point at its own game: Posit arithmetic",
        "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",
        "Learning both weights and connections for efficient neural networks",
        "Deep residual learning for image recognition",
        "Quantization and training of neural networks for efficient integer-arithmetic-only inference",
        "Biscaled-dnn: Quantizing longtailed datastructures with two scale factors for deep neural networks",
        "TASO: optimizing deep learning computation with automatic generation of graph substitutions",
        "Digital image processing: An algorithmic approach",
        "In-datacenter performance analysis of a tensor processing unit",
        "Learning to quantize deep networks by optimizing quantization intervals with task loss",
        "Ieee standard 754 for binary floating-point arithmetic",
        "Imagenet classification with deep convolutional neural networks",
        "Logic synthesis using Synopsys?",
        "Asymmetric resilience: Exploiting task-level idempotency for transient error recovery in accelerator-based systems",
        "Additive powers-of-two quantization: An efficient non-uniform discretization for neural networks",
        "Mqbench: Towards reproducible and deployable model quantization benchmark",
        "VELTAIR: towards high-performance multi-tenant deep learning services via adaptive compilation and scheduling",
        "Heracles: improving resource efficiency at scale",
        "Bubble-up: increasing utilization in modern warehouse scale computers via sensible co-locations",
        "Mixed precision training",
        "Convolutional neural networks using logarithmic data representation",
        "Cacti 6.0: A tool to model large caches",
        "Up or down? adaptive rounding for post-training quantization",
        "A white paper on neural network quantization",
        "Reduct: Keep it close, keep it cool!: Efficient scaling of dnn inference on multi-core cpus with near-cache compute",
        "Tensorrt: A c++ library for high performance inference on nvidia gpus and deep learning accelerators",
        "Nvidia a100 tensor core architecture",
        "An algorithmic and novel design of a leading zero detector circuit: Comparison with logic synthesis",
        "Energy-efficient neural network accelerator based on outlier-aware low-precision computation",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Memory-centric accelerator design for convolutional neural networks",
        "Sigma: A sparse and irregular gemm accelerator with flexible interconnects for dnn training",
        "Adversarial defense through network profiling based path extraction",
        "Deepscaletool: A tool for the accurate estimation of technology scaling in the deepsubmicron era",
        "From highlevel deep neural models to fpgas",
        "Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural network",
        "Q-bert: Hessian based ultra low precision quantization of bert",
        "Very deep convolutional networks for large-scale image recognition",
        "Drq: dynamic region-based quantization for deep neural network acceleration",
        "Rethinking the inception architecture for computer vision",
        "Algorithm-hardware co-design of adaptive floating-point encodings for resilient deep learning inference",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "Spatten: Efficient sparse attention architecture with cascade token and head pruning",
        "Haq: Hardwareaware automated quantization with mixed precision",
        "Dual-side sparse tensor core",
        "Learning channel-wise interactions for binary convolutional neural networks",
        "Bubble-flux: precise online qos management for increased utilization in warehouse scale computers",
        "Forms: finegrained polarized reram-based in-situ computation for mixedsignal dnn accelerator",
        "Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference",
        "Q8bert: Quantized 8bit bert",
        "Optimizing fpga-based accelerator design for deep convolutional neural networks",
        "Lq-nets: Learned quantization for highly accurate and compact deep neural networks",
        "Cambricon-x: An accelerator for sparse neural networks",
        "Cambricon-f: machine learning computers with",
        "Flextensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "Ansor: Generating high-performance tensor programs for deep learning",
        "Incremental network quantization: Towards lossless cnns with lowprecision weights",
        "Dorefanet: Training low bitwidth convolutional neural networks with low bitwidth gradients",
        "Cambricon-s: Addressing irregularity in sparse neural networks through a cooperative software/hardware approach",
        "Characterizing and demystifying the implicit convolution algorithm on commercial matrixmultiplication accelerators",
        "ROLLER: Fast and efficient tensor compilation for deep learning",
        "Sparse tensor core: Algorithm and hardware co-design for vector-wise sparse neural networks on modern gpus",
        "Effective training of convolutional neural networks with low-bitwidth weights and activations"
    ],
    "62a2b6955aee126c0f4d8e7b": [
        "None",
        "None",
        "Food-101-mining discriminative components with random forests",
        "Language models are few-shot learners",
        "Autoformer: Searching transformers for visual recognition",
        "Remote sensing image scene classification: Benchmark and state of the art",
        "Describing textures in the wild",
        "Imagenet: A large-scale hierarchical image database",
        "Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories",
        "Vision meets robotics: The kitti dataset",
        "Towards a unified view of parameter-efficient transfer learning",
        "Deep residual learning for image recognition",
        "Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification",
        "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "Natural adversarial examples",
        "Parameter-efficient transfer learning for nlp",
        "Low-rank adaptation of large language models",
        "None",
        "Clevr: A diagnostic dataset for compositional language and elementary visual reasoning",
        "Kaggle diabetic retinopathy detection",
        "3d object representations for finegrained categorization",
        "Learning multiple layers of features from tiny images",
        "Learning methods for generic object recognition with invariance to pose and lighting",
        "The power of scale for parameter-efficient prompt tuning",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Darts: Differentiable architecture search",
        "Prompt distribution learning",
        "Finegrained visual classification of aircraft",
        "Unipelt: A unified framework for parameter-efficient language model tuning",
        "dsprites: Disentanglement testing sprites dataset",
        "Reading digits in natural images with unsupervised feature learning",
        "A visual vocabulary for flower classification",
        "Cats and dogs",
        "Efficient neural architecture search via parameters sharing",
        "Learning transferable visual models from natural language supervision",
        "Large-scale evolution of image classifiers",
        "Do imagenet classifiers generalize to imagenet",
        "Jost Tobias Springenberg, et al. A generalist agent",
        "Attention is all you need",
        "Rotation equivariant CNNs for digital pathology",
        "Learning robust global representations by penalizing local predictive power",
        "Sun database: Large-scale scene recognition from abbey to zoo",
        "A new foundation model for computer vision",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "Visualizing and understanding convolutional networks",
        "A large-scale study of representation learning with the visual task adaptation benchmark",
        "Building mega-scale vision dataset continually with human-machine synergy",
        "Factual probing is [mask]: Learning vs. learning to recall",
        "Domain generalization: A survey",
        "Learning to prompt for vision-language models",
        "Conditional prompt learning for vision-language models",
        "Learning generalisable omni-scale representations for person re-identification",
        "Neural architecture search with reinforcement learning",
        "Learning transferable architectures for scalable image recognition"
    ],
    "6389d6b590e50fcafdfead12": [
        "Software Optimization Guide for AMD EPYC™ 7003 Processors",
        "ARM Architecture Reference Manual ARMv8-A",
        "Arm ® Cortex™-A77 Core Software Optimization Guide",
        "Arm ® Neoverse™-N2 Core Software Optimization Guide",
        "Filter caching for free: The untapped potential of the store buffer",
        "Fat loads: Exploiting locality amongst contemporaneous load operations to optimize cache accesses",
        "The renewed case for the reduced instruction set computer: Avoiding isa bloat with macro-op fusion for risc-v",
        "Memory dependence prediction using store sets",
        "Two techniques to enhance the performance of memory consistency models",
        "Processor Microarchitecture: An Implementation Perspective, ser. Synthesis Lectures on Computer Architecture",
        "Mibench: A free, commercially representative embedded benchmark suite",
        "Intel ® 64 and IA-32 Architectures Optimization Reference Manual",
        "Intel ® 64 and IA-32 Architectures Software Developer's Manual, Pub 325383-076us",
        "Reducing cache traffic and energy with macro data load",
        "The alpha 21264 microprocessor architecture",
        "Macro-op scheduling: Relaxing scheduling loop constraints",
        "Implementing optimizations at decode time",
        "Streamlining inter-operation memory communication via data dependence prediction",
        "Reducing data cache energy consumption via cached load/store queue",
        "Probabilistic counter updates for predictor hysteresis and stratification",
        "None",
        "On high-bandwidth data cache design for multi-issue processors",
        "Non-speculative store coalescing in total store order",
        "Journal of Instruction-Level Parallelism (JILP) Special Issue: The Second Championship Branch Prediction Competition (CBP-2)",
        "The L-TAGE branch predictor",
        "Design tradeoffs for the alpha ev8 conditional branch predictor",
        "A case for (partially) tagged geometric history length branch prediction",
        "Standard Performance Evaluation Corporation",
        "Combining load or store instructions",
        "Design of the RISC-V instruction set architecture",
        "Increasing cache port efficiency for dynamic superscalar microprocessors",
        "Two-level adaptive training branch prediction"
    ],
    "63608e5090e50fcafdee1257": [
        "Intrinsic dimensionality explains the effectiveness of language model fine-tuning",
        "A framework for learning predictive structures from multiple tasks and unlabeled data",
        "Scalable training of L1-regularized log-linear models",
        "BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "Language models are few-shot learners",
        "Revisiting parameterefficient tuning: Are we really there yet? arXiv preprint",
        "Recall and learn: Fine-tuning deep pretrained language models with less forgetting",
        "Editing factual knowledge in language models",
        "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models",
        "Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping",
        "Transformer feed-forward layers are key-value memories",
        "Accurate, large minibatch sgd: Training imagenet in 1 hour",
        "Parameter-efficient transfer learning with diff pruning",
        "Don't stop pretraining: Adapt language models to domains and tasks",
        "Algorithms on Strings, Trees and Sequences",
        "Towards a unified view of parameter-efficient transfer learning",
        "Masked autoencoders are scalable vision learners",
        "Deberta: Decoding-enhanced bert with disentangled attention",
        "Long short-term memory",
        "Parameter-efficient transfer learning for nlp",
        "Universal language model fine-tuning for text classification",
        "Lora: Low-rank adaptation of large language models",
        "Attention is not explanation",
        "What does bert learn about the structure of language?",
        "SMART: Robust and efficient fine-tuning for pretrained natural language models through principled regularized optimization",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Overcoming catastrophic forgetting in neural networks",
        "Fine-tuning can distort pretrained features and underperform out-ofdistribution",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Mixout: Effective regularization to finetune large-scale pretrained language models",
        "What would elsa do? freezing layers during transformer fine-tuning",
        "The power of scale for parameter-efficient prompt tuning",
        "Measuring the intrinsic dimension of objective landscapes",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Linguistic knowledge and transferability of contextual representations",
        "P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks",
        "Gpt understands, too",
        "A robustly optimized bert pretraining approach",
        "Cutting down on prompts and parameters: Simple few-shot learning with language models",
        "Decoupled weight decay regularization",
        "Learning sparse neural networks through l_0 regularization",
        "Catastrophic interference in connectionist networks: The sequential learning problem",
        "Locating and editing factual knowledge in gpt",
        "Intermediate-task transfer learning with pretrained language models: When and why does it work?",
        "Learning transferable visual models from natural language supervision",
        "Tim Salimans, and Ilya Sutskever. a. Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Know what you don't know: Unanswerable questions for squad",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Yara parser: A fast and accurate dependency parser",
        "A primer in bertology: What we know about how bert works",
        "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
        "Is attention interpretable? arXiv preprint",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Attention is all you need",
        "Overcoming catastrophic forgetting in zero-shot cross-lingual generation",
        "Bertnesia: Investigating the capture and forgetting of knowledge in bert",
        "Superglue: A stickier benchmark for general-purpose language understanding systems",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "Attention is not not explanation",
        "Huggingface's transformers: State-of-the-art natural language processing",
        "Raise a child in large language model: Towards effective and generalizable fine-tuning",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Kformer: Knowledge injection in transformer feed-forward layers",
        "How transferable are features in deep neural networks? Advances in neural information processing systems",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked languagemodels"
    ],
    "628ef0495aee126c0f82db2f": [
        "TACRED revisited: A thorough evaluation of the TACRED relation extraction task",
        "Do not have enough data? deep learning to the rescue! In Proceedings of AAAI",
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Language models are few-shot learners",
        "N-gram counts and language models from the common crawl",
        "H-FND: hierarchical false-negative denoising for distant supervision relation extraction",
        "HacRED: A largescale relation extraction dataset toward hard cases in practical applications",
        "RelationPrompt: leveraging prompts to generate synthetic data for zero-shot relation triplet extraction",
        "Unsupervised cross-lingual representation learning at scale",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "An end-to-end model for entity-level relation extraction using multiinstance learning",
        "Manual evaluation matters: Reviewing test protocols of distantly supervised relation extraction",
        "FewRel 2.0: Towards more challenging few-shot relation classification",
        "More data, more relations, more context and more openness: A review and outlook for relation extraction",
        "Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation",
        "Knowing false negatives: An adversarial training method for distantly supervised relation extraction",
        "Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals",
        "Does recommend-revise produce reliable annotations? an analysis on missing instances in DocRED",
        "Data augmentation using pre-trained transformer models",
        "Roberta: A robustly optimized bert pretraining approach",
        "Distant supervision for relation extraction without labeled data",
        "Relation extraction with matrix factorization and universal schemas",
        "The New York Times annotated corpus. Linguistic Data Consortium",
        "Generating datasets with pretrained language models",
        "Document-level relation extraction with adaptive focal loss and knowledge distillation",
        "ACE 2005 multilingual training corpus. Linguistic Data Consortium",
        "Symbolic knowledge distillation: from general language models to commonsense models",
        "Generative data augmentation for commonsense reasoning",
        "DocRED: a large-scale document-level relation extraction dataset",
        "Document-level relation extraction as semantic segmentation",
        "Positionaware attention and supervised data improve slot filling",
        "MELM: data augmentation with masked entity language modeling for cross-lingual NER",
        "An improved baseline for sentence-level relation extraction",
        "But this relation is not in the DocRED's label space. In this case, the architect relation shall be excluded from DocRED. However, annotators from Huang et al. (2022) uses creator to describe this kind of relation, which is not precise. Document: Sir David Alan Chipperfield ( born 18 December 1953 ) is an English architect . He established David Chipperfield Architects in 1985",
        "the Neues Museum",
        "Wrong Triples: (Museo Jumex, David Alan Chipperfield, creator), (River and Rowing Museum, David Alan Chipperfield, creator), (Museum of Modern Literature, David Alan Chipperfield, creator), (Saint Louis Art Museum, David Alan Chipperfield, creator), (Hepworth Wakefield gallery, David Alan Chipperfield, creator), (Neues Museum, David Alan Chipperfield, creator) Example 2 Misunderstanding of Definition: series vs. part of Error Cause: Annotator's Misunderstanding of Wikidata Relation Definition Document: Chapman Square is the debut studio album released by four piece British band Lawson . The album was released on 19 October 2012 via Polydor Records . The album includes their three top ten singles \" When She Was Mine",
        "Ia?i ) , was a Moldavian Romanian writer , literary critic and publicist . Russo is credited with having discovered one of the most elaborate forms of the Romanian national folk ballad Miori?a . He was also a contributor to the Ia?i periodical Zimbrul , in which he published one of his best -known works , Studie Moldovan?",
        "Example 4 Error Type 3: Slippery slope Error Cause: Improper reasoning based on punctuations for judgement of date of birth/death. Document: South Wigston High School was founded in 1938 and is a school serving the local community of South Wigston . Today the school is an 11 ??? 16 yrs Academy . The main feeder primary schools are Glen Hills , Fairfield and Parkland . The school also attracts students from many areas of the city of Leicester and the county of Leicestershire . The school is oversubscribed and is growing year on year . South Wigston is known for its wide range of extra -curricular opportunities and for being a school that is inclusive and at the heart of the community . The school has extensive grounds and a purpose build sports centre opened by Gary Lineker",
        "date of birth), (Brett Deacon, 1996, date of death), (Brett Deacon, 1992, date of birth), (Sue Townsend, 1946, date of birth), (Sue Townsend, 1950, date of death), (Louis Deacon, 1995, date of death) Table 9: Examples for the common error types by"
    ],
    "622819cdd18a2b26c7ab496a": [
        "Augmented natural language for generative sequence labeling",
        "Unilmv2: Pseudo-masked language models for unified language model pre-training",
        "PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Contextconditioned Generation",
        "Language Models are Few-Shot Learners",
        "Boolq: Exploring the surprising difficulty of natural yes/no questions",
        "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators",
        "The pascal recognising textual entailment challenge",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Enabling language models to fill in the blanks",
        "Unified language model pre-training for natural language understanding and generation",
        "Learning to Ask: Neural Question Generation for Reading Comprehension",
        "The Pile: An 800gb dataset of diverse text for language modeling",
        "None",
        "Bridging nonlinearities and stochastic regularizers with gaussian error linear units",
        "SpanBERT: Improving Pre-training by Representing and Predicting Spans",
        "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences",
        "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
        "The winograd schema challenge",
        "BART: Denoising Sequence-to-Sequence Pretraining for Natural Language Generation, Translation, and Comprehension",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Distributed representations of words and phrases and their compositionality",
        "Structured prediction as translation between augmented natural languages",
        "The LAMBADA dataset: Word prediction requiring a broad discourse context",
        "Glove: Global Vectors for Word Representation",
        "Wic: the word-in-context dataset for evaluating context-sensitive meaning representations",
        "Improving Language Understanding by Generative Pre-Training",
        "Language models are unsupervised multitask learners",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Squad: 100, 000+ questions for machine comprehension of text",
        "Choice of plausible alternatives: An evaluation of commonsense causal reasoning",
        "A neural attention model for abstractive sentence summarization",
        "It's not just size that matters: Small language models are also few-shot learners",
        "Exploiting cloze questions for few-shot text classification and natural language inference",
        "Blank language models",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "MASS: Masked Sequence to Sequence Pre-training for Language Generation",
        "Simple Method for Commonsense Reasoning",
        "Attention is all you need",
        "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems",
        "XLNet: Generalized Autoregressive Pretraining for Language Understanding",
        "Improved variational autoencoders for text modeling using dilated convolutions",
        "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization",
        "Record: Bridging the gap between human and machine commonsense reading comprehension",
        "Addressing semantic drift in question generation for semisupervised question answering",
        "None",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books"
    ],
    "623d90d46750f864fe4cafd6": [
        "Layer normalization",
        "Predicting structured data",
        "Statistical analysis of non-lattice data. The statistician",
        "Simple and deep graph convolutional networks",
        "Understanding deep architecture with reasoning layer",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "A stochastic parts program and noun phrase parser for unrestricted text",
        "Fast and accurate deep network learning by exponential linear units (elus)",
        "Discriminative embeddings of latent variable models for structured data",
        "Fast graph representation learning with PyTorch Geometric",
        "Training structural svms when exact inference is intractable",
        "Graph u-nets",
        "Large-scale learnable graph convolutional networks",
        "Neural message passing for quantum chemistry",
        "Inductive representation learning on large graphs",
        "Multiscale conditional random fields for image labeling",
        "Adam: A method for stochastic optimization",
        "Semi-supervised classification with graph convolutional networks",
        "Probabilistic graphical models: principles and techniques",
        "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
        "Neural architectures for named entity recognition",
        "Deepgcns: Can gcns go as deep as cnns",
        "Empower sequence labeling with task-aware neural language model",
        "A flexible generative framework for graph-based semi-supervised learning",
        "Copulagnn: Towards integrating representational and correlational roles of graphs in graph neural networks",
        "Conditional graph neural fields. ICLR Submission",
        "End-to-end sequence labeling via bi-directional lstm-cnns-crf",
        "Loopy belief propagation for approximate inference: An empirical study",
        "Rectified linear units improve restricted boltzmann machines",
        "Glove: Global vectors for word representation",
        "Gmnn: Graph markov neural networks",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "Accurate max-margin training for structured output spaces",
        "Neural enhanced belief propagation on factor graphs",
        "Combining generative and discriminative models for hybrid inference",
        "Shallow parsing with conditional random fields",
        "An introduction to conditional random fields for relational learning. Introduction to statistical relational learning",
        "Piecewise training for structured prediction",
        "An Introduction to Conditional Random Fields",
        "Arnetminer: extraction and mining of academic social networks",
        "Large margin methods for structured and interdependent output variables",
        "Graph attention networks",
        "Graphical models, exponential families, and variational inference",
        "Tree-reweighted belief propagation algorithms and approximate ml estimation by pseudo-moment matching",
        "Semi-supervised node classification on graphs: Markov random fields vs. graph neural networks",
        "On the optimality of solutions of the max-product beliefpropagation algorithm in arbitrary graphs",
        "Continuous graph neural networks",
        "Revisiting semi-supervised learning with graph embeddings",
        "Constructing free-energy approximations and generalized belief propagation algorithms",
        "Graphsaint: Graph sampling based inductive learning method",
        "Efficient probabilistic logic reasoning with graph neural networks",
        "Predicting multicellular function through multi-layer tissue networks"
    ],
    "634d805690e50fcafd4e07bc": [
        "Can far memory improve job throughput?",
        "Memory disaggregation: Research problems and opportunities",
        "System-level implications of disaggregated memory",
        "Efficient memory disaggregation with infiniswap",
        "Remote regions: a simple abstraction for remote memory",
        "Semeru: A memory-disaggregated managed runtime",
        "Thymesisflow: a softwaredefined, hw/sw co-designed interconnect stack for rackscale memory disaggregation",
        "Mind: In-network memory management for disaggregated data centers",
        "Clio: A hardware-software codesigned disaggregated memory system",
        "Rethinking software runtimes for disaggregated memory",
        "Disaggregating persistent memory and controlling them remotely: An exploration of passive disaggregated keyvalue stores",
        "Using rdma efficiently for key-value services",
        "Farm: Fast remote memory",
        "No compromises: Distributed transactions with consistency, availability, and performance",
        "Latency-tolerant software distributed shared memory",
        "Aifm: High-performance, application-integrated far memory",
        "Gen-Z Final Specifications",
        "Compute Express Link Specification Revision 2",
        "Compute Express Link™ 2.0 White Paper",
        "Milestone in Moving Data",
        "CXL: Coherency, Memory, and I/O Semantics on PCIe Infrastructure",
        "Compute Express Link or CXL What it is and Examples",
        "Rdma over ethernet-a preliminary study",
        "Minimizing the hidden cost of rdma",
        "Persistent Memory Developer Kit Version v1",
        "NVDIMM Namespace Specification",
        "Advanced Configuration and Power Interface (ACPI) Specification Version 6",
        "The devicetree specification",
        "ConnectX-3 FDR (56Gbps) Infini-Band VPI",
        "OpenFabrics Enterprise Distribution",
        "Liang Xiong, and Misha Smelyanskiy. Deep learning recommendation model for personalization and recommendation systems",
        "A simple parallel algorithm for the maximal independent set problem",
        "Breadth-first search",
        "Connected components in random graphs with given expected degree sequences",
        "A faster algorithm for betweenness centrality",
        "Ligra: a lightweight graph processing framework for shared memory"
    ],
    "621ee1845aee126c0f26a9df": [
        "Iron Out A Coherent Interconnect Strategy",
        "Memory Scaling: A Systems Architecture Perspective",
        "ArchShield: Architectural Framework for Assisting DRAM Scaling by Tolerating High Error Rates",
        "Main Memory Scaling: Challenges and Solution directions",
        "Technology Scaling Challenge and Future Prospects of DRAM and NAND Flash Memory",
        "Scaling and Performance Challenges of Future DRAM",
        "The Next New Memories",
        "Micron Ends 3D XPoint Memory",
        "Evaluating Job Packing in Warehouse-scale Computing",
        "the Next Generation",
        "Network Requirements for Resource Disaggregation",
        "Remote Memory in the Age of Fast Networks",
        "Thymes-isFlow: A Software-Defined, HW/SW Co-Designed Interconnect Stack for Rack-Scale Memory Disaggregation",
        "Page Fault Support for Network Controllers",
        "SR-IOV Networking in Xen: Architecture, Design and Implementation",
        "Welcome to Zombieland: Practical and Energy-efficient Memory Disaggregation in a Datacenter",
        "Project PBerry: FPGA Acceleration for Remote Memory",
        "Rack-scale Disaggregated Cloud Data Centers: The dReDBox Project Vision",
        "Disaggregated Memory for Expansion and Sharing in Blade Servers",
        "AIFM: High-Performance, Application-Integrated Far Memory",
        "Semeru: A Memory-Disaggregated Managed Runtime",
        "Rethinking Software Runtimes for Disaggregated Memory",
        "FaRM: Fast Remote Memory",
        "Remote Regions: a Simple Abstraction for Remote Memory",
        "Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores",
        "Disaggregated Memory with Operator Offloading for Database Engines",
        "System-level Implications of Disaggregated Memory",
        "Efficient Memory Disaggregation with Infiniswap",
        "Le-goOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation",
        "Software-Defined Far Memory in Warehouse-Scale Computers",
        "Disaggregated Cloud Memory with Elastic Block Management",
        "Can Far Memory Improve Job Throughput?",
        "Effectively Prefetching Remote Memory with Leap",
        "FluidMem: Full, Flexible, and Fast Memory Disaggregation for the Cloud",
        "Hierarchical Orchestration of Disaggregated Memory",
        "Mitigating the Performance-Efficiency Tradeoff in Resilient Memory Disaggregation",
        "The Breakthrough CPU-to-Device Interconnect",
        "Sapphire Rapids Uncovered: 56 Cores, 64GB HBM2E, Multi-Chip Design",
        "CXL Consortium Member Spotlight: Arm",
        "AMD Unveils Workload-Tailored Innovations and Products at The Accelerated Data Center Premiere",
        "Samsung Unveils Industry-First Memory Module Incorporating New CXL Interconnect Standard",
        "None",
        "CXL May Have Just Won as AMD Joins CXL",
        "Autonuma: the other approach to numa scheduling",
        "vnuma-mgr: Managing vm memory on numa platforms",
        "Optimizing Virtual Machine Consolidation Performance on NUMA Server Architecture for Cloud Workloads",
        "Scalable Tiered Memory Management for Big Data Applications and Real NVM",
        "Nimble Page Management for Tiered Memory Systems",
        "Linux Memory Management Documentation -zswap",
        "Thermostat: Applicationtransparent Page Management for Two-tiered Main Memory",
        "Page Placement in Hybrid Memory Systems",
        "The-Flavors-of-Memory-Su pported-by-Linux-their-Use-and-Benefit-Christoph-Lameter-Jump-Trading-LLC.pdf",
        "Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms",
        "Protean: VM Allocation Service at Scale",
        "Large-scale cluster management at Google with Borg",
        "Heuristics for Vector Bin Packing",
        "Multi-Resource Packing for Cluster Schedulers",
        "Tight Bounds for Online Vector Bin Packing",
        "SmartHarvest: Harvesting Idle CPUs Safely and Efficiently in the Cloud",
        "Sameh Elnikety, Marcus Fontoura, and Ricardo Bianchini. Providing SLOs for Resource-Harvesting VMs in Cloud Platforms",
        "Coordinated and Efficient Huge Page Management with Ingens",
        "Making Huge Pages Actually Useful",
        "Benchmarking Cloud Serving Systems with YCSB",
        "HiBench: The Bigdata Micro Benchmark Suite",
        "The gap benchmark suite",
        "None",
        "The PARSEC Benchmark Suite: Characterization and Architectural Implications",
        "PAR-SEC3.0: A Multicore Benchmark Suite with Network Stacks and SPLASH-2X",
        "Firecracker: Lightweight Virtualization for Serverless Applications",
        "LeapIO: Efficient and Portable Virtual NVMe Storage on ARM SoCs",
        "Single-Root Input/Output Virtualization",
        "coIOMMU: A Virtual IOMMU with Cooperative DMA Buffer Tracking for Efficient Memory Management in Direct I/O",
        "On the DMA Mapping Problem in Direct Device Assignment",
        "Protection Strategies for Direct Access to Virtualized I/O Devices",
        "Proceedings of the 2011 USENIX Annual Technical Conference (ATC)",
        "The Turtles Project: Design and Implementation of Nested Virtualization",
        "Vm live migration at scale",
        "CXL Specification",
        "RAS) Integration and Validation Guide for the Intel Xeon Processor E7 Family",
        "AMD EPYC brings new RAS capability",
        "CXL Use-cases Driving the Need For Low Latency Performance Retimers",
        "Enabling PCIe 5.0 System Level Testing and Low Latency Mode for CXL",
        "New tau vms deliver leading price-performance for scaleout workloads",
        "Amazon ec2 m6g instances",
        "Use Single-Socket Servers to Reduce Costs in the Data Center",
        "Why Single-socket Servers Could Rule the Future",
        "MIPI I3C Bus Sensor Specification",
        "Advanced Configuration and Power Interface Specification",
        "AutoNUMA: Optimize Memory Placement for Memory Tiering System",
        "A Top-Down Method for Performance Analysis and Counters Architecture",
        "Top-down Microarchitecture Analysis Method",
        "Top-Down Characterization Approximation Based on Performance Counters Architecture for AMD Processors",
        "Machine Learning in Virtualization: Estimate a Virtual Machine's Working Set Size",
        "More Accurate Estimation of Working Set Size in Virtual Machines",
        "Scikit-learn: Machine Learning in Python",
        "Lightgbm: A Highly Efficient Gradient Boosting Decision Tree",
        "Neural Network Exchange: the Open Standard for Machine Learning Interoperability",
        "Tensorflow-serving: Flexible, High-performance ML Serving",
        "Clipper: A Low-Latency Online Prediction Serving System",
        "Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms",
        "Communications of the ACM",
        "Paragon: Qos-aware scheduling for heterogeneous datacenters",
        "Tarcil: Reconciling Scheduling Speed and Quality in Large Shared Clusters",
        "Omega: flexible, scalable schedulers for large compute clusters",
        "Large-scale Cluster Management at Google with Borg",
        "None",
        "None",
        "The Relationship Between Recall and Precision",
        "A Hardware-Software Co-Designed Disaggregated Memory System",
        "Optically Connected Memory for Disaggregated Data Centers",
        "None",
        "MIND: In-Network Memory Management for Disaggregated Data Centers",
        "Using RDMA Efficiently for Key-Value Services",
        "Scale-Out ccNUMA: Exploiting Skew with Strongly Consistent Caching",
        "The End of a Myth: Distributed Transactions Can Scale",
        "HeteroOS: OS Design for Heterogeneous Memory Management in Datacenters",
        "Exploiting the Byte-Accessibility of SSDs within a Unified Memory-Storage Hierarchy",
        "Exploring the Design Space of Page Management for Multi-Tiered Memory Sys-tems",
        "Learning on Distributed Traces for Data Center Storage Systems",
        "Learning-based Memory Allocation for C++ Server Workloads",
        "Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices",
        "A Hierarchical Neural Model of Data Prefetching",
        "Applying Deep Learning to the Cache Replacement Problem",
        "The SGI Origin: A ccNUMA Highly Scalable Server",
        "Thread and Memory Placement on NUMA Systems: Asymmetry Matters",
        "Implementation and Performance of Munin",
        "Memory Coherence in Shared Virtual Memory Systems"
    ],
    "63438d2990e50fcafd4ebd66": [
        "Nvdla deep learning accelerator",
        "Reinforcement learning and adaptive sampling for optimized dnn compilation",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "Once-for-all: Train one network and specialize it for efficient deployment",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Marvel: A data-centric compiler for dnn operators on spatial accelerators",
        "Learning to optimize tensor programs",
        "Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks",
        "Eyeriss v2: A flexible accelerator for emerging deep neural networks on mobile devices",
        "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks",
        "Generating long sequences with sparse transformers",
        "Dmazerunner: Executing perfectly nested loops on dataflow accelerators",
        "Tangram: Optimized coarse-grained dataflow for scalable nn accelerators",
        "Tetris: Scalable and efficient neural network acceleration with 3d memory",
        "Polly-polyhedral optimization in llvm",
        "Reweighted proximal pruning for large-scale language representation",
        "The cma evolution strategy: a comparing review",
        "Deep residual learning for image recognition",
        "Mind mappings: enabling efficient algorithm-accelerator mapping space search",
        "Evolution under strong noise: A self-adaptive evolution strategy can reach the lower performance bound-the pccmsaes",
        "Genetic algorithms",
        "Ruby: Improving hardware efficiency for tensor algebra accelerators through imperfect factorization",
        "Cosa: Scheduling by constrained optimization for spatial accelerators",
        "Union: A unified hwsw co-design ecosystem in mlir for evaluating tensor operations on spatial accelerators",
        "Beyond data and model parallelism for deep neural networks",
        "Smash: Codesigning software compression and hardware-accelerated indexing for efficient sparse matrix operations",
        "Confuciux: Autonomous hardware resource assignment for dnn accelerators using reinforcement learning",
        "Gamma: Automating the hw mapping of dnn models on accelerators via genetic algorithm",
        "E3: A hw/sw co-design neuroevolution platform for autonomous learning in edge device",
        "Magma: An optimization framework for mapping multiple dnns on multiple accelerator cores",
        "Digamma: Domain-aware genetic algorithm for hw-mapping co-optimization for dnn accelerators",
        "An optimized dataflow for mitigating attention performance bottlenecks",
        "Particle swarm optimization",
        "Understanding reuse, performance, and hardware cost of dnn dataflow: A data-centric approach",
        "Maestro: A data-centric approach to understand reuse, performance, and hardware cost of dnn mappings",
        "Maeri: Enabling flexible dataflow mapping over dnn accelerators via reconfigurable interconnects",
        "Stitch-x: An accelerator architecture for exploiting unstructured sparsity in deep neural networks",
        "Pruning filters for efficient convnets",
        "Progressive neural architecture search",
        "Rethinking the value of network pruning",
        "Flexflow: A flexible dataflow accelerator architecture for convolutional neural networks",
        "Zigzag: Enlarging joint architecture-mapping design space exploration for dnn accelerators",
        "Outerspace: An outer product based sparse matrix multiplication accelerator",
        "Timeloop: A systematic approach to dnn accelerator evaluation",
        "Scnn: An accelerator for compressed-sparse convolutional neural networks",
        "Buffets: An efficient and composable storage idiom for explicit decoupled data orchestration",
        "Efficient neural architecture search via parameter sharing",
        "Sigma: A sparse and irregular gemm accelerator with flexible interconnects for dnn training",
        "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "A case for efficient accelerator design space exploration via bayesian optimization",
        "Poor man's bert: Smaller and faster transformer models",
        "Scale-sim: Systolic cnn accelerator simulator",
        "Mo-bilenetv2: Inverted residuals and linear bottlenecks",
        "Simba: Scaling deep-learning inference with multichip-module-based architecture",
        "Maximizing cnn accelerator efficiency through resource partitioning",
        "Very deep convolutional networks for large-scale image recognition",
        "Hypar: Towards hybrid parallelism for deep learning accelerator array",
        "Towards efficient microarchitectural design for accelerating unsupervised gan-based deep learning",
        "Optimally scheduling cnn convolutions for efficient memory access",
        "Throughput-optimized opencl-based fpga accelerator for large-scale convolutional neural networks",
        "Mnasnet: Platform-aware neural architecture search for mobile",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "Triton: an intermediate language and compiler for tiled neural network computations",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "Attention is all you need",
        "Scaledeep: A scalable compute architecture for learning and evaluating deep networks",
        "Deeptools: Compiler and execution runtime extensions for rapid ai accelerator",
        "Spatten: Efficient sparse attention architecture with cascade token and head pruning",
        "Structured pruning of large language models",
        "Automated systolic array architecture synthesis for high throughput cnn inference on fpgas",
        "Sparseloop: An analytical, energy-focused design space exploration methodology for sparse tensor accelerators",
        "Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling",
        "Hasco: Towards agile hardware and software co-design for tensor computation",
        "Sparse reram engine: Joint exploration of activation and weight sparsity in compressed neural networks",
        "Interstellar: Using halide's scheduling language to analyze dnn accelerators",
        "Optimizing fpga-based accelerator design for deep convolutional neural networks",
        "Snap: An efficient sparse neural acceleration processor for unstructured sparse deep neural network inference",
        "Cambricon-x: An accelerator for sparse neural networks",
        "Flextensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "To prune, or not to prune: exploring the efficacy of pruning for model compression"
    ],
    "63a413f790e50fcafd6d1f93": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "On the bottleneck of graph neural networks and its practical implications",
        "Geometric deep learning: going beyond euclidean data",
        "Iterative deep graph learning for graph neural networks: Better and robust node embeddings",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Rethinking attention with performers",
        "Latent patient network learning for automatic diagnosis",
        "Learning steadystates of iterative algorithms over graphs",
        "A generalization of transformer networks to graphs",
        "Variational inference for graph convolutional networks in the absence of graph data and adversarial settings",
        "Learning discrete structures for graph neural networks",
        "Room-and-object aware knowledge reasoning for remote embodied referring expression",
        "Implicit graph neural networks",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Categorical reparameterization with gumbel-softmax",
        "Semi-supervised learning with graph learning-convolutional networks",
        "Graph structure learning for robust graph neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "New benchmarks for learning on non-homophilous graphs",
        "Learning to drop: Robust graph neural network via topological denoising",
        "The concrete distribution: A continuous relaxation of discrete random variables",
        "Inferring networks of substitutable and complementary products",
        "Scikitlearn: Machine learning in python",
        "Geom-gcn: Geometric graph convolutional networks",
        "Random features for large-scale kernel machines",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Characteristic functions on graphs: Birds of a feather, from statistical descriptors to parametric models",
        "Learning to simulate complex physics with graph networks",
        "Few-shot learning with graph neural networks",
        "The graph neural network model",
        "Collective classification in network data",
        "Fast graph attention networks using effective resistance based graph sparsification",
        "Graph structure learning with variational information bottleneck",
        "Advances in neural information processing systems",
        "Graph attention networks",
        "Matching networks for one shot learning",
        "Dynamic graph CNN for learning on point clouds",
        "Simplifying graph convolutional networks",
        "Towards open-world feature extrapolation: An inductive graph learning approach",
        "Towards open-world recommendation: An inductive model-based collaborative filtering approach",
        "Graph information bottleneck",
        "A quest for structure: Jointly learning the graph structure and semi-supervised classification",
        "Representation learning on graphs with jumping knowledge networks",
        "Graph convolutional networks for text classification",
        "GNN explainer: A tool for post-hoc explanation of graph neural networks",
        "Graphsaint: Graph sampling based inductive learning method",
        "Scalegcn: Efficient and effective graph convolution via channel-wise scale transformation",
        "Gnnguard: Defending graph neural networks against adversarial attacks",
        "Bayesian graph convolutional neural networks for semi-supervised classification",
        "Robust graph representation learning via neural sparsification",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Deep graph structure learning for robust representations: A survey"
    ],
    "632bd2a990e50fcafdb7a24d": [
        "Promptsource: An integrated development environment and repository for natural language prompts",
        "Semantic parsing on freebase from question-answer pairs",
        "Autoregressive search engines: Generating substrings as document identifiers",
        "Language models are few-shot learners",
        "Reading wikipedia to answer opendomain questions",
        "Unitedqa: A hybrid approach for open domain question answering",
        "Scaling language modeling with pathways",
        "Autoregressive entity retrieval",
        "Wizard of wikipedia: Knowledge-powered conversational agents",
        "Glam: Efficient scaling of language models with mixture-of-experts",
        "Fool me twice: Entailment from wikipedia gamification",
        "Leveraging knowledge in multilingual commonsense reasoning",
        "Entities as experts: Sparse memory access with entity supervision",
        "Retrieval augmented language model pre-training",
        "Training compute-optimal large language models",
        "The curious case of neural text degeneration",
        "Distilling knowledge from reader to retriever for question answering",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Unsupervised dense information retrieval with contrastive learning",
        "Few-shot learning with retrieval augmented language models",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "Dense passage retrieval for open-domain question answering",
        "Colbert: Efficient and effective passage search via contextualized late interaction over bert",
        "Relevance-guided supervision for openqa with colbert",
        "Large language models are zero-shot reasoners",
        "Natural questions: A benchmark for question answering research",
        "Internetaugmented language models through few-shot prompting for open-domain question answering",
        "Latent retrieval for weakly supervised open domain question answering",
        "Standing on the shoulders of giant frozen language models",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "On the advance of making language models better reasoners",
        "Generated knowledge prompting for commonsense reasoning",
        "Generation-augmented retrieval for open-domain question answering",
        "Ambigqa: Answering ambiguous open-domain questions",
        "Codex (available via openai api for free",
        "Training language models to follow instructions with human feedback",
        "Language models as knowledge bases?",
        "Kilt: a benchmark for knowledge intensive language tasks",
        "Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "How much knowledge can you pack into the parameters of a language model?",
        "The probabilistic relevance framework: Bm25 and beyond",
        "Questions are all you need to train a dense passage retriever",
        "End-to-end training of multi-document reader and retriever for open-domain question answering",
        "Transformer memory as a differentiable search index",
        "Fever: a largescale dataset for fact extraction and verification",
        "Finetuned language models are zero-shot learners",
        "Emergent abilities of large language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Kg-fid: Infusing knowledge graph in fusion-in-decoder for open-domain question answering",
        "A technical question answering system with transfer learning",
        "Crossing variational autoencoders for answer retrieval",
        "A survey of knowledge-enhanced text generation",
        "Situatedqa: Incorporating extra-linguistic contexts into qa",
        "Opt: Open pre-trained transformer language models",
        "Jianming Zheng, Soujanya Poria, and Tat-Seng Chua. Retrieving and reading: A comprehensive survey on open-domain question answering"
    ],
    "62fa0d1390e50fcafd246228": [
        "Representation Learning for Attributed Multiplex Heterogeneous Network",
        "Fast and Accurate Network Embeddings via Very Sparse Random Projection",
        "PME: projected metric embedding on heterogeneous networks for link prediction",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding",
        "node2vec: Scalable feature learning for networks",
        "Inductive Representation Learning on Large Graphs",
        "Click-Through Rate Prediction with Multi-Modal Hypergraphs",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Adversarial Learning on Heterogeneous Information Networks",
        "Heterogeneous graph transformer",
        "Recent advances in heterogeneous relation learning for recommendation",
        "Xiaoping Lai, and Yanfang Ye. 2021. Knowledge-aware coupled graph neural network for social recommendation",
        "Heterogeneous Graph Propagation Network",
        "Hdmi: High-order deep multiplex infomax",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Hierarchical bipartite graph neural networks: Towards large-scale e-commerce applications. In ICDE",
        "Principled multilayer network embedding. In ICDMW",
        "Motif-preserving dynamic attributed network embedding",
        "Fast Attributed Multiplex Heterogeneous Network Embedding",
        "Social Recommendation with Self-Supervised Metagraph Informax Network",
        "Relation structureaware heterogeneous information network embedding",
        "Unsupervised Attributed Multiplex Network Embedding",
        "DeepWalk: online learning of social representations",
        "Netsmf: Large-scale network embedding as sparse matrix factorization",
        "Modeling relational data with graph convolutional networks",
        "Heterogeneous information network embedding for recommendation",
        "Line: Large-scale information network embedding",
        "Graph Attention Networks",
        "Heterogeneous Graph Attention Network",
        "Dynamic heterogeneous information network embedding with meta-path based proximity",
        "Am-gcn: Adaptive multi-channel graph convolutional networks",
        "Contrastive meta learning with behavior multiplicity for recommendation",
        "Simplifying Graph Convolutional Networks",
        "Graph convolutional networks with markov random field reasoning for social spammer detection",
        "Multiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network",
        "Multiplex bipartite network embedding using dual hypergraph convolutional networks",
        "Scalable graph neural networks for heterogeneous graphs",
        "Graph Transformer Networks",
        "Heterogeneous graph neural network",
        "Scalable multiplex network embedding",
        "Billion-Scale Network Embedding with Iterative Random Projection",
        "Heterogeneous Graph Structure Learning for Graph Neural Networks"
    ],
    "634d805490e50fcafd4e02c8": [
        "High performance graph convolutional networks with applications in testability analysis",
        "High-speed adder design space exploration via graph neural processes",
        "Machine learning for electronic design automation: A survey",
        "Wordrev: Finding word-level structures in a sea of bit-level gates",
        "Deep learning-based circuit recognition using sparse mapping and level-dependent decaying sum circuit representations",
        "Graph learning-based arithmetic block identification",
        "How powerful are graph neural networks?",
        "Inductive representation learning on large graphs",
        "Graph attention networks",
        "Link prediction based on graph neural networks",
        "Exact-K Recommendation via Maximal Clique Optimization",
        "Deep h-gcn: Fast analog ic aging-induced degradation estimation",
        "Directed acyclic graph neural networks",
        "D-vae: A variational autoencoder for directed acyclic graphs",
        "Learning Representations by Maximizing Mutual Information Across Views",
        "A simple framework for contrastive learning of visual representations",
        "On variational bounds of mutual information",
        "Deep graph infomax",
        "Graph contrastive learning with augmentations",
        "Graph contrastive learning with adaptive augmentation",
        "What makes for good views for contrastive learning",
        "What should not be contrastive in contrastive learning",
        "On sampling strategies for neural networkbased collaborative filtering",
        "Improved deep metric learning with multi-class n-pair loss objective",
        "Formal design of arithmetic circuits based on arithmetic description language"
    ],
    "63a413f790e50fcafd6d24b3": [
        "Semi-supervised classification with graph convolutional networks",
        "Graph attention networks",
        "How powerful are graph neural networks?",
        "A meta-transfer objective for learning to disentangle causal mechanisms",
        "Graph neural network-based diagnosis prediction",
        "Using external knowledge for financial event prediction based on graph neural networks",
        "Moleculenet: a benchmark for molecular machine learning",
        "None",
        "Out-of-distribution generalization with maximal invariant predictor",
        "Invariance principle meets information bottleneck for out-of-distribution generalization",
        "Invariant rationalization",
        "Invariant models for causal transfer learning",
        "Gnnexplainer: Generating explanations for graph neural networks",
        "Parameterized explainer for graph neural network",
        "Algorithm as 136: A k-means clustering algorithm",
        "Xiangnan He, and Tat-Seng Chua. Discovering invariant rationales for graph neural networks",
        "Understanding attention and generalization in graph neural networks",
        "Gradient-based learning applied to document recognition",
        "Explainability in graph neural networks: A taxonomic survey",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Graph u-nets",
        "Self-attention graph pooling",
        "Asap: Adaptive structure aware pooling for learning hierarchical graph representations",
        "Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization",
        "Out-of-distribution generalization via risk extrapolation (rex)",
        "Interpretable and generalizable graph learning via stochastic attention mechanism",
        "Weisfeiler and lehman go cellular: Cw networks",
        "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis",
        "Visualizing data using t-sne",
        "Disentangled graph convolutional networks",
        "Intention-aware sequential recommendation with structured intent transition",
        "Disentangled contrastive learning on graphs",
        "Disentangled representation learning for recommendation",
        "Fates of microscopic social ecosystems: Keep alive or dead?",
        "Disentangled graph contrastive learning with independence promotion",
        "Gqnas: Graph q network for neural architecture search",
        "Out-of-distribution generalization on graphs: A survey",
        "A pac-bayesian approach to generalization bounds for graph neural networks",
        "Generalization and representational limits of graph neural networks",
        "Stability and generalization of graph convolutional neural networks",
        "The vapnik-chervonenkis dimension of graph and recursive neural networks",
        "Wild-time: A benchmark of in-the-wild distribution shift over time",
        "Learning to solve travelling salesman problem with hardness-adaptive curriculum",
        "Ood-gnn: Out-of-distribution generalized graph neural network",
        "Graph neural architecture search under distribution shifts",
        "Dynamic graph neural networks under spatio-temporal distribution shift",
        "How neural networks extrapolate: From feedforward to graph neural networks",
        "From local structures to size generalization in graph neural networks",
        "Size-invariant graph representations for graph classification extrapolations",
        "Shift-robust gnns: Overcoming the limitations of localized graph training data",
        "Debiased graph neural networks with agnostic label selection bias",
        "Handling distribution shifts on graphs: An invariance perspective",
        "Causal inference",
        "Causal attention for unbiased visual recognition",
        "Domain generalization using a mixture of multiple latent domains",
        "Environment inference for invariant learning",
        "Heterogeneous risk minimization"
    ],
    "62d16e8a5aee126c0fd6847a": [
        "A Comparison of Software and Hardware Techniques for x86 Virtualization",
        "Firecracker: Lightweight Virtualization for Serverless Applications",
        "Revisiting Hardwareassisted Page Walks for Virtualized Systems",
        "Do-It-Yourself Virtual Memory Translation",
        "BioBench: A Benchmark Suite of Bioinformatics Applications",
        "Enhancing and Exploiting Contiguity for Fast Memory Virtualization",
        "Elastic Compute Cloud (EC2)",
        "AMD64 Virtualization Codenamed \"Pacifica\" Technology: Secure Virtual Machine Architecture Reference Manual",
        "AMD-V 𝑇 𝑀 Nested Paging",
        "Samba: A Detailed Memory Management Unit (MMU) for the SST Simulation Framework",
        "Software Prefetching and Caching for Translation Lookaside Buffers",
        "CACTI 7: New Tools for Interconnect Exploration in Innovative Off-Chip Memories",
        "Translation Caching: Skip, Don't Walk (the Page Table)",
        "SpecTLB: A Mechanism for Speculative Address Translation",
        "Efficient Virtual Memory for Big Memory Servers",
        "Accelerating Two-dimensional Page Walks for Virtualized Systems",
        "Large-reach Memory Management Unit Caches",
        "Translation-Triggered Prefetching",
        "Shared Last-level TLBs for Chip Multiprocessors",
        "Inter-Core Cooperative TLB Prefetchers for Chip Multiprocessors",
        "Methodology for Performance Analysis of VMware vSphere under Tier-1 Applications",
        "Simulation and Analysis Engine for Scale-Out Workloads",
        "Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers",
        "Efficient Address Translation for Architectures with Multiple Page Sizes",
        "KVM/ARM: The Design and Implementation of the Linux ARM Hypervisor",
        "Optimizing the Idle Task and Other MMU Tricks",
        "The Linux/ia64 Project: Kernel Design and Status Update",
        "Space Efficient Hash Tables with Worst Case Constant Access Time. Theory of",
        "Efficient Memory Virtualization: Reducing Dimensionality of Nested Page Walks",
        "Agile Paging: Exceeding the Best of Nested and Shadow Paging",
        "Large Pages May Be Harmful on NUMA Systems",
        "None",
        "Google. 2021. gVisor: Container Runtime Sandbox",
        "Performance Characteristics of Explicit Superpage Support",
        "Itanium -A System Implementor's Tale",
        "Proactively Breaking Large Pages to Improve Memory Overcommitment Performance in VMware ESXi",
        "Tailored Page Sizes",
        "The Virtual Block Interface: A Flexible Alternative to the Conventional Virtual Memory Framework",
        "Devirtualizing Memory in Heterogeneous Systems",
        "Architectural Support for Translation Table Management in Large Address Space Machines",
        "PowerPC Microprocessor Family: The Programming Environments Manual for 32 and 64-bit Microprocessors",
        "Intel Virtualization Technology Specification for the IA-32 Intel Architecture",
        "Itanium Architecture Software Developer's Manual",
        "5-Level Paging and 5-Level EPT (White Paper",
        "Sunny Cove Microarchitecture",
        "and IA-32 Architectures Software Developer's Manual",
        "Intel® Optane™ Persistent Memory",
        "Basic Performance Measurements of the Intel Optane DC Persistent Memory Module",
        "A Look at Several Memory Management Units, TLB-refill Mechanisms, and Page Table Organizations",
        "IBM POWER9 system software",
        "Going the Distance for TLB Prefetching: An Application-driven Study",
        "Redundant Memory Mappings for Fast Access to Large Memories",
        "Energy-Efficient Address Translation",
        "Operating System Support for Virtual Machines",
        "KVM. 2021. Page Table Allocation in KVM",
        "Coordinated and Efficient Huge Page Management with Ingens",
        "Linux Kernel. 2021. Page Table Header File",
        "The HPC Challenge (HPCC) Benchmark Suite",
        "Simics: A Full System Simulation Platform",
        "CSALT: Context Switch Aware Large TLB",
        "Prefetched Address Translation",
        "CHiRP: Control-Flow History Reuse Prediction",
        "GraphBIG: Understanding Graph Computing in the Context of Industrial Solutions",
        "Cuckoo Hashing. Journal of Algorithms",
        "HawkEye: Efficient Finegrained OS Support for Huge Pages",
        "Making Huge Pages Actually Useful",
        "Perforated Page: Supporting Fragmented Memory Allocation for Large Pages",
        "Hybrid TLB Coalescing: Improving TLB Translation Coverage under Diverse Fragmented Memory Allocations",
        "Increasing TLB Reach by Exploiting Clustering in Page Translations",
        "Aamer Jaleel, and Abhishek Bhattacharjee",
        "Large Pages and Lightweight Memory Management in Virtualized Environments: Can You Have it Both Ways?",
        "Scalable High Performance Main Memory System Using Phase-Change Memory Technology",
        "The Structural Simulation Toolkit",
        "DRAMSim2: A Cycle Accurate Memory System Simulator",
        "Rethinking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB",
        "Recency-Based TLB Preloading",
        "BabelFish: Fusing Address Translations for Containers",
        "Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism",
        "The Architecture of Virtual Machines",
        "Synergistic TLBs for High Performance Address Translation in Chip Multiprocessors",
        "A modular, cross-platform and multi-threaded benchmark tool",
        "Surpassing the TLB Performance of Superpages with Less Operating System Support",
        "The Linux Kernel Archives",
        "Memory Resource Management in VMware ESX Server",
        "Characterizing and Modeling Non-Volatile Memory Systems",
        "Intel Skylake Timing",
        "Translation Ranger: Operating System Support for Contiguity-Aware TLBs",
        "Hash, Don't Cache (the Page Table)"
    ],
    "628704275aee126c0f5b583a": [
        "Huge Page Support -Xen",
        "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines",
        "Predicting Execution Times With Partial Simulations in Virtual Memory Research: Why and How",
        "Revisiting Hardwareassisted Page Walks for Virtualized Systems",
        "Compendia: Reducing Virtual-Memory Costs via Selective Densification",
        "BioBench: A Benchmark Suite of Bioinformatics Applications",
        "Enhancing and Exploiting Contiguity for Fast Memory Virtualization",
        "Software Optimization Guide for AMD Family 17h Models 30h and Greater Processors",
        "Transparent Hugepage Support",
        "Arm Architecture Reference Manual Supplement: Memory System Resource Partitioning and Monitoring (MPAM), for Armv8-A",
        "Arm Cortex-A76 Core Technical Reference Manual",
        "MASK: Redesigning the GPU Memory Hierarchy to Support Multi-Application Concurrency",
        "Translation Caching: Skip, Don't Walk (the Page Table)",
        "SpecTLB: A Mechanism for Speculative Address Translation",
        "Efficient Virtual Memory for Big Memory Servers",
        "Accelerating Two-dimensional Page Walks for Virtualized Systems",
        "Large-Reach Memory Management Unit Caches",
        "Translation-Triggered Prefetching",
        "The Gem5 Simulator",
        "Efficient Address Translation for Architectures with Multiple Page Sizes",
        "Virtualising for the Masses: Exposing KVM on Android",
        "Supporting Superpages in Non-Contiguous Physical Memory",
        "LIBLINEAR: A Library for Large Linear Classification",
        "Efficient Memory Virtualization: Reducing Dimensionality of Nested Page Walks",
        "Agile Paging: Exceeding the Best of Nested and Shadow Paging",
        "Tailored Page Sizes",
        "SPEC CPU2006 Benchmark Descriptions",
        "TLBs, Paging-Structure Caches, and Their Invalidation",
        "Intel 64 and IA-32 Architectures Optimization Reference Manual",
        "Intel 2017. 5-Level Paging and 5-Level EPT. Intel",
        "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "Redundant Memory Mappings for Fast Access to Large Memories",
        "Coordinated and Efficient Huge Page Management with Ingens",
        "CSALT: Context Switch Aware Large TLB",
        "Prefetched Address Translation",
        "Dead Page and Dead Block Predictors: Cleaning TLBs and Caches Together",
        "A Survey of Techniques for Architecting TLBs",
        "Optimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0",
        "GraphBIG: Understanding Graph Computing in the Context of Industrial Solutions",
        "Making Huge Pages Actually Useful",
        "Perforated Page: Supporting Fragmented Memory Allocation for Large Pages",
        "Efficient Synonym Filtering and Scalable Delayed Translation for Hybrid Virtual Caching",
        "Hybrid TLB Coalescing: Improving TLB Translation Coverage under Diverse Fragmented Memory Allocations",
        "Increasing TLB Reach by Exploiting Clustering in Page Translations",
        "Aamer Jaleel, and Abhishek Bhattacharjee",
        "Large Pages and Lightweight Memory Management in Virtualized Environments: Can You Have it Both Ways?",
        "Rethinking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB",
        "Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism",
        "XS-Bench -The Development and Verification of a Performance Abstraction for Monte Carlo Reactor Analysis",
        "Hash, Don't Cache (the Page Table)",
        "Enigma: Architectural and Operating System Support for Reducing the Impact of Address Translation",
        "A Comprehensive Analysis of Superpage Management Mechanisms and Policies"
    ],
    "628d27f85aee126c0f4de037": [
        "Blasting through the front-end bottleneck with shotgun",
        "DBMSs on a modern processor: Where does time",
        "Performance characterization of a quad Pentium pro SMP using OLTP workloads",
        "Performance of database workloads on shared-memory systems with out-of-order processors",
        "Profiling a warehouse-scale computer",
        "Instruction prefetching using branch prediction information",
        "Temporal instruction fetch streaming",
        "RDIP: Return-address-stack directed instruction prefetching",
        "Fetch directed instruction prefetching",
        "Effective instruction prefetching in chip multiprocessors for modern commercial applications",
        "Two level bulk preload branch prediction",
        "Phantom-BTB: A virtualized branch target buffer design",
        "SHIFT: Shared history instruction fetch for lean-core server processors",
        "Confluence: Unified instruction supply for scale-out servers",
        "Boomerang: A metadata-free architecture for control flow delivery",
        "Proactive instruction fetch",
        "A comprehensive instruction fetch mechanism for a processor supporting speculative execution",
        "SimFlex: Statistical sampling of computer system simulation",
        "SMARTS: Accelerating microarchitecture simulation via rigorous statistical sampling",
        "A case for (partially) TAgged GEometric history length branch prediction",
        "Sequential program prefetching in memory hierarchies",
        "Instruction prefetching using branch prediction information",
        "Branch history guided instruction prefetching",
        "Non-sequential instruction cache prefetching for multiple.issue processors",
        "Execution history guided instruction prefetching",
        "The entangling instruction prefetcher",
        "pTask: A smart prefetching scheme for OS intensive applications",
        "AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications",
        "Lightweight feedback-directed cross-module optimization",
        "Optimizing function placement for large-scale data-center applications",
        "Ispike: A post-link optimizer for the Intel/spl reg/ Itanium/spl reg/ architecture",
        "BOLT: A practical binary optimizer for data centers and beyond",
        "Cooperative prefetching: Compiler and hardware support for effective instruction prefetching in modern processors",
        "Call graph prefetching for database applications",
        "AsmDB: Understanding and mitigating front-end stalls in warehouse-scale computers",
        "I-SPY: Context-driven conditional instruction prefetching with coalescing",
        "BTB-X: A storage-effective BTB organization",
        "Divide and conquer frontend bottleneck",
        "Twig: Profile-guided BTB prefetching for data center applications"
    ],
    "632630ff90e50fcafdf67484": [
        "Automatically characterizing large scale program behavior",
        "SMARTS: Accelerating microarchitecture simulation via rigorous statistical sampling",
        "Minnespec: A new SPEC benchmark workload for simulation-based computer architecture research",
        "Improved automatic testcase synthesis for performance model validation",
        "FireSim: FPGAaccelerated cycle-exact scale-out system simulation in the public cloud",
        "Sniper: Exploring the level of abstraction for scalable and accurate parallel multi-core simulation",
        "ZSim: Fast and accurate microarchitectural simulation of thousand-core systems",
        "Variability in architectural simulations of multi-threaded workloads",
        "SimFlex: Statistical sampling of computer system simulation",
        "ESESC: A fast multicore simulator using time-based sampling",
        "Sampled simulation of multi-threaded applications",
        "BarrierPoint: Sampled simulation of multi-threaded applications",
        "TaskPoint: Sampled simulation of task-based programs",
        "Sampled simulation of task-based programs",
        "Evaluating non-deterministic multithreaded commercial workloads",
        "PinPlay: A framework for deterministic replay and reproducible analysis of parallel programs",
        "IPC considered harmful for multiprocessor workloads",
        "NASA Ames Research Center, Tech. Rep",
        "Selecting software phase markers with code structure analysis",
        "Pinballs: portable and shareable user-level checkpoints for reproducible analysis and simulation",
        "ELFies: Executable region checkpoints for performance analysis and simulation",
        "How to use SimPoint to pick simulation points",
        "Motivation for variable length intervals and hierarchical phase behavior",
        "Cluster analysis of multivariate data: efficiency versus interpretability of classifications",
        "Estimating the dimension of a model",
        "Accelerating multiprocessor simulation with a memory timestamp record",
        "Simulation sampling with live-points",
        "Directed statistical warming through time traveling",
        "Pin: Building customized program analysis tools with dynamic instrumentation",
        "SPEC CPU®2017 documentation index",
        "SPEC CPU2017: Nextgeneration compute benchmark",
        "A workload characterization of the SPEC CPU2017 benchmark suite",
        "The NAS parallel benchmarks",
        "The NAS parallel benchmarks summary and preliminary results",
        "The OpenMP implementation of NAS parallel benchmarks and its performance",
        "DCFG generation with PinPlay",
        "Graph-matching-based simulationregion selection for multiple binaries",
        "Reproducible simulation of multi-threaded workloads for architecture design exploration",
        "OpenMP 3.1 API C/C++ Syntax Quick Reference Card",
        "Spin detection hardware for improved management of multithreaded systems",
        "Pinpointing representative portions of large Intel Itanium programs with dynamic instrumentation",
        "LiveSim: Going live with microarchitecture simulation",
        "Enhancing multiprocessor architecture simulation speed using matched-pair comparison",
        "Detecting phases in parallel applications on shared memory architectures",
        "Analytical processor performance and power modeling using micro-architecture independent characteristics",
        "Micro-architecture independent analytical processor performance and power modeling",
        "RPPM: Rapid performance prediction of multithreaded workloads on multicore processors",
        "Invited paper for the hot workloads special session hot regions in SPEC CPU2017",
        "Simulation points for SPEC CPU 2006",
        "The gem5 simulator",
        "LoopPoint artifacts",
        "LoopPoint source code",
        "Sniper simulator"
    ],
    "62d16e8a5aee126c0fd684cf": [
        "Data reorganization in memory using 3D-stacked DRAM",
        "JEDEC Solid State Technology Association et al. 2012",
        "Classifying Memory Access Patterns for Prefetching",
        "Unsupervised Learning and Deep Architectures",
        "Mainmemory hash joins on multi-core CPUs: Tuning to the underlying hardware",
        "The PARSEC benchmark suite: Characterization and architectural implications",
        "CAn't touch this: Software-only mitigation against Rowhammer attacks targeting kernel memory",
        "Compiler-directed page coloring for multiprocessors",
        "Cacheconscious data placement",
        "BOOM v2",
        "Managing DRAM latency divergence in irregular GPGPU applications",
        "Dymaxion: Optimizing memory access patterns for heterogeneous systems",
        "BATMAN: Maximizing Bandwidth Utilization of Hybrid Memory Systems",
        "Cache-conscious structure layout",
        "Simple but effective heterogeneous main memory with on-chip memory controller support",
        "A scalable concurrent malloc (3) implementation for FreeBSD",
        "Dream: Dynamic re-arrangement of address mapping to improve the performance of DRAMs",
        "Learning Memory Access Patterns",
        "SPEC CPU2006 benchmark descriptions",
        "Physical Address Decoding in Intel Xeon v3/v4 CPUs: A Supplemental Datasheet",
        "Efficient Parallel Graph Exploration on Multi-Core CPU and GPU",
        "Intel Xeon Processor E7 v4 Product Family Datasheet",
        "High bandwidth memory (hbm) dram",
        "Understanding object-level memory access patterns across the spectrum",
        "Billion-scale similarity search with GPUs",
        "HeteroOS-OS design for heterogeneous memory management in datacenter",
        "A bandwidth-aware memory-subsystem resource management using non-invasive resource profilers for large cmp systems",
        "NUMA (Non-Uniform Memory Access): An Overview",
        "A software memory partition approach for eliminating bank-level interference in multicore systems",
        "Get out of the valley: power-efficient address mapping for GPUs",
        "Least squares quantization in PCM",
        "Heterogeneous memory architectures: A HW/SW approach for mixing die-stacked and off-package memories",
        "A survey of clustering with deep learning: From the perspective of network architecture",
        "Introducing the graph 500",
        "MOCA: Memory object classification and allocation in heterogeneous memory systems",
        "Fine-grained DRAM: energy-efficient DRAM for extreme bandwidth systems",
        "Hybrid memory cube (HMC)",
        "MLP aware heterogeneous memory system",
        "Pseudo-randomly interleaved memory",
        "Micro-pages: increasing DRAM efficiency with locality-aware data placement",
        "The Locality Descriptor: A Holistic Cross-Layer Abstraction to Express Data Locality In GPUs",
        "A case for richer cross-layer abstractions: Bridging the semantic gap with expressive memory",
        "A parallel sort merge join algorithm for managing data skew",
        "Exposing memory access regularities using object-relative memory profiling",
        "AXI High Bandwidth Memory Controller v1",
        "UltraScale+ FPGA Product Tables and Product Selection Guide",
        "Boosting the Performance of FPGA-based Graph Processor Using Hybrid Memory Cube: A Case for Breadth First Search",
        "MEG: A RISCV-Based System Simulation Infrastructure for Exploring Memory Optimization Using FPGAs and Hybrid Memory Cube",
        "The impulse memory controller",
        "A permutation-based page interleaving scheme to reduce row-buffer conflicts and exploit data locality"
    ],
    "628704555aee126c0f5c7953": [
        "llvm-mca -LLVM Machine Code Analyzer",
        "Profile Guided Software Prefetching",
        "TensorFlow: A System for Large-Scale Machine Learning",
        "Crono: A benchmark suite for multithreaded graph algorithms executing on futuristic multicores",
        "Graph prefetching using data structure knowledge",
        "Software prefetching for indirect memory accesses",
        "An event-triggered programmable prefetcher for irregular workloads",
        "Compilerdirected content-aware prefetching for dynamic data structures",
        "Data prefetching by dependence graph precomputation",
        "Memory hierarchy for web search",
        "Classifying Memory Access Patterns for Prefetching",
        "AsmDB: understanding and mitigating front-end stalls in warehousescale computers",
        "Rob Van Der Wijngaart, Alex Woo, and Maurice Yarrow. 1995. The NAS parallel benchmarks 2.0",
        "Domino temporal data prefetcher",
        "Bingo spatial data prefetcher",
        "Main-memory hash joins on multi-core CPUs: Tuning to the underlying hardware",
        "Analysis and optimization of the memory hierarchy for graph processing workloads",
        "Dspatch: Dual spatial pattern prefetcher",
        "Serving mobile apps: A slice at a time",
        "Rock you like a hurricane: Taming skew in large scale analytics",
        "Google workloads for consumer devices: Mitigating data movement bottlenecks",
        "Runtime object lifetime profiler for latency sensitive big data applications",
        "Software Prefetching",
        "Compiler optimizations for improving data locality",
        "Learning i/o access patterns to improve prefetching in ssds",
        "CQA: A code quality analyzer tool at binary level",
        "Generalized correlationbased hardware prefetching",
        "AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications",
        "Improving Hash Join Performance through Prefetching",
        "Improving index performance through prefetching",
        "TVM: An automated end-to-end optimizing compiler for deep learning",
        "Data access microarchitectures for superscalar processors with compiler-assisted data prefetching",
        "BHive: A benchmark suite and measurement framework for validating x86-64 basic block performance models",
        "Dynamic hot data stream prefetching for general-purpose programs",
        "Pointer cache assisted prefetching",
        "Speculative precomputation: Long-range prefetching of delinquent loads",
        "A stateless, content-directed data prefetching mechanism",
        "Coz: Finding code that counts with causal profiling",
        "Effectiveness of Hardware-Based Stride and Sequential Prefetching in Shared-Memory Multiprocessors",
        "The new linux'perf'tools",
        "A compiler cost model for speculative parallelization",
        "Improved peak detection in mass spectrum by incorporating continuous wavelet transform-based pattern matching",
        "Improving data cache performance by pre-executing instructions under a cache miss",
        "Add AMD Fam19h Branch Sampling support",
        "A primer on hardware prefetching",
        "Make the most out of last level cache in intel processors",
        "Clearing the clouds: a study of emerging scale-out workloads on modern hardware",
        "Spatial memory streaming with rotated patterns. 1st",
        "Propeller: Profile Guided Optimizing Large Scale LLVMbased Relinker",
        "Compiler-directed data prefetching in multiprocessors with memory hierarchies",
        "Continuous runahead: Transparent hardware acceleration for memory intensive workloads",
        "Christos Kozyrakis, and Parthasarathy Ranganathan",
        "Memory prefetching using adaptive stream detection",
        "Stride prefetching by dynamically inspecting objects",
        "Intel Architecture Code Analyzer",
        "Access map pattern matching for high performance data cache prefetch",
        "Linearizing irregular memory accesses for improved correlated prefetching",
        "Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers",
        "Profiling a Warehouse-scale Computer",
        "A case for resource efficient prefetching in multicores",
        "Twig: Profile-Guided BTB Prefetching for Data Center Applications",
        "DMon: Efficient Detection and Correction of Data Locality Problems using Selective Profiling",
        "I-SPY: Context-Driven Conditional Instruction Prefetching with Coalescing",
        "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications",
        "Path confidence based lookahead prefetching",
        "Kill the program counter: Reconstructing program behavior in the processor cache hierarchy",
        "An Introduction to Last Branch Records",
        "GitHub -andikleen/pmu-tools: Intel PMU profiling tools",
        "LLVM: A compilation framework for lifelong program analysis &amp; transformation",
        "Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)",
        "performance modeling, benchmarking and simulation of high performance computer systems (PMBS)",
        "Prefetching with helper threads for loosely coupled multiprocessor systems",
        "When prefetching works, when it doesn't, and why",
        "SNAP Datasets: Stanford large network dataset collection",
        "Competitive prefetching for concurrent sequential I/O",
        "CRISP: Critical Slice Prefetching",
        "Bridging the processor-memory performance gap with 3D IC technology",
        "The performance of runtime data cache prefetching in a dynamic optimization system",
        "Dynamic helper threaded prefetching on the sun ultrasparc cmp processor",
        "Compiler-based prefetching for recursive data structures",
        "Profile-guided post-link stride prefetching",
        "The HPC Challenge (HPCC) benchmark suite",
        "Break dancing: low overhead, architecture neutral software branch tracing",
        "Ithemal: Accurate, portable and fast basic block throughput estimation using deep neural networks",
        "Best-offset hardware prefetching",
        "Tolerating latency through software-controlled prefetching in shared-memory multiprocessors",
        "Automatic Compiler-Inserted I/O Prefetching for Out-of-Core Applications",
        "Design and Evaluation of a Compiler Algorithm for Prefetching",
        "Introducing the graph 500",
        "Techniques for efficient processing in runahead execution engines",
        "Runahead execution: An alternative to very large instruction windows for out-of-order processors",
        "Data cache prefetching using a global history buffer",
        "BOLT: a practical binary optimizer for data centers and beyond",
        "Lightning BOLT: powerful, fast, and scalable binary optimization",
        "Locating cache performance bottlenecks using data profiling",
        "Add support for the Branch Record Buffer extension",
        "Sandbox prefetching: Safe run-time evaluation of aggressive prefetchers",
        "Runahead threads to improve SMT performance",
        "Google-wide profiling: A continuous profiling infrastructure for data centers",
        "Difftune: Optimizing cpu simulator parameters with learned differentiable surrogates",
        "Dependence based prefetching for linked data structures",
        "Effective jump-pointer prefetching for linked data structures",
        "A decoupled predictor-directed stream prefetching architecture",
        "Efficiently prefetching complex address patterns",
        "A hierarchical neural model of data prefetching",
        "Sequential program prefetching in memory hierarchies",
        "Spatial memory streaming",
        "A compiler-directed data prefetching scheme for chip multiprocessors",
        "Thermometer: Profile-Guided BTB Replacement for Data Center Applications",
        "Softsku: Optimizing server architectures for microservice diversity@ scale",
        "Prodigy: Improving the memory latency of data-indirect irregular workloads using hardware-software codesign",
        "Disclosure of hardware prefetcher control on some Intel processors",
        "Guided region prefetching: A cooperative hardware/software approach",
        "Practical off-chip meta-data for temporal memory streaming",
        "Temporal streaming of shared memory",
        "Intel Performance Counter Monitor -A Better Way to Measure CPU Utilization",
        "High performance compilers for parallel computing",
        "Temporal prefetching without the off-chip metadata",
        "Efficient metadata management for irregular data prefetching",
        "Compiler-driven dependence profiling to guide program parallelization",
        "Efficient discovery of regular stride patterns in irregular programs and its use in compiler prefetching",
        "Hitting the Memory Wall: Implications of the Obvious",
        "IMP: Indirect memory prefetcher",
        "Dynamic control flow in large-scale machine learning",
        "Spark: Cluster computing with working sets. HotCloud",
        "RnR: A software-assisted record-and-replay hardware prefetcher",
        "Riffle: optimized shuffle service for large-scale data analytics",
        "A selfrepairing prefetcher in an event-driven dynamic optimization framework",
        "Accelerating and adapting precomputation threads for efficient prefetching"
    ],
    "6287044a5aee126c0f5c33ff": [
        "Algorithms for Hyper-Parameter Optimization",
        "Weight Uncertainty in Neural Networks",
        "Underspecification Presents Challenges for Credibility in Modern Machine Learning",
        "Can we ditch feature engineering? end-to-end deep learning for affect recognition from physiological sensor data",
        "Rethinking importance weighting for deep learning under distribution shift",
        "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
        "A Survey of Uncertainty in Deep Neural Networks",
        "On Calibration of Modern Neural Networks",
        "On calibration of modern neural networks",
        "The meaning and use of the area under a receiver operating characteristic (ROC) curve",
        "Deep Residual Learning for Image Recognition",
        "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "Benchmarking neural network robustness to common corruptions and perturbations",
        "Natural adversarial examples",
        "cStress: towards a gold standard for continuous stress assessment in the mobile environment. Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing",
        "The 'Trier Social Stress Test'-a tool for investigating psychobiological stress responses in a laboratory setting",
        "WILDS: A Benchmark of in-the-Wild Distribution Shifts",
        "Stable prediction with model misspecification and agnostic distribution shift",
        "Verified uncertainty calibration",
        "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
        "Focal loss for dense object detection",
        "Stable Adversarial Learning under Distributional Shifts",
        "On the Variance of the Adaptive Learning Rate and Beyond",
        "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
        "Uncertainty estimation in deep learning with application to spoken language assessment",
        "Calibrating deep neural networks using focal loss",
        "Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift",
        "Biomedical signal analysis",
        "BREEDS: Benchmarks for Subpopulation Shift. arXiv: Computer Vision and Pattern Recognition",
        "Introducing wesad, a multimodal dataset for wearable stress and affect detection",
        "Stress without distress",
        "Fairness violations and mitigation under covariate shift",
        "On mixup training: Improved calibration and predictive uncertainty for deep neural networks",
        "Manifold Mixup: Better Representations by Interpolating Hidden States",
        "Time series classification from scratch with deep neural networks: A strong baseline",
        "mixup: Beyond Empirical Risk Minimization"
    ],
    "62d7a7d15aee126c0f3fe03e": [
        "Adding processor trace support to linux",
        "Apache cassandra",
        "Apache kafka",
        "Apache tomcat",
        "Champsim",
        "Clang c language family frontend for llvm",
        "Github -chipsalliance/rocket-chip: Rocket chip generator",
        "An introduction to last branch records",
        "Postgresql: Documentation: 14: pgbench",
        "Postgresql: The world's most advanced open source database",
        "The python performance benchmark suite",
        "Twitter finagle",
        "Verilator",
        "Welcome to python.org",
        "Championship branch prediction",
        "facebookarchive/oss-performance: Scripts for benchmarking various php implementations when running open source software",
        "The 1st instruction prefetching championship",
        "Iatac: a smart predictor to turn-off l2 cache lines",
        "The hiphop virtual machine",
        "Exploring predictive replacement policies for instruction cache and branch target buffer",
        "Keeping master green at scale",
        "Mana: Microarchitecting an instruction prefetcher",
        "Divide and conquer frontend bottleneck",
        "Btb-x: A storage-effective btb organization",
        "Memory hierarchy for web search",
        "Classifying memory access patterns for prefetching",
        "Asmdb: understanding and mitigating front-end stalls in warehouse-scale computers",
        "Talus: A simple way to remove cliffs in cache performance",
        "A study of replacement algorithms for a virtual-storage computer",
        "On-line measurement of paging behavior by the multivalued min algorithm",
        "Proceedings of the 21st annual ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications",
        "Bulldozer: An approach to multithreaded compute performance",
        "Autofdo: Automatic feedback-directed optimization for warehouse-scale applications",
        "Hot cold optimization of large windows/nt applications",
        "Tpc-c",
        "{REPT}: Reverse debugging of failures in deployed software",
        "Predicting whole-program locality through reuse distance analysis",
        "Improving cache management policies using dynamic reuse distances",
        "Reverse debugging at scale",
        "Partial resolution in branch target buffers",
        "Leeway: Addressing variability in dead-block prediction for last-level caches",
        "Clearing the clouds: a study of emerging scale-out workloads on modern hardware",
        "Proactive instruction fetch",
        "Temporal instruction fetch streaming",
        "A dueling segmented lru replacement algorithm with adaptive bypassing",
        "The temporal ancestry prefetcher",
        "Propeller: Profile guided optimizing large scale llvm-based relinker",
        "Barca: Branch agnostic region searching algorithm",
        "Evolution of the samsung exynos cpu microarchitecture",
        "Intel® 64 and ia-32 architectures software developer's manual",
        "Run-jump-run: Bouquet of instruction pointer jumpers for high performance instruction prefetching",
        "Steps towards cache-resident transaction processing",
        "Active benchmarking for better performance predictions",
        "Learning memory access patterns",
        "Profile inference revisited",
        "Timekeeping in the memory system: predicting and optimizing memory behavior",
        "Rebasing instruction prefetching: An industry perspective",
        "Re-establishing fetch-directed instruction prefetching: An industry perspective",
        "Path-based next trace prediction",
        "Back to the future: leveraging belady's algorithm for improved cache replacement",
        "Rethinking belady's algorithm to accommodate prefetching",
        "High performance cache replacement using re-reference interval prediction (rrip)",
        "Apt-get: Profile-guided timely software prefetching",
        "Insertion and promotion for tree-based pseudolru last-level caches",
        "The impact of delay on the design of branch predictors",
        "Multiperspective reuse prediction",
        "Profiling a warehouse-scale computer",
        "Caching strategies to improve disk system performance",
        "Lazy diagnosis of in-production concurrency bugs",
        "Failure sketches: A better way to debug",
        "Failure sketching: A technique for automated root cause diagnosis of in-production failures",
        "Shift: Shared history instruction fetch for lean-core server processors",
        "Confluence: unified instruction supply for scale-out servers",
        "Sampling dead block prediction for last-level caches",
        "Twig: Profile-guided btb prefetching for data center applications",
        "Dmon: Efficient detection and correction of data locality problems using selective profiling",
        "I-spy: Context-driven conditional instruction prefetching with coalescing",
        "Ripple: Profile-guided instruction cache replacement for data center applications",
        "Huron: hybrid false sharing detection and repair",
        "Counter-based cache replacement algorithms",
        "A cost-effective branch target buffer with a two-level table organization",
        "Rdip: return-address-stack directed instruction prefetching",
        "Blasting through the front-end bottleneck with shotgun",
        "Boomerang: A metadata-free architecture for control flow delivery",
        "Llvm: A compilation framework for lifelong program analysis &amp; transformation",
        "Codestitcher: inter-procedural basic block layout optimization",
        "Branch prediction strategies and branch target buffer design",
        "On the existence of a spectrum of policies that subsumes the least recently used (lru) and least frequently used (lfu) policies",
        "Lightweight feedback-directed cross-module optimization",
        "Optimal bypass monitor for high performance last-level caches",
        "CRISP: critical slice prefetching",
        "An imitation learning approach for cache replacement",
        "Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency",
        "Ispike: a post-link optimizer for the intel/spl reg/itanium/spl reg/architecture",
        "Cooperative prefetching: Compiler and hardware support for effective instruction prefetching in modern processors",
        "Evaluation techniques for storage hierarchies",
        "Dead page and dead block predictors: Cleaning tlbs and caches together",
        "Some mathematical facts about optimal cache replacement",
        "Pips: Prefetching instructions with probabilistic scouts",
        "Vespa: static profiling for binary optimization",
        "D-jolt: Distant jolt prefetcher",
        "The lru-k page replacement algorithm for database disk buffering",
        "Hhvm jit: A profile-guided, region-based compiler for php and hack",
        "Hhvm jump-start: Boosting both warmup and steadystate performance at scale",
        "Optimizing function placement for large-scale datacenter applications",
        "Bolt: a practical binary optimizer for data centers and beyond",
        "Lightning bolt: powerful, fast, and scalable binary optimization",
        "B-fetch: Branch prediction directed prefetching for in-order processors",
        "The arm neoverse n1 platform: Building blocks for the next-gen cloud-to-edge infrastructure soc",
        "Branch target buffer design and optimization",
        "Architectural and compiler support for effective instruction prefetching: a cooperative approach",
        "The hardness of cache conscious data placement",
        "Profile guided code positioning",
        "Renaissance: Benchmarking suite for parallel applications on the jvm",
        "Adaptive insertion policies for high performance caching",
        "A case for mlp-aware cache replacement",
        "Code layout optimizations for transaction processing workloads",
        "A scalable front-end architecture for fast instruction delivery",
        "Fetch directed instruction prefetching",
        "The entangling instruction prefetcher",
        "A cost-effective entangling prefetcher for instructions",
        "Trace cache: a low latency approach to high bandwidth instruction fetching",
        "Samsung exynos m3 processor",
        "ARM architecture reference manual",
        "The evicted-address filter: A unified mechanism to address both cache pollution and thrashing",
        "Tage-sc-l branch predictors",
        "The fnl+ mma instruction cache prefetcher",
        "Don't use the page number, but a pointer to it",
        "Applying deep learning to the cache replacement problem",
        "Eelru: simple and effective adaptive page replacement",
        "Sequential program prefetching in memory hierarchies",
        "Pdede: Partitioned, deduplicated, delta branch target buffer",
        "Softsku: Optimizing server architectures for microservice diversity@ scale",
        "Adaptive caches: Effective shaping of cache behavior to workloads",
        "The amd \"zen 2\" processor",
        "Inter-reference gap distribution replacement: an improved replacement algorithm for set-associative caches",
        "Perceptron learning for reuse prediction",
        "Morrigan: A composite instruction tlb prefetcher",
        "Temporal streams in commercial server applications",
        "Practical off-chip meta-data for temporal memory streaming",
        "Temporal streaming of shared memory",
        "Drupal -Wikipedia, the free encyclopedia",
        "Mediawiki -Wikipedia, the free encyclopedia",
        "Wordpress -Wikipedia, the free encyclopedia",
        "Cross-validation (statistics) -Wikipedia, the free encyclopedia",
        "Mysql -Wikipedia, the free encyclopedia",
        "Ship: Signature-based hit predictor for high performance caching",
        "A comprehensive instruction fetch mechanism for a processor supporting speculative execution",
        "Buffering databse operations for enhanced instruction cache performance",
        "On the impact of instruction address translation overhead",
        "Execution reconstruction: Harnessing failure reoccurrences for failure reproduction"
    ],
    "62d7a7d15aee126c0f3fe05a": [
        "Shared memory consistency models: A tutorial",
        "Compute caches",
        "The MIT Alewife machine: architecture and performance",
        "The microarchitecture of Intel, AMD and VIA CPUs",
        "PIM-enabled instructions: a low-overhead, locality-aware processing-in-memory architecture",
        "An Event-Triggered Programmable Prefetcher for Irregular Workloads",
        "Data reorganization in memory using 3D-stacked DRAM",
        "AMNESIAC: Amnesic Automatic Computer",
        "Adaptive cache compression for high-performance processors",
        "P-OPT: Practical Optimal Cache Replacement for Graph Analytics",
        "Near-data processing: Insights from a MICRO-46 workshop",
        "Adaptive caches as a defense mechanism against cache side-channel attacks",
        "Locality exists in graph processing: Workload characterization on an Ivy Bridge server",
        "Reducing PageRank communication via propagation blocking",
        "Jigsaw: Scalable Software-Defined Caches",
        "Talus: A Simple Way to Remove Cliffs in Cache Performance",
        "Scaling distributed cache hierarchies through computation and data co-scheduling",
        "Die Stacking is Happening!",
        "The parallel persistent memory model",
        "Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks",
        "Web caching and Zipf-like distributions: Evidence and implications",
        "On the representation and multiplication of hypersparse matrices",
        "Impulse: Building a smarter memory controller",
        "PARTIES: QoS-Aware Resource Partitioning for Multiple Interactive Services",
        "Flexible hardware acceleration for instructiongrain program monitoring",
        "Leveraging Hardware Transactional Memory for Cache Side-Channel Defenses",
        "Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory",
        "Chain: Tasks and Channels for Reliable Intermittent Programs",
        "Improving Real-Time Performance by Using Cache Allocation Technology",
        "GPU Computing: To Exascale and Beyond",
        "Merrimac: Supercomputing with streams",
        "Domain-Specific Hardware Accelerators",
        "The University of Florida sparse matrix collection",
        "Understanding and Optimizing Asynchronous Low-Precision Stochastic Gradient Descent",
        "Unlimited Vector Extension with Data Streaming Support",
        "A robust main-memory compression scheme",
        "KPart: A Hybrid Cache Partitioning-Sharing Technique for Commodity Multicores",
        "Dark Silicon and The End of Multicore Scaling",
        "Coherence domain restriction on large scale systems",
        "Scaling Datacenter Accelerators With Compute-Reuse Architectures",
        "Practical near-data processing for in-memory analytics frameworks",
        "HRL: Efficient and flexible reconfigurable logic for near-data processing",
        "Snafu: An Ultra-Low-Power, Energy-Minimal CGRA-Generation Framework and Architecture",
        "Processing in memory: The Terasys massively parallel PIM array",
        "PipeRench: A coprocessor for streaming multimedia acceleration",
        "Strong and Efficient Cache Side-Channel Protection Using Hardware Transactional Memory",
        "A Memory Encryption Engine Suitable for General Purpose Processors",
        "Cache games-Bringing access-based cache attacks on AES to practice",
        "Reducing memory and traffic requirements for scalable directory-based cache coherence schemes",
        "EIE: Efficient Inference Engine on Compressed Deep Neural Network",
        "Accelerating dependent cache misses with an enhanced memory controller",
        "How secure is your cache against sidechannel attacks?",
        "A New Golden Age for Computer Architecture: Domain-Specific Hardware/Software Co-Design, Enhanced Security, Open Instruction Sets, and Agile Chip Development",
        "Accelerating linked-list traversal through near-data processing",
        "Computing's energy problem (and what we can do about it)",
        "Informing memory operations: Providing memory performance feedback in modern processors",
        "Transparent Offloading and Mapping (TOM): Enabling Programmer-Transparent Near-Data Processing in GPU Systems",
        "Accelerating pointer chasing in 3D-stacked memory: Challenges, mechanisms, evaluation",
        "Elastic cgras",
        "Intel Optane Persistent Memory",
        "S$A: A shared cache attack that works across cores and defies VM sandboxing-and its application to AES",
        "High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)",
        "A scalable architecture for ordered parallelism",
        "FlexRAM: Towards an intelligent memory system",
        "AMD Memory Encryption",
        "Ubik: Efficient Cache Sharing with Strict QoS for Latency-Critical Workloads",
        "Tvarak: softwaremanaged hardware offload for redundancy in direct-access NVM storage",
        "A highresolution side-channel attack on last-level cache",
        "Imagine: media processing with streams",
        "Optimizing indirect memory references with milk",
        "EXECUBE-A new architecture for scaleable MPPs",
        "Scalable processors in the billion-transistor era",
        "The Stanford FLASH multiprocessor",
        "Coordinated and Efficient Huge Page Management with Ingens",
        "BSSync: Processing near memory for machine learning workloads with bounded staleness consistency models",
        "There's plenty of room at the Top: What will drive computer performance after Moore's law?",
        "The directory-based cache coherence protocol for the DASH multiprocessor",
        "Statistical properties of community structure in large social and information networks",
        "Cache Attack on AES for Android Smartphone",
        "Pinatubo: A processing-in-memory architecture for bulk bitwise operations in emerging non-volatile memories",
        "Lastlevel cache side-channel attacks are practical",
        "Heracles: improving resource efficiency at scale",
        "Livia: Data-centric computing throughout the memory hierarchy",
        "A Simpler, Safer Programming and Execution Model for Intermittent Systems",
        "A Hardware Accelerator for Tracing Garbage Collection",
        "Alpaca: Intermittent Execution without Checkpoints",
        "Adaptive Dynamic Checkpointing for Safe Efficient Intermittent Computing",
        "Why on-chip cache coherence is here to stay",
        "DoppelgäNger: A Cache for Approximate Computing",
        "The anytime automaton",
        "LogTM: log-based transactional memory",
        "Exploiting Locality in Graph Analytics through Hardware-Accelerated Traversal Scheduling",
        "Whirlpool: Improving dynamic cache management with static data classification",
        "Cache-Guided Scheduling: Exploiting Caches to Maximize Locality in Graph Processing",
        "PHI: Architectural Support for Synchronization-and Bandwidth-Efficient Commutative Scatter Updates",
        "Run-time detection of prime+ probe side-channel attack on AES encryption algorithm",
        "Fifer: Practical Acceleration of Irregular Applications on Reconfigurable Architectures",
        "The Jmachine multicomputer: an architectural evaluation",
        "Stream-dataflow acceleration",
        "IRONHIDE:A Secure Multicore that Efficiently Mitigates Microarchitecture State Attacks for Interactive Applications",
        "Active Pages: A Model of Computation for Intelligent Memory",
        "Cache attacks and countermeasures: the case of AES",
        "Triggered instructions: A control paradigm for spatially-programmed architectures",
        "A case for intelligent RAM",
        "Opportunistic computing in gpu architectures",
        "Linearly compressed pages: a low-complexity, low-latency main memory compression framework",
        "Base-delta-immediate compression: Practical data compression for on-chip caches",
        "Optimus prime: Accelerating data transformation in servers",
        "NDC: Analyzing the Impact of 3D-Stacked Memory + Logic Devices on MapReduce Workloads",
        "Utility-based cache partitioning: A lowoverhead, high-performance, runtime mechanism to partition shared caches",
        "CEASER: Mitigating conflict-based cache attacks via encrypted-address and remapping",
        "New attacks and defense for encrypted-address cache",
        "Tempest and Typhoon: User-level shared memory",
        "Pipelining a triggered processing element",
        "Morphable counters: Enabling compact integrity trees for low-overhead secure memories",
        "The ZCache: Decoupling Ways and Associativity",
        "Vantage: Scalable and Efficient Fine-Grain Cache Partitioning",
        "Decoupled compressed cache: exploiting spatial locality for energy-optimized compressed caching",
        "The Role of Edge Offload for Hardware-Accelerated Mobile Devices",
        "Jumanji: The Case for Dynamic NUCA in the Datacenter",
        "A case for two-way skewed-associative caches",
        "Decoupled sectored caches: conciliating low tag implementation cost",
        "Smart memories polymorphic chip multiprocessor",
        "ISAAC: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars",
        "Micro-architectural cache side-channel attacks and countermeasures",
        "Chasing away rats: Semantics and evaluation for relaxed atomics on heterogeneous systems",
        "Pageforge: a near-memory content-aware page-merging architecture",
        "GraphR: Accelerating graph processing using ReRAM",
        "Cache automaton",
        "Andrew Schwerin, and Mark Oskin. 2003. WaveScalar",
        "Prodigy: Improving the Memory Latency of Data-Indirect Irregular Workloads Using Hardware-Software Co-Design",
        "Ultra-Elastic CGRAs for Irregular Loop Specialization",
        "Jenga: Software-Defined Cache Hierarchies",
        "Adaptive Scheduling for Systems with Asymmetric Memory Hierarchies",
        "Rethinking the Memory Hierarchy for Modern Languages",
        "Compress objects, not cache lines: An object-based compressed memory hierarchy",
        "A case for richer cross-layer abstractions: Bridging the semantic gap with expressive memory",
        "Single-graph multiple flows: Energy efficient design alternative for GPGPUs",
        "Baring it all to software: Raw machines",
        "Stream-based memory access specialization for general purpose processors",
        "Near-Stream Computing: General and Transparent Near-Cache Acceleration",
        "Stream Floating: Enabling Proactive and Decentralized Cache Optimizations",
        "A hybrid systolic-dataflow architecture for inductive matrix algorithms",
        "NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File System",
        "Secure hierarchy-aware cache replacement policy (SHARP): Defending against cache-based side channel attacks",
        "SpZip: Architectural Support for Effective Data Compression In Irregular Applications",
        "Preventing and Detecting Cache Side-Channel Attacks in Cloud Computing",
        "TOP-PIM: Throughputoriented Programmable Processing in Memory",
        "Worklist-directed Prefetching",
        "Minnow: Lightweight Offload Engines for Worklist Management and Worklist-Directed Prefetching",
        "Exploiting Semantic Commutativity in Hardware Speculation",
        "Exploiting commutativity to reduce the cost of updates to shared data in cache-coherent systems",
        "Leveraging Hardware Caches for Memoization",
        "Leveraging caches to accelerate hash tables and memoization",
        "Software-Defined Address Mapping: A Case on 3D Memory",
        "Pangolin: A Fault-Tolerant Persistent Memory Programming Library",
        "GraphP: Reducing communication for PIM-based graph processing with efficient data partition"
    ],
    "62d7a7d15aee126c0f3fe03d": [
        "I am error: The Nintendo family computer/entertainment system platform",
        "A disposable electrochemical sensor for the rapid determination of levodopa",
        "Recent advances in materials and flexible electronics for peripheral nerve interfaces",
        "A natively flexible 32-bit Arm microprocessor",
        "Printed microprocessors",
        "Blue Spark Technologies",
        "Challenges and opportunities in flexible electronics",
        "IGZO-based electrolyte-gated field-effect transistor for in situ biological sensing platform",
        "Disposable colorimetric geometric barcode sensor for food quality monitoring",
        "A three-dimensionally interconnected carbon nanotube-conducting polymer hydrogel network for high-performance flexible battery electrodes",
        "Flexible 6502 takes us back to the future",
        "Large-area soft e-skin: The challenges beyond sensor designs",
        "RFCPUs on glass and plastic substrates fabricated by TFT transfer technology",
        "Smart bandages: The future of wound care",
        "Nintendo Entertainment System Documentation. Tokyo: Nintendo",
        "Ultra-thin wafer technology and applications: A review",
        "Centip3de: A 64-core, 3d stacked near-threshold system",
        "Fluorine-implanted indium-gallium-zinc oxide (IGZO) chemiresistor sensor for high-response NO2 detection",
        "What is the optimal interval between successive home blood pressure readings using an automated oscillometric device",
        "Using portable transducers to measure tremor severity. Tremor and Other Hyperkinetic Movements",
        "A wireless respiratory monitoring system using a wearable patch sensor network",
        "Light Level Sensor -Ceiling Mounted",
        "Low cost inkjet printed smart bandage for wireless monitoring of chronic wounds",
        "Low Cost Inkjet Printed Smart Bandage for Wireless Monitoring of Chronic Wounds",
        "QL's Quest for business status. Electronics &amp; Power 30",
        "Factory-calibrated continuous glucose monitoring: how and why it works, and the dangers of reuse beyond approved duration of wear",
        "Flexible electronics toward wearable sensing",
        "Flexible electronics",
        "Printed silver circuits for FMCG packaging",
        "None",
        "A wearable and highly sensitive pressure sensor with ultrathin gold nanowires",
        "The creation and the demise of VisiCalc",
        "Neurological tremor: sensors, signal processing and emerging applications",
        "Fully printed high performance humidity sensors based on twodimensional materials",
        "Modern microprocessor built from complementary carbon nanotube transistors",
        "None",
        "Pseudo-CMOS: A design style for low-cost and robust flexible electronics",
        "Assembly and applications of 3D conformal electronics on curvilinear surfaces",
        "Ultra low voltage 1-V RFID tag implement in a-IGZO TFT technology on plastic",
        "None",
        "Nano-Power System Timer for Power Gating",
        "Analysis of Mechanical and Electrical Origins of Degradations in Device Durability of Flexible InGaZnO Thin-Film Transistors",
        "A flexible 8b asynchronous microprocessor based on low-temperature poly-silicon TFT technology",
        "Energysmart: Toward energy-efficient manycores for near-threshold computing",
        "Hypothermia during saturation diving in the North Sea",
        "A new frontier of printed electronics: flexible hybrid electronics",
        "Soft wearable pressure sensors for beat-to-beat blood pressure monitoring",
        "Wearable temporary tattoo sensor for real-time trace metal monitoring in human sweat",
        "Noninvasive Alcohol Monitoring Using a Wearable Tattoo-Based Iontophoretic-Biosensing System",
        "Low-temperature fabrication of high-performance metal oxide thin-film electronics via combustion processing",
        "Organic TFT array on a paper substrate",
        "Critical evaluation of organic thin-film transistor models",
        "Doping of polycrystalline CdTe for high-efficiency solar cells on flexible metal foil",
        "UHF RFCPUs on flexible and glass substrates for secure RFID systems",
        "Ultra-thin wafer fabrication through dicing-by-thinning",
        "A CPU on a glass substrate using CG-silicon TFTs",
        "High-Performance a-IGZO TFT With ZrO2 Gate Dielectric Fabricated at Room Temperature",
        "From flexible electronics technology in the era of IoT and artificial intelligence toward future implanted body sensor networks",
        "All-inkjetprinted flexible piezoelectric generator made of solvent evaporation assisted BaTiO3 hybrid material",
        "Flip Chip integration of ultra-thinned dies in lowcost flexible printed electronics; the effects of die thickness, encapsulation and conductive adhesives",
        "Disposable DNA electrochemical biosensors for environmental monitoring",
        "Xorshift rngs",
        "Bendable energy-harvesting module with organic photovoltaic, rechargeable battery, and a-IGZO TFT charging electronics",
        "None",
        "Vehicle ignition interlock systems having transdermal alcohol sensor",
        "Wireless Flexible Smart Bandage for Continuous Monitoring of Wound Oxygenation",
        "Printed machine learning classifiers",
        "The development of flexible integrated circuits based on thin-film transistors",
        "A thin-film microprocessor with inkjet print-programmable memory",
        "An 8-bit, 40-instructions-per-second organic microprocessor on plastic foil",
        "Energy optimization of subthreshold-voltage sensor network processors",
        "Energy optimization of subthreshold-voltage sensor network processors",
        "Intelligent MotionSensing Pedometer",
        "Odor-sensing system to support social participation of people suffering from incontinence",
        "A hardwired machine learning processing engine fabricated with submicron metal-oxide thin-film transistors on a flexible substrate",
        "Myriam Willegems, Raf Appeltans, and Kris Myny. 2021. 2cm diameter Antenna &amp; Sharp Multi-threshold Detection Thin-film RFID Tags on Flexible substrate",
        "A performance comparison of hypervisors",
        "The physics of amorphous-silicon thin-film transistors",
        "Wearable Devices and Smart Garments for Stress Management",
        "Pragmatic Semiconductor. 2022. FlexLogIC Fab",
        "Digital humidity, pressure and temperature sensor",
        "Digital Pressure Sensor",
        "USDA FSIS Directive 7110.3 Rev 1: Time/Temperature Guidelines for Cooling Heated Products",
        "None",
        "Ultra-low voltage metal oxide thin film transistor by low-temperature annealed solution processed LiAlO 2 gate dielectric",
        "Flavor Determination for Milk Quality Assessment using Embedded Electronic Noses",
        "Fully printed disposable IoT soil moisture sensors for precision agriculture",
        "A CPU on a plastic film substrate",
        "Flexible substrate with floating island structure for mounting ultra-thin silicon chips",
        "Ultrahigh sensitive NO2 gas sensor based on tunable polarity transport in CVD-WS2/IGZO pN heterojunction",
        "Heartbeat monitor for wearing during exercise",
        "Oxide TFT rectifiers on flexible substrates operating at NFC frequency range",
        "Flexible hybrid electronics: review and challenges",
        "Towards a low cost fully integrated IGZO TFT NO2 detection and quantification: A solution-processed approach",
        "A microprocessor based on a two-dimensional semiconductor",
        "Highly compressible cross-linked polyacrylamide hydrogel-enabled compressible Zn-MnO2 battery and a flexible battery-sensor system",
        "Highly sensitive flexible pressure sensor by the integration of microstructured PDMS film with a-IGZO TFTs",
        "A transparent logic circuit for RFID tag in a-IGZO TFT technology",
        "Wearable and flexible electronics for continuous molecular monitoring",
        "Towards a wearable perspiration sensor",
        "Recycling strategy for fabricating low-cost and high-performance carbon nanotube TFT devices",
        "Fast flexible plastic substrate ZnO circuits",
        "300mm low K wafer dicing saw study"
    ],
    "62d7a7d15aee126c0f3fe044": [
        "Leap Scratchpads: Automatic Memory and Cache Management for Reconfigurable Logic",
        "OpenROAD: Toward a Self-Driving, Open-Source Digital Layout Implementation Tool Chain",
        "ASCELLA: Accelerating Sparse Computation by Enabling Stream Accesses to Memory",
        "Impulse: building a smarter memory controller",
        "Efficient data supply for hardware accelerators with prefetching and access/execute decoupling",
        "CoRAM: an in-fabric memory architecture for FPGA-based computing",
        "A Patch Memory System for Image Processing and Computer Vision",
        "Domain-Specific Hardware Accelerators",
        "Type-directed scheduling of streaming accelerators",
        "Near-Memory Data Transformation for Efficient Sparse Matrix Multi-Vector Multiplication",
        "MANIC: A Vector-Dataflow Architecture for Ultra-Low-Power Embedded Systems",
        "DeSC: decoupled supply-compute communication management for heterogeneous architectures",
        "Efficient gather and scatter operations on graphics processors",
        "A New Golden Age for Computer Architecture",
        "Efficient execution of memory access phases using dataflow specialization",
        "Scratchpad Sharing in GPUs",
        "Programmable Stream Processors",
        "Meet the walkers: accelerating index traversals for in-memory databases",
        "Spatial: a language and compiler for application accelerators",
        "Automatic Generation of Efficient Accelerators for Reconfigurable Hardware",
        "Stash: have your scratchpad and cache it too",
        "DASX: Hardware accelerator for software data structures",
        "An Efficient Hardware Accelerator for Sparse Convolutional Neural Networks on FPGAs",
        "Optimizing NUCA Organizations and Wiring Alternatives for Large Caches with CACTI 6.0",
        "Stream-Dataflow Acceleration",
        "A Sparse Matrix Vector Multiply Accelerator for Support Vector Machine",
        "Outerspace: An outer product based sparse matrix multiplication accelerator",
        "Buffets: An Efficient and Composable Storage Idiom for Explicit Decoupled Data Orchestration",
        "SIGMA: A Sparse and Irregular GEMM Accelerator with Flexible Interconnects for DNN Training",
        "GraphPulse: An Event-Driven Hardware Accelerator for Asynchronous Graph Processing",
        "Gather-Scatter DRAM: In-DRAM Address Translation to Improve the Spatial Locality of Non-Unit Strided Accesses",
        "A Primer on Memory Consistency and Cache Coherence",
        "Jenga: Software-Defined Cache Hierarchies",
        "Rethinking the memory hierarchy for modern languages",
        "Gamma: leveraging Gustavson's algorithm to accelerate sparse matrix multiplication",
        "Gamma: Leveraging Gustavson's Algorithm to Accelerate Sparse Matrix Multiplication",
        "SpArch: Efficient architecture for sparse matrix multiplication"
    ],
    "62d7a7d15aee126c0f3fe059": [
        "Zip LZMA Benchmark. 2022. Intel Skylake",
        "Firecracker: Lightweight Virtualization for Serverless Applications",
        "Micro-Sliced Virtual Processors to Hide the Effect of Discontinuous CPU Availability for Consolidated Systems",
        "A Demo Running 4000 Firecracker MicroVMs",
        "AWS Lambda Pricing",
        "Use API Gateway Lambda Authorizers. Retrieved",
        "Divide and Conquer Frontend Bottleneck",
        "The Gem5 Simulator. SIGARCH Comput. Archit. News",
        "Stress-ng",
        "Cache restoration for highly partitioned virtualized systems",
        "The State of Serverless",
        "The State of Serverless 2021",
        "Catalyzer: Sub-millisecond Startup for Serverless Computing with Initialization-less Booting",
        "Emmanuel Cecchet, Snigdhaswin Kar, and Prabodh Mishra. 2019. The Design and Operation of CloudLab",
        "A Review of Serverless Use Cases and their Characteristics",
        "Proactive instruction fetch",
        "Temporal instruction fetch streaming",
        "An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud &amp; Edge Systems",
        "Cloud Functions Pricing",
        "Implementing SLOs",
        "Online Boutique",
        "gRPC: A High-Performance, Open Source Universal RPC Framework",
        "THE DISTRIBUTION OF THE FLORA IN THE ALPINE ZONE.1",
        "Die-Stacked DRAM Caches for Servers: Hit Ratio, Latency, or Bandwidth? Have It All with Footprint Cache",
        "Nightcore: efficient and scalable serverless computing for latency-sensitive, interactive microservices",
        "Memory compaction",
        "Cache decay: Exploiting generational behavior to reduce cache leakage power",
        "SHIFT: shared history instruction fetch for lean-core server processors",
        "Confluence: unified instruction supply for scale-out servers",
        "perf: Linux profiling with performance counters",
        "FunctionBench: A Suite of Workloads for Serverless Cloud Function Service",
        "Practical Cloud Workloads for Serverless FaaS",
        "Boomerang: A Metadata-Free Architecture for Control Flow Delivery",
        "Linux Foundation. 2008. pthread_create -Linux manual page",
        "None",
        "When Does Cold Start Happen on AWS Lambda? Retrieved",
        "When Does Cold Start Happen on Azure Functions?",
        "When Does Cold Start Happen on Google Cloud Functions?",
        "Chapter 3 Thread Create Attributes",
        "Leaked AMD Zen 4 Cache Upgrades Could Be Key In Competing With Alder Lake",
        "Fetch Directed Instruction Prefetching",
        "Architectural Implications of Function-as-a-Service Computing",
        "Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider",
        "Faasm: Lightweight Isolation for Efficient Stateful Serverless Computing",
        "µTune: Auto-Tuned Threading for OLDI Microservices",
        "ARMs Race: Ampere Altra Takes on the AWS Gravi-ton2",
        "The EPYC Journey Continues to Milan in Cloudflare's 11th Generation Edge Server",
        "Production Host Setup Recommendations. Retrieved",
        "Analyzing Tail Latency in Serverless Clouds with STeLLAR",
        "Benchmarking, analysis, and optimization of serverless function snapshots",
        "Replayable Execution Optimized for Page Sharing for a Managed Runtime Environment",
        "A Top-Down method for performance analysis and counters architecture",
        "RECAP: A region-based cure for the common cold (cache)",
        "Treadmill: Attributing the Source of Tail Latency through Precise Load Testing and Statistical Inference",
        "Microarchitectural implications of event-driven server-side web applications"
    ],
    "62d7a7d15aee126c0f3fe049": [
        "Delay and Bypass: Ready and Criticality Aware Instruction Scheduling in Outof-Order Processors",
        "Early Address Prediction: Efficient Pipeline Prefetch and Reuse",
        "Apache Software Foundation",
        "Zero-Cycle Loads: Microarchitecture Support for Reducing Load Latency",
        "An Effective On-Chip Preloading Scheme to Reduce Data Access Penalty",
        "Bingo Spatial Data Prefetcher",
        "Focused Value Prediction",
        "SYSmark",
        "Correlated Load-Address Predictors",
        "DSPatch: Dual Spatial Pattern Prefetcher",
        "Perceptron-Based Prefetch Filtering",
        "Select-Free Instruction Scheduling Logic",
        "Introducing Hierarchy-awareness in Replacement and Bypass Algorithms for Last-level Caches",
        "Memory Dependence Prediction Using Store Sets",
        "Speculative Precomputation: Longrange Prefetching of Delinquent Loads",
        "Standard Performance Evaluation Corporation",
        "Standard Performance Evaluation Corporation",
        "Standard Performance Evaluation Corporation",
        "Standard Performance Evaluation Corporation",
        "TPC-C",
        "TPC-E",
        "Intel's 11th Gen Core Tiger Lake SoC Detailed: SuperFin, Willow Cove and Xe-LP",
        "Effectiveness of Hardware-Based Stride and Sequential Prefetching in Shared-Memory Nultiprocessors",
        "Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss",
        "A load-instruction unit for pipelined processors",
        "Focusing Processor Policies via Critical-Path Prediction",
        "Stride Directed Prefetching In Scalar Processors",
        "BigBench: Towards an Industry Standard Benchmark for Big Data Analytics",
        "Speculative Execution via Address Prediction and Data Prefetching",
        "Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads",
        "Improving Branch Predictors by Correlating on Data Values",
        "Computer Architecture: A Quantitative Approach",
        "Memory Prefetching Using Adaptive Stream Detection",
        "Access Map Pattern Matching for Data Cache Prefetch",
        "Back to the Future: Leveraging Belady's Algorithm for Improved Cache Replacement",
        "High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)",
        "Prefetching using Markov Predictors",
        "Helper Thread Prefetching for Loosely-Coupled Multiprocessor Systems",
        "Instruction Criticality Based Energy-Efficient Hardware Data Prefetching",
        "UC-Check: Characterizing Micro-operation Caches in x86 Processors and Implications in Security and Performance",
        "Path Confidence based Lookahead Prefetching",
        "T2: A Highly Accurate and Energy Efficient Stride Prefetcher",
        "Primate Labs",
        "LAMMPS",
        "Dead-Block Prediction &amp; Dead-Block Correlating Prefetchers",
        "Value Locality and Load Value Prediction",
        "CRISP: Critical Slice Prefetching",
        "Dynamic Helper Threaded Prefetching on the Sun UltraSPARC® CMP Processor",
        "Extended Histories: Improving Regularity and Performance in Correlation Prefetchers",
        "Best-Offset Hardware Prefetching",
        "Delaying Physical Register Allocation Through Virtual-Physical Registers",
        "Data Cache Prefetching Using a Global History Buffer",
        "Criticality Aware Tiered Cache Hierarchy: A Fundamental Relook at Multi-level Cache Hierarchies",
        "Evaluating Stream Buffers as a Secondary Cache Replacement",
        "Reducing Design Complexity of the Load/Store Queue",
        "Leveraging Targeted Value Prediction to Unlock New Hardware Strength Reduction Potential",
        "EOLE: Paving the Way for an Effective Implementation of Value Prediction",
        "Practical Data Value Speculation for Future High-end Processors",
        "BeBoP: A cost effective predictor infrastructure for superscalar value prediction",
        "Sandbox Prefetching: Safe run-time evaluation of aggressive prefetchers",
        "Store Vulnerability Window (SVW): Re-Execution Filtering for Enhanced Load Optimization",
        "A decoupled predictor-directed stream prefetching architecture",
        "The Predictability of Data Values",
        "Long Term Parking (LTP): Criticality-aware Resource Allocation in OOO Processors",
        "Exploring value prediction with the EVES predictor",
        "A case for (partially) TAgged GEometric history length branch prediction",
        "Load Value Prediction via Path-based Address Prediction: Avoiding Mispredictions due to Conflicting Stores",
        "Efficient Load Value Prediction Using Multiple Predictors and Filters",
        "Automatically Characterizing Large Scale Program Behavior",
        "Efficiently Prefetching Complex Address Patterns",
        "Applying Deep Learning to the Cache Replacement Problem",
        "Sequential Program Prefetching in Memory Hierarchies",
        "Using a User-Level Memory Thread for Correlation Prefetching",
        "Spatial Memory Streaming",
        "PDede: Partitioned, Deduplicated, Delta Branch Target Buffer",
        "On Pipelining Dynamic Instruction Scheduling Logic",
        "Memory Renaming: Fast, Early and Accurate Processing of Memory Communication",
        "None",
        "None",
        "None",
        "None",
        "Speculation Techniques for Improving Load Related Instruction Scheduling",
        "Apache Spark: A Unified Engine for Big Data Processing",
        "Accelerating and Adapting Precomputation Threads for Effcient Prefetching",
        "SIPT: Speculatively Indexed, Physically Tagged Caches"
    ],
    "634d805b90e50fcafd4e117a": [
        "CUDA Basic Linear Algebra Subroutine library",
        "None",
        "None",
        "MLIR",
        "NVIDIA cuDNN",
        "NVIDIA cutlass",
        "None",
        "ONNX",
        "XLA",
        "AMD Radeon Instinct™ MI50 Accelerator",
        "TensorFlow: A System for Large-Scale Machine Learning",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "TVM: An automated endto-end optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Tensor processing primitives: A programming abstraction for efficiency and portability in deep learning workloads",
        "Deep residual learning for image recognition",
        "Long short-term memory",
        "Dissecting the nvidia volta gpu architecture via microbenchmarking",
        "Dissecting the graphcore ipu architecture via microbenchmarking",
        "Fast algorithms for convolutional neural networks",
        "Analytical characterization and design space exploration for optimization of cnns",
        "Romou: Rapidly generate high-performance tensor kernels for mobile gpus",
        "Rammer: Enabling holistic deep learning compiler optimizations with rtasks",
        "Halide: A language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "Drew: Efficient winograd cnn inference with deep reuse",
        "Poclib: A high-performance framework for enabling near orthogonal processing on compression",
        "Akg: Automatic kernel generation for neural processing units using polyhedral transformations",
        "Ansor: Generating high-performance tensor programs for deep learning",
        "Deep-learning model sparsity via tensorwith-sparsity-attribute",
        "Flextensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "Learning transferable architectures for scalable image recognition"
    ],
    "62fc5c7b90e50fcafdbca64d": [
        "Complex Query Answering with Neural Link Predictors",
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Translating embeddings for modeling multi-relational data",
        "Toward an architecture for never-ending language learning",
        "Neural Query Language: A Knowledge Base Query Language for Tensorflow",
        "Introduction to lattices and order",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Knowledge vault: A web-scale approach to probabilistic knowledge fusion",
        "Graph Random Neural Network for Semi-Supervised Learning on Graphs",
        "Hyperbolic neural networks. In NeurIPS",
        "Transformer Feed-Forward Layers Are Key-Value Memories",
        "Embedding logical queries on knowledge graphs",
        "Fastmoe: A fast mixture-of-expert training system",
        "Gaussian error linear units (gelus)",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Strategies For Pre-training Graph Neural Networks",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "Heterogeneous graph transformer",
        "Triangular norms",
        "Answering Complex Queries in Knowledge Graphs with Bidirectional Sequence Encoders",
        "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding",
        "Self-supervised learning: Generative or contrastive",
        "Decoupled Weight Decay Regularization",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs",
        "Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings",
        "Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs",
        "Pattern classification using ensemble methods",
        "Sequence-to-Sequence Knowledge Graph Completion and Question Answering",
        "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer",
        "ZINC 15-ligand discovery for everyone",
        "Faithful Embeddings for Knowledge Base Queries",
        "Observed versus latent features for knowledge base and text inference",
        "Complex embeddings for simple link prediction",
        "Composition-based Multi-Relational Graph Convolutional Networks",
        "Attention is all you need",
        "Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures",
        "Wikidata: a free collaborative knowledgebase",
        "Knowledge base completion via search-based question answering",
        "On layer normalization in the transformer architecture",
        "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning",
        "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning",
        "Do Transformers Really Perform Badly for Graph Representation?",
        "Graph contrastive learning with augmentations",
        "Graph transformer networks",
        "Oag: Toward linking large-scale heterogeneous entity graphs",
        "MoEfication: Conditional Computation of Transformer Models for Efficient Inference",
        "Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks"
    ],
    "634d80f190e50fcafd4ef483": [
        "Inter-coder agreement for computational linguistics",
        "FrameNet: A knowledge base for natural language processing",
        "Longformer: The long-document transformer",
        "Automatically labeled data generation for large scale event extraction",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Oxford english dictionary",
        "ELG: an event logic graph",
        "Hownet -a hybrid language and knowledge resource",
        "Developing a core ontology to improve military intelligence analysis",
        "Document-level event role filler extraction using multi-granularity contextualized encoding",
        "Document-level event role filler extraction using multi-granularity contextualized encoding",
        "Event extraction by answering (almost) natural questions",
        "Multi-sentence argument linking",
        "Information Extraction",
        "Eventwiki: A knowledge base of major events",
        "Eventkg: A multilingual event-centric temporal knowledge graph",
        "Message Understanding Conference-6: A brief history",
        "Giveme5w1h: A universal system for extracting main events from news articles",
        "Giveme5w: Main event retrieval from news articles by extraction of the five journalistic w questions",
        "Extraction of historical events from wikipedia",
        "Event Extraction for Document-Level Structured Summarization",
        "Overview of genia event task in bionlp shared task 2011",
        "The genia event extraction shared task, 2013 edition-overview",
        "Convolutional neural networks for sentence classification",
        "Text classification algorithms: A survey",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Hard news, soft news, 'general' news: The necessity and utility of an intermediate classification",
        "Document-level event argument extraction by conditional generation",
        "None",
        "Interrater reliability: the kappa statistic",
        "A dataset for open event extraction in English",
        "Graph convolutional networks with argument-aware pooling for event detection",
        "Overview of the pathway curation (pc) task of bionlp shared task",
        "Overview of the epigenetics and posttranslational modifications (epi) task of bionlp shared task 2011",
        "Event detection with neural networks: A rigorous empirical evaluation",
        "Overview of the cancer genetics (CG) task of BioNLP shared task",
        "Hard and soft news: A review of concepts, operationalizations and key findings",
        "Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter",
        "Making news by doing work: Routinizing the unexpected",
        "Yves Van de Peer, et al. 2013. Large-scale event extraction from literature with multi-level gene normalization",
        "Aquaontology-based question answering system",
        "Tdjee: A document-level joint model for financial event extraction",
        "MAVEN: A massive general domain event detection dataset",
        "Document-level event extraction via heterogeneous graph-based interaction model with a tracker",
        "Public opinion detection in an online lending forum: Sentiment analysis and data visualization",
        "Doc2edag: An end-to-end document-level framework for chinese financial event extraction"
    ],
    "6237ecc25aee126c0f3bef94": [
        "None",
        "Language models are few-shot learners",
        "Open Catalyst 2020 (OC20) Dataset and Community Challenges",
        "Neural message passing for quantum chemistry",
        "Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond",
        "A new model for learning in graph domains",
        "ForceNet: A Graph Neural Network for Large-Scale Quantum Calculations",
        "Gpipe: Efficient training of giant neural networks using pipeline parallelism",
        "Accelerating graph sampling for graph machine learning using gpus",
        "Improving the accuracy, scalability, and performance of graph neural networks with roc",
        "Neural message passing with edge updates for predicting properties of molecules and materials",
        "Fast and uncertainty-aware directional message passing for non-equilibrium molecules",
        "Directional message passing for molecular graphs",
        "GemNet: Universal Directional Graph Neural Networks for Molecules",
        "Quantifying the carbon emissions of machine learning",
        "Spherical message passing for 3d molecular graphs",
        "Decoupled weight decay regularization",
        "Neugraph: Parallel deep neural network computation on large graphs",
        "Orbnet: Deep learning for quantum chemistry using symmetry-adapted atomic-orbital features",
        "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions",
        "Quantum-chemical insights from deep tensor neural networks",
        "Schnet-a deep learning architecture for molecules and materials",
        "None",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "Rotation Invariant Graph Neural Networks using Spin Convolutions",
        "Energy and policy considerations for deep learning in NLP",
        "Reducing communication in graph neural network training",
        "Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties",
        "Do Transformers Really Perform Badly for Graph Representation?",
        "Scaling vision transformers",
        "AGL: a Scalable System for Industrial-purpose Graph Machine Learning",
        "DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs",
        "Graph neural networks: A review of methods and applications",
        "Model Training IS2RS Test Dataset AFbT↑ ADwT↑ FbT↑",
        "None",
        "DimeNet++ S2EF 20M + MD 21.08% 48.6% 0.2% DimeNet++-XL S2EF 20M + MD 40",
        "OOD Ads GemNet-T S2EF-ALL 26",
        "None",
        "None",
        "DimeNet++-XL S2EF 20M + MD 36.01% 55.68%",
        "GemNet-XL S2EF-ALL 30",
        "OOD Cat GemNet-T S2EF-ALL 24",
        "0% SpinConv S2EF-ALL 15.86% 53.92% 0% DimeNet++-S2EF 20M + MD 16.43% 48.19% 0% DimeNet++-XL S2EF 20M + MD 29",
        "OOD Both GemNet-T S2EF-ALL 25",
        "None",
        "DimeNet++-XL S2EF 20M + MD 28",
        "Experimental results on the IS2RS task comparing our models to the top four entries on the Open Catalyst leaderboard, showing metrics for each test dataset. The DimeNet++ and DimeNet++-XL models were trained on the S2EF 20M + MD dataset, that contains additional molecular dynamics data"
    ],
    "6257c5b25aee126c0f468af6": [
        "Cormorant: Covariant molecular neural networks",
        "Geom: Energy-annotated molecular conformations for property prediction and molecular generation",
        "Relational inductive biases, deep learning, and graph networks",
        "Se (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials",
        "Geometric deep learning: Grids, groups, graphs, geodesics, and gauges",
        "The open catalyst 2020 (oc20) dataset and community challenges",
        "Clusternet: Deep hierarchical cluster network with rigorously rotation-invariant representation for point cloud analysis",
        "Machine learning of accurate energy-conserving molecular force fields",
        "Towards exact molecular dynamics simulations with machine-learned force fields",
        "Gauge equivariant convolutional networks and the icosahedral cnn",
        "Gauge equivariant mesh cnns: Anisotropic convolutions on geometric graphs",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Protein interface prediction using graph convolutional networks",
        "Se (3)-transformers: 3d rototranslation equivariant attention networks",
        "Graph U-nets",
        "Large-scale learnable graph convolutional networks",
        "Topology-aware graph pooling networks",
        "Generalization and representational limits of graph neural networks",
        "Neural message passing for quantum chemistry",
        "Simple gnn regularisation for 3d molecular property prediction and beyond",
        "A new model for learning in graph domains",
        "Introduction to quantum mechanics",
        "Deep learning for 3d point clouds: A survey",
        "Forcenet: A graph neural network for large-scale quantum calculations",
        "Generative models for graphbased protein design",
        "Adam: A method for stochastic optimization",
        "Semi-supervised classification with graph convolutional networks",
        "Fast and uncertainty-aware directional message passing for non-equilibrium molecules",
        "Directional message passing for molecular graphs",
        "Gemnet: Universal directional graph neural networks for molecules",
        "Point cloud oversegmentation with graph-structured deep metric learning",
        "Large-scale point cloud semantic segmentation with superpoint graphs",
        "Dig: a turnkey library for diving into graph deep learning research",
        "N-gram graph: Simple unsupervised representation for graphs, with applications to molecules",
        "Deep learning of high-order interactions for protein interface prediction",
        "Molecular property prediction: A multilevel quantum interactions modeling perspective",
        "Provably powerful graph networks",
        "Deepsphere: Efficient spherical convolutional neural network with healpix sampling for cosmological applications",
        "Orbnet: Deep learning for quantum chemistry using symmetry-adapted atomic-orbital features",
        "Quantum chemistry structures and properties of 134 kilo molecules",
        "Learning to simulate complex physics with graph networks",
        "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions",
        "Equivariant message passing for the prediction of tensorial properties and molecular spectra",
        "Mining point cloud local structures by kernel correlation and graph pooling",
        "Weisfeiler-lehman graph kernels",
        "Reinforcement learning for molecular design guided by quantum mechanics",
        "Dynamic edge-conditioned filters in convolutional neural networks on graphs",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "End-to-end learning on 3d protein structure for interface prediction",
        "Physnet: A neural network for predicting energies, forces, dipole moments, and partial charges",
        "Graph attention networks",
        "Building powerful and equivariant graph neural networks with message-passing",
        "Graph attention convolution for point cloud semantic segmentation",
        "Dynamic graph cnn for learning on point clouds",
        "Advanced graph and sequence neural networks for molecular property prediction and drug discovery",
        "Moleculenet: a benchmark for molecular machine learning",
        "Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties",
        "How powerful are graph neural networks?",
        "An end-to-end deep learning architecture for graph classification"
    ],
    "6257c5b15aee126c0f468a55": [
        "Etc: Encoding long and structured inputs in transformers",
        "Longformer: The long-document transformer",
        "Jax: composable transformations of python+ numpy programs",
        "End-to-end object detection with transformers",
        "Generating long sequences with sparse transformers",
        "Rethinking attention with performers",
        "Adaptively sparse transformers",
        "Transformer-xl: Attentive language models beyond a fixed-length context",
        "Efficient attention using asymmetric clustering",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Flax: A neural network library and ecosystem for jax",
        "Transformers are rnns: Fast autoregressive transformers with linear attention",
        "Reformer: The efficient transformer",
        "Learning multiple layers of features from tiny images",
        "Generating wikipedia by summarizing long sequences",
        "Roberta: A robustly optimized bert pretraining approach",
        "Sgdr: Stochastic gradient descent with warm restarts",
        "Decoupled weight decay regularization",
        "Learning word vectors for sentiment analysis",
        "Sparse and constrained attention for neural machine translation",
        "Pointer sentinel mixture models",
        "On evaluation of adversarial perturbations for sequence-to-sequence models",
        "Listops: A diagnostic dataset for latent tree learning",
        "None",
        "Vahed Qazvinian, and Amjad Abu-Jbara. The acl anthology network corpus. Language Resources and Evaluation",
        "Compressive transformers for long-range sequence modelling",
        "Random features for large-scale kernel machines",
        "Efficient content-based sparse attention with routing transformers",
        "Adaptive attention span in transformers",
        "Synthesizer: Rethinking self-attention in transformer models",
        "Sparse sinkhorn attention",
        "Long range arena: A benchmark for efficient transformers",
        "Predicting attention sparsity in transformers",
        "Attention is all you need",
        "Fast transformers with clustered attention",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "A survey on learning to hash",
        "Cluster-former: Clustering-based sparse transformer for long-range dependency encoding",
        "Linformer: Self-attention with linear complexity",
        "Transformers: State-of-the-art natural language processing",
        "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting",
        "omformer: A nystr\\\" om-based algorithm for approximating self-attention",
        "Generalized autoregressive pretraining for language understanding",
        "Slurm: Simple linux utility for resource management",
        "Poolingformer: Long document modeling with pooling attention",
        "Informer: Beyond efficient transformer for long sequence time-series forecasting"
    ],
    "62c2a5625aee126c0fcca6f5": [
        "Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "A simple framework for contrastive learning of visual representations",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Batch virtual adversarial training for graph convolutional networks",
        "Benchmarking graph neural networks",
        "A fair comparison of graph neural networks for graph classification",
        "Graph adversarial training: Dynamically regularizing based on graph structure",
        "Splinecnn: Fast geometric deep learning with continuous b-spline kernels",
        "Large-scale adversarial training for vision-and-language representation learning",
        "Few-shot learning with graph neural networks",
        "Link-based classification",
        "Neural message passing for quantum chemistry",
        "Simple GNN regularisation for 3d molecular property prediction and beyond",
        "Explaining and harnessing adversarial examples",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Strategies for pre-training graph neural networks",
        "Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization",
        "Latent adversarial training of graph convolution networks",
        "Semi-supervised classification with graph convolutional networks",
        "Imagenet classification with deep convolutional neural networks",
        "Encoding social information with graph convolutional networks forpolitical perspective detection in news media",
        "Deepergcn: All you need to train deeper gcns",
        "Learning graphlevel representation for drug discovery",
        "Towards deep learning models resistant to adversarial attacks",
        "Adversarial training methods for semi-supervised text classification",
        "Virtual adversarial training: a regularization method for supervised and semi-supervised learning",
        "Deepinf: Social influence prediction with deep learning",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Adversarial training for free!",
        "Pitfalls of graph neural network evaluation",
        "Person re-identification with deep similarity-guided graph neural network",
        "Prepare for the worst: Generalizing across domain shifts with adversarial batch normalization",
        "Robustness may be at odds with accuracy",
        "Generalizing to unseen domains via adversarial data augmentation",
        "Nodeaug: Semi-supervised node classification with data augmentation",
        "Eda: Easy data augmentation techniques for boosting performance on text classification tasks",
        "Fast is better than free: Revisiting adversarial training",
        "Adversarial examples improve image recognition",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Graph contrastive learning with augmentations",
        "Graphsaint: Graph sampling based inductive learning method",
        "Freelb: Enhanced adversarial training for language understanding",
        "Adversarial attacks on neural networks for graph data"
    ],
    "6287492a5aee126c0ffe82dd": [
        "Neural program induction for KBQA without gold programs or query annotations",
        "Semantic parsing with Combinatory Categorial Grammars",
        "Abstract Meaning Representation for sembanking",
        "Linguistic generalization and compositionality in modern artificial neural networks",
        "Semantic parsing on Freebase from question-answer pairs",
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Large-scale simple question answering with memory networks",
        "Unsupervised dual paraphrasing for two-stage semantic parsing",
        "On the properties of neural machine translation: Encoder-decoder approaches",
        "Empirical evaluation of gated recurrent neural networks on sequence modeling",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Language to logical form with neural attention",
        "Benefits of intermediate annotations in reading comprehension",
        "Lc-quad 2.0: A large dataset for complex question answering over wikidata and dbpedia",
        "Message passing for hyper-relational knowledge graphs",
        "Beyond i.i.d.: Three levels of generalization for question answering on knowledge bases",
        "Dialog-to-action: Conversational question answering over a large-scale knowledge base",
        "Knowledge graph embedding based question answering",
        "Unseen entity handling in complex question answering over knowledge base via language generation",
        "Data recombination for neural semantic parsing",
        "Measuring compositional generalization: A comprehensive method on realistic data",
        "Adam: A method for stochastic optimization",
        "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
        "A survey on complex knowledge base question answering: Methods, challenges and solutions",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Neural symbolic machines: Learning semantic parsers on Freebase with weak supervision",
        "Lambda dependency-based compositional semantics",
        "Role-aware modeling for n-ary relational knowledge bases",
        "Key-value memory networks for directly reading documents",
        "Compositional semantic parsing on semi-structured tables",
        "Inferring logical forms from denotations",
        "Sim-pleQuestions nearly solved: A new upperbound and baseline approach",
        "Stepwise reasoning for multi-relation question answering over knowledge graph with weak supervision",
        "Complex program induction for querying knowledge bases in the absence of gold programs",
        "Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph",
        "Improving multi-hop question answering over knowledge graphs using knowledge base embeddings",
        "Modeling relational data with graph convolutional networks",
        "Compositional generalization and natural language variation: Can a semantic parsing approach handle both?",
        "TransferNet: An effective and transparent framework for multi-hop question answering over relation graph",
        "On generating characteristic-rich question sets for QA evaluation",
        "Open domain question answering using early fusion of knowledge bases and text",
        "SPARQA: skeleton-based semantic parsing for complex questions over knowledge bases",
        "The web as a knowledge-base for answering complex questions",
        "Representing text for joint embedding of text and knowledge bases",
        "Wikidata: a free collaborative knowledge base",
        "Building a semantic parser overnight",
        "Variational reasoning for question answering with knowledge graph",
        "Seq2sql: Generating structured queries from natural language using reinforcement learning"
    ],
    "6327ec7990e50fcafd928963": [
        "Highly accurate protein structure prediction with alphafold",
        "Rishub Jain",
        "What's next for AlphaFold and the AI protein-folding revolution",
        "Hidden markov model speed heuristic and iterative HMM search procedure",
        "MGnify: the microbiome analysis resource in 2020",
        "UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches",
        "HHblits: lightningfast iterative protein sequence searching by HMM-HMM alignment",
        "Uniclust databases of clustered and deeply annotated protein sequences and alignments",
        "UniProt: the universal protein knowledgebase in 2021",
        "Deep learning reveals many more inter-protein residue-residue contacts than direct coupling analysis",
        "Gaussian error linear units (gelus)",
        "None",
        "Revisiting bfloat16 training",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "Efficient denoising pretraining of large scale autoencoding language models with model generated signals",
        "Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters",
        "Oneflow: Redesign the distributed deep learning framework from scratch",
        "Protein Data Bank (PDB): The single global macromolecular structure archive",
        "Helixfold: An efficient implementation of alphafold2 using paddlepaddle",
        "Fastfold: Reducing alphafold training time from 11 days to 67 hours",
        "Accurate prediction of protein structures and interactions using a three-track neural network",
        "None"
    ],
    "63520de390e50fcafd60ec75": [
        "Blended diffusion for text-driven editing of natural images",
        "Image-based clip-guided essence transfer",
        "Conditioning method for denoising diffusion probabilistic models",
        "Perception prioritized training of diffusion models",
        "Stargan v2: Diverse image synthesis for multiple domains",
        "Style transformer: Unpaired text style transfer without disentangled latent representation",
        "Diffusion models beat gans on image synthesis",
        "Stylegan-nada: Clipguided domain adaptation of image generators",
        "Generative adversarial networks",
        "Ganspace: Discovering interpretable gan controls",
        "Denoising diffusion probabilistic models",
        "Progressive growing of gans for improved quality, stability, and variation",
        "Training generative adversarial networks with limited data",
        "Elucidating the design space of diffusionbased generative models",
        "Diffusionclip: Text-guided image manipulation using diffusion models",
        "Auto-encoding variational bayes",
        "Maskgan: Towards diverse and interactive facial image manipulation",
        "Editgan: High-precision semantic image editing",
        "More control for free! image synthesis with semantic diffusion guidance",
        "Deep learning face attributes in the wild",
        "Repaint: Inpainting using denoising diffusion probabilistic models",
        "Sdedit: Image synthesis and editing with stochastic differential equations",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "Improved denoising diffusion probabilistic models",
        "Styleclip: Textdriven manipulation of stylegan imagery",
        "Diffusion autoencoders: Toward a meaningful and decodable representation",
        "Learning transferable visual models from natural language supervision",
        "Highresolution image synthesis with latent diffusion models",
        "Learning internal representations by error propagation",
        "Generating high fidelity data from low-density regions using diffusion models",
        "Interpreting the disentangled face representation learned by gans",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Denoising diffusion implicit models",
        "Score-based generative modeling through stochastic differential equations",
        "Score-based generative modeling in latent space",
        "Learning fast samplers for diffusion models by differentiating through sample quality",
        "Luc Van Gool, and Errui Ding. Predict, prevent, and evaluate: Disentangled text-driven image manipulation empowered by pre-trained vision-language model",
        "Bisenet: Bilateral segmentation network for real-time semantic segmentation",
        "Construction of a large-scale image dataset using deep learning with humans in the loop",
        "Latentclr: A contrastive learning approach for unsupervised discovery of interpretable directions",
        "Scene parsing through ade20k dataset",
        "Semantic understanding of scenes through the ade20k dataset"
    ],
    "63520de890e50fcafd60f4dd": [
        "Explanations for CommonsenseQA: New Dataset and Models",
        "Muppet: Massive multi-task representations with pre-finetuning",
        "Open-domain question answering goes conversational via question rewriting",
        "On the opportunities and risks of foundation models",
        "JAX: composable transformations of Python+NumPy programs",
        "Language models are few-shot learners",
        "Taskmaster-1: Toward a realistic and diverse dialog dataset",
        "Make up your mind! Adversarial generation of inconsistent natural language explanations",
        "Evaluating large language models trained on code",
        "Scaling language modeling with Pathways",
        "TyDiQA: A benchmark for information-seeking question answering in typologically diverse languages",
        "Training verifiers to solve math word problems",
        "Dialog inpainting: Turning documents into dialogs",
        "Efficient Scaling of Language Models with Mixture-of-Experts. ICML",
        "Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies",
        "Measuring massive multitask language understanding",
        "Training compute-optimal large language models",
        "Large language models can self-improve",
        "A domain-specific supercomputer for training deep neural networks",
        "Scaling laws for neural language models",
        "UnifiedQA: Crossing format boundaries with a single QA system",
        "QASC: A dataset for question answering via sentence composition",
        "Large language models are zero-shot reasoners",
        "QED: A framework and dataset for explanations in question answering",
        "The power of scale for parameter-efficient prompt tuning",
        "Solving quantitative reasoning problems with language models",
        "Competition-level code generation with alphacode",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Learning to learn in context",
        "Model cards for model reporting",
        "Show your work: Scratchpads for intermediate computation with language models",
        "CREAK: A dataset for commonsense reasoning over entity knowledge",
        "Training language models to follow instructions with human feedback",
        "Exploring the role of task transferability in large-scale multi-task learning",
        "The LAMBADA dataset: Word prediction requiring a broad discourse context",
        "How many data samples is an additional instruction worth",
        "Data cards: Purposeful and transparent dataset documentation for responsible ai",
        "Language models are unsupervised multitask learners",
        "Scaling language models: Methods, analysis &amp; insights from training Gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Explain yourself! Leveraging language models for commonsense reasoning",
        "Scaling up models and data with t5x and seqio",
        "Gender bias in coreference resolution",
        "Multitask prompted training enables zero-shot task generalization",
        "Continual-T0: Progressively instructing 50+ tasks to language models without forgetting",
        "Adafactor: Adaptive learning rates with sublinear memory cost",
        "Language models are multilingual chain-of-thought reasoners",
        "Searching for efficient transformers for language modeling",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Updates and lessons from ai forecasting. Blog post",
        "Challenging BIG-Bench tasks and whether chain-of-thought can solve them",
        "Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge",
        "Unifying language learning paradigms",
        "Transcending scaling laws with 0.1% extra compute",
        "SuperGlue: A stickier benchmark for general-purpose language understanding systems",
        "Does it make sense? And why? A pilot study for sense making and explanation",
        "What language model architecture and pretraining objective work best for zero-shot generalization? ICML",
        "Self-consistency improves chain of thought reasoning in language models",
        "Benchmarking generalization via in-context instructions on 1,600+ language tasks",
        "Finetuned language models are zero-shot learners",
        "Emergent abilities of large language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "ByT5: Towards a token-free future with pre-trained byte-to-byte models",
        "Graph-based, self-supervised program repair from diagnostic feedback",
        "Crossfit: A few-shot learning challenge for cross-task generalization in NLP",
        "STaR: Bootstrapping reasoning with reasoning",
        "Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections"
    ],
    "6389d6e490e50fcafdff693f": [
        "Growth of Hyperscale Data Centers",
        "Moore's Law Is Dead. Now What",
        "A new golden age for computer architecture",
        "Why data centres are the new frontier in the fight against climate change",
        "Carbon emissions and large neural network training",
        "The Chip Shortage Keeps Getting Worse. Why Can't We Just Make More",
        "A domain-specific supercomputer for training deep neural networks",
        "A cloud-scale acceleration architecture",
        "Ten lessons from three generations shaped google's tpuv4i: Industrial product",
        "The datacenter as a computer: An introduction to the design of warehouse-scale machines",
        "Fine-grain power breakdown of modern out-of-order cores and its implications on skylake-based systems",
        "CAMP: A technique to estimate perstructure power at run-time using a few simple parameters",
        "Efficient embedded computing",
        "Power balanced pipelines",
        "APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors",
        "? suite: A Benchmark Suite for Microservices",
        "An open-source benchmark suite for microservices and their hardware-software implications for cloud &amp; edge systems",
        "The nanoPU: Redesigning the CPU-Network Interface to Minimize RPC Tail Latency",
        "Dagger: efficient and fast RPCs in cloud microservices with near-memory reconfigurable NICs",
        "SoftSKU: Optimizing server architectures for microservice diversity@ scale",
        "Accelerometer: Understanding acceleration opportunities for data center overheads at hyperscale",
        "?tune: Auto-tuned threading for OLDI microservices",
        "Profiling a Warehouse-Scale Computer",
        "Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware",
        "Memory Hierarchy for Web Search",
        "AsmDB: Understanding and Mitigating Front-End Stalls in Warehouse-Scale Computers",
        "Classifying Memory Access Patterns for Prefetching",
        "Architectural support for server-side PHP processing",
        "Scale-Out Processors",
        "The next generation AMD enterprise server product architecture",
        "Cascade Lake: Next generation Intel XEON scalable processor",
        "The ARM Neoverse N1 platform: Building blocks for the next-gen cloud-to-edge infrastructure SoC",
        "Ampere Computing",
        "Marvell Thun-derX3: Next-Generation Arm-Based Server Processor",
        "IBM Power9 processor architecture",
        "Memcachedgpu: Scaling-up scale-out key-value stores",
        "Rhythm: Harnessing Data Parallel Hardware for Server Workloads",
        "GPUfs: Integrating a file system with GPUs",
        "GPUnet: Networking abstractions for GPU programs",
        "Generic system calls for GPUs",
        "NVIDIA GPUDirect",
        "ispc: A SPMD compiler for high-performance CPU programming",
        "Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs",
        "Netflix on AWS",
        "Massively Parallel Server Processors",
        "First-generation inference accelerator deployment at facebook",
        "Caching beyond RAM: Riding the Cliff",
        "Improving streaming graph processing performance using input knowledge",
        "DreamWeaver: Architectural Support for Deep Sleep",
        "PowerNap: Eliminating Server Idle Power",
        "?DPM: Dynamic power management for the microsecond era",
        "Brawny cores still beat wimpy cores, most of the time",
        "Octopus-Man: QoSdriven task management for heterogeneous multicores in warehouse-scale computers",
        "Amdahl's law for tail latency",
        "DDR5 specifications",
        "Introducing Micron DDR5 SDRAM: More Than a Generational Update",
        "DDR5 vs DDR4 -All the Design Challenges &amp; Advantages",
        "NVIDIA enters the ARMs race with homegrown Grace CPUS",
        "DDR5 vs. DDR6: Here's What to Expect in RAM Modules",
        "Intel to Launch Next-Gen Sapphire Rapids Xeon with High Bandwidth Memory",
        "SIMT-X: Extending single-instruction multi-threading to out-of-order cores",
        "Register renaming and scheduling for dynamic execution of predicated code",
        "General-Purpose Graphics Processor Architectures",
        "Stack-less SIMT reconvergence at low cost",
        "Control flow optimization via dynamic reconvergence prediction",
        "A mechanism for SIMD execution of SPMD programs",
        "Dynamic warp formation and scheduling for efficient GPU control flow",
        "CUDA Binary Utilities",
        "CUDA Toolkit Documentation",
        "MIMD synchronization on SIMT architectures",
        "CUDA and Applications to Task-based Programming",
        "NVIDIA Tesla V100 GPU architecture",
        "Branch prediction and simultaneous multithreading",
        "Effective ahead pipelining of instruction block address generation",
        "Improving GPU performance via large warps and two-level warp scheduling",
        "Attack of the killer microseconds",
        "Enhancing server efficiency in the face of killer microseconds",
        "Taming the killer microsecond",
        "Systems and methods for coalescing memory accesses of parallel threads",
        "GPUWattch: enabling energy optimizations in GPGPUs",
        "Dynamic speculation and synchronization of data dependences",
        "INVLPG -Invalidate Specific TLB Entries",
        "Eventual consistency today: limitations, extensions, and beyond",
        "Overview of memory consistency",
        "Simplifying ARM concurrency: multicopyatomic axiomatic and operational models for ARMv8",
        "Understanding power multiprocessors",
        "A tutorial introduction to the ARM and POWER relaxed memory models",
        "HMG: Extending cache coherence protocols across modern hierarchical multi-gpu systems",
        "QuickRelease: A throughput-oriented approach to release consistency on GPUs",
        "Content-addressable memory (CAM) circuits and architectures: A tutorial and survey",
        "A new x86 core architecture for the next generation of computing",
        "Exploiting interthread temporal locality for chip multithreading",
        "Effects of multithreading on cache performance",
        "ParVec: vectorizing the PARSEC benchmark suite",
        "The Apache HTTP server project",
        "Enhancing the scalability of MemCached",
        "Hoard: A Scalable Memory Allocator for Multithreaded Applications",
        "Throughput-oriented GPU memory allocation",
        "TCMalloc : Thread-Caching Malloc",
        "Speculative reconvergence for improved SIMT efficiency",
        "CUDA C Programming Guide",
        "Raw Linux Threads via System Calls",
        "mmap -Linux manual page",
        "Are dynamic memory managers on GPUs slow? a survey and benchmarks",
        "Eliminating cache conflict misses through XOR-based placement functions",
        "Pseudo-Randomly Interleaved Memory",
        "ld.so -Linux manual page",
        "What is the LDPRELOAD trick",
        "Dynamic warp subdivision for integrated branch and memory divergence tolerance",
        "The Dual-Path Execution Model for Efficient GPU Control Flow",
        "A Scalable Multi-Path Microarchitecture for Efficient GPU Control Flow",
        "SAGA-bench: Software and hardware characterization of streaming graph analytics workloads",
        "gRPC: A high performance, open source universal RPC framework",
        "PIN: Building customized program analysis tools with dynamic instrumentation",
        "A SIMT Analyzer for Multi-Threaded CPU Applications",
        "Accel-Sim: An Extensible Simulation Framework for Validated GPU Modeling",
        "A detailed and flexible cycle-accurate network-on-chip simulator",
        "ZSim: Fast and accurate microarchitectural simulation of thousand-core systems",
        "CACTI 6.0: A tool to model large caches",
        "?qsim: Enabling accurate and scalable simulation for interactive microservices",
        "McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures",
        "McPAT-Calib: A Microarchitecture Power Modeling Framework for Modern CPUs",
        "A100 Tensor Core GPU architecture",
        "The Tail at Scale",
        "Modern X86 Assembly Language Programming",
        "The ARM scalable vector extension",
        "Which are the most used web servers",
        "What is the python global interpreter lock (gil)",
        "Are GPUs Non-Green Computing Devices?",
        "Debunking the 100X GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU",
        "Computing benchmarks: Processors",
        "Comparing energy efficiency of CPU, GPU and FPGA implementations for vision kernels",
        "CUDA C Programming Guide",
        "Programming Massively Parallel Processors: A Hands-on Approach",
        "Optimizing CUDA Applications for NVIDIA A100 GPU",
        "PCI Express 6.0 With 256GB/s Coming in 2022 Because Screw Bandwidth Constraints",
        "Characterizing and evaluating a key-value store application on heterogeneous CPU-GPU systems",
        "Vortex: Extending the RISC-V ISA for GPGPU and 3D-Graphics",
        "Simty: generalized SIMT execution on RISC-V",
        "None",
        "DITVA: Dynamic inter-thread vectorization architecture",
        "Dynamic inter-thread vectorization architecture: extracting DLP from TLP",
        "The Vector-Thread Architecture",
        "LOOG: Improving GPU Efficiency With Light-Weight Out-Of-Order Execution",
        "Warped-preexecution: A GPU pre-execution approach for improving latency hiding",
        "HAWS: Accelerating GPU wavefront execution through selective out-of-order execution",
        "Revisiting ILP designs for throughput-oriented GPGPU architecture",
        "Out-of-Order Vector Architectures",
        "Optimus Prime: Accelerating Data Transformation in Servers",
        "Cerebros: Evading the RPC tax in datacenters",
        "E3:{Energy-Efficient} microservices on {SmartNIC-Accelerated} servers",
        "Multi-execution: multicore caching for data-similar executions"
    ],
    "63a2c50090e50fcafdb97c2f": [
        "Bottom-up and top-down attention for image captioning and visual question answering",
        "A large annotated corpus for learning natural language inference",
        "Alec Radford, Ilya Sutskever, and Dario Amodei",
        "UNITER: Universal image-text representation learning",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "An empirical study of training end-to-end vision-and-language transformers",
        "Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering",
        "Seeing out of the box: End-to-end pre-training for visionlanguage representation learning",
        "nnU-Net: Self-adapting framework for U-Net-based medical image segmentation",
        "Syn-thRef: Generation of synthetic referring expressions for object segmentation",
        "ViLT: Vision-and-language transformer without convolution or region supervision",
        "Visual Genome: Connecting language and vision using crowdsourced dense image annotations",
        "Align before fuse: Vision and language representation learning with momentum distillation",
        "VisualBERT: A simple and performant baseline for vision and language",
        "Unsupervised vision-and-language pre-training without parallel images and captions",
        "2021c. UNIMO: Towards unified-modal understanding and generation via cross-modal contrastive learning",
        "Oscar: Object-semantics aligned pre-training for vision-language tasks",
        "Microsoft COCO: Common objects in context",
        "Referring expression generation and comprehension via attributes",
        "2021a. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Improving referring expression grounding with cross-modal attention-guided erasing",
        "Xuming He, and Nan Duan. 2021b. KD-VLP: Improving end-to-end vision-and-language pretraining with object knowledge distillation",
        "2021c. Swin Transformer: Hierarchical vision Transformer using shifted windows",
        "ViLBERT: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
        "Im2Text: Describing images using 1 million captioned photographs. Advances in neural information processing systems",
        "Flickr30k entities: Collecting region-to-phrase correspondences for richer imageto-sentence models",
        "Girish Sastry, Amanda Askell, Pamela Mishkin",
        "Learning transferable visual models from natural language supervision",
        "Zero-shot text-to-image generation",
        "Conceptual Captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning",
        "A corpus for reasoning about natural language grounded in photographs",
        "Visual entailment: A novel task for fine-grained image understanding",
        "E2E-VLP: End-to-end vision-language pre-training enhanced by visual learning",
        "Probing inter-modality: Visual parsing with self-attention for vision-and-language pre-training",
        "Deep modular co-attention networks for visual question answering",
        "Decoding strategies for neural referring expression generation",
        "VinVL: Revisiting visual representations in vision-language models",
        "Unsupervised vision-and-language pre-training via retrieval-based multi-granular alignment",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books"
    ],
    "62be66205aee126c0f07d1e0": [
        "Characterizing the pedagogical benefits of adaptive feedback for compilation errors by novice programmers",
        "Syntax-guided synthesis",
        "Is github's copilot as bad as humans at introducing vulnerabilities in code? arXiv preprint",
        "Language models are few-shot learners",
        "Evaluating large language models trained on code",
        "multi-mode translation of natural language and python code with transformers",
        "A coefficient of agreement for nominal scales",
        "None",
        "Introduction to algorithms reviews",
        "Generating formal system models from natural language descriptions",
        "Solving linear algebra by program synthesis",
        "Cyclomatic complexity",
        "None",
        "A pre-trained model for programming and natural languages",
        "The space of developer productivity: There's more to it than you think",
        "None",
        "Dimensions in program synthesis",
        "Automated clustering and program repair for introductory programming assignments",
        "Learning formal grammars to translate natural language specifications into hardware assertions",
        "Re-factoring based program repair applied to programming assignments",
        "Competition-level code generation with alphacode",
        "A deductive approach to program synthesis",
        "Nlp (natural language processing) for nlp (natural language programming)",
        "The potential of artificial intelligence as a method of software developer's productivity improvement",
        "An empirical evaluation of GitHub Copilot's code suggestions",
        "Bleu: a method for automatic evaluation of machine translation",
        "Asleep at the keyboard? assessing the security of github copilot's code contributions",
        "Machine translation from natural language to code using long-short term memory",
        "Codebleu: a method for automatic evaluation of code synthesis",
        "Comparing python programs using abstract syntax trees",
        "Cyclomatic complexity: The nesting problem",
        "Choose your programming copilot: A comparison of the program synthesis performance of github copilot and genetic programming",
        "Recent developments in program synthesis with evolutionary algorithms",
        "Solving probability and statistics problems by program synthesis",
        "Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models",
        "W3schools Team. W3schools",
        "Productivity assessment of neural code completion"
    ],
    "633e477c90e50fcafde5a596": [
        "Language models are few-shot learners",
        "On the opportunities and risks of foundation models",
        "Calibrate before use: Improving few-shot performance of language models",
        "Training language models to follow instructions with human feedback",
        "Multitask prompted training enables zero-shot task generalization",
        "Chain of thought prompting elicits reasoning in large language models",
        "Can language models learn from explanations in context?",
        "Reframing instructional prompts to gptk's language",
        "Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts",
        "Maieutic prompting: Logically consistent reasoning with recursive explanations",
        "How can we know what language models know? Transactions of the",
        "It's not just size that matters: Small language models are also few-shot learners",
        "Snorkel: Rapid training data creation with weak supervision",
        "Learning dependency structures for weak supervision models",
        "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow",
        "Opt: Open pre-trained transformer language models",
        "Can foundation models wrangle your data?",
        "Can foundation models help us achieve perfect secrecy?",
        "Scaling laws for neural language models",
        "Scaling language modeling with pathways",
        "Benchmarking generalization via in-context instructions on 1,600+ language tasks",
        "Finetuned language models are zero-shot learners",
        "Is a question decomposition unit all we need?",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "What makes good incontext examples for gpt-3?",
        "Self-consistency improves chain of thought reasoning in language models",
        "Data programming: Creating large training sets, quickly",
        "Training complex models with multi-task weak supervision",
        "Fast and three-rious: Speeding up weak supervision with triplet methods",
        "Language models in the loop: Incorporating prompting into weak supervision",
        "SuperGLUE: A stickier benchmark for general-purpose language understanding systems",
        "Character-level convolutional networks for text classification",
        "Training compute-optimal large language models",
        "Lsdsem 2017 shared task: The story cloze test",
        "Adversarial nli: A new benchmark for natural language understanding",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Realtime qa: What's the answer right now? arXiv preprint",
        "Natural questions: a benchmark for question answering research",
        "Semantic parsing on Freebase from question-answer pairs",
        "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Promptsource: An integrated development environment and repository for natural language prompts",
        "Ethical and social risks of harm from language models",
        "None",
        "None",
        "Robust principal component analysis?",
        "ROUGE: A package for automatic evaluation of summaries",
        "Know what you don't know: Unanswerable questions for squad",
        "Boolq: Exploring the surprising difficulty of natural yes/no questions",
        "The commitmentbank: Investigating projection in naturally occurring discourse",
        "Choice of plausible alternatives: An evaluation of commonsense causal reasoning",
        "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences"
    ],
    "62afe5495aee126c0f668b42": [
        "Neural Machine Translation by Jointly Learning to Align and Translate",
        "Relational Graph Attention Networks",
        "Preliminary study on the construction of Chinese medical knowledge graph",
        "Structured Dialogue Policy with Graph Neural Networks",
        "MedDialog: A Large-scale Medical Dialogue Dataset",
        "Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation",
        "Wizard of Wikipedia: Knowledge-Powered Conversational Agents",
        "Extracting Symptoms and their Status from Clinical Conversations",
        "Learning to Infer Entities, Properties and their Relations from Clinical Conversations",
        "Dialogue Discourse-Aware Graph Model and Data Augmentation for Meeting Summarization",
        "A knowledge-grounded neural conversation model",
        "Dense Passage Retrieval for Open-Domain Question Answering",
        "Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue",
        "Adam: A Method for Stochastic Optimization",
        "Semi-Supervised Variational Reasoning for Medical Dialogue Generation",
        "A Diversity-Promoting Objective Function for Neural Conversation Models",
        "Zero-resource knowledge-grounded dialogue generation",
        "Learning to Select Knowledge for Response Generation in Dialog Systems",
        "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation",
        "Enhancing dialogue symptom diagnosis with global attention and symptom graph",
        "MedDG: A Large-scale Medical Consultation Dataset for Building Medical Dialogue System",
        "Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems",
        "Bleu: a Method for Automatic Evaluation of Machine Translation",
        "Get To The Point: Summarization with Pointer-Generator Networks",
        "Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models",
        "Summarizing Medical Conversations via Identifying Important Utterances",
        "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
        "Unsupervised Learning of Deterministic Dialogue Structure with Edge-Enhanced Graph Auto-Encoder",
        "Sequence to Sequence Learning with Neural Networks",
        "Attention is All you Need",
        "Discovering Dialog Structure Graph for Coherent Dialog Generation",
        "MIE: A medical information extractor towards medical dialogues",
        "DIALOGPT: Large-Scale Generative Pre-training for Conversational Response Generation",
        "Low-Resource Knowledge-Grounded Dialogue Generation"
    ],
    "634781fe90e50fcafd2c1a49": [
        "Pre-training of deep bidirectional transformers for language understanding",
        "A robustly optimized bert pretraining approach",
        "Language models are few-shot learners",
        "Attention is all you need",
        "Big bird: Transformers for longer sequences",
        "Sparse is enough in scaling transformers",
        "Are sixteen heads really better than one?",
        "Revealing the dark secrets of bert",
        "What does bert look at? an analysis of bert's attention",
        "Attention is not all you need: Pure attention loses rank doubly exponentially with depth",
        "Mixout: Effective regularization to finetune large-scale pretrained language models",
        "On the stability of finetuning bert: Misconceptions, explanations, and strong baselines",
        "Raise a child in large language model: Towards effective and generalizable fine-tuning",
        "Good-enough compositional data augmentation",
        "Hiddencut: Simple data augmentation for natural language understanding with better generalizability",
        "Adversarial training for large neural language models",
        "Simple contrastive representation adversarial learning for nlp tasks",
        "R-drop: regularized dropout for neural networks",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Concrete dropout",
        "A regularization method for convolutional networks",
        "Autodropout: Learning dropout patterns to regularize deep networks",
        "Self-attention attribution: Interpreting information interactions inside transformer",
        "Ale? Leonardis, and Ke Tang. A survey on neural network interpretability",
        "How to explain individual classification decisions",
        "Axiomatic attribution for deep networks",
        "Attention is not explanation",
        "Influence patterns for explaining information flow in bert",
        "Pre-training text encoders as discriminators rather than generators",
        "OPUS-MT -Building open translation services for the World",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "Findings of the 2016 conference on machine translation",
        "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
        "Paws-x: A cross-lingual adversarial dataset for paraphrase identification",
        "Deep inside convolutional networks: Visualising image classification models and saliency maps",
        "Automatically constructing a corpus of sentential paraphrases",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Quora question pairs",
        "Cola: The corpus of linguistic acceptability",
        "Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation",
        "The fifth pascal recognizing textual entailment challenge",
        "Comparison of the predicted and observed secondary structure of t4 phage lysozyme",
        "Pearson correlation coefficient",
        "Transformers: State-of-theart natural language processing",
        "Super tickets in pre-trained language models: From model compression to improving generalization",
        "Regularization of neural networks using dropconnect",
        "Understanding neural networks through representation erasure",
        "Pathologies of neural models make interpretations difficult",
        "Restricting the flow: Information bottlenecks for attribution",
        "Layer-wise relevance propagation for neural networks with local renormalization layers",
        "Reasoning about entailment with neural attention",
        "Is attention interpretable?",
        "Attention is not not explanation",
        "Deep inside convolutional networks: Visualising image classification models and saliency maps",
        "Striving for simplicity: The all convolutional net",
        "On identifiability in transformers",
        "Revisiting over-smoothing in bert from the perspective of graph"
    ],
    "62ceb9215aee126c0f4090b0": [
        "Deep neural networks for multiple speaker detection and localization",
        "Robust real-time embedded emg recognition framework using temporal convolutional networks on a multicore iot processor",
        "Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalogram",
        "Data-driven structural health monitoring and damage detection through deep learning: State-of-the-art review",
        "Manufacturing as a data-driven practice: Methodologies, technologies, and tools",
        "A critical review of recurrent neural networks for sequence learning",
        "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling",
        "Edge computing: Vision and challenges",
        "Neural architecture search with reinforcement learning",
        "Fbnetv2: Differentiable neural architecture search for spatial and channel dimensions",
        "Morphnet: Fast &amp; simple resource-constrained structure learning of deep networks",
        "Mnasnet: Platform-aware neural architecture search for mobile",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Pruning in time (pit): A light-weight network architecture optimizer for temporal convolutional networks",
        "Gap-8: A risc-v soc for ai at the edge of the iot",
        "STM32H7",
        "Robust and energy-efficient ppg-based heart-rate monitoring",
        "Temporal convolution for real-time keyword spotting on mobile devices",
        "Improved gesture recognition based on semg signals and tcn",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Shufflenet v2: Practical guidelines for efficient cnn architecture design",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and &lt; 1mb model size",
        "Learning transferable architectures for scalable image recognition",
        "Designing neural network architectures using reinforcement learning",
        "Large-scale evolution of image classifiers",
        "Darts: Differentiable architecture search",
        "Single-path mobile automl: Efficient convnet design and nas hyperparameter optimization",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Fine-Grained Stochastic Architecture Search",
        "Scalpel: Customizing dnn pruning to the underlying hardware parallelism",
        "Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1",
        "X-cube-ai",
        "Gap8 nntool",
        "Deep ppg: large-scale heart rate estimation with convolutional neural networks",
        "A general framework for never-ending learning from time series streams",
        "Ecg-tcn: Wearable cardiac arrhythmia detection with a temporal convolutional network",
        "Building the ninapro database: A resource for the biorobotics community",
        "Hierarchical attention networks for document classification",
        "Speech commands: A dataset for limited-vocabulary speech recognition",
        "Benchmarking tinyml systems: Challenges and direction",
        "Tcn mapping optimization for ultra-low power time-series edge inference",
        "Dory: Automatic end-to-end deployment of real-world dnns on low-cost iot mcus"
    ],
    "63bb859d90e50fcafd06ee17": [
        "Bullseye polytope: A scalable clean-label poisoning attack with improved transferability",
        "Venomave: Targeted poisoning against speech recognition",
        "Amazon codewhisperer, ml-powered coding companion",
        "Program synthesis with large language models",
        "{T-Miner}: A generative approach to defend against trojan attacks on {DNN-based} text classification",
        "Language models are few-shot learners",
        "The secret sharer: Evaluating and testing unintended memorization in neural networks",
        "Extracting training data from large language models",
        "Poison attacks against text datasets with conditional adversarially regularized autoencoder",
        "Detecting backdoor attacks on deep neural networks by activation clustering",
        "Deepinspect: A black-box trojan detection and mitigation framework for deep neural networks",
        "Evaluating large language models trained on code",
        "Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach. computers &amp; security",
        "Badnl: Backdoor attacks against nlp models",
        "Targeted backdoor attacks on deep learning systems using data poisoning",
        "A backdoor attack against lstm-based text classification systems",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Trojan attack on deep generative models in autonomous driving",
        "Codebert: A pre-trained model for programming and natural languages",
        "Incoder: A generative model for code infilling and synthesis",
        "The pile: An 800gb dataset of diverse text for language modeling",
        "Witches' brew: Industrial scale data poisoning via gradient matching",
        "Codeql, a semantic code analysis engine",
        "Github copilot -your ai pair programmer",
        "Pre-trained models: Past, present and future",
        "The curious case of neural text degeneration",
        "Metapoison: Practical general-purpose clean-label data poisoning",
        "Adversarial machine learning-industry perspectives",
        "Competition-level code generation with alphacode",
        "Fine-pruning: Defending against backdooring attacks on deep neural networks",
        "Self-supervised learning: Generative or contrastive",
        "Piccolo: Exposing complex backdoors in nlp transformer models",
        "Codexglue: A machine learning benchmark dataset for code understanding and generation",
        "2022 cwe top 25 most dangerous software weaknesses",
        "Silvio Savarese, and Caiming Xiong. A conversational paradigm for program synthesis",
        "Asleep at the keyboard? assessing the security of github copilot's code contributions",
        "Do users write more insecure code with ai assistants? arXiv preprint",
        "Hidden killer: Invisible textual backdoor attacks with syntactic trigger",
        "Turn the combination lock: Learnable textual backdoor attacks via word substitution",
        "Pre-trained models for natural language processing: A survey",
        "Semgrep, a static analysis engine for code",
        "Semgrep, a static analysis engine for code",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Hidden trigger backdoor attacks",
        "Baaan: Backdoor attacks against autoencoder and ganbased machine learning models",
        "You autocomplete me: Poisoning vulnerabilities in neural code completion",
        "Scott Coull, and Alina Oprea. {Explanation-Guided} backdoor poisoning attacks against malware classifiers",
        "Pythia: Ai-assisted code completion system",
        "Spectral signatures in backdoor attacks",
        "Natural language processing with transformers",
        "Clean-label backdoor attacks",
        "Attention is all you need",
        "Concealed data poisoning attacks on nlp models",
        "Gpt-j-6b: A 6 billion parameter autoregressive language model",
        "Neural cleanse: Identifying and mitigating backdoor attacks in neural networks",
        "Detecting ai trojans using meta neural analysis",
        "Data poisoning attack against recommender system using incomplete and perturbed data",
        "Trojaning language models for fun and profit",
        "Transferable clean-label poisoning attacks on deep neural nets"
    ],
    "628749265aee126c0ffe6e73": [
        "Virtual cardiologist -a conversational system for medical diagnosis",
        "A chatbot solution to chat app problems: Envisioning a chatbot counseling system for teenage victims of online sexual exploitation",
        "A virtual conversational agent for teens with autism spectrum disorder: Experimental results and design lessons",
        "Novel computational linguistic measures, dialogue system and the development of sophie: Standardized online patient for healthcare interaction education",
        "Institutional Review Board Approval and Publication of Human Research Results",
        "Spoken dialogue system for learning braille",
        "Dialogue system: A brief review",
        "A call for more rigor in unsupervised cross-lingual learning",
        "Chatbot for healthcare system using artificial intelligence",
        "Use of voice activated interfaces by people with intellectual disability",
        "A graph based chatbot for cancer patients",
        "Linguistically na?ve != language independent: Why NLP needs linguistic typology",
        "On the dangers of stochastic parrots: Can language models be too big",
        "Privacy and ownership preserving of outsourced medical data",
        "Some novel aspects of health communication from a dialogue systems perspective",
        "Preferred modalities in dialogue systems",
        "Learning end-to-end goal-oriented dialog",
        "A virtual reality dialogue system for the treatment of social phobia",
        "Nexhmedin Morina, Paul Emmelkamp, and Mark Neerincx. 2012b. A virtual reality dialogue system for the treatment of social phobia",
        "SHIHbot: A Facebook chatbot for sexual health information on HIV/AIDS",
        "Description of the Patient-Genesys dialogue system",
        "Designing a virtual patient dialogue system based on terminology-rich resources: Challenges and evaluation",
        "Customizable cloud-healthcare dialogue system based on lvcsr with prosodiccontextual post-processing",
        "A survey on dialogue systems: Recent advances and new frontiers",
        "Creating and evaluating chatbots as eligibility assistants for clinical trials: An active deep learning approach towards user-centered classification",
        "Empathic chatbot response for medical assistance",
        "Vaidya: A spoken dialog system for health domain",
        "Investigating students' use of a mental health chatbot to alleviate academic stress",
        "A multipersona chatbot for hotline counselor training",
        "Survey on evaluation methods for dialogue systems",
        "Verbal indicators of psychological distress in interactive dialogue with a virtual human",
        "An explorative study on robotics for supporting children with autism spectrum disorder during clinical procedures",
        "Enriching neural models with targeted features for dementia detection",
        "Anticipating safety issues in e2e conversational ai: Framework and tooling",
        "Delivering cognitive behavioral therapy using a conversational social robot",
        "Show your work: Improved reporting of experimental results",
        "Samvaadhana: A Telugu dialogue system in hospital domain",
        "Chatbot implementation to collect data on possible covid-19 cases and release the pressure on the primary health care system",
        "Ollobot -towards a text-based arabic health conversational agent: Evaluation and results",
        "Modeling dialogue in conversational cognitive health screening interviews",
        "Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols",
        "Implicit bias in healthcare professionals: a systematic review",
        "Intelligent agent based flight search and booking system",
        "Predictive engagement: An efficient metric for automatic evaluation of open-domain dialogue systems",
        "An assistive conversation skills training system for caregivers of persons with alzheimer's disease",
        "Hiv health information access using spoken dialogue systems: Touchtone vs. speech",
        "End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2",
        "Metrics and evaluation of spoken dialogue systems",
        "Usability testing of a healthcare chatbot: Can we use conventional methods to assess conversational user interfaces?",
        "A simple language model for task-oriented dialogue",
        "Alexa, siri, cortana, and more: An introduction to voice assistants",
        "A chatbot-supported smart wireless interactive healthcare system for weight control and health promotion",
        "Implementation of interactive healthcare advisor model using chatbot and visualization",
        "Talking with ERICA, an autonomous android",
        "Beyond the HIPAA Privacy Rule: Enhancing Privacy, Improving Health Through Research",
        "Robot-assisted socio-emotional intervention framework for children with autism spectrum disorder",
        "Speech and Language Processing",
        "kbot: Knowledge-enabled personalized chatbot for asthma self-management",
        "Artificial intelligence in rehabilitation targeting the participation of children and youth with disabilities: Scoping review",
        "Promotion of continuous use of a self-guided mental healthcare system by a chatbot",
        "A pilot study on the ebear socially assistive robot: Implication for interacting with elderly people with moderate depression",
        "Human-computer interaction: Overview on state of the art",
        "A systematic review of health dialog systems",
        "Conversational agents in healthcare: A systematic review",
        "Medical big data: promise and challenges",
        "The chatbot feels you -a counseling service using emotional response generation",
        "Development and usability of a life-logging behavior monitoring application for obese patients",
        "Effect of self-monitoring on long-term patient engagement with mobile health applications",
        "Designing a chatbot as a mediator for promoting deep self-disclosure to a real mental health professional",
        "i hear you, i feel you\": Encouraging deep self-disclosure through a chatbot",
        "Lekbot: A talking and playing robot for children with disabilities",
        "None",
        "TRIK: A talking and drawing robot for children with communication disabilities",
        "Designing a human-computer dialog system for medical information search",
        "ACM International Conferences on Web Intelligence and Intelligent Agent Technology -Workshops",
        "Spoken, Multilingual and Multimodal Dialogue Systems: Development and Assessment",
        "Training end-to-end dialogue systems with the ubuntu dialogue corpus",
        "hear me out\": Smart speaker based conversational agent to monitor symptoms in mental health",
        "Chatbot for disease prediction and treatment recommendation using machine learning",
        "Chapter 9 -the role of spoken dialogue in user-environment interaction",
        "Language diversity in ACL",
        "Robo: A counselor chatbot for opioid addicted patients",
        "Survey of conversational agents in health. Expert Systems with Applications",
        "A demonstration of dialogue processing in SimSensei kiosk",
        "A mixed-initiative conversational dialogue system for healthcare",
        "Translational NLP: A new paradigm and general principles for natural language processing research",
        "A chatbot for psychiatric counseling in mental healthcare service based on emotional dialogue analysis and sentence generation",
        "Reading with robots: Towards a human-robot book discussion system for elderly adults",
        "Ai meets austen: Towards human-robot discussions of literary metaphor",
        "Combating depression in students using an intelligent chatbot: A cognitive behavioral therapy",
        "Robot-assisted autism spectrum disorder diagnostics using pomdps",
        "Healthassistantbot: A personal health assistant for the italian language",
        "A multimodal dialogue system for medical decision support inside virtual reality",
        "Entity-consistent end-to-end task-oriented dialogue system with kb retriever",
        "Alexa depression and anxiety self-tests: A preliminary analysis of user experience and trust",
        "Disha: An implementation of machine learning based bangla healthcare chatbot",
        "Usability testing and the relation of clinical information systems to patient safety",
        "Chatbot utilization for medical consultant system",
        "Pregnancy companion chatbot using alexa and amazon web services",
        "A survey of available corpora for building data-driven dialogue systems",
        "Digital psychiatry -curbing depression using therapy chatbot and depression analysis",
        "Improving leo robot conversational ability via deep learning algorithms for children with autism",
        "Proposal of spoken interactive home doctor system for elderly people",
        "Chatbot implementation for icd-10 recommendation system",
        "Prototyping semantic dialogue systems for radiologists",
        "Supporting a rapid dialogue engineering process",
        "Automatized medical chatbot (medibot)",
        "Limitations for health research with restricted data collection from uk primary care",
        "Health care spoken dialogue system for diagnostic reasoning and medical product recommendation",
        "A multimodal adaptive dialogue manager for depressive and anxiety disorder screening: A wizard-of-oz experiment",
        "Conversational agents in health care: Scoping review and conceptual analysis",
        "Chatbots and conversational agents in mental health: A review of the psychiatric landscape",
        "Identifying medical self-disclosure in online communities",
        "Best Practice Recommendations for Replicating Experiments in Public Administration",
        "Alexa as coach: Leveraging smart speakers to build social agents that reduce public speaking anxiety",
        "Bliss: An agent for collecting spoken dialogue data about health and well-being",
        "Task-oriented dialogue system for automatic diagnosis",
        "Expressive interviewing: A conversational system for coping with COVID-19",
        "A network-based end-to-end trainable task-oriented dialogue system",
        "A new chatbot for customer service on social media",
        "Recipes for safety in open-domain chatbots",
        "End-to-end knowledgerouted relational dialogue system for automatic diagnosis",
        "Learning support system for effectively conversing with individuals with autism using a humanoid robot",
        "Chatbot for peer support realization based on mutual care",
        "Recent advances and challenges in task-oriented dialog system",
        "A review of the research on dialogue management of task-oriented systems",
        "The design and implementation of xiaoice, an empathetic social chatbot"
    ],
    "63608e5090e50fcafdee1224": [
        "Translating embeddings for modeling multirelational data",
        "Relational graph attention networks",
        "Temporal knowledge graph completion: A survey",
        "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
        "HyTE: Hyperplane-based temporally aware knowledge graph embedding",
        "A novel representation learning for dynamic graphs based on graph convolutional networks",
        "Graph neural architecture search",
        "Learning sequence encoders for temporal knowledge graph completion",
        "Diachronic embedding for temporal knowledge graph completion",
        "Single path one-shot neural architecture search with uniform sampling",
        "Automated machine learning: methods, systems, challenges",
        "Learning to walk across time for interpretable temporal knowledge graph completion",
        "Simple embedding for link prediction in knowledge graphs",
        "Tensor decompositions for temporal knowledge base completion",
        "Deriving validity time in knowledge graph",
        "Gdelt: Global data on events, location, and tone, 1979-2012",
        "Deepgcns: Making gcns go as deep as cnns",
        "Autograph: Automated graph neural network",
        "Darts: Differentiable architecture search",
        "Dynamic graph convolutional networks. Pattern Recognition, Johannes Messner, Ralph Abboud, and Ismail Ilkan Ceylan",
        "Pytorch: an imperative style, high-performance deep learning library",
        "Chronor: Rotation based temporal knowledge graph embedding",
        "Dysat: Deep neural representation learning on dynamic graphs via self-attention networks",
        "Question answering over temporal knowledge graphs",
        "Modeling relational data with graph convolutional networks",
        "The evolved transformer",
        "Learning to represent the evolution of dynamic graphs with recurrent models",
        "Complex embeddings for simple link prediction",
        "Composition-based multirelational graph convolutional networks",
        "Attention is all you need",
        "2021a. Spatio-temporal urban knowledge graph enabled mobility prediction",
        "Evolutionary markov dynamics for network community detection",
        "Autogel: An automated graph neural network with explicit link information",
        "TeMP: Temporal message passing for temporal knowledge graph completion",
        "Snas: stochastic neural architecture search",
        "Temporal knowledge graph completion using a linear temporal regularizer and multivector embeddings",
        "Representation learning on graphs with jumping knowledge networks",
        "Modeling attention flow on graphs",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Taking human out of learning applications: A survey on automated machine learning",
        "Searching a high performance feature extractor for text recognition network",
        "Bilinear scoring function search for knowledge graph learning",
        "Automated machine learning on graphs: A survey",
        "Simplifying architecture search for graph neural network",
        "Search to aggregate neighborhood for graph neural network",
        "Time-aware path reasoning on knowledge graph for recommendation",
        "Neural architecture search of graph neural networks"
    ],
    "6306e8c890e50fcafdebd565": [
        "Outlier Analysis",
        "Outlier ensembles: An introduction",
        "Random forests",
        "Classification and regression trees",
        "Thermometer encoding: One hot way to resist adversarial examples",
        "On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study",
        "Xgboost: A scalable tree boosting system",
        "StableMoE: Stable Routing Strategy for Mixture of Experts",
        "Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a Scalable Hyper-Ensemble Solution",
        "Glam: Efficient scaling of language models with mixture-ofexperts",
        "Who said what: Modeling individual labelers improves classification",
        "A survey of label-noise representation learning: Past, present and future",
        "Co-teaching: Robust training of deep neural networks with extremely noisy labels",
        "ADBench: Anomaly Detection Benchmark",
        "Adaptive mixtures of local experts",
        "Lightgbm: A highly efficient gradient boosting decision tree",
        "Tods: An automated time series outlier detection system",
        "Self-training multisequence learning with Transformer for weakly supervised video anomaly detection",
        "D ?oT: A federated self-learning anomaly detection system for IoT",
        "Deep learning for anomaly detection: A review",
        "Deep anomaly detection with deviation networks",
        "Making deep neural networks robust to label noise: A loss correction approach",
        "Scaling vision with sparse mixture of experts",
        "Deep learning from crowds",
        "The perceptron: a probabilistic model for information storage and organization in the brain",
        "A unifying review of deep and shallow anomaly detection",
        "Deep Semi-Supervised Anomaly Detection",
        "Deep One-Class Classification",
        "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
        "Learning from noisy labels with deep neural networks: A survey",
        "Learning to compose topic-aware mixture of experts for zero-shot video captioning",
        "Combating noisy labels by agreement: A joint training method with coregularization",
        "Deep Learning From Multiple Noisy Annotators as A Union",
        "Hyperparameter ensembles for robustness and uncertainty quantification",
        "How does disagreement help generalization against label corruption",
        "XGBOD: Improving Supervised Outlier Detection with Unsupervised Representation Learning",
        "LSCP: Locally Selective Combination in Parallel Outlier Ensembles",
        "PyOD: A Python Toolbox for Scalable Outlier Detection",
        "Automatic unsupervised outlier model selection",
        "Meta label correction for noisy label learning",
        "Self-supervised mixture-of-experts by uncertainty estimation",
        "A brief introduction to weakly supervised learning",
        "Ensembles for unsupervised outlier detection: challenges and research questions a position paper",
        "Taming Sparsely Activated Transformer with Stochastic Experts"
    ],
    "62451c325aee126c0f47b416": [
        "Unsupervised label noise modeling and loss correction",
        "Model compression",
        "Online knowledge distillation with diverse peers",
        "Moonshine: Distilling with cheap convolutions",
        "Learning with retrospection",
        "Improved regularization of convolutional neural networks with cutout",
        "Born again neural networks",
        "Online knowledge distillation via collaborative learning",
        "Deep residual learning for image recognition",
        "Distilling the knowledge in a neural network",
        "Densely connected convolutional networks",
        "Self-knowledge distillation with progressive refinement of targets",
        "Learning multiple layers of features from tiny images",
        "Knowledge distillation by on-the-fly native ensemble",
        "Selfsupervised label augmentation via input transformations",
        "Analyzing the noise robustness of deep neural networks",
        "Msd: Multi-self-distillation learning via multi-classifiers within deep neural networks",
        "Unsupervised multi-target domain adaptation through knowledge distillation",
        "Distillation-based training for multi-exit architectures",
        "Training deep neural networks on noisy labels with bootstrapping",
        "Hints for thin deep nets",
        "The state of knowledge distillation for classification",
        "Imagenet large scale visual recognition challenge",
        "Knowledge distillation beyond model compression",
        "Very deep convolutional networks for large-scale image recognition",
        "Patient knowledge distillation for bert model compression",
        "Rethinking the inception architecture for computer vision",
        "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results",
        "None",
        "Memory-replay knowledge distillation",
        "Knowledge distillation and student-teacher learning for visual intelligence: A review and new outlooks",
        "Harmonized dense knowledge distillation training for multi-exit architectures",
        "Peer collaborative learning for online knowledge distillation",
        "Knowledge distillation meets self-supervision",
        "Data-distortion guided self-distillation for deep neural networks",
        "Snapshot distillation: Teacher-student optimization in one generation",
        "Revisiting knowledge distillation via label smoothing regularization",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "Regularizing class-wise predictions via self-knowledge distillation",
        "Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer",
        "Wide residual networks",
        "Delving deep into label smoothing",
        "Be your own teacher: Improve the performance of convolutional neural networks via self distillation",
        "Deep mutual learning"
    ],
    "62725cd25aee126c0fae91f3": [
        "Distilling the knowledge in a neural network",
        "Contrastive representation distillation",
        "Relational knowledge distillation",
        "On the efficacy of knowledge distillation",
        "Revisiting knowledge distillation via label smoothing regularization",
        "Fitnets: Hints for thin deep nets",
        "Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer",
        "A gift from knowledge distillation: Fast optimization, network minimization and transfer learning",
        "Paraphrasing complex network: Network compression via factor transfer",
        "Knowledge transfer via distillation of activation boundaries formed by hidden neurons",
        "Knowledge transfer with Jacobian matching",
        "Tree-like decision distillation",
        "Knowledge distillation via instance relationship graph",
        "Similarity-preserving knowledge distillation",
        "Knowledge distillation via route constrained optimization",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Deep mutual learning",
        "Knowledge transfer via dense cross-layer mutualdistillation",
        "Be your own teacher: Improve the performance of convolutional neural networks via self distillation",
        "Revisiting knowledge distillation via label smoothing regularization",
        "Self-distillation as instance-specific label smoothing",
        "Student becoming the master: Knowledge amalgamation for joint scene parsing, depth estimation, and more",
        "Amalgamating knowledge towards comprehensive classification",
        "Data-free learning of student networks",
        "Data-free adversarial distillation",
        "Elastic knowledge distillation by learning from recollection",
        "Mosaicking to distill: Knowledge distillation from out-of-domain data",
        "Routing networks: Adaptive selection of non-linear functions for multi-task learning",
        "Routing networks and the challenges of modular and compositional computation",
        "Modular networks: Learning to decompose neural computation",
        "Pathnet: Evolution channels gradient descent in super neural networks",
        "Conditional computation in neural networks for faster models",
        "Accme : Actively compressed conditional mean embeddings for model-based reinforcement learning",
        "Adaptive mixtures of local experts",
        "Correcting forecasts with multifactor neural attention",
        "Outrageously large neural networks: The sparselygated mixture-of-experts layer",
        "Spottune: Transfer learning through adaptive fine-tuning",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Categorical reparameterization with gumbel-softmax",
        "A tutorial on the cross-entropy method",
        "Approximating the kullback leibler divergence between gaussian mixture models",
        "Learning multiple layers of features from tiny images",
        "Tiny imagenet visual recognition challenge",
        "Imagenet: A large-scale hierarchical image database",
        "Deep residual learning for image recognition",
        "Wide residual networks",
        "Very deep convolutional networks for large-scale image recognition",
        "Shufflenet: An extremely efficient convolutional neural network for mobile devices",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Correlation congruence for knowledge distillation",
        "Variational information distillation for knowledge transfer",
        "Learning deep representations with probabilistic knowledge transfer",
        "She is currently a Postdoctoral Fellow with National University of Singapore. Her research interests include transfer learning, human parsing, scene parsing, depth estimation, and image processing in various applications. Mingli Song (Senior Member"
    ],
    "63ae56ca90e50fcafda968ed": [
        "Open-domain question answering goes conversational via question rewriting",
        "Language models are few-shot learners",
        "Selecting good expansion terms for pseudo-relevance feedback",
        "Reading Wikipedia to answer open-domain questions",
        "Scaling language modeling with pathways",
        "Question rewriting for open-domain conversational qa: Best practices and limitations",
        "Language model cascades",
        "Combination of multiple searches",
        "be12ae02cfad4aa430d77dc940cb tributed text generation via post-hoc research and revision",
        "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
        "Fidlight: Efficient and effective retrieval-augmented text generation",
        "Large language models can self-improve",
        "Survey of hallucination in natural language generation",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Few-shot learning with retrieval augmented language models",
        "HoVer: A dataset for many-hop fact extraction and claim verification",
        "Dense passage retrieval for open-domain question answering",
        "Efficient and effective passage search via contextualized late interaction over BERT",
        "Robust Multi-Hop Reasoning at Scale via Condensed Retrieval",
        "Relevance-guided supervision for openqa with ColBERT",
        "Decomposed prompting: A modular approach for solving complex tasks",
        "Large language models are zero-shot reasoners",
        "Improving text generation with large ranking models",
        "Fusion in information retrieval: Sigir 2018 half-day tutorial",
        "Natural questions: A benchmark for question answering research",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "Few-shot anaphora resolution in scientific protocols via mixtures of in-context experts",
        "Latent retrieval for weakly supervised open domain question answering",
        "Standing on the shoulders of giant frozen language models",
        "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
        "Contrastive decoding: Open-ended text generation as optimization",
        "What makes good in-context examples for gpt-3?",
        "The natural language decathlon: Multitask learning as question answering",
        "Multi-hop reading comprehension through question decomposition and rescoring",
        "Training language models to follow instructions with human feedback",
        "Hindsight: Posterior-guided Training of Retrievers for Improved Open-ended Generation",
        "True few-shot learning with language models",
        "Measuring and narrowing the compositionality gap in language models",
        "Retrieve, rerank, read, then iterate: Answering open-domain questions of arbitrary complexity from text",
        "Language models are unsupervised multitask learners",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Question rewriting? assessing its importance for conversational question answering",
        "PLAID: An Efficient Engine for Late Interaction Retrieval",
        "ColBERTv2: Effective and efficient retrieval via lightweight late interaction",
        "Retrieval augmentation reduces hallucination in conversation",
        "Prompting gpt-3 to be reliable",
        "Recitation-augmented language models",
        "FEVER: a large-scale dataset for fact extraction and VERification",
        "SCAI-QReCC shared task on conversational question answering",
        "Colbert-prf: Semantic pseudo-relevance feedback for dense passage and document retrieval",
        "Rationale-augmented ensembles in language models",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "On decoding strategies for neural text generators",
        "Answering complex open-domain questions with multihop dense retrieval",
        "Modeling reformulation using query distributions",
        "A dataset for diverse, explainable multi-hop question answering",
        "Synergizing reasoning and acting in language models",
        "Bootstrapping reasoning with reasoning",
        "Automatic chain of thought prompting in large language models"
    ],
    "63aab708a4a9066abca549f8": [
        "LIBSVM: a library for support vector machines",
        "Diaformer: Automatic Diagnosis via Symptoms Sequence Generation",
        "A simple framework for contrastive learning of visual representations",
        "Strategic dialogue management via deep reinforcement learning",
        "Momentum contrast for unsupervised visual representation learning",
        "Rainbow: Combining improvements in deep reinforcement learning",
        "Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning",
        "Supervised contrastive learning",
        "End-to-end task-completion neural dialogue systems",
        "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning",
        "Human-level control through deep reinforcement learning. nature",
        "Large-scale object detection in the wild from imbalanced multi-labels",
        "A review of approaches to identifying patient phenotype cohorts using electronic health records",
        "Inquire and diagnose: Neural symptom checking ensemble using deep reinforcement learning",
        "The interplay of a conversational ontology and AI planning for health dialogue management",
        "Attention is all you need",
        "Graph attention networks",
        "Task-oriented dialogue system for automatic diagnosis",
        "Generative adversarial regularized mutual information policy gradient framework for automatic diagnosis",
        "Pomdp-based statistical spoken dialog systems: A review",
        "Reinforcement learning in healthcare: A survey"
    ],
    "620e302d5aee126c0fadda4d": [
        "Intel Xeon Phi Coprocessor Architecture",
        "IBM POWER9 processor core",
        "A 40 nm 16-core 128-thread CMT sparc SOC processor",
        "Bringing hardware multithreading to the real-time domain",
        "Hardwarelevel thread migration to reduce on-chip data movement via reinforcement learning",
        "A survey of processors with explicit multithreading",
        "IBM Power9 processor architecture",
        "The IBM 13 multithreaded microprocessor",
        "Data criticality in multithreaded applications: An insight for many-core systems",
        "A novel warp scheduling scheme considering long-latency operations for highperformance GPUs",
        "ABCDPlace: Accelerated batch-based concurrent detailed placement on multithreaded CPUs and GPUs",
        "VisoMT: A collaborative multithreading multicore processor for multimedia applications with a fast data switching mechanism",
        "Computer Architecture: A Quantitative Approach",
        "A small footprint interleaved multithreaded processor for embedded systems",
        "Design of the tera MTA integrated circuits",
        "APRIL: A processor architecture for multiprocessing",
        "Efficient mathematical accelerator design coupled with an interleaved multi-threading RISC-V microprocessor",
        "Schedulability analysis of nMPRA processor based on multithreaded execution",
        "Memristor-based multithreading",
        "Simultaneous multithreading: Maximizing on-chip parallelism",
        "MiBench: A free, commercially representative embedded benchmark suite",
        "A benchmark characterization of the EEMBC benchmark suite",
        "Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1",
        "The RISC-V instruction set manual",
        "Privileged architecture version 1.9",
        "A low-cost synthesizable RISC-V dual-issue processor core leveraging the compressed instruction set extension",
        "The rocket chip generator",
        "The Berkeley out-of-order machine (boom): An industry-competitive, synthesizable, parameterized RISC-V processor",
        "An IoT endpoint system-on-chip for secure and energyefficient near-sensor analytics",
        "Slow and steady wins the race? A comparison of ultra-low-power RISC-V cores for Internet-of-Things applications",
        "Energy-efficient vision on the PULP platform for ultra-low power parallel computing",
        "SIMTY: Generalized SIMT execution on RISC-V",
        "The microarchitecture of a multi-threaded RISC-V compliant processing core family for IoT end-nodes",
        "A multithreading RISC-V implementation for Lagarto architecture",
        "Investigation on the optimal pipeline organization in RISC-V multithreaded soft processor cores",
        "Multithread RISC architecture based on programmable interleaved pipelining",
        "Simpipe-A Flexible CPU Pipeline Simulator",
        "None",
        "The gem5 simulator"
    ],
    "625f6bf75aee126c0ffb36b6": [
        "Efficient string matching: an aid to bibliographic search",
        "Online medical consultation: A review of literature and practice",
        "Beyond kappa: A review of interrater agreement measures",
        "Towards interpretable clinical diagnosis with bayesian network ensembles stacked on entity-aware cnns",
        "Convolutional neural network for sentence classification",
        "Introduction to the practice of telemedicine",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Extracting symptoms and their status from clinical conversations",
        "Infusing disease knowledge into bert for health question answering, medical inference and disease name recognition",
        "Deep pyramid convolutional neural networks for text categorization",
        "Dr. summarize: Global summarization of medical dialogue by exploiting local structures",
        "Context-aware symptom checking for disease diagnosis using hierarchical reinforcement learning",
        "Recurrent convolutional neural networks for text classification",
        "Semi-supervised variational reasoning for medical dialogue generation",
        "Flat: Chinese ner using flat-lattice transformer",
        "Task-oriented dialogue system for automatic disease diagnosis via hierarchical reinforcement learning",
        "Looking for a few good metrics: Automatic summarization evaluation-how many samples are enough",
        "Graph-evolving meta-learning for low-resource medical dialogue generation",
        "Enhancing dialogue symptom diagnosis with global attention and symptom graph",
        "Recurrent neural network for text classification with multi-task learning",
        "Meddg: A large-scale medical consultation dataset for building medical dialogue system",
        "Lexicon enhanced chinese sequence labeling using bert adapter",
        "Using context information for dialog act classification in dnn framework",
        "Abstractive text summarization using sequenceto-sequence rnns and beyond",
        "What is a support vector machine?",
        "Prophetnet-x: large-scale pre-training models for english, chinese, multi-lingual, dialog, and code generation",
        "Text chunking using transformation-based learning",
        "An overview of multi-task learning in deep neural networks",
        "Get to the point: Summarization with pointergenerator networks",
        "Understanding medical conversations with scattered keyword attention and weak supervision from responses",
        "Online medical consultation: A review",
        "A review of coronavirus disease-2019 (covid-19)",
        "Attention is all you need",
        "Task-oriented dialogue system for automatic diagnosis",
        "Medical named entity recognition from un-labelled medical records based on pre-trained language models and domain dictionary",
        "Telemedicine",
        "Generative adversarial regularized mutual information policy gradient framework for automatic diagnosis",
        "End-to-end knowledge-routed relational dialogue system for automatic diagnosis",
        "mt5: A massively multilingual pre-trained text-to-text transformer",
        "Meddialog: Large-scale medical dialogue dataset",
        "A review on multi-label learning algorithms",
        "Chinese ner using lattice lstm",
        "Mie: A medical information extractor towards medical dialogues",
        "Ernie: Enhanced language representation with informative entities",
        "Drug package recommendation via interactionaware graph induction",
        "An end-to-end progressive multi-task learning framework for medical named entity recognition and normalization"
    ],
    "63bcd73690e50fcafdefa108": [
        "Inductive representation learning on large graphs",
        "Collective classification in network data",
        "Predicting multicellular function through multi-layer tissue networks",
        "A survey on knowledge graphs: Representation, acquisition, and applications",
        "Mining heterogeneous information networks: a structural analysis approach",
        "A survey of heterogeneous information network analysis",
        "A comprehensive survey on graph neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "Medical entity disambiguation using graph neural networks",
        "Heterogeneous graph attention network",
        "Graph transformer networks",
        "Relation structureaware heterogeneous graph neural network",
        "Heterogeneous graph neural network",
        "Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding",
        "Heterogeneous graph transformer",
        "An attentionbased graph neural network for heterogeneous structural learning",
        "Are we really making much progress? revisiting, benchmarking and refining heterogeneous graph neural networks",
        "Heterogeneous graph neural network via attribute completion",
        "Efficient neural architecture search via proximal iterations",
        "Graph attention networks",
        "Entity resolution with hierarchical graph attention networks",
        "Reliable data distillation on graph convolutional network",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "Asgcn: Adaptive semantic architecture of graph convolutional networks for text-rich networks",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "Analyzing heterogeneous networks with missing attributes by unsupervised contrastive learning",
        "Node attribute completion in knowledge graphs with multi-relational propagation",
        "Neural architecture search: A survey",
        "Automated graph machine learning: Approaches, libraries and directions",
        "Policy-gnn: Aggregation optimization for graph neural networks",
        "Simplifying architecture search for graph neural network",
        "Graphnas: Graph neural architecture search with reinforcement learning",
        "Auto-gnn: Neural architecture search of graph neural networks",
        "Psp: Progressive space pruning for efficient graph neural architecture search",
        "Genetic meta-structure search for recommendation on heterogeneous information network",
        "Diffmg: Differentiable meta graph search for heterogeneous graph neural networks",
        "Proximal algorithms",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Model-agnostic meta-learning for fast adaptation of deep networks",
        "Darts: Differentiable architecture search",
        "Maximum likelihood from incomplete data via the em algorithm",
        "Classification and analysis of multivariate observations",
        "Performance of modularity maximization in practical contexts",
        "Spectral clustering with graph neural networks for graph pooling",
        "Graph clustering with graph neural networks",
        "Adam: A method for stochastic optimization",
        "Representation learning for attributed multiplex heterogeneous network",
        "Second workshop on information heterogeneity and fusion in recommender systems (hetrec2011)"
    ],
    "6215a4242c356815940385b3": [
        "An analysis of deep neural network models for practical applications",
        "A unified lottery ticket hypothesis for graph neural networks",
        "EarlyBERT: Efficient BERT Training via Earlybird Lottery Tickets",
        "Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks",
        "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks",
        "Graphnas: Graph neural architecture search with reinforcement learning",
        "AWB-GCN: A graph convolutional network accelerator with runtime workload rebalancing",
        "2021. I-GCN: A Graph Convolutional Network Accelerator with Runtime Locality Enhancement through Islandization",
        "Inductive representation learning on large graphs",
        "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Benchmark Data Sets for Graph Kernels",
        "Semi-supervised classification with graph convolutional networks",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Deepergcn: All you need to train deeper gcns",
        "SGCN: A Graph Sparsifier Based on Graph Convolutional Networks",
        "Learning Graph Convolutional Network for Skeleton-Based Human Action Recognition by Neural Searching",
        "Collective classification in network data",
        "Dynamic edge-conditioned filters in convolutional neural networks on graphs",
        "Degree-Quant: Quantization-Aware Training for Graph Neural Networks",
        "Graph Attention Networks",
        "A comprehensive survey on graph neural networks",
        "How powerful are graph neural networks? arXiv preprint",
        "How Powerful are Graph Neural Networks?",
        "Hygcn: A gcn accelerator with hybrid architecture",
        "Hierarchical graph representation learning with differentiable pooling",
        "Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks",
        "An end-to-end deep learning architecture for graph classification",
        "G-CoS: GNN-Accelerator Co-Search Towards Both Better Accuracy and Efficiency"
    ],
    "63a1751790e50fcafd1f4880": [
        "Model Answer Supporting EM F1 EM F1 Baseline Model",
        "None",
        "None",
        "None",
        "None",
        "None",
        "None",
        "FE2H on ALBERT",
        "Towards better decoding and language model integration in sequence to sequence models",
        "ELECTRA: pretraining text encoders as discriminators rather than generators",
        "Hierarchical graph network for multi-hop question answering",
        "Towards a better understanding of label smoothing in neural machine translation",
        "Generalizing back-translation in neural machine translation",
        "A simple yet strong pipeline for HotpotQA",
        "2020a. Deberta: Decoding-enhanced bert with disentangled attention",
        "Retinal optical coherence tomography image classification with label smoothing generative adversarial network",
        "The NarrativeQA reading comprehension challenge",
        "Asynchronous multi-grained graph network for interpretable multi-hop reading comprehension",
        "From easy to hard: Two-stage selector and reader for multi-hop question answering",
        "From easy to hard: Two-stage selector and reader for multi-hop question answering",
        "Roberta: A robustly optimized bert pretraining approach",
        "Does label smoothing mitigate label noise?",
        "Semantic label smoothing for sequence to sequence problems",
        "When does label smoothing help?",
        "Answering while summarizing: Multi-task learning for multi-hop QA with evidence extraction",
        "Weakly supervised label smoothing",
        "Dynamically fused graph network for multi-hop reasoning",
        "Know what you don't know: Unanswerable questions for SQuAD",
        "Similarity based label smoothing for dialogue generation",
        "Is Graph Structure Necessary for Multi-hop Question Answering?",
        "Rethinking the inception architecture for computer vision",
        "Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents",
        "Constructing datasets for multi-hop reading comprehension across documents",
        "Transformers: State-of-the-art natural language processing",
        "2021a. Graph-free multi-hop reading comprehension: A select-to-guide strategy",
        "2021b. Graph-free multi-hop reading comprehension: A select-to-guide strategy",
        "Towards understanding label smoothing",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "Robust machine reading comprehension by learning soft labels",
        "Robust machine reading comprehension by learning soft labels",
        "Boundary smoothing for named entity recognition"
    ],
    "63d9d87b90e50fcafd580980": [
        "Few-Shot Object Detection via Association and DIscrimination",
        "End-to-end object detection with transformers",
        "MMDetection: Open MMLab Detection Toolbox and Benchmark",
        "Pix2seq: A language modeling framework for object detection",
        "Guided variational autoencoder for disentanglement learning",
        "The pascal visual object classes (voc) challenge",
        "Fewshot object detection with attention-RPN and multi-relation detector",
        "Generalized fewshot object detection without forgetting",
        "Dynamic few-shot visual learning without forgetting",
        "Fast R-CNN",
        "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "Query adaptive few-shot object detection with heterogeneous graph convolutional networks",
        "Meta faster r-cnn: Towards accurate few-shot object detection with attentive feature alignment",
        "Deep residual learning for image recognition",
        "Dense relation distillation with context-aware aggregation for fewshot object detection",
        "Few-shot object detection via feature reweighting",
        "Variational prototyping-encoder: One-shot learning with prototypical images",
        "Auto-encoding variational bayes",
        "Cornernet: Detecting objects as paired keypoints",
        "Transformation invariant few-shot object detection",
        "Beyond max-margin: Class margin equilibrium for few-shot object detection",
        "Few-shot object detection via classification refinement and distractor retreatment",
        "Focal loss for dense object detection",
        "Microsoft coco: Common objects in context",
        "Deep variational metric learning",
        "SSD: Single shot multibox detector",
        "DeFRCN: Decoupled Faster R-CNN for Few-Shot Object Detection",
        "You only look once: Unified, real-time object detection",
        "Faster R-CNN: Towards real-time object detection with region proposal networks",
        "Imagenet large scale visual recognition challenge",
        "Fsce: Few-shot object detection via contrastive proposal encoding",
        "Matching networks for one shot learning",
        "Frustratingly simple few-shot object detection",
        "Metalearning to detect rare objects",
        "Universalprototype enhancing for few-shot object detection",
        "Multi-scale positive sample refinement for few-shot object detection",
        "Few-shot object detection and viewpoint estimation for objects in the wild",
        "Variational Feature Disentangling for Fine-Grained Few-Shot Classification",
        "Meta r-cnn: Towards general solver for instance-level low-shot learning",
        "Variational few-shot learning",
        "Accurate few-shot object detection with support-query mutual guidance and hybrid loss",
        "Hallucination improves few-shot object detection",
        "Objects as Points",
        "Semantic relation reasoning for shot-stable few-shot object detection"
    ],
    "62ce38205aee126c0f18bb75": [
        "None",
        "Training a helpful and harmless assistant with reinforcement learning from human feedback",
        "Evaluating large language models trained on code",
        "Training verifiers to solve math word problems",
        "Truthful ai: Developing and governing ai that does not lie",
        "Measuring massive multitask language understanding",
        "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
        "Deep anomaly detection with outlier exposure",
        "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "Truthfulqa: Measuring how models mimic human falsehoods",
        "Teaching models to express their uncertainty in words",
        "None",
        "Linguistic calibration through metacognition: aligning dialogue agent responses with expected correctness",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Posterior calibration and exploratory analysis for natural language processing models",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Shaking the foundations: delusions in sequence models for interaction and control",
        "Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Self-consistency improves chain of thought reasoning in language models"
    ],
    "629587465aee126c0fe149f5": [
        "None",
        "A general language assistant as a laboratory for alignment",
        "Gpt-3 nonfiction -calibration",
        "Language models are few-shot learners",
        "Scaling language modeling with pathways",
        "ARC's first technical report: Eliciting latent knowledge",
        "Domain adaptation for visual applications: A comprehensive survey",
        "Calibration of pre-trained transformers",
        "Truthful AI: Developing and governing AI that does not lie",
        "Confidence calibration for domain generalization under covariate shift",
        "On calibration of modern neural networks",
        "Deep anomaly detection with outlier exposure",
        "Measuring massive multitask language understanding",
        "Training compute-optimal large language models",
        "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
        "Selective question answering under domain shift",
        "Soft calibration objectives for neural networks",
        "Calibrated language model fine-tuning for in-and out-of-distribution data",
        "Calibrated structured prediction",
        "Measuring how models mimic human falsehoods",
        "On faithfulness and factuality in abstractive summarization",
        "Revisiting the calibration of modern neural networks",
        "Calibrating deep neural networks using focal loss",
        "Introducing text and code embeddings in the openai api",
        "Posterior calibration and exploratory analysis for natural language processing models",
        "Measuring calibration in deep learning",
        "Fine-tuning",
        "Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty under Dataset Shift",
        "Prompt programming for large language models: Beyond the few-shot paradigm",
        "Retrieval augmentation reduces hallucination in conversation",
        "Learning to summarize from human feedback",
        "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model",
        "Generalizing to unseen domains: A survey on domain generalization",
        "Recursively summarizing books with human feedback"
    ],
    "629587475aee126c0fe14c42": [
        "Neurosymbolic language modeling with automaton-augmented retrieval",
        "The local paradigm for modeling and control: from neuro-fuzzy to lazy learning. Fuzzy sets and systems",
        "Language models are few-shot learners",
        "Lightner: A lightweight generative framework with prompt-guided attention for low-resource NER",
        "Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Prompt-learning for fine-grained entity typing",
        "Few-nerd: A few-shot named entity recognition dataset",
        "Memorization vs. generalization : Quantifying data leakage in NLP performance evaluation",
        "Does learning require memorization? a short tale about a long tail",
        "What neural networks memorize and why: Discovering the long tail via influence estimation",
        "Making pre-trained language models better few-shot learners",
        "REALM: retrieval-augmented language model pre-training",
        "PTR: prompt tuning with rules for text classification",
        "Efficient nearest neighbor language models",
        "SemEval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals",
        "Mining and summarizing customer reviews",
        "Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification",
        "Billion-scale similarity search with gpus",
        "Spanbert: Improving pre-training by representing and predicting spans",
        "Dense passage retrieval for open-domain question answering",
        "Bert-knn: Adding a knn search component to pretrained language models for better QA",
        "Nearest neighbor machine translation",
        "Generalization through memorization: Nearest neighbor language models",
        "Understanding black-box predictions via influence functions",
        "Reordering examples helps during priming-based few-shot learning",
        "Good examples make A faster learner: Simple demonstration-based learning for low-resource NER",
        "The power of scale for parameter-efficient prompt tuning",
        "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
        "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Focal loss for dense object detection",
        "What makes good in",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "GPT understands",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
        "Template-free prompt tuning for few-shot NER",
        "Text classification using label names only: A language model self-training approach",
        "GNN-LM: language modeling based on global contexts via GNN",
        "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Improving language understanding by generative pre-training",
        "Squad: 100, 000+ questions for machine comprehension of text",
        "Sentence-bert: Sentence embeddings using siamese bertnetworks",
        "The probabilistic relevance framework: BM25 and beyond",
        "Learning to retrieve prompts for in-context learning",
        "Multitask prompted training enables zero-shot task generalization",
        "Automatically identifying words that can serve as labels for few-shot text classification",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Memorisation versus generalisation in pre-trained language models",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Finetuned language models are zero-shot learners",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Do prompts solve NLP tasks using natural language?",
        "Differentiable prompt makes pre-trained language models better few-shot learners",
        "Positionaware attention and supervised data improve slot filling",
        "An empirical study of memorization in NLP"
    ],
    "624fa8db5aee126c0f3a5b79": [
        "Localizing moments in video with natural language",
        "Frozen in time: A joint video and image encoder for end-to-end retrieval",
        "Activitynet: A large-scale video benchmark for human activity understanding",
        "Improving video-text retrieval by multi-stream corpus alignment and dual softmax loss",
        "Teachtext: Crossmodal generalized distillation for text-video retrieval",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Mdmmt: Multidomain multimodal transformer for video retrieval",
        "Clip2video: Mastering video-text retrieval via image clip",
        "Multi-modal transformer for video retrieval",
        "Clip2tv: An empirical study on transformer-based methods for video-text retrieval",
        "Pixel-bert: Aligning image pixels with text by deep multi-modal transformers",
        "Colbert: Efficient and effective passage search via contextualized late interaction over bert",
        "Vilt: Vision-and-language transformer without convolution or region supervision",
        "Mdmmt-2: Multidomain multimodal transformer for video retrieval",
        "Less is more: Clipbert for video-and-language learning via sparse sampling",
        "Align and prompt: Video-and-language pretraining with entity prompts",
        "Hero: Hierarchical encoder for video+ language omni-representation pre-training",
        "Oscar: Object-semantics aligned pre-training for vision-language tasks",
        "Hit: Hierarchical transformer with momentum contrast for video-text retrieval",
        "Use what you have: Video retrieval using representations from collaborative experts",
        "Univl: A unified video and language pre-training model for multimodal understanding and generation",
        "Clip4clip: An empirical study of clip for end to end video clip retrieval",
        "Support-set bottlenecks for video-text representation learning",
        "A straightforward framework for video retrieval using clip",
        "Learning transferable visual models from natural language supervision",
        "A dataset for movie description",
        "Avlnet: Learning audio-visual language representations from instructional videos",
        "Disentangled representation learning for text-video retrieval",
        "Deep learning for video classification and captioning",
        "Videoclip: Contrastive pre-training for zero-shot video-text understanding",
        "Msr-vtt: A large video description dataset for bridging video and language"
    ],
    "634d805690e50fcafd4e07d5": [
        "10 Myths of Enterprise Python",
        "None",
        "The Computer Language Benchmarks Game",
        "A distributed, reliable key-value store for the most critical data of a distributed system",
        "Go memory ballast: How I learnt to stop worrying and love the heap",
        "The Go Programming Language",
        "Go Programming Language Documentation",
        "Go Programming Language Specification",
        "Introduction to Intel Advanced Vector Extensions",
        "DayTrader Benchmark",
        "Make G1 the Default Garbage Collector",
        "Check tsc synchronization",
        "M3: Uber's Open Source, Large-scale Metrics Platform for Prometheus",
        "Most popular languages on GitHub",
        "OpenJDK 13",
        "None",
        "Optimizing a Golang service to reduce over 40% CPU",
        "Our journey to type checking 4 million lines of Python",
        "Production-Grade Container Orchestration -Kubernetes",
        "Project Tungsten: Bringing Apache Spark Closer to Bare Metal",
        "PYPL PopularitY of Programming Language",
        "Python Implementations -Python Wiki",
        "what cases is Java faster than C",
        "what cases is Java slower than C by a big margin",
        "None",
        "None",
        "None",
        "SPECjbb 2015 Benchmark",
        "Stack Overflow: C++11 regex slower than python",
        "Why do std::string operations perform poorly?",
        "Why is python faster than c++ in this case?",
        "The State of Developer Ecosystem",
        "The State of Serverless",
        "The State of the Octoverse",
        "Transducers Speed Up JavaScript Arrays",
        "Twitter Shifting More Code to JVM, Citing Performance and Encapsulation As Primary Drivers",
        "Why Discord is switching from Go to Rust",
        "Why is Dynamic Type Checking Expensive?",
        "Why the Hell Would You Use Node",
        "Why we switched from Python to Go",
        "Python is Slow, and I Don't Care",
        "Intel? 64 and IA-32 architectures software developer's manual",
        "Bladerunner: Stream processing at scale for a live view of backend data mutations at the edge",
        "The dacapo benchmarks: Java benchmarking development and analysis",
        "Dynamic vertical memory scalability for OpenJDK cloud applications",
        "The benefits and costs of writing a POSIX kernel in a high-level language",
        "Statistically rigorous Java performance evaluation",
        "None",
        "Handra. Comparing Hotspot and OpenJ",
        "The HiBench benchmark suite: Characterization of the MapReduce-based data analysis",
        "HiBench: A representative and comprehensive Hadoop benchmark suite",
        "Tailbench: a benchmark suite and evaluation methodology for latency-critical applications",
        "Practical in-place mergesort",
        "SNAP Datasets: Stanford Large Network Dataset Collection",
        "The Java?Virtual Machine Specification -Java SE 13 Edition",
        "Don't get caught in the cold, warm-up your JVM: Understand and eliminate JVM warm-up overhead in data-parallel systems",
        "M3: Endto-end memory management in elastic system software stacks",
        "Cross-language compiler benchmarking: Are we fast yet?",
        "Improving cloud function cold ctart time",
        "Benchmarking usability and performance of multicore languages",
        "A comparative study of programming languages in Rosetta code",
        "How to benchmark code execution times on Intel IA-32 and IA-64 instruction set architectures",
        "Optimize JVM start-up with Eclipse OpenJ9",
        "Renaissance: Benchmarking suite for parallel applications on the JVM",
        "Analyzing the performance of code-copying virtual machines",
        "An analysis of performance evolution of Linux's core operations",
        "CLP: Efficient and scalable search on compressed text logs",
        "End-to-end Arguments in System Design",
        "Innovations for Java running in containers",
        "Spark",
        "Replayable execution optimized for page sharing for a managed runtime environment",
        "Improving the performance guarantee for approximate graph coloring",
        "CRAMM: Virtual memory support for garbage-collected applications",
        "Characterizing serverless platforms with Serverlessbench"
    ],
    "62281ae45aee126c0f7aa8a8": [
        "Generating natural language adversarial examples",
        "Hierarchical transfer learning for multi-label text classification",
        "Hyperbolic interaction model for hierarchical multi-label classification",
        "Hierarchy-aware label semantics matching network for hierarchical text classification",
        "A simple framework for contrastive learning of visual representations",
        "HTCInfoMax: A global model for hierarchical text classification via information maximization",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Cert: Contrastive self-supervised learning for language understanding",
        "Simcse: Simple contrastive learning of sentence embeddings",
        "Explaining and harnessing adversarial examples",
        "Recursive regularization for large-scale classification with hierarchical and graphical dependencies",
        "Momentum contrast for unsupervised visual representation learning",
        "Categorical reparameterization with gumbel-softmax",
        "Effective use of word order for text categorization with convolutional neural networks",
        "Self-guided contrastive learning for BERT sentence representations",
        "Hdltex: Hierarchical deep learning for text classification",
        "Recurrent convolutional neural networks for text classification",
        "Rcv1: A new benchmark collection for text categorization research",
        "Hierarchical text classification with reinforced label assignment",
        "Coco-lm: Correcting and contrasting text sequences for language model pretraining",
        "Saloni Potdar, and Mo Yu. 2021. Improved text classification via contrastive adversarial training",
        "Hierarchical taxonomy-aware and attentional graph capsule rcnns for large-scale multi-label text classification",
        "The new york times annotated corpus. Linguistic Data Consortium",
        "HFT-CNN: Learning hierarchical category structure for multi-label short text categorization",
        "A survey of hierarchical classification across different application domains",
        "It's morphin' time! Combating linguistic discrimination with inflectional perturbations",
        "Attention is all you need",
        "2021a. Cognitive structure learning model for hierarchical multi-label text classification",
        "CLINE: Contrastive learning with semantic negative examples for natural language understanding",
        "Hierarchical multi-label classification networks",
        "Transformers: State-of-the-art natural language processing",
        "Learning to learn and predict: A metalearning approach for multi-label classification",
        "Clear: Contrastive learning for sentence representation",
        "Do transformers really perform badly for graph representation?",
        "Adversarial attacks on deep-learning models in natural language processing: A survey",
        "La-hcn: Label-based attention for hierarchical multi-label text classification neural network. Expert Systems with Applications",
        "Hierarchical multi-label text classification: Self-adaption semantic awareness network integrating text topic and label level information",
        "Hierarchy-aware global model for hierarchical text classification"
    ],
    "63aa965790e50fcafd008008": [
        "LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations",
        "Language to Logical Form with Neural Attention",
        "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
        "ER-SQL: Learning enhanced representation for Text-to-SQL using table contents",
        "X-SQL: reinforce schema representation with context. CoRR abs/1908",
        "Semantic Parsing Natural Language into SPARQL: Improving Target Language Representation with Neural Attention",
        "Knowledge Graph Question Answering via SPARQL Silhouette Generation",
        "RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers",
        "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task",
        "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning"
    ],
    "63eef09c90e50fcafda0d2a1": [
        "Measuring and relieving the oversmoothing problem for graph neural networks from the topological view",
        "Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach",
        "Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach",
        "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions",
        "Contrastive multi-view representation learning on graphs",
        "Neural collaborative filtering",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Automated selfsupervised learning for graphs",
        "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
        "Matrix factorization techniques for recommender systems",
        "Task-adaptive neural process for user cold-start recommendation",
        "Improving graph collaborative filtering with neighborhood-enriched contrastive learning",
        "Interest-aware message-passing gcn for recommendation",
        "Leveraging distribution alignment via stein path for cross-domain cold-start recommendation",
        "Representation learning with contrastive predictive coding",
        "Graph representation learning via graphical mutual information maximization",
        "Image denoising using the higher order singular value decomposition",
        "Learning matrix space image representations",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "Visualizing data using t-sne",
        "Deep graph infomax. ICLR",
        "Next-item recommendation with sequential hypergraphs",
        "Neural graph collaborative filtering",
        "Disentangled graph collaborative filtering",
        "Selfsupervised graph learning for recommendation",
        "Robust tensor graph convolutional networks via t-svd based graph augmentation",
        "Simgrace: A simple framework for graph contrastive learning without data augmentation",
        "Hypergraph contrastive collaborative filtering",
        "Self-supervised hypergraph transformer for recommender systems",
        "Contrastive learning for sequential recommendation",
        "Autogcl: Automated graph contrastive learning via learnable view generators",
        "Graph contrastive learning with augmentations",
        "Self-supervised multi-channel hypergraph convolutional network for social recommendation",
        "Are graph augmentations necessary? simple graph contrastive learning for recommendation",
        "Sail: Self-augmented graph contrastive learning",
        "Star-gcn: Stacked and reconstructed graph convolutional networks for recommender systems",
        "Enhancing sequential recommendation with graph contrastive learning",
        "Deep graph contrastive representation learning",
        "An empirical study of graph contrastive learning",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "63eef09c90e50fcafda0cfa0": [
        "BEiT: BERT Pre-Training of Image Transformers",
        "SciBERT: A Pretrained Language Model for Scientific Text",
        "Protein function prediction via graph kernels",
        "Language models are few-shot learners",
        "A comprehensive survey of graph embedding: Problems, techniques, and applications",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Unified language model pretraining for natural language understanding and generation",
        "Convolutional networks on graphs for learning molecular fingerprints",
        "Model-agnostic metalearning for fast adaptation of deep networks",
        "Graph u-nets",
        "Neural message passing for quantum chemistry",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Contrastive multi-view representation learning on graphs",
        "Strategies for Pre-training Graph Neural Networks",
        "GPT-GNN: Generative pre-training of graph neural networks",
        "Graph meta learning via local subgraphs",
        "Self-supervised auxiliary learning with meta-paths for heterogeneous graphs",
        "Variational graph auto-encoders",
        "Semi-supervised classification with graph convolutional networks",
        "Self-attention graph pooling",
        "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "GPT understands, too",
        "Node-wise Localization of Graph Neural Networks",
        "Relative and absolute location embedding for few-shot node classification on graph",
        "Tail-GNN: Tail-Node Graph Neural Networks",
        "Towards Locality-Aware Meta-Learning of Tail Node Embeddings on Networks",
        "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
        "Learning to pre-train graph neural networks",
        "Graph convolutional networks with eigenpooling",
        "Graph representation learning via graphical mutual information maximization",
        "DeepWalk: Online learning of social representations",
        "GCC: Graph contrastive coding for graph neural network pre-training",
        "The Network Data Repository with Interactive Graph Analytics and Visualization",
        "Weisfeiler-lehman graph kernels",
        "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization",
        "InfoGraph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks",
        "Adversarial graph augmentation to improve graph contrastive learning",
        "LINE: Large-scale information network embedding",
        "Wasserstein weisfeiler-lehman graph kernels",
        "Graph attention networks",
        "Deep Graph Infomax",
        "Deep Graph Infomax",
        "Graph few-shot learning with attribute matching",
        "FAITH: Few-Shot Graph Classification with Hierarchical Task Graphs",
        "Meta-inductive node classification across graphs",
        "A comprehensive survey on graph neural networks",
        "A survey of pretraining on graphs: Taxonomy, methods, and applications",
        "How powerful are graph neural networks?",
        "Hierarchical graph representation learning with differentiable pooling",
        "Graph contrastive learning automated",
        "Graph contrastive learning with augmentations",
        "Learning to Count Isomorphisms with Graph Neural Networks",
        "GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates",
        "Link prediction based on graph neural networks",
        "An endto-end deep learning architecture for graph classification",
        "Meta-GNN: On few-shot node classification in graph meta-learning",
        "ACM International Conference on Information and Knowledge Management"
    ],
    "62620f1c5aee126c0f686d0d": [
        "Learning from hints in neural networks",
        "Rednemo: topology-based ppi network reconstruction via repeated diffusion with neighborhood modifications",
        "Diffusion-convolutional neural networks",
        "Outlier aware network embedding for attributed networks",
        "Beyond low-frequency information in graph convolutional networks",
        "How attentive are graph attention networks?",
        "Spectral networks and locally connected networks on graphs",
        "Improving the accuracy and speed of support vector machines",
        "Minimum curvilinearity to enhance topological prediction of protein interactions by network embedding",
        "Stochastic training of graph convolutional networks with variance reduction",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Semi-supervised learning on graphs with generative adversarial nets",
        "Graph random neural networks for semi-supervised learning on graphs",
        "Fast graph representation learning with pytorch geometric",
        "Neural message passing for quantum chemistry",
        "Missing and spurious interactions and the reconstruction of complex networks",
        "Inductive representation learning on large graphs",
        "Improving neural networks by preventing co-adaptation of feature detectors",
        "Revealing missing parts of the interactome via link prediction",
        "Categorical reparameterization with gumbel-softmax",
        "Graph structure learning for robust graph neural networks",
        "Adam: A method for stochastic optimization",
        "Auto-encoding variational bayes",
        "Variational graph autoencoders",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "A novel link prediction algorithm for reconstructing protein-protein interaction networks by topological similarity",
        "Gated graph sequence neural networks",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Deeprobust: A pytorch library for adversarial attacks and defenses",
        "Semi-supervised embedding in attributed networks with outliers",
        "Learning to drop: Robust graph neural network via topological denoising",
        "Learning with marginalized corrupted features",
        "The concrete distribution: A continuous relaxation of discrete random variables",
        "Noise injection into inputs in backpropagation learning",
        "Birds of a feather: Homophily in social networks",
        "Learning graph neural networks with noisy labels",
        "Robust graph embedding with noisy link weights",
        "Graph neural networks exponentially lose expressive power for node classification",
        "Predicting missing links and identifying spurious links via likelihood analysis",
        "Geom-gcn: Geometric graph convolutional networks",
        "Noise-resilient similarity preserving network embedding for social networks",
        "A distributed approach to node clustering in decentralized peerto-peer networks",
        "The manifold tangent classifier",
        "Adding noise to the input of a model trained with a regularized objective",
        "Dropedge: Towards deep graph convolutional networks on node classification",
        "Graph sparsification approaches for laplacian smoothing",
        "Collective classification in network data",
        "Transformation invariance in pattern recognition-tangent distance and tangent propagation",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Graph attention networks",
        "Dropout training as adaptive regularization",
        "Regularization of neural networks using dropconnect",
        "Network enhancement as a general method to denoise weighted biological networks",
        "Graph information bottleneck",
        "A comprehensive survey on graph neural networks",
        "Representation learning on graphs with jumping knowledge networks",
        "How powerful are graph neural networks?",
        "Robust network enhancement from flawed networks",
        "Understanding default behavior in online lending",
        "Mining fraudsters and fraudulent strategies in large-scale mobile social networks",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Graphsaint: Graph sampling based inductive learning method",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Prediction of links and weights in networks by reliable routes",
        "Robust graph representation learning via neural sparsification",
        "Graph neural networks: A review of methods and applications",
        "Class noise vs. attribute noise: A quantitative study",
        "Robust graph convolutional networks against adversarial attacks",
        "Adversarial attacks on neural networks for graph data"
    ],
    "63a413f690e50fcafd6d1a7a": [
        "Simgnn: A neural network approach to fast graph similarity computation",
        "Unsupervised inductive graph-level representation learning via graph-graph proximity",
        "Learning-based efficient graph similarity computation via multi-scale convolutional set matching",
        "On the exact computation of the graph edit distance",
        "On a relation between graph edit distance and maximum common subgraph",
        "A graph distance metric based on the maximal common subgraph",
        "On the equivalence between graph isomorphism testing and function approximation with gnns",
        "Interpretable graph similarity computation via differentiable optimal alignment of node embeddings",
        "Speeding up graph edit distance computation through fast bipartite matching",
        "A graph distance metric combining maximum common subgraph and minimum common supergraph",
        "A hausdorff heuristic for efficient computation of graph edit distance",
        "Computers and intractability: a guide to the theory of np-completeness (michael r. garey and david s. johnson)",
        "Multilayer feedforward networks are universal approximators",
        "Similarity search in biological and engineering databases",
        "The hungarian method for the assignment problem",
        "Graph matching networks for learning the similarity of graph structured objects",
        "Similarity search in graph databases: A multi-layered indexing approach",
        "Multilevel graph matching networks for deep graph similarity learning",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Fast suboptimal algorithms for the computation of graph edit distance",
        "Discovering patterns in social networks with graph matching algorithms",
        "Slow learning and fast inference: Efficient graph similarity computation via knowledge distillation",
        "Ghashing: semantic graph hashing for approximate similarity search in graph databases",
        "Probabilistic substructure mining from small-molecule screens",
        "A novel software toolkit for graph edit distance computation",
        "Reasoning with neural tensor networks for knowledge base completion",
        "Community detection in a large real-world social network",
        "Saga: a subgraph matching tool for biological graphs",
        "Visualizing data using t-sne",
        "Combinatorial learning of graph edit distance via dynamic embedding",
        "A comprehensive survey on graph neural networks",
        "How powerful are graph neural networks?",
        "Deep sets. Advances in neural information processing systems",
        "Proximity enhanced graph neural networks with channel contrast",
        "Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] (b) Did you describe the limitations of your work"
    ],
    "637c3dcf90e50fcafd77c35b": [
        "SPEC CPU",
        "Architectural and compiler support for effective instruction prefetching: A cooperative approach",
        "Dbmss on a modern processor: Where does time go",
        "Divide and conquer frontend bottleneck",
        "Memory hierarchy for web search",
        "Asmdb: Understanding and mitigating front-end stalls in warehouse-scale computers",
        "Cacti 7: New tools for interconnect exploration in innovative off-chip memories",
        "Scavenger: A new last level cache architecture with global block priority",
        "A study of replacement algorithms for a virtual-storage computer",
        "Qemu, a fast and portable dynamic translator",
        "Pseudo-lifo: The foundation of a new family of replacement policies for last-level caches",
        "Introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches",
        "Autofdo: Automatic feedbackdirected optimization for warehouse-scale applications",
        "Improving cache performance by selective cache bypass",
        "Hardware identification of cache conflict misses",
        "Oltpbench: An extensible testbed for benchmarking relational databases",
        "Improving cache management policies using dynamic reuse distances",
        "Enhancing last-level cache performance by block bypassing and early miss determination",
        "Leeway: Addressing variability in dead-block prediction for last-level caches",
        "Clearing the clouds: A study of emerging scale-out workloads on modern hardware",
        "Proactive instruction fetch",
        "Temporal instruction fetch streaming",
        "A Dueling Segmented LRU Replacement Algorithm with Adaptive Bypassing",
        "Bypass and insertion algorithms for exclusive last-level caches",
        "A data cache with multiple caching strategies tuned to different types of locality",
        "Adaptive cache bypassing for inclusive last level caches",
        "A fully associative software-managed cache design",
        "Reactive nuca: Near-optimal block placement and replication in distributed caches",
        "Guaranteeing hits to improve the efficiency of a small instruction cache",
        "Timekeeping in the memory system: Predicting and optimizing memory behavior",
        "Re-establishing fetchdirected instruction prefetching: An industry perspective",
        "Back to the future: Leveraging belady's algorithm for improved cache replacement",
        "Rethinking belady's algorithm to accommodate prefetching",
        "High performance cache replacement using re-reference interval prediction (rrip)",
        "Insertion and promotion for tree-based pseudolru lastlevel caches",
        "Multiperspective reuse prediction",
        "Run-time cache bypassing",
        "Run-time adaptive cache hierarchy via reference analysis",
        "Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers",
        "ptask: A smart prefetching scheme for os intensive applications",
        "Profiling a warehouse-scale computer",
        "Shift: Shared history instruction fetch for lean-core server processors",
        "Confluence: Unified instruction supply for scale-out servers",
        "Using dead blocks as a virtual victim cache",
        "Sampling dead block prediction for last-level caches",
        "I-spy: Context-driven conditional instruction prefetching with coalescing",
        "Ripple: Profile-guided instruction cache replacement for data center applications",
        "Counter-based cache replacement algorithms",
        "The filter cache: an energy efficient memory structure",
        "Rdip: Return-address-stack directed instruction prefetching",
        "Lockup-free instruction fetch/prefetch cache organization",
        "Blasting through the frontend bottleneck with shotgun",
        "Boomerang: A metadata-free architecture for control flow delivery",
        "On the existence of a spectrum of policies that subsumes the least recently used (lru) and least frequently used (lfu) policies",
        "LRFU: A spectrum of policies that subsumes the least recently used and least frequently used policies",
        "A new cache architecture based on temporal and spatial locality",
        "Lightweight feedbackdirected cross-module optimization",
        "Optimal bypass monitor for high performance last-level caches",
        "Mcpat: An integrated power, area, and timing modeling framework for multicore and manycore architectures",
        "An imitation learning approach for cache replacement",
        "Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency",
        "Ispike: a post-link optimizer for the intel/spl reg/ itanium/spl reg/ architecture",
        "ARC: A self-tuning, low overhead replacement cache",
        "Exploring predictive replacement policies for instruction cache and branch target buffer",
        "Callchain software instruction prefetching in J2EE server applications",
        "The lru-k page replacement algorithm for database disk buffering",
        "Optimizing function placement for large-scale data-center applications",
        "Evaluating stream buffers as a secondary cache replacement",
        "Bolt: A practical binary optimizer for data centers and beyond",
        "Renaissance: Benchmarking suite for parallel applications on the jvm",
        "A case for mlp-aware cache replacement",
        "The v-way cache: demandbased associativity via global replacement",
        "Adaptive insertion policies for high performance caching",
        "Code layout optimizations for transaction processing workloads",
        "Data cache management using frequency-based replacement",
        "A cost-effective entangling prefetcher for instructions",
        "Tejas: A java based versatile micro-architectural simulator",
        "The evictedaddress filter: A unified mechanism to address both cache pollution and thrashing",
        "A case for (partially) tagged geometric history length branch prediction",
        "Applying deep learning to the cache replacement problem",
        "Eelru: Simple and effective adaptive page replacement",
        "Softsku: Optimizing server architectures for microservice diversity @scale",
        "Inter-reference gap distribution replacement: An improved replacement algorithm for set-associative caches",
        "Active management of data caches by exploiting reuse information",
        "Perceptron learning for reuse prediction",
        "A spatial and temporal locality-aware adaptive cache design with network optimization for tiled many-core architectures",
        "Using the compiler to improve cache replacement decisions",
        "Modified lru policies for improving secondlevel cache behavior",
        "Ship: Signature-based hit predictor for high performance caching",
        "Compiler managed micro-cache bypassing for high performance epic processors",
        "Less reused filter: Improving l2 cache performance via filtering less reused lines",
        "Two-level adaptive training branch prediction"
    ],
    "634d805b90e50fcafd4e1168": [
        "Architectural support for dynamic linking",
        "Lightweight data race detection with per-thread memory protection",
        "Breaking the boundaries in heterogeneous-isa datacenters",
        "Composing os extensions safely and efficiently with bascule",
        "Dune: Safe user-level access to privileged CPU features",
        "Xios: Extended application sandboxing on ios",
        "Graphene-sgx: A practical library OS for unmodified applications on SGX",
        "Flick: Fast and lightweight isa-crossing call for heterogeneous-isa environments",
        "Dynamic linking and loading in networked embedded systems",
        "Clearing the clouds: A study of emerging scale-out workloads on modern hardware",
        "Dynamic linking of software components",
        "Gnu lesser general public license",
        "Repurposing segmentation as a practical lvi-null mitigation in sgx",
        "Hodor: Intra-process isolation for highthroughput data plane libraries",
        "An approach to genuine dynamic linking",
        "Intel. Intel(R) Software Guard Extensions",
        "Intel R 64 and IA-32 Architectures Software Developer",
        "A cfi countermeasure against got overwrite attacks",
        "The missing link: Explaining elf static linking, semantically",
        "Sel4: Formal verification of an os kernel",
        "Trustlite: A security architecture for tiny embedded devices",
        "Code-pointer integrity",
        "Linkers and Loaders",
        "Minibox: A two-way sandbox for x86 native code",
        "Controlflow carrying code",
        "Aslr-guard: Stopping address space leakage for code reuse attacks",
        "Transparent huge pages for filesystems",
        "Developer and user-transparent compiler optimization for interactive applications",
        "Redleaf: Isolation and communication in a safe operating system",
        "Closing controlled channels with selfpaging enclaves",
        "Safebricks: Shielding network functions in the cloud",
        "Blankit library debloating: Getting what you want instead of cutting what you don't",
        "Rethinking the library os from the top down",
        "Debloating software through piece-wise compilation and loading",
        "Fine-grained isolation for scalable, dynamic, multi-tenant edge clouds",
        "Spons &amp; shields: Practical isolation for trusted execution",
        "Cubicleos: A library os with software componentisation for practical isolation",
        "Domain keys -efficient inprocess isolation for risc-v and x86",
        "Occlum: Secure and efficient multitasking inside a single enclave of intel sgx",
        "Carat: A case for virtual memory through compiler-and runtime-based address translation",
        "Phoronix Test Suite",
        "Intra-unikernel isolation with intel memory protection keys",
        "rkt-io: a direct I/O stack for shielded execution",
        "Cooperation and security isolation of library oses for multi-process applications",
        "A study of modern linux api usage and compatibility: What to support when you're supporting",
        "Practical context-sensitive cfi",
        "Yoav Etsion, and Mateo Valero. Direct inter-process communication (dipc): Repurposing the codoms architecture to accelerate ipc",
        "SPeCK: a kernel for scalable predictability",
        "Secure and efficient in-process monitor (and library) protection with intel mpk",
        "Binary stirring: Self-randomizing instruction addresses of legacy x86 binary code",
        "Tapping into the fountain of cpus: on operating system support for programmable devices",
        "Shuffler: Fast and deployable continuous code re-randomization",
        "Egalito: Layout-agnostic binary recompilation",
        "Native client: A sandbox for portable, untrusted x86 native code",
        "Architectural support for containment-based security",
        "Architectural support for containment-based security",
        "Control flow integrity for COTS binaries",
        "Kylinx: A dynamic library operating system for simplified and efficient cloud virtualization",
        "Mptee: Bringing flexible and efficient memory protection to intel sgx"
    ],
    "62d4cf305aee126c0fa9ab5a": [
        "Layer normalization",
        "Can weight sharing outperform random architecture search? an investigation with tunas",
        "Oncefor-all: Train one network and specialize it for efficient deployment",
        "Behavior sequence transformer for e-commerce recommendation in alibaba",
        "Wide &amp; deep learning for recommender systems",
        "Deep neural networks for youtube recommendations",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Progressive Feature Interaction Search for Deep Sparse Network",
        "Modularized transfomer-based ranking framework",
        "DeepFM: a factorization-machine based neural network for CTR prediction",
        "Single path one-shot neural architecture search with uniform sampling",
        "Practical lessons from predicting clicks on ads at facebook",
        "Differentiable NAS Framework and Application to Ads CTR Prediction",
        "xdeepfm: Combining explicit and implicit feature interactions for recommender systems",
        "Darts: Differentiable architecture search",
        "Sgdr: Stochastic gradient descent with warm restarts",
        "Deep learning recommendation model for personalization and recommendation systems",
        "Regularized evolution for image classifier architecture search",
        "Fast context-aware recommendations with factorization machines",
        "Predicting clicks: estimating the click-through rate for new ads",
        "Deep crossing: Web-scale modeling without manually crafted combinatorial features",
        "The evolved transformer",
        "Towards automated neural interaction discovery for click-through rate prediction",
        "Autoint: Automatic feature interaction learning via selfattentive neural networks",
        "Attention is all you need",
        "Hat: Hardware-aware transformers for efficient natural language processing",
        "Deep &amp; cross network for ad click predictions",
        "DCN V2: Improved deep &amp; cross network and practical lessons for web-scale learning to rank systems",
        "Neural predictor for neural architecture search",
        "Ruoming Pang, and Quoc Le. 2020. Bignas: Scaling up neural architecture search with big single-stage models",
        "Learning transferable architectures for scalable image recognition"
    ],
    "63dcdb422c26941cf00b6094": [
        "Graph transformer for graph-to-sequence learning",
        "Path-augmented graph transformer network",
        "Glit: Neural architecture search for global and local image transformer",
        "Autoformer: Searching transformers for visual recognition",
        "Searching the search space of vision transformer",
        "A generalization of transformer networks to graphs",
        "Neural architecture search: A survey",
        "A fair comparison of graph neural networks for graph classification",
        "One-shot neural channel search: What works and what's next",
        "Single path one-shot neural architecture search with uniform sampling",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Heterogeneous graph transformer",
        "Edge-augmented graph transformers: Global self-attention is enough for graphs",
        "Interpretable rumor detection in microblogs by attending to user interactions",
        "Rethinking graph transformers with spectral attention",
        "DARTS: Differentiable architecture search",
        "Shufflenet v2: Practical guidelines for efficient cnn architecture design",
        "Transformer for graphs: An overview from architecture perspective",
        "Masked transformer for neighhourhood-aware click-through rate prediction",
        "Tudataset: A collection of benchmark datasets for learning with graphs",
        "Efficient neural architecture search via parameter sharing",
        "Self-supervised graph transformer on large-scale molecular data",
        "Masked label prediction: Unified message passing model for semi-supervised classification",
        "The evolved transformer",
        "Knowledge-enhanced hierarchical graph transformer network for multi-behavior recommendation",
        "NAS-BERT: task-agnostic and adaptive-size BERT compression with neural architecture search",
        "How powerful are graph neural networks?",
        "Deep graph kernels",
        "Heterogeneous graph transformer for graph-tosequence learning",
        "Do transformers really perform badly for graph representation?",
        "Hierarchical graph representation learning with differentiable pooling",
        "Text graph transformer for document classification",
        "Graph-bert: Only attention is needed for learning graph representations",
        "An end-to-end deep learning architecture for graph classification",
        "Gophormer: Ego-graph transformer for node classification",
        "Autotrans: Automating transformer design via reinforced architecture search",
        "Neural architecture search with reinforcement learning"
    ],
    "633cf5cf90e50fcafd772e24": [
        "Towards interpretable math word problem solving with operation-based formalisms",
        "Promptsource: An integrated development environment and repository for natural language prompts",
        "Autoregressive search engines: Generating substrings as document identifiers",
        "Language models are few-shot learners",
        "The secret sharer: Evaluating and testing unintended memorization in neural networks",
        "Extracting training data from large language models",
        "Quantifying memorization across neural language models",
        "Reading wikipedia to answer opendomain questions",
        "Evaluating large language models trained on code",
        "Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension",
        "Scaling language modeling with pathways",
        "Scaling instruction-finetuned language models",
        "Training verifiers to solve math word problems",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Retrieval augmented language model pre-training",
        "Training compute-optimal large language models",
        "Distilling knowledge from reader to retriever for question answering",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Few-shot learning with retrieval augmented language models",
        "How can we know what language models know",
        "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
        "How bpe affects memorization in transformers",
        "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
        "Natural questions: a benchmark for question answering research",
        "Can language models learn from explanations in context? arXiv preprint",
        "Internetaugmented language models through few-shot prompting for open-domain question answering",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Question and answer test-train overlap in open-domain question answering datasets",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Generated knowledge prompting for commonsense reasoning",
        "Challenges in generalization in open domain question answering",
        "A robustly optimized bert pretraining approach",
        "The read-recite-review study strategy: Effective and portable",
        "None",
        "Training language models to follow instructions with human feedback",
        "Language models as knowledge bases?",
        "Open-domain question-answering",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "How much knowledge can you pack into the parameters of a language model?",
        "The probabilistic relevance framework: Bm25 and beyond",
        "Equation parsing: Mapping sentences to grounded equations",
        "Multitask prompted training enables zero-shot task generalization",
        "Unsupervised commonsense question answering with self-talk",
        "olmpics-on what language model pre-training captures",
        "Unifying language learning paradigms",
        "Transformer memory as a differentiable search index",
        "Rajiv Mathews, and Franc ?oise Beaufays. Understanding unintended memorization in federated learning",
        "Memorization without overfitting: Analyzing the training dynamics of large language models",
        "Can generative pre-trained language models serve as knowledge bases for closed-book qa?",
        "Rationaleaugmented ensembles in language models",
        "Self-consistency improves chain of thought reasoning in language models",
        "A neural corpus indexer for document retrieval",
        "Finetuned language models are zero-shot learners",
        "Chain of thought prompting elicits reasoning in large language models",
        "End-to-end open-domain question answering with bertserini",
        "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Counterfactual memorization in neural language models",
        "Opt: Open pre-trained transformer language models",
        "Calibrate before use: Improving few-shot performance of language models",
        "Ultron: An ultimate retriever on corpus with a model-based indexer",
        "Bridging the gap between indexing and retrieval for differentiable search index with query generation"
    ],
    "635b486790e50fcafd32f8b1": [
        "How reliable are model diagnostics?",
        "The problem with bias: from allocative to representational harms in machine learning",
        "Unmasking contextual stereotypes: Measuring and mitigating BERT's gender bias",
        "The fifth pascal recognizing textual entailment challenge",
        "Stereotyping Norwegian salmon: An inventory of pitfalls in fairness benchmark datasets",
        "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
        "A large annotated corpus for learning natural language inference",
        "Semantics derived automatically from language corpora contain human-like biases",
        "SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation",
        "A simple framework for contrastive learning of visual representations",
        "Fairfil: Contrastive neural debiasing method for pretrained text encoders",
        "Conditional supervised contrastive learning for fair text classification",
        "SentEval: An evaluation toolkit for universal sentence representations",
        "Supervised learning of universal sentence representations from natural language inference data",
        "The pascal recognising textual entailment challenge",
        "Bias in bios: A case study of semantic representation bias in a high-stakes setting",
        "Bias in bios: A case study of semantic representation bias in a high-stakes setting",
        "On measuring and mitigating biased inferences of word embeddings",
        "OSCaR: Orthogonal subspace correction and rectification of biases in word embeddings",
        "Attenuating bias in word vectors",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Automatically constructing a corpus of sentential paraphrases",
        "Understanding undesirable word embedding associations",
        "SimCSE: Simple contrastive learning of sentence embeddings",
        "The fourth pascal recognizing textual entailment challenge",
        "The third PASCAL recognizing textual entailment challenge",
        "Intrinsic bias metrics do not correlate with application bias",
        "Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases",
        "Autodebias: Debiasing masked language models with automated biased prompts",
        "The second pascal recognising textual entailment challenge",
        "2021a. Balancing out bias: Achieving fairness through training reweighting",
        "2021b. Diverse adversaries for mitigating bias in training",
        "OntoNotes: The 90% solution",
        "On transferability of bias mitigation effects in language model fine-tuning",
        "Debiasing pre-trained contextualised embeddings",
        "Debiasing isn't enough! -on the effectiveness of debiasing MLMs and their social biases in downstream tasks",
        "Measuring bias in contextualized word representations",
        "Sustainable modular debiasing of language models",
        "Towards debiasing sentence representations",
        "RoBERTa: A robustly optimized BERT pretraining approach",
        "On measuring social biases in sentence encoders",
        "An empirical survey of the effectiveness of debiasing techniques for pre-trained language models",
        "StereoSet: Measuring stereotypical bias in pretrained language models",
        "CrowS-pairs: A challenge dataset for measuring social biases in masked language models",
        "How gender debiasing affects internal model representations, and why it matters",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Deep contextualized word representations",
        "Perturbation augmentation for fairer nlp",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Null it out: Guarding protected attributes by iterative nullspace projection",
        "Linear adversarial concept erasure",
        "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
        "Gender bias in coreference resolution",
        "Timothy Baldwin, and Lea Frermann. 2021. Contrastive learning for fair representations",
        "Towards a comprehensive understanding and accurate evaluation of societal biases in pre-trained transformers",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Evaluating debiasing techniques for intersectional biases",
        "Visualizing data using t-sne",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Bilateral multi-perspective matching for natural language sentences",
        "Neural network acceptability judgments",
        "Measuring and reducing gendered correlations in pre",
        "ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Transformers: State-of-the-art natural language processing",
        "Revealing the myth of higher-order inference in coreference resolution",
        "Gender bias in contextualized word embeddings",
        "Gender bias in coreference resolution: Evaluation and debiasing methods"
    ],
    "628749485aee126c0fff0290": [
        "Constructing a psychometric testbed for fair natural language processing",
        "A deep learning architecture for psychometric natural language processing",
        "Data decisions and theoretical implications when adversarially learning fair representations",
        "Language (technology) is power: A critical survey of \"bias\" in NLP",
        "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
        "Language models are few-shot learners",
        "Semantics derived automatically from language corpora contain human-like biases",
        "Fairfil: Contrastive neural debiasing method for pretrained text encoders",
        "Marked attribute bias in natural language inference",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Measuring and mitigating unintended bias in text classification",
        "Adversarial removal of demographic attributes from text data",
        "Word embeddings quantify 100 years of gender and ethnic stereotypes",
        "He is very intelligent, she is very beautiful? on mitigating social biases in language modelling and generation",
        "Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them",
        "Explaining and harnessing adversarial examples",
        "Detecting emergent intersectional biases: Contextualized word embeddings contain a distribution of human-like biases",
        "Decoupling adversarial training for fair nlp",
        "Social biases in nlp models as barriers for persons with disabilities",
        "Gender-preserving debiasing for pre-trained word embeddings",
        "Debiasing pre-trained contextualised embeddings",
        "Examining gender and race bias in two hundred sentiment analysis systems",
        "Measuring bias in contextualized word representations",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Sustainable modular debiasing of language models",
        "Towards debiasing sentence representations",
        "Roberta: A robustly optimized bert pretraining approach",
        "Decoupled weight decay regularization",
        "Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings",
        "On measuring social biases in sentence encoders",
        "An empirical survey of the effectiveness of debiasing techniques for pre-trained language models",
        "Crows-pairs: A challenge dataset for measuring social biases in masked language models",
        "Probing toxic content in large pre-trained language models",
        "Practical black-box attacks against machine learning",
        "Language models as knowledge bases?",
        "Perturbation sensitivity analysis to detect unintended model biases",
        "Null it out: Guarding protected attributes by iterative nullspace projection",
        "Gender bias in coreference resolution",
        "Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in nlp",
        "The woman worked as a babysitter: On biases in language generation",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Assessing social and intersectional biases in contextualized word representations",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Measuring and reducing gendered correlations in pre-trained models",
        "Transformers: State-of-theart natural language processing",
        "Low frequency names exhibit bias and overfitting in contextualizing language models",
        "Mitigating unwanted biases with adversarial learning",
        "Hurtful words: quantifying biases in clinical contextual word embeddings",
        "Gender bias in contextualized word embeddings",
        "Learning gender-neutral word embeddings",
        "Factual probing is [MASK]: learning vs. learning to recall",
        "Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology"
    ],
    "627cdc8e5aee126c0f50229e": [
        "Advanced profiling topics. pebs and lbr",
        "Defensive loop tiling for shared cache",
        "Hoard: A scalable memory allocator for multithreaded applications",
        "The parsec benchmark suite: Characterization and architectural implications",
        "Data centric cache measurement on the Intel ltanium 2 processor",
        "Featherlight on-the-fly false-sharing detection",
        "Rodinia: A benchmark suite for heterogeneous computing",
        "Intel vtune profiler",
        "Intel math kernel library",
        "Linux kernel profiling with perf",
        "Collective loop fusion for array contraction",
        "Tcmalloc: Thread-caching malloc",
        "Himeno benchmark",
        "Intel. Intel xed",
        "ntel? 64 and IA-32 Architectures Software Developer Manuals",
        "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "Memory profiling using hardware counters",
        "On modeling and analyzing cache hierarchies using casper",
        "Cmp$im: A pin-based on-the-fly multi-core cache simulator",
        "Detection of false sharing using machine learning",
        "Reducing compulsory and capacity misses",
        "Automated memory leak detection for production use",
        "Lulesh programming model and performance ports overview",
        "Dmon: Efficient detection and correction of data locality problems using selective profiling",
        "Huron: Hybrid false sharing detection and repair",
        "Inefficient innodb row stats implementation",
        "Kripke-a massively parallel transport mini-app",
        "Cache profiling and the spec benchmarks: A case study",
        "Performance analysis guide for intel core? i7 processor and intel xeon 5500 processors",
        "Oprofile: A system profiler for linux",
        "Sheriff: precise detection and automatic mitigation of false sharing",
        "Cheetah: Detecting false sharing efficiently and effectively",
        "Predator: Predictive false sharing detection",
        "Arraytool: A lightweight profiler to guide array regrouping",
        "A data-centric profiler for parallel programs",
        "Arraytool: A lightweight profiler to guide array regrouping",
        "Multicachesim: A coherent multiprocessor cache simulator",
        "Laser: Light, accurate sharing detection and repair",
        "Valgrind: A framework for heavyweight dynamic binary instrumentation",
        "Delorean: Virtualized Directed Profiling for Cache Modeling in Sampled Simulation",
        "Delorean: Virtualized directed profiling for cache modeling in sampled simulation",
        "Locating cache performance bottlenecks using data profiling",
        "None",
        "Evaluating mapreduce for multi-core and multiprocessor systems",
        "Lightweight detection of cache conflicts",
        "Analyzing data locality in numeric applications",
        "Addresssanitizer: A fast address sanity checker",
        "Cachegrind: a cache-miss profiler",
        "Racez: A lightweight and non-invasive race detection tool for production applications",
        "Detailed cache simulation for detecting bottleneck, miss reason and optimization potentialities",
        "Detailed cache simulation for detecting bottleneck, miss reason and optimization potentialities",
        "Cache performance measurement and metric: Capacity misses",
        "Team. header only, dependency-free deep learning framework in c++14",
        "Loop optimization",
        "Speckle reducing anisotropic diffusion",
        "A mathematical cache miss analysis for pointer data structures",
        "Dynamic cache contention detection in multi-threaded applications"
    ],
    "62d16e895aee126c0fd68310": [
        "Intel Data Direct I/O Technology",
        "Linux AF_XDP",
        "LLVM Alias Analysis",
        "None",
        "CloudLab",
        "Policy-Driven Optimization of P4 Pipeline",
        "Decoupling Algorithms and Optimizations in Network Functions",
        "Fast, Effective Dynamic Compilation",
        "None",
        "Istio -Connect, secure, control, and observe services",
        "Dynamo: A Transparent Dynamic Optimization System",
        "Enabling End-Host Network Functions",
        "Automatic Generation of Peephole Superoptimizers",
        "Fast Userspace Packet Processing",
        "A High-Speed Load-Balancer Design with Guaranteed Per-Connection-Consistency",
        "A Preliminary Performance Model for Optimizing Software Packet Processing Pipelines",
        "Benchmarking Terminology for Network Interconnection Devices. RFC 1242. RFC Editor. 1?12 pages",
        "Benchmarking Methodology for Network Interconnect Devices. RFC 2544",
        "OpenBox: A Software-Defined Framework for Developing, Deploying, and Managing Network Functions",
        "An Infrastructure for Adaptive Dynamic Optimization",
        "The CAIDA Anonymized Internet Traces Data Access",
        "The CAIDA UCSD Anonymized Internet Traces",
        "AutoFDO: Automatic Feedback-Directed Optimization for Warehouse-Scale Applications",
        "VeGen: A Vectorizer Generator for SIMD and Beyond",
        "PVPP: A Programmable Vector Packet Processor",
        "The Case for a Flexible Low-Level Backend for Software Data Planes",
        "Perf (linux)",
        "Pin -A Dynamic Binary Instrumentation Tool",
        "Compiling Java Just in Time",
        "Redundant Logic Elimination in Network Functions",
        "Pktgen Traffic Generator Using DPDK",
        "L3 Forwarding with Access Control Sample Application",
        "MoonGen: A Scriptable High-Speed Packet Generator (IMC '15)",
        "New Directions in Traffic Measurement and Accounting",
        "PacketMill: Toward per-Core 100-Gbps Networking",
        "Tradeoffs for packet classification",
        "Vector Packet Processing (VPP) platform",
        "Open Information Security Foundation",
        "Trace-Based Just-in-Time Type Specialization for Dynamic Languages",
        "GNU Compiler Collection",
        "Gprof: A Call Graph Execution Profiler",
        "Blueswitch: enabling provably consistent configuration of network switches",
        "SoftNIC: A software NIC to augment hardware",
        "Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback",
        "Katran: A high performance layer 4 load balancer",
        "Kubernetes: Production-Grade Container Orchestration",
        "Propeller: Profile Guided Optimizing Large Scale LLVMbased Relinker",
        "Performance Contracts for Software Network Functions",
        "Kubernetes Long Road to Dual IPv4/IPv6 Support",
        "Denali: A Goal-Directed Superoptimizer",
        "Metron: NFV Service Chains at the True Speed of the Underlying Hardware",
        "SNF: synthesizing high performance NFV service chains",
        "Header Space Analysis: Static Checking for Networks",
        "Moving the Mobile Evolved Packet Core to the Cloud",
        "DMon: Efficient Detection and Correction of Data Locality Problems Using Selective Profiling",
        "Adaptive Execution of Compiled Queries",
        "Manageability of the QUIC Transport Protocol",
        "LLVM: A Compilation Framework for Lifelong Program Analysis and Transformation",
        "Oprofile: A system profiler for linux",
        "Survey of Performance Acceleration Techniques for Network Function Virtualization",
        "Microboxes: High Performance NFV with Customizable, Asynchronous TCP Stacks and Dynamic Subscriptions (SIGCOMM '18). Association for Computing Machinery",
        "Contention-Aware Performance Prediction For Virtualized Network Functions",
        "ClickOS and the Art of Network Function Virtualization",
        "Morpheus: Domain Specific Run Time Optimization for Software Data Planes -Artifact for ASPLOS'22",
        "Polycube (Morpheus branch)",
        "Securing Linux with a Faster and Scalable Iptables. SIGCOMM Comput. Commun. Rev",
        "A Service-Agnostic Software Framework for Fast and Efficient in-Kernel Network Services",
        "Creating Complex Network Services with eBPF: Experience and Lessons Learned",
        "A Framework for eBPF-based Network Functions in an Era of Microservices",
        "Dataplane Specialization for High-Performance OpenFlow Software Switching",
        "Dataflow-Based Pruning for Speeding up Superoptimization",
        "Stateless Datacenter Load-balancing with Beamer",
        "None",
        "Java HotSpot VM Options",
        "The Open Virtual Network architecture: Tunnel Encapsulations",
        "BOLT: A Practical Binary Optimizer for Data Centers and Beyond",
        "NetBricks: Taking the V out of NFV",
        "Automated Synthesis of Adversarial Workloads for Network Functions",
        "Scaling up Superoptimization",
        "SymPerf: Predicting Network Function Performance",
        "Dynamic Compilation and Optimization of Packet Processing Programs",
        "DPDK burst replay tool",
        "Netmap: A Novel Framework for Fast Packet I/O",
        "Souper: A Synthesizing Superoptimizer",
        "Design and Implementation of a Consolidated Middlebox Architecture",
        "The Case for an Intermediate Representation for Programmable Data Planes",
        "The Case for an Intermediate Representation for Programmable Data Planes",
        "Snort -Network Intrusion Detection &amp; Prevention System",
        "What can cause my code to run slower when the server JIT is activated",
        "NFP: Enabling Network Function Parallelism in NFV",
        "Classbench Filter Set &amp; Trace Generator",
        "Classbench: A packet classification benchmark",
        "P2GO: P4 Profile-Guided Optimizations",
        "Eliminating unrequired guards",
        "Unimog -Cloudflare's edge load balancer",
        "Leveraging EBPF for Programmable Network Functions with IPv6 Segment Routing",
        "bpf: adding map batch processing support",
        "Don't Forget the I/O When Allocating Your LLC",
        "Micro-Specialization: Dynamic Code Specialization of Database Management Systems"
    ],
    "63dcdb422c26941cf00b604a": [
        "Dehb: Evolutionary hyberband for scalable, robust and efficient hyperparameter optimization",
        "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures",
        "Random search for hyper-parameter optimization",
        "Dr{nas}: Dirichlet neural architecture search",
        "Heteroscedastic evolutionary bayesian optimisation",
        "Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves",
        "One-shot neural architecture search via self-evaluated template network",
        "Searching for a robust neural architecture in four gpu hours",
        "NAS-Bench-201: Extending the scope of reproducible neural architecture search",
        "Brp-nas: Prediction-based nas using gcns",
        "Neural architecture search: A survey",
        "Meta-learning of neural architectures for few-shot learning",
        "BOHB: Robust and efficient hyperparameter optimization at scale",
        "Scalable meta-learning for bayesian optimization",
        "Practical transfer learning for bayesian optimization",
        "Model-agnostic meta-learning for fast adaptation of deep networks",
        "Gpytorch: Blackbox matrix-matrix gaussian process inference with GPU acceleration",
        "Automated Machine Learning: Methods, Systems, Challenges",
        "Dataset2vec: learning dataset metafeatures",
        "Transfer learning for bayesian hpo with end-to-end landmark meta-features",
        "Neural architecture search with bayesian optimisation and optimal transport",
        "Rapid neural architecture search by learning to generate graphs from datasets",
        "Set transformer: A framework for attention-based permutation-invariant neural networks",
        "Towards fast adaptation of neural architectures with meta learning",
        "Best practices for scientific research on neural architecture search",
        "DARTS: Differentiable architecture search",
        "Machine learning: a probabilistic perspective",
        "On first-order meta-learning algorithms",
        "Bayesian meta-learning for the few-shot setting via deep kernels",
        "Learning search spaces for bayesian optimization: Another view of hyperparameter transfer learning",
        "Gaussian processes for machine learning. Adaptive computation and machine learning",
        "Regularized evolution for image classifier architecture search",
        "A comprehensive survey of neural architecture search: Challenges and solutions",
        "Meta-features for meta-learning. Knowledge-Based Systems",
        "Interpretable neural architecture search via bayesian optimisation with weisfeiler-lehman kernels",
        "A quantile-based approach for hyperparameter transfer learning",
        "Taking the human out of the loop: A review of Bayesian optimization",
        "Weisfeiler-lehman graph kernels",
        "Nasbench-301 and the case for surrogate benchmarks for neural architecture search",
        "Practical bayesian optimization of machine learning algorithms",
        "Scalable bayesian optimization using deep neural networks",
        "Bayesian optimization with robust Bayesian neural networks",
        "Raiders of the lost architecture: Kernels for Bayesian optimization in conditional parameter spaces",
        "Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge",
        "Meta-learning",
        "Meta-learning: A survey",
        "Neural predictor for neural architecture search",
        "A study on encodings for neural architecture search",
        "Bananas: Bayesian optimization with neural architectures for neural architecture search",
        "A deeper look at zero-cost proxies for lightweight nas",
        "Deep kernel learning",
        "Xfernas: Transfer neural architecture search",
        "Few-shot bayesian optimization with deep kernel surrogates",
        "Two-stage transfer surrogate model for automatic hyperparameter optimization",
        "A survey on neural architecture search",
        "Transfer learning with neural automl",
        "Pc-darts: Partial channel connections for memory-efficient architecture search",
        "Understanding and robustifying differentiable architecture search",
        "D-vae: A variational autoencoder for directed acyclic graphs",
        "Neural architecture search with reinforcement learning"
    ],
    "640fe64790e50fcafd9e237f": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Graph Barlow Twins: A self-supervised representation learning framework for graphs",
        "Beyond low-frequency information in graph convolutional networks",
        "A simple framework for contrastive learning of visual representations",
        "Spectral graph theory",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Graph-structured data viewed through a Fourier lens",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "Contrastive multi-view representation learning on graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "Complete the missing half: Augmenting aggregation filtering with diversification for graph convolutional networks",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Representation learning with contrastive predictive coding",
        "Geom-gcn: Geometric graph convolutional networks",
        "Graph representation learning via graphical mutual information maximization",
        "Deepwalk: Online learning of social representations",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Multi-scale attributed node embedding",
        "Largescale representation learning on graphs via bootstrapping",
        "None",
        "Deep Graph Infomax. ICLR (Poster)",
        "Demystifying graph neural network via graph filter assessment",
        "How powerful are graph neural networks? arXiv preprint",
        "Two sides of the same coin: Heterophily and oversmoothing in graph convolutional neural networks",
        "Revisiting semisupervised learning with graph embeddings",
        "Graph contrastive learning with augmentations",
        "Graph neural networks with heterophily",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Interpreting and unifying graph neural networks with an optimization framework",
        "An empirical study of graph contrastive learning",
        "Deep graph contrastive representation learning",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "628749355aee126c0ffec021": [
        "A survey on data augmentation for text classification",
        "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",
        "Latent dirichlet allocation",
        "Enriching word vectors with subword information",
        "Language models are fewshot learners",
        "What you can cram into a single $&amp;!#* vector: Probing sentence embeddings for linguistic properties",
        "Approximation by superpositions of a sigmoidal function",
        "Are we really making much progress? A worrying analysis of recent neural recommendation approaches",
        "The efficiency misnomer",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Be more with less: Hypergraph attention networks for inductive text classification",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "GNNAutoScale: Scalable and expressive graph neural networks via historical embeddings",
        "A practical survey on faster and lighter transformers",
        "Using titles vs. fulltext as source for automated semantic document annotation",
        "Comparing BERT against traditional machine learning text classification",
        "Graph Representation Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning",
        "Deep unordered composition rivals syntactic methods for text classification",
        "TinyBERT: Distilling BERT for natural language understanding",
        "Bag of tricks for efficient text classification",
        "Survey on supervised machine learning techniques for automatic text classification",
        "A convolutional neural network for modelling sentences",
        "Adam: A method for stochastic optimization",
        "Semisupervised classification with graph convolutional networks",
        "Text classification algorithms: A survey",
        "Recurrent convolutional neural networks for text classification",
        "A survey on text classification: From shallow to deep learning",
        "Le. 2021a. Pay attention to MLPs",
        "Tensor graph convolutional networks for text classification",
        "Yanchun Liang, and Xiaoyue Feng. 2021b. Deep attention diffusion graph neural networks for text classification",
        "Graph star net for generalized multi-task learning",
        "Combine convolution with recurrent networks for text classification",
        "Luke Melas-Kyriazi. 2021. Do you even need attention? A stack of feed-forward layers does surprisingly well on ImageNet",
        "Distributed representations of words and phrases and their compositionality",
        "Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. Deep learning-based text classification: A comprehensive review",
        "Deep double descent: Where bigger models and more data hurt",
        "Towards understanding the role of over-parametrization in generalization of neural networks",
        "Keygraph: Automatic indexing by cooccurrence graph based on building construction metaphor",
        "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
        "Large-scale hierarchical text classification with recursively regularized deep graph-cnn",
        "GloVe: Global vectors for word representation",
        "HeteGCN: Heterogeneous graph convolutional networks for text classification",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter",
        "Pitfalls of graph neural network evaluation",
        "Baseline needs more love: On simple word-embedding-based models and associated pooling mechanisms",
        "Masked language modeling and the distributional hypothesis: Order word matters pre-training for little",
        "MobileBERT: a compact task-agnostic BERT for resource-limited devices",
        "PTE: predictive text embedding through large-scale heterogeneous text networks",
        "Efficient transformers: A survey",
        "MLP-Mixer: An all-MLP architecture for vision",
        "Attention is all you need",
        "Graph attention networks",
        "A comparison of deeplearning methods for analysing and predicting business processes",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Convolutional recurrent neural networks for text classification",
        "None",
        "Sentiment analysis by capsules",
        "Simplifying graph convolutional networks",
        "Graph neural networks for natural language processing: A survey",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "Efficient path prediction for semi-supervised and weakly supervised hierarchical text classification",
        "Graph convolutional networks for text classification",
        "When SIMPLE is better than complex: A case study on deep learning for predicting Bugzilla issue close time",
        "Bayesian performance comparison of text classifiers",
        "Weakly-supervised text classification based on keyword graph",
        "Text classification improved by integrating bidirectional LSTM with two-dimensional max pooling",
        "A survey on text classification and its applications"
    ],
    "6287045b5aee126c0f5ca192": [
        "Multi-dimensional balanced graph partitioning via projected gradient descent",
        "Distributed balanced partitioning via linear embedding",
        "Group formation in large social networks",
        "Graph Partitioning and Graph Clustering",
        "Graph partitioning for scalable distributed graph computations",
        "Recent Advances in Graph Partitioning",
        "Metrics for community analysis: A survey",
        "Pt-scotch: A tool for efficient parallel graph ordering",
        "A graph partitioning algorithm for edge or vertex balance",
        "Social network analysis, estimation and sampling in",
        "Network sampling",
        "Random multigraphs and aggregated triads with fixed degrees",
        "Finding overlapping communities in networks by label propagation",
        "Scalable graph processing frameworks: A taxonomy and open challenges",
        "Multilevel graph partitioning schemes",
        "What is Twitter, a social network or a news media?",
        "Signed networks in social media",
        "Community structure in large networks: Natural cluster sizes and the absence of large welldefined clusters",
        "Spinner: Scalable graph partitioning in the cloud",
        "Parallel graph partitioning for complex networks",
        "Near linear time algorithm to detect community structures in large-scale networks",
        "Computational comparison of major proposed methods for graph partitioning problem",
        "The network data repository with interactive graph analytics and visualization",
        "FENNEL: Streaming graph partitioning for massive scale graphs",
        "Rank degree: An efficient algorithm for graph sampling",
        "Users joining multiple sites: Distributions and patterns"
    ],
    "62708f615aee126c0fa6920a": [
        "Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on interpretability",
        "Semeval-2014 task 10: Multilingual semantic textual similarity",
        "Semeval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation",
        "Semeval-2012 task 6: A pilot on semantic textual similarity",
        "*sem 2013 shared task: Semantic textual similarity",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "Contrastive curriculum learning for sequential user behavior modeling via data augmentation",
        "A large annotated corpus for learning natural language inference",
        "Universal sentence encoder for english",
        "Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation",
        "A simple framework for contrastive learning of visual representations",
        "Senteval: An evaluation toolkit for universal sentence representations",
        "Supervised learning of universal sentence representations from natural language inference data",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "How contextual are contextualized word representations? comparing the geometry of bert, elmo, and GPT-2 embeddings",
        "CERT: contrastive self-supervised learning for language understanding",
        "Simcse: Simple contrastive learning of sentence embeddings",
        "Dimensionality reduction by learning an invariant mapping",
        "Momentum contrast for unsupervised visual representation learning",
        "Learning distributed representations of sentences from unlabelled data",
        "Distilling the knowledge in a neural network",
        "Whiteningbert: An easy unsupervised sentence embedding approach",
        "SMART: robust and efficient fine-tuning for pretrained natural language models through principled regularized optimization",
        "Self-guided contrastive learning for BERT sentence representations",
        "Adam: A method for stochastic optimization",
        "Raquel Urtasun, Antonio Torralba, and Sanja Fidler",
        "Adversarial examples in the physical world",
        "Distributed representations of sentences and documents",
        "On the sentence embeddings from pre-trained language models",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Towards deep learning models resistant to adversarial attacks",
        "A SICK cure for the evaluation of compositional distributional semantic models",
        "Distributed representations of words and phrases and their compositionality",
        "Adversarial training methods for semisupervised text classification",
        "Virtual adversarial training: A regularization method for supervised and semisupervised learning",
        "Glove: Global vectors for word representation",
        "Less is more: zero-shot learning from online textual documents with noise suppression",
        "Adversarial robustness through local linearization",
        "Sentencebert: Sentence embeddings using siamese bertnetworks",
        "Measuring social biases in grounded vision and language embeddings",
        "Whitening sentence representations for better semantics and faster retrieval",
        "Robust unsupervised neural machine translation with adversarial denoising training",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Transformers: State-of-the-art natural language processing",
        "Smoothed contrastive learning for unsupervised sentence embedding",
        "CLEAR: contrastive learning for sentence representation",
        "Consert: A contrastive framework for self-supervised sentence representation transfer",
        "Peng Jiang, and He Hu. 2022. C 2 -crs: Coarse-to-fine contrastive learning for conversational recommender system",
        "Freelb: Enhanced adversarial training for natural language understanding"
    ],
    "63fd715990e50fcafd146bdb": [
        "Generalizing from a few examples: A survey on few-shot learning",
        "A survey on few-shot learning in natural language processing",
        "Hierarchical attention prototypical networks for few-shot text classification",
        "Meta-learning for few-shot natural language processing: A survey",
        "Transprompt: Towards an automatic transferable prompting framework for fewshot text classification",
        "Bert: Pretraining of deep bidirectional transformers for language understanding",
        "Meta learning for natural language processing: A survey",
        "Language models are few-shot learners",
        "The power of scale for parameter-efficient prompt tuning",
        "Ptr: Prompt tuning with rules for text classification",
        "Towards unified prompt tuning for few-shot text classification",
        "Eda: Easy data augmentation techniques for boosting performance on text classification tasks",
        "A closer look at feature space data augmentation for few-shot intent classification",
        "A survey of data augmentation approaches for nlp",
        "Improving neural machine translation models with monolingual data",
        "Augmenting nlp models using latent feature interpolations",
        "Text data augmentation for deep learning",
        "A survey on data augmentation for text classification",
        "Recent advances in natural language processing via large pre-trained language models: A survey",
        "Survey on natural language processing in medical image analysis",
        "Training language models to follow instructions with human feedback",
        "Synthetic and natural noise both break neural machine translation",
        "Text Data Augmentation Made Simple By Leveraging NLP Cloud APIs",
        "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks",
        "Ppdb 2.0: Better paraphrase ranking, finegrained entailment relations, word embeddings, and style classification",
        "Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models",
        "None",
        "Wordnet: a lexical database for english",
        "That's so annoying!!!: A lexical and frame-semantic embedding based data augmentation approach to automatic categorization of annoying behaviors using# petpeeve tweets",
        "Distributed representations of words and phrases and their compositionality",
        "Counter-fitting Word Vectors to Linguistic Constraints",
        "Generating Natural Language Adversarial Examples",
        "Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations",
        "Data Augmentation Using Pre-trained Transformer Models",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
        "Roberta: A robustly optimized bert pretraining approach",
        "Improving Neural Machine Translation Models with Monolingual Data",
        "Nareor: The narrative reordering problem",
        "One-shot learning of object categories",
        "Fewshot learning for medical text: A systematic review",
        "Few-shot text classification with triplet networks, data augmentation, and curriculum learning",
        "Making pre-trained language models better few-shot learners",
        "How to train your maml",
        "Model-agnostic meta-learning for fast adaptation of deep networks",
        "Modelagnostic multi-stage loss optimization meta learning",
        "Improving language understanding by generative pre-training",
        "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Palm: Scaling language modeling with pathways",
        "Bloom: A 176b-parameter open-access multilingual language model",
        "Opt: Open pre-trained transformer language models",
        "The flan collection: Designing data and methods for effective instruction tuning",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Clinicalradiobert: Knowledge-infused few shot learning for clinical notes named entity recognition",
        "Is chatgpt a general-purpose natural language processing task solver?",
        "Is chatgpt a good translator? a preliminary study",
        "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
        "Chatgpt and other large language models are doubleedged swords",
        "Evaluating the performance of chatgpt in ophthalmology: An analysis of its successes and shortcomings",
        "Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models",
        "Collaborating with chatgpt: Considering the implications of generative artificial intelligence for journalism and media education",
        "Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning",
        "Mathematical capabilities of chatgpt",
        "Chatgpt for (finance) research: The bananarama conjecture",
        "Chatgpt: five priorities for research",
        "Is chat gpt biased against conservatives? an empirical study",
        "Breaking chatgpt with dangerous questions understanding how chatgpt prioritizes safety, context, and obedience",
        "Co-authoring with an ai? ethical dilemmas and artificial intelligence",
        "Chatgpt: The end of online exam integrity?",
        "Will chatgpt get you caught? rethinking of plagiarism detection",
        "Are chatgpt and alphacode going to replace programmers?",
        "Economics of chatgpt: A labor market view on the occupational impact of artificial intelligence",
        "Pubmed 200k rct: a dataset for sequential sentence classification in medical abstracts",
        "Language models are unsupervised multitask learners",
        "Attention is all you need",
        "Proximal policy optimization algorithms",
        "Bert: Pretraining of deep bidirectional transformers for language understanding",
        "Mask-guided bert for few shot text classification",
        "Agribert: Knowledge-infused agricultural language models for matching food and nutrition",
        "Nlp augmentation",
        "Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp",
        "Facebook fair's wmt19 news translation task submission",
        "Frustratingly easy transferability estimation",
        "Measurement of text similarity: a survey",
        "Elements of information theory",
        "Chestxraybert: A pretrained language model for chest radiology report summarization",
        "Covidsum: A linguistically enriched scibert-based summarization model for covid-19 scientific papers",
        "Hierarchical text-conditional image generation with clip latents",
        "High-resolution image synthesis with latent diffusion models",
        "Lora: Low-rank adaptation of large language models",
        "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation",
        "Theory of mind may have spontaneously emerged in large language models",
        "Coupling artificial neurons in bert and biological neurons in the human brain"
    ],
    "62b52c635aee126c0f459d22": [
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Language models are few-shot learners",
        "Noisy channel language model prompting for few-shot text classification",
        "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "Offline reinforcement learning with implicit q-learning",
        "Conservative q-learning for offline reinforcement learning",
        "Offline reinforcement learning as one big sequence modeling problem",
        "Decision transformer: Reinforcement learning via sequence modeling",
        "Mopo: Model-based offline policy optimization",
        "Morel : Model-based offline reinforcement learning",
        "Chai: A chatbot ai for task-oriented dialogue with offline reinforcement learning",
        "Human-centric dialog training via offline reinforcement learning",
        "Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control",
        "Context-aware language modeling for goal-oriented dialogue systems",
        "Learning to write with cooperative discriminators",
        "FUDGE: Controlled text generation with future discriminators",
        "Learning to decode for future success",
        "Generative discriminator guided sequence generation",
        "Sequence level training with recurrent neural networks",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "A deep reinforced model for abstractive summarization",
        "Learning to extract coherent summary via deep reinforcement learning",
        "Controllable neural story plot generation via reward shaping",
        "Trainable greedy decoding for neural machine translation",
        "Training language models to follow instructions with human feedback",
        "Learning to summarize from human feedback",
        "Fine-tuning language models from human preferences",
        "Ido Dagan, and Iryna Gurevych. Better rewards yield better summaries: Learning to summarise without references",
        "Emaq: Expected-max q-learning operator for simple yet effective offline and online rl",
        "GPT-critic: Offline reinforcement learning for end-to-end task-oriented dialogue systems",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "Personalizing dialogue agents: I have a dog, do you have pets too?",
        "Hellaswag: Can a machine really finish your sentence?",
        "Know what you don't know: Unanswerable questions for squad",
        "If beam search is the answer, what was the question?",
        "Beam decoding with controlled patience",
        "Typical decoding for natural language generation",
        "Hierarchical neural story generation",
        "The curious case of neural text degeneration",
        "Mirostat: A neural text decoding algorithm that directly controls perplexity",
        "Ctrl: A conditional transformer language model for controllable generation",
        "Discriminative adversarial search for abstractive summarization",
        "Hafez: an interactive poetry generation system",
        "Machine translation decoding beyond beam search",
        "Generating more interesting responses in neural conversation models with distributional constraints",
        "Offline rl without off-policy evaluation",
        "Advantage-weighted regression: Simple and scalable off-policy reinforcement learning",
        "Addressing function approximation error in actor-critic methods",
        "Towards automatic evaluation of dialog systems: A model-free off-policy evaluation approach",
        "Survey on evaluation methods for dialogue systems",
        "A review of evaluation techniques for social dialogue systems",
        "Wordle is np-hard",
        "Introduction to reinforcement learning",
        "Visual dialog",
        "Learning cooperative visual dialog agents with deep reinforcement learning",
        "Awac: Accelerating online reinforcement learning with offline datasets",
        "None",
        "Proximal policy optimization algorithms",
        "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "Language models are unsupervised multitask learners",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "None",
        "Learning to Forget: Continual Prediction with LSTM",
        "D4rl: Datasets for deep data-driven reinforcement learning",
        "Image Caption: Yellow and blue passenger train rounding a curve"
    ],
    "6417d04190e50fcafd83de21": [
        "All experiments are conducted on a Linux server with GPU (NVIDIA RTX A6000) and CPU (Intel i9-10980XE), using PyTorch 1.12 and Python 3.9. Datasets. We experiment on nine open graph benchmark datasets, including three citation networks",
        "Details are in Appendix A.3. Parameter settings. For SE-GSL with various backbones, we uniformly adopt two-layer GNN encoders. To avoid over-fitting, We adopt ReLU (ELU for GAT) as the activation function and apply a dropout layer with a dropout rate of 0.5. The training iteration is set to 10. The embedding dimension ? is chosen from {8",
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Spectral clustering with graph neural networks for graph pooling",
        "Certifiable robustness to graph perturbations",
        "Simple and deep graph convolutional networks",
        "Iterative deep graph learning for graph neural networks: Better and robust node embeddings",
        "Nrgnn: Learning a label noise resistant graph neural network on sparsely and noisily labeled graphs",
        "Graph random neural networks for semi-supervised learning on graphs",
        "Learning discrete structures for graph neural networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Diffusion improves graph learning",
        "Link-based classification",
        "Neural message passing for quantum chemistry",
        "Explaining explanations: An overview of interpretability of machine learning",
        "Inductive representation learning on large graphs",
        "Graphlime: Local interpretable model explanations for graph neural networks",
        "Graph structure learning for robust graph neural networks",
        "How powerful are graph neural networks",
        "Structural information and dynamical complexity of networks",
        "Three-dimensional gene map of cancer cell types: Structural entropy minimisation principle for defining tumour subtypes",
        "Decoding topologically associating domains with ultra-low resolution Hi-C data by graph structural entropy",
        "Resistance maximization principle for defending networks against virus attack",
        "Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN",
        "Adaptive graph convolutional neural networks",
        "REM: From structural entropy to community structure deception",
        "Learning to drop: Robust graph neural network via topological denoising",
        "Graph entropy guided node embedding dimension selection for graph neural networks",
        "An Information-theoretic Perspective of Hierarchical Clustering",
        "Geom-GCN: Geometric Graph Convolutional Networks",
        "Fine-Grained Event Categorization with Heterogeneous Graph Convolutional Networks",
        "Motif-Matching Based Subgraph-Level Attentional Convolutional Network for Graph Classification",
        "Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks",
        "Reinforced, Incremental and Cross-Lingual Event Detection From Social Messages",
        "Graph Structure Learning with Variational Information Bottleneck",
        "DropEdge: Towards Deep Graph Convolutional Networks on Node Classification",
        "Multi-scale attributed node embedding",
        "Twitch gamers: a dataset for evaluating proximity preserving and structural role-based node embeddings",
        "A mathematical theory of communication",
        "Adversarial Attack and Defense on Graph Data: A Survey",
        "Position-Aware Structure Learning for Graph Topology-Imbalance by Relieving Under-Reaching and Over-Squashing",
        "Social influence analysis in large-scale networks",
        "Graph attention networks",
        "Deep graph library: A graphcentric, highly-performant package for graph neural networks",
        "Graph structure estimation neural networks",
        "Amgcn: Adaptive multi-channel graph convolutional networks",
        "Semi-supervised classification with graph convolutional networks",
        "Adversarial examples for graph data: deep insights into attack and defense",
        "Structural entropy guided graph hierarchical pooling",
        "Graph information bottleneck",
        "A comprehensive survey on graph neural networks",
        "How Powerful are Graph Neural Networks",
        "Revisiting semisupervised learning with graph embeddings",
        "Minimum Entropy Principle Guided Graph Neural Networks",
        "Gnnexplainer: Generating explanations for graph neural networks",
        "Hierarchical graph representation learning with differentiable pooling",
        "Graphrnn: Generating realistic graphs with deep auto-regressive models",
        "Effective and Stable Role-based Multi-Agent Collaboration by Structural Information Principles",
        "Gnnguard: Defending graph neural networks against adversarial attacks",
        "Robust graph representation learning via neural sparsification",
        "Graph neural networks: A review of methods and applications",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Deep graph structure learning for robust representations: A survey",
        "Graph contrastive learning with adaptive augmentation",
        "Cagnn: Cluster-aware graph neural networks for unsupervised graph representation learning",
        "we adopt implementation from DGL library"
    ],
    "628d1ea25aee126c0f3e9734": [
        "Freebase: A collaboratively created graph database for structuring human knowledge",
        "Translating embeddings for modeling multi-relational data",
        "Target-aware holistic influence maximization in spatial social networks",
        "Effective deep attributed network representation learning with topology adapted smoothing",
        "Transition-based knowledge graph embedding with relational mapping properties",
        "Sse: Semantically smooth embedding for knowledge graphs",
        "Openke: An open toolkit for knowledge embedding",
        "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts",
        "Path-enhanced explainable recommendation with knowledge graphs",
        "Knowledge graph embedding via dynamic mapping matrix",
        "A survey on knowledge graphs: Representation, acquisition, and applications",
        "Simple embedding for link prediction in knowledge graphs",
        "Deep attributed network representation learning of complex coupling and interaction",
        "Learning entity and relation embeddings for knowledge graph completion",
        "Differentiating concepts and instances for knowledge graph embedding",
        "Holographic embeddings of knowledge graphs",
        "A three-way model for collective learning on multi-relational data",
        "Open-world knowledge graph completion with multiple interaction attention",
        "Datatype-aware knowledge graph representation learning in hyperbolic space",
        "Reasoning with neural tensor networks for knowledge base completion",
        "Complex embeddings for simple link prediction",
        "Adaptive knowledge subgraph ensemble for robust and trustworthy knowledge graph completion",
        "Knowledge base completion using embeddings and rules",
        "Knowledge graph embedding by translating on hyperplanes",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Representation learning of knowledge graphs with hierarchical types",
        "A survey on heterogeneous network representation learning",
        "Dynamic network embedding survey",
        "Interpretable and efficient heterogeneous graph convolutional network",
        "Heterogeneous network representation learning: A unified framework with survey and benchmark",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Transrhs: A representation learning method for knowledge graphs with relation hierarchical structure",
        "Knowledge graph embedding with hierarchical relation structure",
        "Semantic-aware heterogeneous information network embedding with incompatible meta-paths"
    ],
    "63dcdb422c26941cf00b6413": [
        "Task2vec: Task embedding for meta-learning",
        "Random search for hyper-parameter optimization",
        "Algorithms for hyper-parameter optimization",
        "Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking",
        "Language models are few-shot learners",
        "Proxylessnas: Direct neural architecture search on target task and hardware",
        "Rethinking graph neural architecture search from message-passing",
        "Diffmg: Differentiable meta graph search for heterogeneous graph neural networks",
        "Autogluon-tabular: Robust and accurate automl for structured data",
        "Graphnas: Graph neural architecture search with reinforcement learning",
        "Single path one-shot neural architecture search with uniform sampling",
        "Deep residual learning for image recognition",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Amc: Automl for model compression and acceleration on mobile devices",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Understanding isomorphism bias in graph data sets",
        "Population based training of neural networks",
        "Geon Park, Eunyoung Hyung, Jinheon Baek, and Sung Ju Hwang. Taskadaptive neural network search with meta-contrastive learning",
        "A taxonomy of global optimization methods based on response surfaces",
        "Universal statistics of fisher information in deep neural networks: Mean field approach",
        "Fisher task distance and its application in neural architecture search",
        "H2o automl: Scalable automatic machine learning",
        "Self-attention graph pooling",
        "Hyperband: A novel bandit-based approach to hyperparameter optimization",
        "One-shot graph neural architecture search with dynamic search space",
        "Darts: Differentiable architecture search",
        "Graph convolutional networks with eigenpooling",
        "The spectrum of the fisher information matrix of a singlehidden-layer neural network",
        "Learning mesh-based simulation with graph networks",
        "Efficient neural architecture search via parameters sharing",
        "Graph differentiable architecture search with structure learning",
        "Large-scale evolution of image classifiers",
        "The analytic hierarchy process-what it is and how it is used",
        "Learning to simulate complex physics with graph networks",
        "Pitfalls of graph neural network evaluation",
        "Pooling architecture search for graph classification",
        "Transfer learning with neural automl",
        "Oboe: Collaborative filtering for automl model selection",
        "Revisiting semi-supervised learning with graph embeddings",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Design space for graph neural networks",
        "Graph contrastive learning automated",
        "Taskonomy: Disentangling task transfer learning",
        "Dataset condensation with differentiable siamese augmentation",
        "Search to aggregate neighborhood for graph neural network",
        "Auto-gnn: Neural architecture search of graph neural networks",
        "Modeling polypharmacy side effects with graph convolutional networks",
        "Neural architecture search with reinforcement learning",
        "Learning transferable architectures for scalable image recognition"
    ],
    "6310233d90e50fcafdc2f5b3": [
        "Recognising nested named entities in biomedical text",
        "Leveraging type descriptions for zeroshot named entity recognition and classification",
        "Eduard S?ckinger, and Roopak Shah. 1993. Signature verification using a\" siamese\" time delay neural network. Advances in neural information processing systems",
        "A constrained latent variable model for coreference resolution",
        "Named entity recognition with bidirectional LSTM-CNNs",
        "Joint extraction of entities and relations for opinion recognition",
        "Learning a similarity metric discriminatively, with application to face verification",
        "Introduction to the bio-entity recognition task at JNLPBA",
        "CON-TaiNER: Few-shot named entity recognition via contrastive learning",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Special report: Ncbi disease corpus: A resource for disease name recognition and concept normalization",
        "Nested named entity recognition",
        "Swellshark: A generative model for biomedical named entity recognition without labeled data",
        "SpanNER: Named entity re-/recognition as span prediction",
        "Unsupervised aspect term extraction with B-LSTM &amp; CRF using automatically labelled datasets",
        "Learning dense representations for entity retrieval",
        "End-to-end retrieval in continuous space",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Convolutional neural network architectures for matching natural language sentences",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Polyencoders: Architectures and pre-training strate-gies for fast and accurate multi-sentence scoring",
        "Dense passage retrieval for open-domain question answering",
        "Nested named entity recognition revisited",
        "Genia corpus-a semantically annotated corpus for bio-textmining",
        "Neural architectures for named entity recognition",
        "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
        "A unified MRC framework for named entity recognition",
        "Bond: Bert-assisted open-domain named entity recognition with distant supervision",
        "Noisy-labeled NER with confidence estimation",
        "None",
        "Joint mention extraction and classification with mention hypergraphs",
        "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
        "End-toend sequence labeling via bi-directional LSTM-CNNs-CRF",
        "Named entity recognition with partially annotated training data",
        "Identifying gene and protein mentions in text using conditional random fields",
        "Coarseto-Fine Pre-training for Named Entity Recognition",
        "Distant supervision for relation extraction without labeled data",
        "A survey of named entity recognition and classification",
        "Association for Computational Linguistics. Aaron van den Oord, Yazhe Li, and Oriol Vinyals",
        "Instance-based learning of span representations: A case study through named entity recognition",
        "Distantly supervised named entity recognition using positiveunlabeled learning",
        "Clustype: Effective entity recognition and typing by relation phrase-based clustering",
        "Learning named entity tagger using domain-specific dictionary",
        "Nested Named Entity Recognition via Second-best Sequence Learning and Decoding",
        "Overview of biocreative ii gene mention recognition",
        "Deep exhaustive model for nested named entity recognition",
        "Neural architectures for nested NER through linearization",
        "A sequence-toset network for nested named entity recognition",
        "Attention is all you need",
        "Nested named entity recognition with span-level graphs",
        "Pyramid: A layered model for nested named entity recognition",
        "Improving named entity recognition by external context retrieving and cooperative learning",
        "Large scale image annotation: learning to rank with joint word-image embeddings",
        "Transformers: Stateof-the-art natural language processing",
        "Starspace: Embed all the things! In Proceedings of the AAAI Conference on Artificial Intelligence",
        "Scalable zero-shot entity linking with dense entity retrieval",
        "Multi-grained named entity recognition",
        "A unified generative framework for various NER subtasks",
        "LinkBERT: Pretraining language models with document links",
        "Learning discriminative projections for text similarity measures",
        "Named entity recognition as dependency parsing",
        "Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2021a. Knowledge-rich self-supervised entity linking",
        "De-bias for generative extraction in unified NER task",
        "2021b. De-biasing distantly supervised named entity recognition via causal intervention",
        "Named entity recognition using an HMM-based chunk tagger",
        "Distantly supervised named entity recognition via confidence-based multi-class positive and unlabeled learning"
    ],
    "6389d6fe90e50fcafdffc634": [
        "Hitting the memory wall: implications of the obvious",
        "Bingo spatial data prefetcher",
        "Best-offset hardware prefetching",
        "Perceptron-based prefetch filtering",
        "Pangloss: a novel markov chain prefetcher",
        "Efficient metadata management for irregular data prefetching",
        "Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning",
        "Temporal prefetching without the off-chip metadata",
        "Spatial memory streaming",
        "Path confidence based lookahead prefetching",
        "Accurately and maximally prefetching spatial data access patterns with bingo",
        "Bump: Bulk memory access prediction and streaming",
        "Dspatch: Dual spatial pattern prefetcher",
        "Not quite my temp: Matching prefetches to memory access times",
        "Spec cpu",
        "Spec cpu",
        "Parsec",
        "Ligra: A lightweight graph processing framework for shared memory",
        "Sandbox prefetching: Safe run-time evaluation of aggressive prefetchers",
        "Mcf homepage",
        "Cacti 6.0: A tool to model large caches",
        "Champsim simulator",
        "Enhancing signature path prefetching with perceptron prefetch filtering",
        "The 2nd data prefetching championship",
        "The 3rd data prefetching championship",
        "Cloudsuite traces",
        "Jedec-ddr4",
        "Jedec-ddr5",
        "Hbm specification",
        "Matryoshka: A Coalesced Delta Sequence Prefetcher",
        "Sequential program prefetching in memory hierarchies",
        "Effective hardware based data prefetching for high-performance processors",
        "Efficiently prefetching complex address patterns",
        "Data cache prefetching using a global history buffer",
        "Linearizing irregular memory accesses for improved correlated prefetching"
    ],
    "63881b9290e50fcafd3db3f8": [
        "Dynamic onloading of deep neural networks from cloud to device",
        "Fusedlayer cnn accelerators",
        "NUCLEO-F767ZI",
        "Neural network architectures for deploying tinyml applications on commodity microcontrollers",
        "Direct neural architecture search on target task and hardware",
        "Tvm: end-to-end optimization stack for deep learning",
        "Visual wake words dataset",
        "TensorFlow Lite Micro: Embedded machine learning on TinyML systems",
        "Imagenet: A large-scale hierarchical image database",
        "Improving strong-scaling of cnn training by exploiting finer-grained parallelism",
        "Channel and filter parallelism for large-scale cnn training",
        "SpArSe: Sparse architecture search for CNNs on resource-constrained microcontrollers",
        "Grand View Research. Microcontroller market size, share &amp; trends report",
        "Searching for MobileNet-v3",
        "Data movement is all you need: A case study on optimizing transformers",
        "Quantization and training of neural networks for efficient integerarithmetic-only inference",
        "Efficient neural network kernels for ARM Cortex-M CPUs",
        "Neural networks on microcontrollers: saving memory at inference via operator reordering",
        "Differentiable network pruning for microcontrollers",
        "Constrained neural architecture search for microcontrollers",
        "Tiny deep learning on IoT devices",
        "Memoryefficient patch-based inference for tiny deep learning",
        "CoopNet: Cooperative convolutional neural network for low-power MCUs",
        "Imagenet scale deep learning on microcontrollers",
        "Rnnpool: efficient non-linear pooling for ram constrained inference",
        "MobileNet V2: Inverted residuals and linear bottlenecks",
        "Deep learning on microcontrollers: a study on deployment costs and challenges",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "Deep residual learning for smallfootprint keyword spotting",
        "Speech commands: A dataset for limited-vocabulary speech recognition",
        "TinyML: Machine learning with TensorFlow Lite on Arduino and ultra-low-power microcontrollers",
        "Etinynet: Extremely tiny network for tinyml",
        "Training of deep learning pipelines on memory-constrained gpus via segmented fused-tiled execution",
        "Properties of ImageNet models. Model PMU Size MACs Acc",
        "MCUNet-v2 M4 , ? 273 kB 1010 kB 119 M 64",
        "MB-v2 (mod.) r172 ? 128 kB 999 kB 110 M 64",
        "MB-v2 (mod.) r256 ? 287 kB 1994 kB 255 M 69.8% MCUNet-v1-S ? 333 kB 748 kB 67",
        "MCUNet-v1-L ? 422 kB 1757 kB 126 M 67",
        "MCUNet-v1-L p 192 kB 1757 kB 126 M 67",
        "MCUNet-v1-L ? 128 kB 994 kB 88",
        "EfficientNet-B0 ? 768 kB 3987 kB 187 M 69",
        "EfficientNet-B0 p 308 kB 3987 kB 187 M 69",
        "EfficientNet-B0 ? 128 kB 1999 kB 118 M 65",
        "EfficientNet-B0 ? 128 kB 1999 kB 118 M 65",
        "123 kB 1990 kB 18 M 50",
        "Properties of Visual Wake Words models. Model PMU Size MACs Acc. MicroNets VWW-1 ? 200 kB 616 kB 71",
        "MicroNets VWW-2 ? 27.9 kB 103 kB 3.38 M 83.5% MCUNet r144 ? 270 kB 657 kB 55",
        "MCUNet 5FPS ? 96.0 kB 455 kB 12.5 M 86",
        "MCUNet-v2 , ? 268 kB unk",
        "MCUNet-v2 , ? 89.6 kB unk",
        "224 ? 223 kB 1 MB 209 M 91",
        "MB-v2 (mod.) r160 ? 114 kB 1 MB 106 M 89",
        "MB-v2 (mod.) r80 ? 27.6 kB 128 kB 11",
        "None",
        "None",
        "None",
        "None",
        "None",
        "None",
        "MB-v2 ? 198 kB 606 kB 58",
        "None",
        "Properties of Speech Commands models. Model PMU Size MACs Acc. MicroNets-KWS-L ? 170 kB 512",
        "1 kB 117 kB 15.6 M 95",
        "None",
        "MicroNets-L-Base p 69 kB 582 kB 74.3 M 96",
        "kB 140 kB 9.83 M 95",
        "None"
    ],
    "640fe64790e50fcafd9e2811": [
        "Unsupervised label noise modeling and loss correction",
        "Understanding and utilizing deep neural networks trained with noisy labels",
        "A simple framework for contrastive learning of visual representations",
        "Exploring simple Siamese representation learning",
        "Maximum likelihood from incomplete data via the EM algorithm",
        "ImageNet: A large-scale hierarchical image database",
        "Robust loss functions under label noise for deep neural networks",
        "Training deep neural-networks using a noise adaptation layer",
        "Semi-supervised learning by entropy minimization",
        "Bootstrap your own latent: A new approach to self-supervised learning",
        "Co-teaching: Robust training of deep neural networks with extremely noisy labels",
        "Momentum contrast for unsupervised visual representation learning",
        "Deep residual learning for image recognition",
        "Identity mappings in deep residual networks",
        "Beyond synthetic noise: Deep learning on controlled noisy labels",
        "MentorNet: Learning data-driven curriculum for very deep neural networks on corrupted labels",
        "Supervised contrastive learning",
        "Fine samples for learning with noisy labels",
        "Learning multiple layers of features from tiny images",
        "Dividemix: Learning with noisy labels as semi-supervised learning",
        "Learning from noisy data with robust representation learning",
        "Mopro: Webly supervised learning with momentum prototypes",
        "Selective-supervised contrastive learning with noisy labels",
        "Webvision database: Visual learning and understanding from web data",
        "Early-learning regularization prevents memorization of noisy labels",
        "Dimensionality-driven learning with noisy labels",
        "Decoupling \"when to update\" from \"how to update",
        "Representation learning with contrastive predictive coding",
        "Multi-objective interpolation training for robustness to label noise",
        "Making deep neural networks robust to label noise: A loss correction approach",
        "Training deep neural networks on noisy labels with bootstrapping",
        "Deep expectation of real and apparent age from a single image without facial landmarks",
        "A mathematical theory of communication",
        "Joint optimization framework for learning with noisy labels",
        "Learning from noisy labels by regularized estimation of annotator confusion",
        "IMAE for noise-robust learning: Mean absolute error does not treat examples equally and gradient magnitude's variance matters",
        "Symmetric cross entropy for robust learning with noisy labels",
        "Unsupervised feature learning via non-parametric instance discrimination",
        "Are anchor points really indispensable in label-noise learning?",
        "Learning from massive noisy labeled data for image classification",
        "L DMI: A novel information-theoretic loss function for training deep nets robust to label noise",
        "Learning from multiple annotators with varying expertise",
        "Probabilistic end-to-end noise correction for learning with noisy labels",
        "How does disagreement help generalization against label corruption",
        "Learning with biased complementary labels",
        "mixup: Beyond empirical risk minimization",
        "Generalized cross entropy loss for training deep neural networks with noisy labels",
        "Contrast to divide: Selfsupervised pre-training for learning with noisy labels"
    ],
    "63d9d87390e50fcafd57e29e": [
        "The transitive reduction of a directed graph",
        "Towards efficient model compression via learned global ranking",
        "Imagenet: A large-scale hierarchical image database",
        "Centripetal sgd for pruning very deep convolutional networks with complicated structure",
        "Approximated oracle filter pruning for destructive cnn width optimization",
        "Auto-balanced filter pruning for efficient convolutional neural networks",
        "Resrep: Lossless cnn pruning via decoupling remembering and forgetting",
        "Learning to prune deep neural networks via layer-wise optimal brain surgeon",
        "Network pruning via transformable architecture search",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Network pruning via performance maximization",
        "Long short-term memory. Supervised sequence labelling with recurrent neural networks",
        "Advances in neural information processing systems",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",
        "Learning both weights and connections for efficient neural network",
        "Deep residual learning for image recognition",
        "Soft filter pruning for accelerating deep convolutional neural networks",
        "Amc: Automl for model compression and acceleration on mobile devices",
        "Filter pruning via geometric median for deep convolutional neural networks acceleration",
        "Channel pruning for accelerating very deep neural networks",
        "Distilling the knowledge in a neural network",
        "Densely connected convolutional networks",
        "Data-driven sparse structure selection for deep neural networks",
        "Learning multiple layers of features from tiny images",
        "Layer-adaptive sparsity for the magnitude-based pruning",
        "A signal propagation perspective for pruning neural networks at initialization",
        "Pruning filters for efficient convnets",
        "Pruning and quantization for deep neural network acceleration: A survey",
        "Hrank: Filter pruning using high-rank feature map",
        "Group fisher pruning for practical network compression",
        "Learning efficient convolutional networks through network slimming",
        "Metapruning: Meta learning for automatic neural network channel pruning",
        "A gradient flow framework for analyzing network pruning",
        "Neural network pruning with residual-connections and limited-data",
        "Thinet: A filter level pruning method for deep neural network compression",
        "Resnet can be pruned 60?: Introducing network purification and unused path removal (p-rm) after weight pruning",
        "Torchvision the machine-vision package of torch",
        "Importance estimation for neural network pruning",
        "Logarithmic pruning is all you need",
        "Lookahead: a far-sighted alternative of magnitude-based pruning",
        "Collaborative channel pruning for deep networks",
        "Designing network design spaces",
        "Comparing rewinding and fine-tuning in neural network pruning",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Movement pruning: Adaptive sparsity by fine-tuning",
        "Parameterized structured pruning for deep neural networks",
        "Very deep convolutional networks for large-scale image recognition",
        "Cp-vit: Cascade vision transformer pruning via progressive sparsity prediction",
        "Understanding lstm-a tutorial into long short-term memory recurrent neural networks",
        "Going deeper with convolutions",
        "Graph attention networks",
        "Eigendamage: Structured pruning in the kroneckerfactored eigenbasis",
        "Neural pruning via growing regularization",
        "Accelerate cnns from three dimensions: a comprehensive pruning framework",
        "Dynamic graph cnn for learning on point clouds",
        "Quantized convolutional neural networks for mobile devices",
        "3d shapenets: A deep representation for volumetric shapes",
        "Aggregated residual transformations for deep neural networks",
        "Netadapt: Platform-aware neural network adaptation for mobile applications",
        "Joint-detnas: upgrade your detector with nas, pruning and dynamic distillation",
        "Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers",
        "Gate decorator: Global filter pruning method for accelerating deep convolutional neural networks",
        "Slimmable neural networks for edge devices",
        "Autoslim: Towards oneshot architecture search for channel numbers",
        "Nisp: Pruning networks using neuron importance score propagation",
        "Character-level convolutional networks for text classification",
        "Aligned structured sparsity learning for efficient image superresolution",
        "Neuron-level structured pruning using polarization regularizer. Advances in neural information processing systems"
    ],
    "6424fe3390e50fcafd78b58e": [
        "Stochastic blockmodel approximation of a graphon: Theory and consistent estimation",
        "Group formation in large social networks: membership, growth, and evolution",
        "Network science. Annu. rev. inf. sci. technol",
        "Classification and estimation in the Stochastic Blockmodel based on the empirical degrees",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Learning Structural Node Embeddings via Diffusion Wavelets",
        "Centrality in social networks: Conceptual clarification. Social network: critical concepts in sociology",
        "node2vec: Scalable Feature Learning for Networks",
        "GraphCL: Contrastive Self-Supervised Learning of Graph Representations",
        "Adaptive Transfer Learning on Graph Neural Networks. SIGKDD",
        "G-Mixup: Graph Data Augmentation for Graph Classification",
        "Contrastive multi-view representation learning on graphs",
        "Momentum contrast for unsupervised visual representation learning",
        "GraphMAE: Self-Supervised Masked Graph Autoencoders",
        "Strategies for pre-training graph neural networks",
        "GPT-GNN: Generative Pre-Training of Graph Neural Networks",
        "Pre-Training Graph Neural Networks for Generic Structural Feature Extraction",
        "Mean clustering coefficients: the role of isolated nodes and leafs on clustering measures for small-world networks",
        "Variational Graph Auto-Encoders",
        "Transferability of Spectral Graph Convolutional Neural Networks",
        "Pairwise Half-graph Discrimination: A Simple Graph-level Self-supervised Strategy for Pre-training Graph Neural Networks",
        "Let Invariant Rationale Discovery Inspire Graph Contrastive Learning",
        "Large networks and graph limits",
        "Limits of dense graph sequences",
        "Learning to Pre-train Graph Neural Networks",
        "Classification and analysis of multivariate observations",
        "Network motifs: simple building blocks of complex networks",
        "2017. graph2vec: Learning Distributed Representations of Graphs",
        "Mixing patterns in networks",
        "DeepWalk: online learning of social representations. SIGKDD",
        "Gromov-wasserstein averaging of kernel and distance matrices",
        "GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training",
        "Learning Node Representations from Structural Identity",
        "A Scalable Permutation Approach Reveals Replication and Preservation Patterns of Network Modules in Large Datasets",
        "Multi-scale Attributed Node Embedding",
        "Transferability Properties of Graph Neural Networks",
        "ZINC 15 -Ligand Discovery for Everyone",
        "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization",
        "Multi-Stage Self-Supervised Learning for Graph Convolutional Networks",
        "MoCL: Data-driven Molecular Fingerprint via Knowledge-aware Contrastive Learning from Molecular Graph",
        "LINE: Large-scale Information Network Embedding",
        "None",
        "Social network analysis: Methods and applications",
        "Semi-supervised classification with graph convolutional networks",
        "MoleculeNet: a benchmark for molecular machine learning",
        "Random walks: A review of algorithms and applications",
        "Towards Effective and Generalizable Fine-tuning for Pre-trained Molecular Graph Models",
        "Learning Graphon Autoencoders for Generative Graph Modeling",
        "How Powerful are Graph Neural Networks?",
        "Defining and evaluating network communities based on ground-truth",
        "Graph contrastive learning automated",
        "Graph contrastive learning with augmentations",
        "When Does Self-Supervision Help Graph Convolutional Networks?",
        "OAG: Toward Linking Large-scale Heterogeneous Entity Graphs",
        "ProNE: Fast and Scalable Network Representation Learning",
        "Fine-Tuning Graph Neural Networks via Graph Topology induced Optimal Transport",
        "Motif-based Graph Self-Supervised Learning for Molecular Property Prediction",
        "Motif-based graph self-supervised learning for molecular property prediction",
        "Data Augmentation for Graph Neural Networks",
        "Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization",
        "Deep Graph Contrastive Representation Learning"
    ],
    "62bab8f95aee126c0f6afca5": [
        "Numerical analysis. Cengage learning",
        "MODALS: Modality-agnostic automated data augmentation in the latent space",
        "Dataset augmentation in feature space",
        "Deep wiener deconvolution: Wiener meets deep learning for image deblurring",
        "Combining neural networks with personalized pagerank for classification on graphs",
        "Understanding the difficulty of training deep feedforward neural networks",
        "node2vec: Scalable feature learning for networks",
        "Contrastive multi-view representation learning on graphs",
        "Strategies for pre-training graph neural networks",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Latent adversarial training of graph convolutional networks",
        "Adam: A method for stochastic optimization",
        "Variational graph auto-encoders",
        "Semi-supervised classification with graph convolutional networks",
        "Diffusion improves graph learning",
        "A closer look at feature space data augmentation for few-shot intent classification",
        "Deconvolutional networks on graph data",
        "Specae: Spectral autoencoder for anomaly detection in attributed networks",
        "Ping Jia, and Jane You. Data augmentation via latent space interpolation for image classification",
        "Graph self-supervised learning: A survey",
        "Tudataset: A collection of benchmark datasets for learning with graphs",
        "Learning distributed representations of graphs",
        "Barycentric-remez algorithms for best polynomial approximation in the chebfun system",
        "Symmetric graph convolutional autoencoder for unsupervised graph representation learning",
        "Graph Representation Learning via Graphical Mutual Information Maximization",
        "Deepwalk: Online learning of social representations",
        "Stationary signal processing on graphs",
        "Collective classification in network data",
        "Pitfalls of graph neural network evaluation",
        "Weisfeiler-lehman graph kernels",
        "Fast non-blind deconvolution via regularized residual networks with long/short skip-connections",
        "Disentangling adversarial robustness and generalization",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Deep feature interpolation for image content changes",
        "Graph Attention Networks",
        "Deep graph infomax. In ICLR",
        "Manifold mixup: Better representations by interpolating hidden states",
        "Mgae: Marginalized graph autoencoder for graph clustering",
        "Augmentation-free graph contrastive learning",
        "Extrapolation, Interpolation, and Smoothing of Stationary Time Series",
        "Simplifying graph convolutional networks",
        "Self-supervised learning of graph neural networks: A unified review",
        "Infogcl: Information-aware graph contrastive learning",
        "How powerful are graph neural networks?",
        "Deep graph kernels",
        "Enhancing geometric deep learning via graph filter deconvolution",
        "Graph contrastive learning automated",
        "Graph contrastive learning with augmentations",
        "When does self-supervision help graph convolutional networks",
        "Graph deconvolutional networks",
        "Deep Graph Contrastive Representation Learning",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "6419208e90e50fcafda928aa": [
        "On the bottleneck of graph neural networks and its practical implications",
        "Neural sheaf diffusion: A topological perspective on heterophily and oversmoothing in gnns",
        "Geometric deep learning: Grids, groups, graphs, geodesics, and gauges",
        "Spectral networks and locally connected networks on graphs",
        "A note on over-smoothing for graph neural networks",
        "GRAND: graph neural diffusion",
        "Beltrami flow and neural diffusion on graphs",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Simple and deep graph convolutional networks",
        "Neural ordinary differential equations",
        "Expander graph propagation",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Traffic Prediction with Graph Neural Networks in Google Maps",
        "Graph neural networks as gradient flows",
        "Pde-gcn: Novel architectures for graph neural networks motivated by partial differential equations",
        "A general framework for adaptive processing of data structures",
        "Utilizing graph machine learning within drug discovery and development",
        "Neural message passing for quantum chemistry",
        "Learning task-dependent distributed representations by backpropagation through structure",
        "A new model for learning in graph domains",
        "Inductive representation learning on large graphs",
        "Bayesian graph neural networks with adaptive connection sampling",
        "Deep residual learning for image recognition",
        "Not too little, not too much: a theoretical analysis of graph (over) smoothing",
        "Semi-supervised classification with graph convolutional networks",
        "Deepgcns: Can gcns go as deep as cnns?",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Towards deeper graph neural networks",
        "Automating the construction of internet portals with machine learning",
        "Geometric deep learning on graphs and manifolds using mixture model cnns",
        "Revisiting graph neural networks: all we have is low pass filters",
        "Graph neural networks exponentially lose expressive power for node classification",
        "Geom-gcn: Geometric graph convolutional networks",
        "Graph neural ordinary differential equations",
        "Towards deep graph convolutional networks on node classification",
        "Graph-coupled oscillator networks",
        "Gradient gating for deep multi-rate learning on graphs",
        "The graph neural network model",
        "Graph neural networks in particle physics",
        "Encoding labeled graphs by labeling RAAM",
        "Supervised neural networks for the classification of structures",
        "Understanding over-squashing and bottlenecks on graphs via curvature",
        "Graph attention networks",
        "Acmp: Allen-cahn message passing for graph neural networks with particle phase transition",
        "Continuous graph neural networks",
        "Representation learning on graphs with jumping knowledge networks",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Graph neural networks: a review of methods and applications",
        "Towards deeper graph neural networks with differentiable group normalization",
        "Dirichlet energy constrained learning for deep graph neural networks",
        "Understanding and resolving performance degradation in deep graph convolutional networks",
        "Beyond homophily in graph neural networks: Current limitations and effective designs"
    ],
    "63dc7b5290e50fcafdc836c3": [
        "The anatomy of a large-scale hypertextual web search engine",
        "Stochastic training of graph convolutional networks with variance reduction",
        "FastGCN: Fast learning with graph convolutional networks via importance sampling",
        "Simple and deep graph convolutional networks",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Minimal variance sampling with provable guarantees for fast training of graph neural networks",
        "Weighted graph cuts without eigenvectors a multilevel approach",
        "Graph neural networks for social recommendation",
        "Fast graph representation learning with PyTorch Geometric",
        "Gnnautoscale: Scalable and expressive graph neural networks via historical embeddings",
        "Openpnm: A pore network modeling package",
        "Implicit graph neural networks",
        "Inductive representation learning on large graphs",
        "Graph representation learning",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Adaptive sampling towards fast graph representation learning",
        "A fast and high quality multilevel scheme for partitioning irregular graphs",
        "Molecular graph convolutions: Moving beyond fingerprints",
        "Semi-supervised classification with graph convolutional networks",
        "Deep Learning on Graphs",
        "Distributed representations of words and phrases and their compositionality",
        "An iterative global optimization algorithm for potential energy minimization",
        "Pytorch: An imperative style, high-performance deep learning library",
        "GloVe: Global vectors for word representation",
        "Sign: Scalable inception graph neural networks",
        "Microsoft academic graph: When experts are not enough",
        "Revisiting semi-supervised learning with graph embeddings",
        "GraphFM: Improving large-scale GNN training via feature momentum",
        "Graphsaint: Graph sampling based inductive learning method",
        "Decoupling the depth and scope of graph neural networks",
        "Layerdependent importance sampling for training deep and large graph convolutional networks"
    ],
    "64363413cf18aa11d8b55a06": [
        "On the bottleneck of graph neural networks and its practical implications",
        "Local graph partitioning using pagerank vectors",
        "Scaling graph neural networks with approximate pagerank",
        "Language models are few-shot learners",
        "Emerging properties in self-supervised vision transformers",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction",
        "Adaptive graph encoder for attributed graph embedding",
        "Graph random neural networks for semi-supervised learning on graphs",
        "Sign: Scalable inception graph neural networks",
        "Bootstrap your own latent: A new approach to self-supervised learning",
        "Inductive representation learning on large graphs",
        "Contrastive multi-view representation learning on graphs",
        "Masked autoencoders are scalable vision learners",
        "Momentum contrast for unsupervised visual representation learning",
        "Autoencoders, Minimum Description Length and Helmholtz Free Energy",
        "GraphMAE: Self-Supervised Masked Graph Autoencoders",
        "Ogb-lsc: A large-scale challenge for machine learning on graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Strategies for pre-training graph neural networks",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "Think locally, act locally: Detection of small, mediumsized, and large communities in large networks",
        "Variational graph auto-encoders",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters",
        "Deepgcns: Can gcns go as deep as cnns?",
        "Continuous control with deep reinforcement learning",
        "Selfkg: self-supervised entity alignment in knowledge graphs",
        "Self-supervised learning: Generative or contrastive",
        "Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries",
        "A unified view on graph neural networks as graph signal denoising",
        "Adversarially regularized graph autoencoder for graph embedding",
        "Symmetric graph convolutional autoencoder for unsupervised graph representation learning",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "A local clustering algorithm for massive graphs and its application to nearly linear time graph partitioning",
        "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization",
        "Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction",
        "Large-Scale Representation Learning on Graphs via Bootstrapping",
        "Augmentations in graph contrastive learning: Current methodological flaws &amp; towards better practices",
        "Graph Attention Networks",
        "Deep Graph Infomax. In ICLR",
        "Mgae: Marginalized graph autoencoder for graph clustering",
        "Augmentation-Free Graph Contrastive Learning",
        "Masked feature prediction for self-supervised visual pretraining",
        "Simplifying graph convolutional networks",
        "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation",
        "Infogcl: Information-aware graph contrastive learning",
        "Revisiting semisupervised learning with graph embeddings",
        "Local higher-order graph clustering",
        "Graph contrastive learning with augmentations",
        "Decoupling the depth and scope of graph neural networks",
        "Graphsaint: Graph sampling based inductive learning method",
        "From canonical correlation analysis to self-supervised graph neural networks",
        "Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination",
        "ibot: Image bert pre-training with online tokenizer",
        "Deep graph contrastive representation learning",
        "Graph contrastive learning with adaptive augmentation",
        "A local algorithm for finding well-connected clusters",
        "Layer-dependent importance sampling for training deep and large graph convolutional networks"
    ],
    "642525e790e50fcafdfdd202": [
        "Accelerate Fast Math with Intel? oneAPI Math Kernel Library",
        "Basic Linear Algebra on NVIDIA GPUs",
        "None",
        "Googles Operations Research Tools",
        "None",
        "Inside Apple's new A11 Bionic processor",
        "Intel Deep Learning Boost -Intel AI",
        "NVIDIA A100 TENSOR CORE GPU",
        "NVIDIA cuDNN",
        "NVIDIA T4 Tensor Core GPU for AI inference",
        "None",
        "NVIDIA V100 TENSOR CORE GPU",
        "oneAPI Deep Neural Network Library (oneDNN)",
        "OpenBLAS: An optimized BLAS library",
        "Poplar Graph Framework Software",
        "Programming Tensor Cores in CUDA 9",
        "Learning to optimize halide with tree search and random programs",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "Random Search for Hyper-Parameter Optimization",
        "Rtx on-the nvidia turing gpu",
        "VIBNN: Hardware Acceleration of Bayesian Neural Networks",
        "Marvel: A Data-centric Compiler for DNN Operators on Spatial Accelerators. arXiv: Distributed, Parallel, and Cluster Computing",
        "DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning",
        "XGBoost: A Scalable Tree Boosting System",
        "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning",
        "Learning to optimize tensor programs",
        "DianNao Family: Energy-Efficient Hardware Accelerators for Machine Learning",
        "DaDianNao: A Machine-Learning Supercomputer",
        "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks",
        "PRIME: A Novel Processing-in-Memory Architecture for Neural Network Computation in ReRAM-Based Main Memory",
        "CONSTRAINT-HANDLING USING AN EVOLU-TIONARY MULTIOBJECTIVE OPTIMIZATION TECHNIQUE",
        "Constraint-handling techniques used with evolutionary algorithms",
        "Optimizing Convolutions on Dataflow Accelerators. ICASSP 2020 -2020 IEEE International Conference on Acoustics, Speech and Signal Processing",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "ShiDianNao: Shifting Vision Processing Closer to the Sensor",
        "TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory",
        "Genetic algorithms in search, optimization, and machine learning",
        "Deep Residual Learning for Image Recognition",
        "Mind mappings: enabling efficient algorithmaccelerator mapping space search",
        "Intel Nervana Neural Network Processor-T (NNP-T) Fused Floating Point Many-Term Dot Product",
        "Constrained Optimization Via Genetic Algorithms",
        "Dissecting the graphcore ipu architecture via microbenchmarking",
        "On the use of non-stationary penalty functions to solve nonlinear constrained optimization problems with GA's",
        "In-Datacenter Performance Analysis of a Tensor Processing Unit",
        "Evolutionary Algorithms, Homomorphous Mappings, and Constrained Parameter Optimization",
        "A Review of Constraint-Handling Techniques for Evolution Strategies",
        "Differentiable programming for image processing and deep learning in Halide",
        "PuDianNao : A Polyvalent Machine Learning Accelerator",
        "Cambricon: An instruction set architecture for neural networks",
        "Optimizing CNN Model Inference on CPUs",
        "SAT-decoding in evolutionary algorithms for discrete constrained optimization problems",
        "Constrained Optimization via Multiobjective Evolutionary Algorithms",
        "Constraint-handling in nature-inspired numerical optimization: Past, present and future",
        "Genocop III: a co-evolutionary algorithm for numerical optimization problems with nonlinear constraints. Proceedings of",
        "A Hardware-Software Blueprint for Flexible Deep Learning Specialization",
        "Automatically scheduling halide image processing pipelines",
        "SpinalFlow: An Architecture and Dataflow Tailored for Spiking Neural Networks",
        "Using a genetic algorithm to optimize problems with feasibility constraints",
        "Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines",
        "An Adaptive Penalty Approach for Constrained Genetic-Algorithm Optimization",
        "Infeasibility Driven Evolutionary Algorithm for Constrained Optimization",
        "Stochastic ranking for constrained evolutionary optimization",
        "Evolution and optimum seeking",
        "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "Rethinking the Inception Architecture for Computer Vision",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "UNIT: Unifying Tensorized Instruction Compilation",
        "Adaptive evolutionary planner/navigator for mobile robots",
        "Penalty Function Methods for Constrained Optimization with Genetic Algorithms",
        "AKG: automatic kernel generation for neural processing units using polyhedral transformations",
        "Ansor: Generating High-performance Tensor Programs for Deep Learning",
        "AMOS: Enabling Automatic Mapping for Tensor Computations On Spatial Accelerators with Hardware Abstraction",
        "Flex-Tensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System"
    ],
    "63aaa48a90e50fcafd27b0fa": [
        "Object detection with deep learning: A review",
        "Pre-trained models for natural language processing: A survey",
        "Speech recognition using deep neural networks: A systematic review",
        "NVDLA deep learning accelerator",
        "In-datacenter performance analysis of a tensor processing unit",
        "STICKER: An energy-efficient multi-sparsity compatible accelerator for convolutional neural networks in 65-nm CMOS",
        "Automated systolic array architecture synthesis for high throughput CNN inference on FPGAs",
        "Systolicarray deep-learning acceleration exploring pattern-indexed coordinateassisted sparsity for real-time on-device speech processing",
        "Efficient scheduling of irregular network structures on CNN accelerators",
        "SMAUG: End-to-end full-stack simulation infrastructure for deep learning workloads",
        "TVM: An automated end-to-end optimizing compiler for deep learning",
        "PyTorch: An imperative style, high-performance deep learning library",
        "TensorFlow: A system for large-scale machine learning",
        "Keras",
        "An efficient hardware design for accelerating sparse CNNs with NAS-based models",
        "ShiDianNao: Shifting vision processing closer to the sensor",
        "SAIL: A deep-learning-based system for automatic gait assessment from TUG videos",
        "Performance evaluation of deep neural networks applied to speech recognition: RNN, LSTM and GRU",
        "An overview of image caption generation methods",
        "ONNX github repository",
        "Multi-bank on-chip memory management techniques for CNN accelerators",
        "ROMANet: Fine-grained reuse-driven off-chip memory access management and data organization for deep neural network accelerators",
        "WaveNet: A generative model for raw audio",
        "LPCNet: Improving neural speech synthesis through linear prediction",
        "A hybrid DSP/deep learning approach to real-time full-band speech enhancement",
        "An 8.93 TOPS/W LSTM recurrent neural network accelerator featuring hierarchical coarse-grain sparsity for on-device speech recognition",
        "Timeloop: A systematic approach to DNN accelerator evaluation",
        "DORY: Automatic end-to-end deployment of real-world DNNs on low-cost IoT MCUs",
        "TensorFlow lite micro: Embedded machine learning on TinyML systems",
        "MAESTRO: A data-centric approach to understand reuse, performance, and hardware cost of DNN mappings"
    ],
    "6427029c90e50fcafd5d6bd8": [
        "Private communication with Intel",
        "Understanding training efficiency of deep learning recommendation models at scale",
        "NetDIMM: Low-latency near-memory network interface architecture",
        "Data direct I/O characterization for future I/O system exploration",
        "Chainreaction: A causal+ consistent datastore based on chain replication",
        "BBB: Simplifying persistent programming using battery-backed buffers",
        "Remote memory calls",
        "FAWN: A fast array of wimpy nodes",
        "FAFNIR: Accelerating sparse gathering by using efficient near-memory intelligent reduction",
        "Elastic Fabric Adapter -Run HPC and ML applications at scale",
        "Introducing new product innovations for SAP HANA, expanded AI collaboration with SAP and more",
        "CORFU: A shared log design for flash clusters",
        "Attack of the killer microseconds",
        "The case for energy-proportional computing",
        "IX: A protected dataplane operating system for high throughput and low latency",
        "From FLOPS to IOPS: The new bottlenecks of scientific computing",
        "Achieving 10Gbps line-rate key-value stores with FPGAs",
        "Available first on Google Cloud: Intel Optane DC persistent memory",
        "PRISM: Rethinking the RDMA interface for distributed systems",
        "Understanding host network stack overheads",
        "Rethinking software runtimes for disaggregated memory",
        "Windows Azure storage: A highly available cloud storage service with strong consistency",
        "Accelerating database analytic query workloads using an associative processor",
        "A cloud-scale acceleration architecture",
        "CCIX",
        "Improving recommendation quality in Google Drive",
        "Fast and general distributed transactions using RDMA and HTM",
        "Scalable RDMA RPC on reliable connection with efficient resource sharing",
        "In-depth analysis on microarchitectures of modern heterogeneous CPU-FPGA platforms",
        "Enzian: An open, general, CPU/FPGA platform for systems software research",
        "Intel to Launch Next-Gen Sapphire Rapids Xeon with High Bandwidth Memory",
        "Using a PCIe slot to install DRAM: New Samsung CXL.mem expansion module",
        "Compute express link (CXL)",
        "Manycore network interfaces for in-memory rack-scale computing",
        "RPCValet: NI-driven tail-aware balancing of ?s-scale RPCs",
        "Network hardware-accelerated consensus",
        "P4xos: Consensus as a network service",
        "A new golden age in computer architecture: Empowering the machine-learning revolution",
        "FaRM: Fast remote memory",
        "Bandana: Using non-volatile memory for storing deep learning models",
        "FlexDriver: A network driver for your accelerator",
        "FPGA for aggregate processing: The good, the bad, and the ugly",
        "HyperDex: A distributed, searchable key-value store",
        "RocksDB: A persistent key-value store for fast storage environments",
        "Unlocking energy",
        "Make the most out of last level cache in Intel processors",
        "Reexamining direct cache access to optimize I/O intensive applications for multihundred-gigabit networks",
        "Network interface design for low latency request-response protocols",
        "When cloud storage meets RDMA",
        "The Google file system",
        "Methods and apparatus for implementing PCI express lightweight notification protocols in a CPU/memory complex",
        "Software data planes: You can't always spin to win",
        "Architectural support for server-side PHP processing",
        "Direct access, High-Performance memory disaggregation with DirectCXL",
        "RDMA over commodity Ethernet at scale",
        "Clio: A hardwaresoftware co-designed disaggregated memory system",
        "Sonata: Query-driven streaming network telemetry",
        "DeepRecSys: A system for optimizing end-to-end at-scale neural recommendation inference",
        "The architectural implications of Facebook's DNN-based personalized recommendation",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Centaur: A chiplet-based, hybrid sparse-dense accelerator for personalized recommendations",
        "The nanoPU: A nanosecond network stack for datacenters",
        "Data plane development kit (DPDK)",
        "eADR: New opportunities for persistent memory applications",
        "Instruction set reference",
        "Intel Arria 10 GX 1150 FPGA",
        "Intel Optane Persistent Memory",
        "Intel Stratix 10 DX FPGAs",
        "Intel Xeon Gold 6138P Processor",
        "Intel? data direct I/O (DDIO)",
        "mTCP: A highly scalable user-level TCP stack for multicore systems",
        "NetChain: Scale-free sub-RTT coordination",
        "NetCache: Balancing key-value stores with fast in-network caching",
        "Challenges and solutions for fast remote persistent memory access",
        "Datacenter RPCs can be general and fast",
        "Using RDMA efficiently for key-value services",
        "Design guidelines for high performance RDMA systems",
        "FaSST: Fast, scalable and simple distributed transactions with two-sided (RDMA) datagram RPCs",
        "Profiling a warehouse-scale computer",
        "A hardware accelerator for protocol buffers",
        "RecNMP: Accelerating personalized recommendation with nearmemory processing",
        "TEA: Enabling state-intensive network functions on programmable switches",
        "HyperLoop: Group-based NIC-offloading to accelerate replicated transactions in multi-tenant storage systems",
        "LineFS: Efficient SmartNIC offload of a distributed file system with pipeline parallelism",
        "Meet the walkers: Accelerating index traversals for in-memory databases",
        "Credit-based flow control for ATM networks: Credit update protocol, adaptive credit allocation and statistical multiplexing",
        "NetCAT: Practical cache attacks from the network",
        "TensorDIMM: A practical near-memory processing architecture for embeddings and tensor operations in deep learning",
        "Dagger: Efficient and fast RPCs in cloud microservices with near-memory reconfigurable NICs",
        "On the impact of cluster configuration on RoCE application design",
        "MIND: In-network memory management for disaggregated data centers",
        "MERCI: Efficient embedding reduction on commodity hardware via sub-query memoization",
        "The case for network accelerated query processing",
        "KV-Direct: High-performance in-memory key-value store with programmable NIC",
        "Eris: Coordination-free consistent transactions using in-network concurrency control",
        "Just say NO to Paxos overhead: Replacing consensus with network ordering",
        "Pegasus: Tolerating skewed workloads in distributed storage with in-network coherence directories",
        "MICA: A holistic approach to fast in-memory key-value storage",
        "Thin servers with smart pipes: Designing SoC accelerators for Memcached",
        "Offloading distributed applications onto SmartNICs using iPipe",
        "IncBricks: Toward in-network computation with an in-network cache",
        "Energy-efficient microservices on SmartNIC-accelerated servers",
        "Livia: Data-centric computing throughout the memory hierarchy",
        "A hypervisor for shared-memory FPGA platforms",
        "Contention-aware performance prediction for virtualized network functions",
        "Mellanox adapters programmer's reference manual (PRM)",
        "Mellanox scalable hierarchical aggregation and reduction protocol (SHARP)",
        "Atomic in-place updates for non-volatile main memories with Kamino-Tx",
        "HyperPlane: A scalable low-latency notification accelerator for software data planes",
        "Enhancing server efficiency in the face of killer microseconds",
        "Using one-sided RDMA reads to build a fast, CPU-efficient key-value store",
        "Balancing CPU and network in the Cell distributed B-Tree store",
        "Birds of a feather flock together: Scaling RDMA RPCs with Flock",
        "mongoDB manual: Manage chained replication",
        "Deep learning recommendation model for personalization and recommendation systems",
        "Understanding PCIe performance for end host networking",
        "Scale-out NUMA",
        "Storm: A fast transactional dataplane for remote data structures",
        "NVIDIA BlueField-2 DPU: Data center infrastructure on a chip",
        "RDMA aware networks programming user manual",
        "NVIDIA extends data center infrastructure processing roadmap with BlueField-3",
        "ExtraTime: Modeling and analysis of wearout due to transistor aging at microarchitecture-level",
        "Revisit DCA, PCIe TPH and DDIO",
        "Fast crash recovery in RAMCloud",
        "Intel Sapphire Rapids with HBM2E, CXL 1.1, and PCIe 5.0 by end of 2022",
        "Centaur: A framework for hybrid CPU-FPGA databases",
        "Running average power limit -RAPL",
        "TRiM: Enhancing processor-memory interfaces with scalable tensor reduction in memory",
        "Flex-KV: Enabling high-performance and flexible KV systems",
        "Floem: A programming system for NIC-accelerated network applications",
        "The benefits of general-purpose on-NIC memory",
        "Lightweight Notification",
        "FlowBlaze: Stateful packet processing in hardware",
        "Designing distributed systems using approximate synchrony in datacenter networks",
        "Cerebros: Evading the RPC tax in datacenters",
        "RDMA is Turing complete, we just did not know it yet",
        "mlx5dv -Linux manual page",
        "How to perform system replication for SAP HANA",
        "In-network computation is a dumb idea whose time has come",
        "Scaling distributed machine learning with in-network aggregation",
        "Xenic: SmartNIC-accelerated distributed transactions",
        "PM-Net: In-network data persistence",
        "A cloud-optimized transport protocol for elastic and scalable HPC",
        "Accelerating pattern matching queries in hybrid CPU-FPGA architectures",
        "StRoM: Smart remote memory",
        "RMA: Re-envisioning remote memory access for multi-tenant datacenters",
        "Accelerometer: Understanding acceleration opportunities for data center overheads at hyperscale",
        "CAPI: A coherent accelerator processor interface",
        "The NeBuLa RPC-optimized architecture",
        "Replex: A scalable, highly available multi-index data store",
        "RDMA persistent meory extensions",
        "Object storage on CRAQ: Highthroughput chain replication for read-mostly workloads",
        "ResQ: Enabling SLOs in network function virtualization",
        "Lynx: A SmartNIC-driven accelerator-centric architecture for network servers",
        "LITE kernel RDMA support for datacenter applications",
        "Chain replication for supporting high throughput and availability",
        "Concordia: Distributed shared memory with in-network cache coherence",
        "Shuhai: Benchmarking high bandwidth memory on FPGAs",
        "SRNIC: A scalable architecture for RDMA NICs",
        "Deconstructing RDMAenabled distributed transactions: Hybrid is better",
        "Fast in-memory transaction processing using RDMA and HTM",
        "Characterizing and optimizing remote persistent memory with RDMA and NVM",
        "Skylake (server -microarchitectures -intel",
        "Alveo U280 data center accelerator card",
        "Xilinx Virtex-7 FPGA VC709 connectivity kit",
        "Dart: Divide and specialize for fast response to congestion in RDMA-based datacenter networks",
        "An empirical guide to the behavior and use of scalable persistent memory",
        "Hardware-based address-centric acceleration of key-value store",
        "NetLock: Fast, centralized lock management using programmable switches",
        "Don't forget the I/O when allocating your LLC",
        "QEI: Query acceleration can be generic and efficient in the cloud",
        "FAERY: An FPGA-accelerated embedding-based retrieval system",
        "Tiara: A scalable and efficient hardware acceleration architecture for stateful layer-4 load balancing",
        "Hetero-ViTAL: A virtualization stack for heterogeneous FPGA clusters",
        "Distributed hierarchical GPU parameter server for massive scale deep learning ads systems",
        "AIBox: CTR prediction model training on a single node",
        "Scalable, high performance Ethernet forwarding with CuckooSwitch",
        "Fault-tolerant replication with pull-based consensus in MongoDB",
        "Harmonia: Near-linear scalability for replicated storage with in-network conflict detection",
        "Congestion control for large-scale RDMA deployments"
    ],
    "63a910a390e50fcafd2a8a6e": [
        "Progresses and challenges in link prediction",
        "Evaluation of different biological data and computational classification methods for use in protein interaction prediction",
        "Drug response prediction as a link prediction problem",
        "A survey on graph neural networks for knowledge graph completion",
        "Active ensemble learning for knowledge graph error detection",
        "Friends and neighbors on the web",
        "Deep representation learning for social network analysis",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Dynamic memory based attention network for sequential recommendation",
        "Generalizable embedding table placement for recommender systems",
        "Graph neural networks for recommender systems",
        "Line graph neural networks for link prediction",
        "Homogeneous network embedding for massive graphs via reweighted personalized pagerank",
        "Variational graph auto-encoders",
        "Inductive representation learning on large graphs",
        "Neural graph collaborative filtering",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Link prediction based on graph neural networks",
        "Labeling trick: A theory of using graph neural networks for multi-node representation learning",
        "Learning to hash with graph neural networks for recommender systems",
        "Neural link prediction with walk pooling",
        "Link prediction in complex networks: A survey",
        "Graph contrastive learning with personalized augmentation",
        "Link creation and information spreading over social and communication ties in an interest-based online social network",
        "Is a single vector enough? exploring node polysemy for network embedding",
        "Sparse-interest network for sequential recommendation",
        "Differentiable architecture search",
        "Semi-supervised classification with graph convolutional networks",
        "Neural message passing for quantum chemistry",
        "Regularized evolution for image classifier architecture search",
        "Learning transferable architectures for scalable image recognition",
        "Practical bayesian optimization of machine learning algorithms",
        "Towards automated imbalanced learning with deep hierarchical reinforcement learning",
        "Towards a unified min-max framework for adversarial exploration and robustness",
        "Pretraining of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Class imbalance problem in data mining review",
        "Collective classification in network data",
        "Ogb-lsc: A large-scale challenge for machine learning on graphs",
        "Modeling user exposure in recommendation",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Neural collaborative filtering. In WWW",
        "Link prediction techniques, applications, and performance: A survey",
        "S2gae: Self-supervised graph autoencoders are gen-eralizable learners with graph masking",
        "Adversarially regularized graph autoencoder for graph embedding",
        "Structure enhanced graph neural networks for link prediction",
        "Graph neural networks in recommender systems: a survey",
        "Temporal augmented graph neural networks for session-based recommendations"
    ],
    "634f6ae490e50fcafdcb6525": [
        "TensorFlow: Large-scale machine learning on heterogeneous systems",
        "Learning to optimize halide with tree search and random programs",
        "Deep learning using rectified linear units (relu)",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "Open neural network exchange",
        "Cudadma: Optimizing gpu memory bandwidth via warp specialization",
        "Optimizing compute shaders for l2 locality using thread-group id swizzling",
        "High performance convolutional neural networks for document processing",
        "Tvm: An automated end-to-end optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "cudnn: Efficient primitives for deep learning",
        "Nvidia a100 tensor core gpu: Performance and innovation",
        "The cityscapes dataset for semantic urban scene understanding",
        "ONNX Runtime developers. Onnx runtime",
        "BERT: pretraining of deep bidirectional transformers for language understanding",
        "Ios: Inter-operator scheduler for cnn acceleration",
        "Tensorir: An abstraction for automatic tensorized program optimization",
        "Demystifying the placement policies of the nvidia gpu thread block scheduler for concurrent kernels. SIGMETRICS Perform",
        "Deep residual learning for image recognition",
        "Basic linear algebra on nvidia gpus",
        "NVIDIA Inc. Nvidia tensorrt",
        "Parallel thread execution isa",
        "Taso: optimizing deep learning computation with automatic generation of graph substitutions",
        "SIGARCH Comput. Archit. News",
        "Cutlass: Cuda template library for dense linear algebra at all levels and scales",
        "Imagenet classification with deep convolutional neural networks",
        "Deep learning",
        "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Optimizing {CNN} model inference on {CPUs}",
        "RAMMER: Enabling Holistic Deep Learning Compiler Optimizations with Rtasks",
        "The gpu computing era",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Language models are unsupervised multitask learners",
        "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Xla : Compiling machine learning for peak performance",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Sequence to sequence learning with neural networks",
        "Going deeper with convolutions",
        "Rethinking the inception architecture for computer vision",
        "Freetensor: A free-form dsl with holistic optimizations for irregular tensor programs",
        "Locality-aware cta scheduling for gaming applications",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "None",
        "UNIT: Unifying Tensorized Instruction Compilation",
        "Bolt: Bridging the gap between auto-tuners and hardware-native performance",
        "DietCode: Automatic optimization for dynamic tensor programs",
        "Ansor: Generating high-performance tensor programs for deep learning",
        "Enabling automatic mapping for tensor computations on spatial accelerators with hardware abstraction",
        "Flextensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "Neural architecture search with reinforcement learning"
    ],
    "64264f7b90e50fcafd68e145": [
        "Unified pretraining for program understanding and generation",
        "Program synthesis with large language models",
        "Layer normalization",
        "Gpt-neox-20b: An open-source autoregressive language model",
        "Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow. If you use this software, please cite it using these metadata",
        "Language models are few-shot learners",
        "Evaluating large language models trained on code",
        "Palm: Scaling language modeling with pathways",
        "-bit matrix multiplication for transformers at scale",
        "Codebert: A pre-trained model for programming and natural languages",
        "Incoder: A generative model for code infilling and synthesis",
        "The pile: An 800gb dataset of diverse text for language modeling",
        "Deep residual learning for image recognition",
        "Measuring coding challenge competence with apps",
        "Gaussian error linear units (gelus)",
        "Adam: A method for stochastic optimization",
        "Spoc: Search-based pseudocode to code",
        "Competition-level code generation with alphacode",
        "Codexglue: A machine learning benchmark dataset for code understanding and generation",
        "On end-to-end program generation from user intention by deep neural networks",
        "Silvio Savarese, and Caiming Xiong. 2022. A conversational paradigm for program synthesis",
        "Bleu: a method for automatic evaluation of machine translation",
        "Cotext: Multi-task learning with code-text transformer",
        "Flashmeta: A framework for inductive program synthesis",
        "Prophetnet-x: large-scale pre-training models for english, chinese, multi-lingual, dialog, and code generation",
        "Improving language understanding by generative pre training",
        "Language models are unsupervised multitask learners",
        "Zero: Memory optimizations toward training trillion parameter models",
        "Codebleu: a method for automatic evaluation of code synthesis",
        "Neural machine translation of rare words with subword units",
        "Program synthesis by sketching",
        "A methodology for lisp program construction from examples",
        "Treegen: A tree-based transformer architecture for code generation",
        "Intellicode compose: Code generation using transformer",
        "Lamda: Language models for dialog applications",
        "Natural language processing with transformers",
        "Attention is all you need",
        "Prow: A step toward automatic program writing",
        "Gpt-j-6b: A 6 billion parameter autoregressive language model",
        "Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation",
        "Chain of thought prompting elicits reasoning in large language models",
        "Huggingface's transformers: State-of-the-art natural language processing",
        "A systematic evaluation of large language models of code",
        "Oneflow: Redesign the distributed deep learning framework from scratch",
        "Glm-130b: An open bilingual pre-trained model",
        "None",
        "Opt: Open pre-trained transformer language models",
        "Xlcost: A benchmark dataset for cross-lingual code intelligence",
        "Productivity assessment of neural code completion"
    ],
    "634d809c90e50fcafd4e77f0": [
        "Semeval-2016 task 13: Taxonomy extraction evaluation (texeval-2)",
        "Graph representation learning: a survey",
        "ELECTRA: pre-training text encoders as discriminators rather than generators",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Infusing disease knowledge into BERT for health question answering, medical inference and disease name recognition",
        "Taxonomy-aware multi-hop reasoning networks for sequential recommendation",
        "X-FACTR: multilingual factual knowledge retrieval from pretrained language models",
        "Semeval-2016 task 14: Semantic taxonomy enrichment",
        "Txtract: Taxonomy-aware knowledge extraction for thousands of product categories",
        "A robustly optimized bert pretraining approach",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Hyperexpan: Taxonomy expansion with hyperbolic representation learning",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Taxoexpan: Selfsupervised taxonomy expansion with position-enhanced graph neural network",
        "Enquire one's parent and child before decision: Fully exploit hierarchical structure for selfsupervised taxonomy expansion",
        "Enhancing taxonomy completion with concept generation via fusing relational representations",
        "Taxonomy completion via triplet matching network"
    ],
    "63dcdb422c26941cf00b642d": [
        "Zero-Cost Proxies for Lightweight NAS",
        "Designing Neural Network Architectures using Reinforcement Learning",
        "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures",
        "Wild Patterns: Ten Years after The Rise of Adversarial Machine Learning",
        "Architectural Backdoors in Neural Networks",
        "Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective",
        "Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective",
        "Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation",
        "Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning",
        "On Lazy Training in Differentiable Programming",
        "ImageNet: A Large-scale Hierarchical Image Database",
        "On Adversarial Robustness: A Neural Architecture Search perspective",
        "NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search",
        "NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size",
        "STRIP: A Defence Against Trojan Attacks on Deep Neural Networks",
        "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain",
        "Deep Residual Learning for Image Recognition",
        "Neural Tangent Kernel: Convergence and Generalization in Neural Networks",
        "Model-Reuse Attacks on Deep Learning Systems",
        "An Empirical Exploration of Recurrent Network Architectures",
        "Learning Multiple Layers of Features from Tiny Images",
        "Wide Neural Networks of Any Depth Evolve as Linear Models under Gradient Descent",
        "SGAS: Sequential Greedy Architecture Search",
        "DARTS: Differentiable Architecture Search",
        "Fine-Pruning: Defending Against Backdooring Attacks on Deep Neural Networks",
        "Trojaning Attack on Neural Networks",
        "ABS: Scanning Neural Networks for Back-Doors by Artificial Brain Stimulation",
        "Neural Architecture Search without Training",
        "Demystifying the Neural Tangent Kernel from a Practical Perspective: Can it be trusted for Neural Architecture Search without training?",
        "Input-Aware Dynamic Backdoor Attack",
        "Evaluating Efficient Performance Estimators of Neural Architectures",
        "A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models",
        "On the Security Risks of AutoML",
        "Tro-janZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors",
        "Efficient Neural Architecture Search via Parameter Sharing",
        "Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks",
        "Regularized Evolution for Image Classifier Architecture Search",
        "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization",
        "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks",
        "Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection",
        "Spectral Signatures in Backdoor Attacks",
        "Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks",
        "A Training-Free Genetic Neural Architecture Search",
        "SNAS: Stochastic Neural Architecture Search",
        "Latent Backdoor Attacks on Deep Neural Networks",
        "Learning Transferable Architectures for Scalable Image Recognition",
        "ASR and ACC of arches perturbed from \"|{0} ? 0| + |{1} ? 0|{2} ? 1| + |skip_connect ? 0|{3} ? 1|{4} ? 2|\" {0} {1} {2} {3} {4} ASR ACC Conv 1x1"
    ],
    "64250fee90e50fcafdb2d890": [
        "IEC/IEEE International Standard -Verilog(R) Register Transfer Level Synthesis",
        "IEEE Standard for SystemVerilog -Unified Hardware Design, Specification, and Verification Language",
        "Chipyard: Integrated Design, Simulation, and Implementation Framework for Custom SoCs",
        "The Rocket Chip Generator",
        "Chisel: Constructing Hardware in a Scala Embedded Language",
        "Efficiently Exploiting Low Activity Factors to Accelerate RTL Simulation",
        "Verification of Chisel Hardware Designs with ChiselVerify",
        "MLIR as Hardware Compiler Infrastructure",
        "RTLFUZZLAB: Building A Modular Open-Source Hardware Fuzzing Framework",
        "None",
        "DIFUZZRTL: Differential Fuzz Testing to Find CPU Bugs",
        "Reusability is FIRRTL Ground: Hardware Construction Languages, Compiler Frameworks, and Transformations",
        "FireSim: FPGA-Accelerated Cycle-Exact Scale-Out System Simulation in the Public Cloud",
        "risc-v mini",
        "RFUZZ: Coverage-Directed Fuzz Testing of RTL on FPGAs",
        "None",
        "Golden Gate: Bridging The Resource-Efficiency Gap Between ASICs and FPGA Prototypes",
        "None",
        "A Compiler Infrastructure for Accelerator Generators",
        "Functional Verification Coverage Measurement and Analysis",
        "Power-efficient Hardware Platform for Spiking Neural Network. Master's thesis",
        "AHIR: A Hardware Intermediate Representation for Hardware Generation from High-level Programs",
        "LLHD: A Multi-level Intermediate Representation for Hardware Description Languages",
        "?IR -An intermediate representation for transforming and optimizing the microarchitecture of application accelerators",
        "None",
        "Fuzzing Hardware Like Software",
        "A Golden Age of Hardware Description Languages: Applying Programming Language Techniques to Improve Design Productivity",
        "fault: A Python Embedded Domain-Specific Language for Metaprogramming Portable Hardware Verification Components",
        "SymbiYosys",
        "Yosys -A Free Verilog Synthesis Suite",
        "American Fuzzy Lop Technical Details",
        "Sonic-BOOM: The 3rd Generation Berkeley Out-of-Order Machine"
    ],
    "643e0acf0746dc40e3418ed8": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Optuna: A next-generation hyperparameter optimization framework",
        "Beyond low-frequency information in graph convolutional networks",
        "Geometric deep learning: going beyond euclidean data",
        "Exploring simple siamese representation learning",
        "Adaptive universal generalized pagerank graph neural network",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "Representation learning on graphs: Methods and applications",
        "Contrastive multi-view representation learning on graphs",
        "Deep residual learning for image recognition",
        "Learning canonical representations for scene graph to image generation",
        "Learning deep representations by mutual information estimation and maximization",
        "Measuring and improving the use of graph information in graph neural networks",
        "Outcome correlation in graph neural network regression",
        "Multi-scale contrastive siamese networks for self-supervised graph representation learning",
        "Automated self-supervised learning for graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Variational graph auto-encoders",
        "Information theory and statistics",
        "Label efficient semi-supervised learning via graph filtering",
        "Graph Representation Learning Beyond Node and Homophily",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "Dual attentive graph neural network for metro passenger flow prediction",
        "Query-driven active surveying for collective classification",
        "Networks",
        "Mixing patterns in networks",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Adversarially regularized graph autoencoder for graph embedding",
        "Multiscale mixing patterns in networks",
        "Geom-gcn: Geometric graph convolutional networks",
        "Deepwalk: Online learning of social representations",
        "struc2vec: Learning node representations from structural identity",
        "On proximity and structural role-based embeddings in networks: Misconceptions, techniques, and applications",
        "Multi-scale attributed node embedding",
        "Which tasks should be learned together in multi-task learning",
        "Graph attention networks",
        "Deep Graph Infomax. ICLR (Poster)",
        "Augmentation-Free Graph Contrastive Learning",
        "Simplifying graph convolutional networks",
        "Graph convolutional networks using heat kernel for semi-supervised learning",
        "Representation learning on graphs with jumping knowledge networks",
        "Network representation learning with rich text information",
        "Position-aware graph neural networks",
        "ProNE: Fast and Scalable Network Representation Learning",
        "A survey on multi-task learning",
        "Graph Neural Networks for Graphs with Heterophily: A Survey",
        "Daniele Grattarola, and Jun Pang. 2022. Unsupervised Heterophilous Network Embedding via ? -Ego Network Discrimination",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Interpreting and unifying graph neural networks with an optimization framework"
    ],
    "634cc7a390e50fcafd162fef": [
        "Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing",
        "Neural machine translation by jointly learning to align and translate",
        "Relational inductive biases, deep learning, and graph networks",
        "Beyond low-frequency information in graph convolutional networks",
        "Neural sheaf diffusion: A topological perspective on heterophily and oversmoothing in gnns",
        "Geometric deep learning: going beyond euclidean data",
        "Simple and deep graph convolutional networks",
        "Adaptive universal generalized pagerank graph neural network",
        "Spectral graph theory",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Graph structured data viewed through a fourier lens",
        "Fast graph representation learning with pytorch geometric",
        "Speech recognition with deep recurrent neural networks",
        "Graph representation learning",
        "Inductive representation learning on large graphs",
        "Bernnet: Learning arbitrary graph spectral filters via bernstein approximation",
        "Measuring and improving the use of graph information in graph neural networks",
        "A method for stochastic optimization",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Imagenet classification with deep convolutional neural networks",
        "Deep learning",
        "Gradient-based learning applied to document recognition",
        "Finding global homophily in graph neural networks when meeting heterophily",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "New benchmarks for learning on non-homophilous graphs",
        "Simple truncated svd based model for node classification on heterophilic graphs",
        "Non-local graph neural networks",
        "Break the ceiling: Stronger multi-scale deep graph convolutional networks",
        "Training matters: Unlocking potentials of deeper graph convolutional neural networks",
        "Complete the missing half: Augmenting aggregation filtering with diversification for graph convolutional networks",
        "Is homophily a necessity for graph neural networks? arXiv preprint",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Birds of a feather: Homophily in social networks",
        "Geom-gcn: Geometric graph convolutional networks",
        "Multi-Scale Attributed Node Embedding",
        "Characteristic Functions on Graphs: Birds of a Feather, from Statistical Descriptors to Parametric Models",
        "The graph neural network model",
        "An adaptive filter-bank equalizer for speech enhancement",
        "Graph attention networks",
        "Simplifying graph convolutional networks",
        "Representation learning on graphs with jumping knowledge networks",
        "Two sides of the same coin: Heterophily and oversmoothing in graph convolutional neural networks",
        "Graph neural networks with heterophily",
        "Beyond homophily in graph neural networks: Current limitations and effective designs"
    ],
    "643e0ad10746dc40e3419478": [
        "POLYGLOT-NER: massive multilingual named entity recognition",
        "Language models are few-shot learners",
        "Zs-bert: Towards zero-shot relation extraction with attribute representation learning",
        "2022a. Crossroads, buildings and neighborhoods: A dataset for fine-grained location recognition",
        "2022b. Crossroads, buildings and neighborhoods: A dataset for fine-grained location recognition",
        "None",
        "Relationprompt: Leveraging prompts to generate synthetic data for zero-shot relation triplet extraction",
        "Broad Twitter corpus: A diverse named entity recognition resource",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Ncbi disease corpus: A resource for disease name recognition and concept normalization",
        "Findvehicle and vehiclefinder: A ner dataset for a text-image cross-modal vehicle retrieval system",
        "Development of a benchmark corpus to support the automatic extraction of drugrelated adverse effects from medical case reports",
        "Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation",
        "Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals",
        "Ontonotes: The 90% solution",
        "REBEL: Relation extraction by end-to-end language generation",
        "Improving distantly supervised relation extraction using word and entity based attention",
        "Estevam Hruschka, and Ndapa Nakashole. 2022. Zero-shot triplet extraction by template infilling",
        "2003a. Genia corpus -a semantically annotated corpus for bio-textmining",
        "Yuka Tateisi, and Jun'ichi Tsujii. 2003b. Genia corpus-a semantically annotated corpus for bio-textmining",
        "Biomedical named entity recognition at scale",
        "Biomedical named entity recognition at scale",
        "Biomedical named entity recognition at scale",
        "2022a. Accurate clinical and biomedical named entity recognition at scale. Software Impacts",
        "2022b. Accurate clinical and biomedical named entity recognition at scale. Software Impacts",
        "The chemdner corpus of chemicals and drugs and its annotation principles",
        "2021a. \"fabner\": information extraction from manufacturing process science domain literature using named entity recognition",
        "2021b. \"fabner\": information extraction from manufacturing process science domain literature using named entity recognition",
        "SUNNYNLP at SemEval-2018 task 10: A supportvector-machine-based method for detecting semantic difference using taxonomy and word embedding features",
        "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
        "Dice loss for dataimbalanced NLP tasks",
        "GCDT: A global context enhanced deep transition architecture for sequence labeling",
        "Crossner: Evaluating crossdomain named entity recognition",
        "The flan collection: Designing data and methods for effective instruction tuning",
        "None",
        "Text2event: Controllable sequence-tostructure generation for end-to-end event extraction",
        "Unified structure generation for universal information extraction",
        "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
        "Cross-task generalization via natural language crowdsourcing instructions",
        "Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Crosslingual name tagging and linking for 282 languages",
        "Crosslingual name tagging and linking for 282 languages",
        "In-BoXBART: Get instructions into biomedical multitask learning",
        "Balancing class for performance of classification with a clinical dataset",
        "Modeling relations and their mentions without labeled text",
        "A linear programming formulation for global inference in natural language tasks",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "FLERT: document-level features for named entity recognition",
        "Phee: A dataset for pharmacovigilance event extraction from text",
        "DoSEA: A domain-specific entity-aware framework for cross-domain named entity recogition",
        "WikiNEuRal: Combined neural and knowledge-based silver data creation for multilingual NER",
        "MultiN-ERD: A multilingual, multi-genre and fine-grained dataset for named entity recognition (and disambiguation)",
        "MultiN-ERD: A multilingual, multi-genre and fine-grained dataset for named entity recognition (and disambiguation)",
        "An information extraction study: Take in mind the tokenization!",
        "T-NER: An all-round python library for transformerbased named entity recognition",
        "Named entity recognition in twitter: A dataset and analysis on short-term temporal shifts",
        "Named entity recognition in twitter: A dataset and analysis on short-term temporal shifts",
        "Walker and Linguistic Data Consortium",
        "Deepstruct: Pretraining of language models for structure prediction",
        "2022a. Instructionner: A multi-task instructionbased generative framework for few-shot ner",
        "MINER: Improving out-of-vocabulary named entity recognition from an information theoretic perspective",
        "2021a. Automated concatenation of embeddings for structured prediction",
        "2021b. UniRE: A unified label space for entity relation extraction",
        "2022c. Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks",
        "Revisiting the negative data of distantly supervised relation extraction",
        "A unified generative framework for aspect-based sentiment analysis",
        "Pack together: Entity and relation extraction with levitated marker",
        "A comprehensive capability analysis of gpt-3 and gpt-3.5 series models",
        "Relation classification via recurrent neural network",
        "Optimizing bi-encoder for named entity recognition via contrastive learning",
        "A frustratingly easy approach for joint entity and relation extraction",
        "For NER(named entity extraction) task, the 21 used datasets includes ACE"
    ],
    "629041ac5aee126c0fb5da8a": [
        "None",
        "Stock price prediction using the arima model",
        "Neural machine translation by jointly learning to align and translate",
        "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling",
        "Direct multi-step estimation and forecasting",
        "Stl : A seasonal-trend decomposition procedure based on loess",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Speech-transformer: a no-recurrence sequence-tosequence model for speech recognition",
        "A granular time series approach to long-term forecasting and trend forecasting",
        "Do we really need deep learning models for time series forecasting? arXiv preprint",
        "Greedy function approximation: a gradient boosting machine",
        "Exponential smoothing: The state of the art",
        "Time series analysis",
        "Forecasting, structural time series models and the kalman filter",
        "Reformer: The efficient transformer",
        "Modeling long-and short-term temporal patterns with deep neural networks",
        "Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting",
        "Time series is a special sequence: Forecasting with sample convolution and interaction",
        "Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting",
        "Multimodal motion prediction with stacked transformers",
        "Recurrent neural networks for time series forecasting",
        "Deepar: Probabilistic forecasting with autoregressive recurrent networks",
        "Recursive and direct multi-step forecasting: the best of both worlds",
        "Forecasting at scale. PeerJ Prepr",
        "An evaluation of change point detection algorithms",
        "Attention is all you need",
        "Transformers in time series: A survey",
        "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting",
        "Informer: Beyond efficient transformer for long sequence time-series forecasting",
        "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting"
    ],
    "63e312ef90e50fcafdc191fd": [
        "Construction of the Literature Graph in Semantic Scholar",
        "Dismec: Distributed sparse machines for extreme multi-label classification",
        "SciBERT: A Pretrained Language Model for Scientific Text",
        "Taming pretrained transformers for extreme multi-label text classification",
        "Empirical evaluation of gated recurrent neural networks on sequence modeling",
        "SPECTER: Document-level Representation Learning using Citationinformed Transformers",
        "Medical subject headings used to search the biomedical literature",
        "Sumeet Agarwal, and Manik Varma. 2021. Deepxml: A deep extreme multi-label learning framework applied to short text documents",
        "FullMeSH: improving large-scale MeSH indexing with full text",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "A century of science: Globalization of scientific collaborations, citations, and innovations",
        "An index to quantify an individual's scientific research output",
        "Heterogeneous graph transformer",
        "Slice: Scalable linear extreme classifiers trained on 100 million labels for related searches",
        "Extreme multilabel loss functions for recommendation, tagging, ranking &amp; other missing label applications",
        "Lightxml: Transformer with dynamic negative sampling for highperformance extreme multi-label text classification",
        "Scientific prizes and the extraordinary growth of scientific topics",
        "Bonsai: diverse and shallow trees for extreme multi-label classification",
        "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "Deep learning for extreme multi-label text classification",
        "MeSHLabeler: improving the accuracy of large-scale MeSH indexing by integrating diverse evidence",
        "The emerging trends of multi-label learning",
        "OAG-BERT: Towards a Unified Backbone Language Model for Academic Knowledge Services",
        "Roberta: A robustly optimized bert pretraining approach",
        "PubMed and beyond: a survey of web tools for searching biomedical literature",
        "Visualizing data using t-SNE",
        "META: Metadata-Empowered Weak Supervision for Text Classification",
        "Decaf: Deep extreme classification with label features",
        "ECLARE: Extreme Classification with Label Graph Correlations",
        "DeepMeSH: deep semantic representation for improving large-scale MeSH indexing",
        "Extreme multi-label learning with label features for warm-start tagging, ranking &amp; recommendation. In WSDM",
        "Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising. In WWW",
        "Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning",
        "Multilevel compression of random walks on networks reveals hierarchical organization in large integrated systems",
        "GalaXC: Graph Neural Networks with Labelwise Attention for Extreme Classification. In WWW'21",
        "A Web-scale system for scientific knowledge exploration",
        "An overview of microsoft academic service (mas) and applications",
        "Annexml: Approximate nearest neighbor search for extreme multi-label classification",
        "Arnetminer: extraction and mining of academic social networks",
        "Attention is all you need",
        "Microsoft academic graph: When experts are not enough",
        "Is preprint the future of science? A thirty year journey of online preprint services",
        "Correlation networks for extreme multi-label text classification",
        "MeSHProbeNet: a self-attentive probe net for MeSH indexing",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Beyond Text: Incorporating Metadata and Label Structure for Multi-Label Document Classification using Heterogeneous Graphs",
        "Pretrained generalized autoregressive model with adaptive probabilistic label clusters for extreme multi-label text classification",
        "Ppdsparse: A parallel primal-dual sparse method for extreme classification",
        "Pd-sparse: A primal and dual sparse approach to extreme multiclass and multilabel classification",
        "Public use and public funding of science",
        "BERTMeSH: deep contextual representation learning for large-scale highperformance MeSH indexing with full text",
        "Attentionxml: Label tree-based attention-aware deep model for high-performance extreme multi-label text classification",
        "PECOS: Prediction for enormous and correlated output spaces",
        "Oag: Toward linking large-scale heterogeneous entity graphs",
        "Fast multi-resolution transformer fine-tuning for extreme multi-label text classification",
        "Hierarchical Metadata-Aware Document Categorization under Weak Supervision",
        "Motifclass: Weakly supervised text classification with higher-order metadata information",
        "MATCH: Metadata-Aware Text Classification in A Large Hierarchy",
        "Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification. In WWW'22"
    ],
    "6344dede90e50fcafd24d1af": [
        "Media competition and news diets",
        "Addressing \"documentation debt",
        "Improving language models by retrieving from trillions of tokens",
        "Language models are few-shot learners",
        "Reprinting, circulation, and the network author in antebellum newspapers",
        "Chronicling america: Historic american newspapers",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Documenting large webtext corpora: A case study on the colossal clean crawled corpus",
        "None",
        "Deduplication of scholarly documents using locality sensitive hashing and word embeddings",
        "Dimensionality reduction by learning an invariant mapping",
        "Mask r-cnn",
        "Efficient natural language response suggestion for smart reply",
        "Comparing partitions",
        "Billion-scale similarity search with gpus",
        "Deduplicating training data mitigates privacy risks in language models",
        "Dense passage retrieval for open-domain question answering",
        "Supervised contrastive learning",
        "Deduplicating training data makes language models better",
        "Mining of massive data sets",
        "Denoising distantly supervised open-domain question answering",
        "A robustly optimized bert pretraining approach",
        "Language models are unsupervised multitask learners",
        "Sentence-bert: Sentence embeddings using siamese bert-networks",
        "Layoutparser: A unified toolkit for deep learning based document image analysis",
        "Deduplication in a massive clinical note dataset",
        "Computational methods for uncovering reprinted texts in antebellum newspapers",
        "Mpnet: Masked and permuted pre-training for language understanding",
        "Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models",
        "A system for identifying and exploring text repetition in large historical document corpora",
        "R 3: Reinforced ranker-reader for open-domain question answering",
        "Scalable zero-shot entity linking with dense entity retrieval",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books"
    ],
    "633ba44790e50fcafdfe4b50": [
        "A survey on graph neural networks for knowledge graph completion",
        "Analyzing the expressive power of graph neural networks in a spectral perspective",
        "Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking",
        "How attentive are graph attention networks?",
        "Graph coarsening with neural networks",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Molgan: An implicit generative model for small molecular graphs",
        "A comprehensive study on large-scale graph training: Benchmarking and rethinking",
        "Exploring the landscape of spatial robustness",
        "Graph neural networks for social recommendation",
        "Tf-gnn: Graph neural networks in tensorflow",
        "Fast graph representation learning with PyTorch Geometric",
        "Gnnautoscale: Scalable and expressive graph neural networks via historical embeddings",
        "Deep ensembles: A loss landscape perspective",
        "Sign: Scalable inception graph neural networks",
        "Neural message passing for quantum chemistry",
        "Inductive representation learning on large graphs",
        "Contrastive multi-view representation learning on graphs",
        "Strategies for pre-training graph neural networks",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Graph-mlp: node classification without message passing in graph",
        "Combining label propagation and simple models out-performs graph neural networks",
        "Understanding generalization through visualizations",
        "Graph neural network for traffic forecasting: A survey. Expert Systems with Applications",
        "Selfsupervised learning on graphs: Deep insights and new direction",
        "Graph condensation for graph neural networks",
        "Adam: A method for stochastic optimization",
        "Semi-supervised classification with graph convolutional networks",
        "Variational graph auto-encoders",
        "Training graph neural networks with 1000 layers",
        "Visualizing the loss landscape of neural nets",
        "Learning deep generative models of graphs",
        "On the loss landscape of adversarial training: Identifying challenges and how to overcome them",
        "Graph rationalization with environment-based augmentations",
        "A unified view on graph neural networks as graph signal denoising",
        "Image-based recommendations on styles and substitutes",
        "Estimating node importance in knowledge graphs using graph neural networks",
        "Pytorch: An imperative style, highperformance deep learning library",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Graph neural networks for friend ranking in large-scale social platforms",
        "Pitfalls of graph neural network evaluation",
        "Scalable and adaptive graph neural networks with selflabel-enhanced training",
        "Do we need anisotropic graph neural networks?",
        "Knowing your fate: Friendship, action and temporal explanations for user engagement prediction on social apps",
        "Friend story ranking with edge-contextual local graph convolutions",
        "Grand++: Graph neural diffusion with a source term",
        "Graph attention networks",
        "Deep graph infomax",
        "Bns-gcn: Efficient full-graph training of graph convolutional networks with partition-parallelism and random boundary node sampling",
        "Mixed-curvature multi-relational graph neural network for knowledge graph completion",
        "Smoothout: Smoothing out sharp minima to improve generalization in deep learning",
        "Simplifying graph convolutional networks",
        "A comprehensive survey on graph neural networks",
        "How powerful are graph neural networks?",
        "Revisiting semi-supervised learning with graph embeddings",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Graphrnn: Generating realistic graphs with deep auto-regressive models",
        "Design space for graph neural networks",
        "Graph contrastive learning with augmentations",
        "When does self-supervision help graph convolutional networks",
        "L2-gcn: Layer-wise and learned efficient training of graph convolutional networks",
        "Graph contrastive learning automated",
        "Graphfm: Improving large-scale gnn training via feature momentum",
        "Graphsaint: Graph sampling based inductive learning method",
        "Agl: a scalable system for industrial-purpose graph machine learning",
        "Graph-less neural networks: Teaching old mlps new tricks via distillation",
        "Graph convolutional networks: Algorithms, applications and open challenges",
        "Graph attention multi-layer perceptron",
        "Graph data augmentation for graph machine learning: A survey",
        "Graph neural networks: A review of methods and applications",
        "Self-supervised training of graph convolutional networks",
        "Deep graph contrastive representation learning",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "628d9e805aee126c0f979841": [
        "None",
        "Pretraining tasks for embedding-based large-scale retrieval",
        "Diffcse: Difference-based contrastive learning for sentence embeddings",
        "Electra: Pre-training text encoders as discriminators rather than generators",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Unified language model pre-training for natural language understanding and generation",
        "Condenser: a pre-training architecture for dense retrieval",
        "Simcse: Simple contrastive learning of sentence embeddings",
        "Realm: Retrievalaugmented language model pre-training",
        "Momentum contrast for unsupervised visual representation learning",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Towards unsupervised dense information retrieval with contrastive learning",
        "Product quantization for nearest neighbor search",
        "Spanbert: Improving pre-training by representing and predicting spans",
        "Dense passage retrieval for open-domain question answering",
        "Skip-thought vectors",
        "Natural questions: a benchmark for question answering research",
        "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Optimus: Organizing sentences via pre-trained modeling of a latent space",
        "Pretrained transformers for text ranking: Bert and beyond",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Less is more: Pre-training a strong siamese encoder using a weak decoder",
        "Sparse, dense, and attentional representations for text retrieval",
        "Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs",
        "Ms marco: A human generated machine reading comprehension dataset",
        "Large dual encoders are generalizable retrievers",
        "Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering",
        "Improving language understanding by generative pre-training",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "A latent semantic model with convolutional-pooling structure for information retrieval",
        "Ernie: Enhanced representation through knowledge integration",
        "Beir: A heterogenous benchmark for zero-shot evaluation of information retrieval models",
        "Tsdae: Using transformer-based sequential denoising auto-encoder for unsupervised sentence embedding learning",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Laprador: Unsupervised pretrained dense retriever for zero-shot text retrieval",
        "Xlnet: Generalized autoregressive pretraining for language understanding"
    ],
    "634d80a390e50fcafd4e7c23": [
        "Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering",
        "Event extraction via dynamic multipooling convolutional neural networks",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Event extraction by answering (almost) natural questions",
        "2021a. Rethinking boundaries: Endto-end recognition of discontinuous mentions with pointer networks",
        "2021b. Encoder-decoder based unified semantic role labeling with label-aware syntax",
        "2022a. Global inference with explicit syntactic and discourse structures for dialogue-level relation extraction",
        "Boundaries and edges rethinking: An end-to-end neural model for overlapping entity relation extraction",
        "Matching structure for dual learning",
        "Yafeng Ren, and Donghong Ji. 2022c. Conversational semantic role labeling with predicate-oriented latent graph",
        "Cross-lingual semantic role labeling with highquality translated training corpus",
        "2021c. End-to-end semantic role labeling with neural transition-based model",
        "Investigating LSTMs for joint extraction of opinion entities and relations",
        "Overview of genia event task in bionlp shared task 2011",
        "The genia event extraction shared task, 2013 edition-overview",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Event extraction as multi-turn question answering",
        "2021a. A span-based model for joint overlapped and discontinuous named entity recognition",
        "Unified named entity recognition as wordword relation classification",
        "Yafeng Ren, and Donghong Ji. 2021b. MRN: A locally and globally mention-based reasoning network for document-level relation extraction",
        "Joint event extraction via structured prediction with global features",
        "Jointly multiple events extraction via attention-based graph information aggregation",
        "Decoupled weight decay regularization",
        "End-to-end relation extraction using LSTMs on sequences and tree structures",
        "A method for integrating and ranking the evidence for biochemical pathways by mining reactions from text",
        "Joint event extraction via recurrent neural networks",
        "One for all: Neural joint modeling of entities and events",
        "An automated framework for incorporating news into stock trading strategies",
        "Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction",
        "Casee: A joint learning framework with cascade decoding for overlapping event extraction",
        "Roformer: Enhanced transformer with rotary position embedding",
        "Circle loss: A unified perspective of pair similarity optimization",
        "Attention is all you need",
        "Tplinker: Single-stage joint extraction of entities and relations through token pair linking",
        "Discontinuous named entity recognition as maximal clique discovery",
        "Neural multimodal cooperative learning toward micro-video understanding",
        "Mmgcn: Multi-modal graph convolution network for personalized recommendation of micro-video",
        "Grid tagging scheme for end-to-end fine-grained opinion extraction",
        "Exploring pre-trained language models for event extraction and generation",
        "Joint extraction of entities and relations based on a novel tagging scheme",
        "What the role is vs. what plays the role: Semi-supervised event argument extraction via dual question answering"
    ],
    "62b3da1e5aee126c0fb1b3bc": [
        "Amazon KDD 2022 challenge",
        "Yelp dataset",
        "Distributed large-scale natural graph factorization",
        "Regularization and semi-supervised learning on large graphs",
        "Laplacian eigenmaps and spectral techniques for embedding and clustering",
        "Geometric deep learning: going beyond euclidean data",
        "Grarep: Learning graph representations with global structural information",
        "Node feature extraction by self-supervised multi-scale neighborhood prediction",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Representation learning on graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Few-shot link prediction via graph neural networks for covid-19 drug-repurposing",
        "Panrep: Graph neural networks for extracting universal node embeddings in heterogeneous graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Adsgnn: Behavior-graph augmented relevance modeling in sponsored search",
        "Asymmetric transitivity preserving graph embedding",
        "Deepwalk: Online learning of social representations",
        "Modeling relational data with graph convolutional networks",
        "Line: Largescale information network embedding",
        "Graph attention networks",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Heterogeneous graph attention network",
        "Huggingface's transformers: State-of-the-art natural language processing",
        "A comprehensive survey on graph neural networks",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Dgl-ke: Training knowledge graph embeddings at scale",
        "Distributed hybrid cpu and gpu training for graph neural networks on billion-scale graphs",
        "Networkbased drug repurposing for novel coronavirus 2019-ncov/sars-cov-2",
        "Textgnn: Improving text encoder via graph neural network in sponsored search"
    ],
    "62e0acfd5aee126c0f20a05e": [
        "Tensorflow: A system for large-scale machine learning",
        "Open neural network exchange",
        "Multimodal machine learning: A survey and taxonomy",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "International Summer School on Engineering Trustworthy Software Systems",
        "Fuzzing: Challenges and reflections",
        "Directed greybox fuzzing",
        "On the reliability of coverage-based fuzzer benchmarking",
        "Language models are few-shot learners",
        "Symbolic execution for software testing: three decades later",
        "TVM: An automated end-to-end optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "Compiler fuzzing through deep learning",
        "Language fuzzing using constraint logic programming",
        "Automated testing of graphics shader compilers",
        "Found result inconsistency in graph-based fuzz testing",
        "None",
        "Testing deep learning libraries via neural architecture fuzzing",
        "Audee: Automated testing for deep learning frameworks",
        "Mask r-cnn",
        "Fuzzing with code fragments",
        "Hfl: Hybrid fuzzing on the linux kernel",
        "Adam: A method for stochastic optimization",
        "LLVM: An infrastructure for multi-stage optimization",
        "Compiler validation via equivalence modulo inputs",
        "Finding deep compiler bugs via guided stochastic program mutation",
        "Montage: A neural network language model-guided javascript engine fuzzer",
        "Fuzzing: a survey",
        "Coverageguided tensor compiler fuzzing with joint ir-pass mutation",
        "Pmfuzz: Test case generation for persistent memory programs",
        "Automatic generation of syntax valid c programs for fuzz testing",
        "An empirical analysis of flaky tests",
        "Graph-based fuzz testing for deep learning inference engines",
        "C11tester: A fuzzer for c/c++ atomics",
        "The art, science, and engineering of fuzzing: A survey",
        "Compiler fuzzing: How much does it matter?",
        "Differential testing for software",
        "Onnx runtime: cross-platform, high performance ml inferencing and training accelerator",
        "An empirical study of the reliability of unix utilities",
        "Z3: An efficient smt solver",
        "Hippocrates: Healing persistent memory bugs without doing any harm",
        "Multimodal deep learning",
        "None",
        "NVIDIA. Nvidia tensorrt",
        "Graph optimizations in onnx runtime",
        "Symbolic shape inference in onnxruntime",
        "Numerical computing with IEEE floating point arithmetic",
        "Fuzzing tensor-level intermediate representation in tvm",
        "On properties of floating point arithmetics: Numerical stability and the cost of accurate computations",
        "None",
        "Learning transferable visual models from natural language supervision",
        "Pep 8 -style guide for python code",
        "Mozilla Security. jsfunfuzz",
        "Finding compiler bugs via live code mutation",
        "Finding missed optimizations through the lens of dead code elimination",
        "Fuzzing hardware like software",
        "Deep learning library testing via effective model generation",
        "The implementation repository of LEMON: Deep Learning Library Testing via Effective Model Generation",
        "Free lunch for testing: Fuzzing deep-learning libraries from open source",
        "Patches as better bug reports",
        "Wikipedia contributors. Venn diagram -Wikipedia",
        "Empirical evaluation of rectified activations in convolutional network",
        "Exposing numerical bugs in deep learning via gradient back-propagation",
        "None",
        "Finding and understanding bugs in c compilers",
        "Automated conformance testing for javascript engines via deep compiler fuzzing",
        "American fuzzing lop (afl)",
        "Skeletal program enumeration for rigorous compiler testing",
        "Predoo: precision testing of deep learning operators",
        "Ansor: Generating {High-Performance} tensor programs for deep learning",
        "{TCP-Fuzz}: Detecting memory and semantic bugs in {TCP} stacks with fuzzing"
    ],
    "62c28ae45aee126c0f8a1660": [
        "Nas-ood: Neural architecture search for outof-distribution generalization",
        "Size-invariant graph representations for graph classification extrapolations",
        "Multimodal continual graph learning with neural architecture search",
        "Rethinking graph neural architecture search from message-passing",
        "Curriculum disentangled recommendation with noisy multi-feedback",
        "Instanas: Instance-aware neural architecture search",
        "Principal neighbourhood aggregation for graph nets",
        "Understanding and exploring the network with stochastic architectures",
        "Debiased graph neural networks with agnostic label selection bias",
        "Graph neural architecture search",
        "Automated attention representation search",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Out-of-distribution (ood) dataset curator and benchmark for ai-aided drug discovery -a focus on affinity prediction problems with noise annotations",
        "Graph neural network architecture search for molecular property prediction",
        "Semi-supervised classification with graph convolutional networks",
        "Understanding attention and generalization in graph neural networks",
        "WILDS: A benchmark of in-the-wild distribution shifts",
        "Policy-gnn: Aggregation optimization for graph neural networks",
        "Sgas: Sequential greedy architecture search",
        "Disentangled contrastive learning on graphs",
        "Hierarchical representations for efficient architecture search",
        "Darts: Differentiable architecture search",
        "Graph self-supervised learning: A survey",
        "Disentangled graph convolutional networks",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Learning graph convolutional network for skeleton-based human action recognition by neural searching",
        "Efficient neural architecture search via parameter sharing",
        "Graph q network for neural architecture search",
        "Graph differentiable architecture search with structure learning",
        "ASAP: adaptive structure aware pooling for learning hierarchical graph representations",
        "Towards out-of-distribution generalization: A survey",
        "Autone: Hyperparameter optimization for massive network embedding",
        "Graph attention networks",
        "Generalizing to unseen domains: A survey on domain generalization",
        "Multimodal disentangled representation for recommendation",
        "Explainable automated graph representation learning with hyperparameter importance",
        "Disentangled representation learning for recommendation",
        "Automated graph machine learning: Approaches, libraries and directions",
        "Customized graph neural networks",
        "Pooling architecture search for graph classification",
        "Discovering invariant rationales for graph neural networks",
        "A benchmark for molecular machine learning. Chemical sciense",
        "Genetic cnn",
        "Snas: stochastic neural architecture search",
        "How powerful are graph neural networks?",
        "How neural networks extrapolate: From feedforward to graph neural networks",
        "From local structures to size generalization in graph neural networks",
        "A tool for post-hoc explanation of graph neural networks",
        "Differentiable dynamic wirings for neural networks",
        "Automated machine learning on graphs: A survey",
        "Learning to solve travelling salesman problem with hardness-adaptive curriculum",
        "Autogel: An automated graph neural network with explicit link information",
        "Auto-gnn: Neural architecture search of graph neural networks",
        "Shiftrobust gnns: Overcoming the limitations of localized graph training data",
        "Multimedia big data computing",
        "Neural architecture search with reinforcement learning"
    ],
    "63f5888490e50fcafd27c90c": [
        "Understanding training efficiency of deep learning recommendation models at scale",
        "High-performance training by exploiting hotembeddings in recommendation systems",
        "None",
        "On the factory floor: Ml engineering for industrial-scale ads recommendation models",
        "CDLRM: Look Ahead Caching for Scalable Training of Recommendation Models",
        "Wide &amp; deep learning for recommender systems",
        "Maxim Naumov, Sam Naghshineh, and Mikhail Smelyanskiy. Low-precision hardware architectures meet recommendation model inference at scale",
        "Random offset block embedding (robe) for compressed embedding tables in deep learning recommendation systems",
        "Using non-volatile memory for storing deep learning models",
        "The graphcore second generation ipu",
        "None",
        "Mixed dimension embeddings with application to memory-efficient recommendation systems",
        "Deeprecsys: A system for optimizing endto-end at-scale neural recommendation inference",
        "Recpipe: Co-designing models and hardware to jointly optimize recommendation quality and performance",
        "The architectural implications of facebook's dnn-based personalized recommendation",
        "Training recommender systems at scale: Communication-efficient model and data parallelism",
        "Applied machine learning at facebook: A datacenter infrastructure perspective",
        "Neural collaborative filtering",
        "Cross-stack workload characterization of deep recommendation systems",
        "Hierarchical training: Scaling deep recommendation models on large cpu clusters",
        "Centaur: A chiplet-based, hybrid sparse-dense accelerator for personalized recommendations",
        "Dissecting the graphcore ipu architecture via microbenchmarking",
        "Microrec: Efficient recommendation inference by hardware and data structure solutions",
        "Fleetrec: Large-scale recommendation inference on hybrid gpu-fpga clusters",
        "Ten lessons from three generations shaped google's tpuv4i : Industrial product",
        "A domain-specific supercomputer for training deep neural networks",
        "In-datacenter performance analysis of a tensor processing unit",
        "Display advertising challenge: Predict clickthrough rates on display ads",
        "Learning to embed categorical features without embedding tables for recommendation",
        "Recnmp: Accelerating personalized recommendation with near-memory processing",
        "Hercules: Heterogeneity-aware inference serving for at-scale personalized recommendation",
        "Near-memory processing in action: Accelerating personalized recommendation with axdimm",
        "Fbgemm: Enabling high-performance low-precision deep learning inference",
        "Tensordimm: A practical near-memory processing architecture for embeddings and tensor operations in deep learning",
        "Tensor casting: Co-designing algorithm-architecture for personalized recommendation training",
        "Understanding capacity-driven scale-out neural recommendation inference",
        "Software-hardware co-design for fast and scalable training of deep learning recommendation models",
        "Deep learning recommendation model for personalization and recommendation systems",
        "Trim: Enhancing processor-memory interfaces with scalable tensor reduction in memory",
        "Deep learning inference in facebook data centers: Characterization, performance optimizations and hardware implications",
        "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "Mlperf inference benchmark",
        "Recshard: Statistical feature-based memory optimization for industry-scale neural recommendation",
        "Flexshard: Flexible sharding for industry-scale sequence recommendation models",
        "Compositional embeddings using complementary partitions for memory-efficient recommendation systems",
        "Criteo terabyte click logs",
        "FlashEmbedding: Storing Embedding Tables",
        "Billion-scale commodity embedding for e-commerce recommendation in alibaba",
        "Recssd: Near data processing for solid state drive based recommendation inference",
        "Developing a recommendation benchmark for mlperf training and inference",
        "Sustainable ai: Environmental implications, challenges and opportunities",
        "Kraken: Memory-efficient continual learning for large-scale realtime recommendations",
        "Factorized deep retrieval and distributed tensorflow serving",
        "Ttrec: Tensor train compression for deep learning recommendation models",
        "Autoshard: Automated embedding table sharding for recommender systems",
        "Dreamshard: Generalizable embedding table placement for recommender systems",
        "Distributed hierarchical gpu parameter server for massive scale deep learning ads systems",
        "Distributed hierarchical gpu parameter server for massive scale deep learning ads systems",
        "Aibox: Ctr prediction model training on a single node",
        "Recommending what video to watch next: A multitask ranking system",
        "Deep interest evolution network for click-through rate prediction",
        "Deep interest network for click-through rate prediction"
    ],
    "626603225aee126c0f2338e4": [
        "ARCore",
        "ARM's First Generation ML Processor, HotChips 30",
        "Artisan Memory Compilers",
        "Jetson TX2 Module",
        "Single-Channel Mobile LPDDR3 SDRAM Features",
        "Micron System Power Calculators",
        "OpenHeritage 3D dataset",
        "Waymo Offers a Peek Into the Huge Trove of Data Collected by Its Self-Driving Cars",
        "Garnet: A detailed on-chip network model inside a full-system simulator",
        "An event-triggered programmable prefetcher for irregular workloads",
        "Distributed kd-trees for retrieval from very large image collections",
        "An optimal algorithm for approximate nearest neighbor searching fixed dimensions",
        "Reducing pagerank communication via propagation blocking",
        "Multidimensional binary search trees used for associative searching",
        "ShapeNet: An Information-Rich 3D Model Repository",
        "4d spatio-temporal convnets: Minkowski convolutional neural networks",
        "Unsupervised detection of vineyards by 3d point-cloud uav photogrammetry for precision agriculture",
        "Mesorasi: Architecture support for point cloud analytics via delayed-aggregation",
        "Tetris: Scalable and efficient neural network acceleration with 3d memory",
        "Are we ready for autonomous driving? the kitti vision benchmark suite",
        "Buffer kd trees: processing massive nearest neighbor queries on gpus",
        "3d semantic segmentation with submanifold sparse convolutional networks",
        "Approximate kd tree search for efficient icp",
        "Kilo-noc: a heterogeneous network-on-chip architecture for scalability and service guarantees",
        "Pcpnet learning local shape properties from raw point clouds",
        "Deep learning for 3d point clouds: A survey",
        "Darkroom: Compiling high-level image processing code into hardware pipelines",
        "A hardware processing unit for point sets",
        "Characterization and analysis of deep learning for 3d point cloud analytics",
        "A parallel sph implementation on multi-core cpus",
        "Datacenter Performance Analysis of a Tensor Processing Unit",
        "In-datacenter performance analysis of a tensor processing unit",
        "Programming massively parallel processors: a hands-on approach",
        "An FPGA Acceleration for the Kd-tree Search in Photon Mapping",
        "Deep continuous fusion for multi-sensor 3d object detection",
        "Pointacc: Efficient point cloud accelerator",
        "Densepoint: Learning densely contextual representation for efficient point cloud processing",
        "3d sceneflownet: Self-supervised 3d scene flow estimation based on graph cnn",
        "An iterative image registration technique with an application to stereo vision",
        "Low latency photon mapping using block hashing",
        "Approximative fast nearest-neighbour recognition",
        "Doppelg?nger: a cache for approximate computing",
        "Vector runahead",
        "Quicknn: Memory and performance optimization of kd tree based nearest neighbor search for 3d point clouds",
        "Photon mapping on programmable graphics hardware",
        "Convolution engine: balancing efficiency &amp; flexibility in specialized computing",
        "Frustum pointnets for 3d object detection from rgb-d data",
        "Pointnet: Deep learning on point sets for 3d classification and segmentation",
        "Pointnet++: Deep hierarchical feature learning on point sets in a metric space",
        "Gpu-accelerated nearest neighbor search for 3d registration",
        "Exploiting staleness for approximating loads on cmps",
        "Towards 3d point cloud based object maps for household environments",
        "The bunker cache for spatio-value approximation",
        "Load value approximation",
        "Lidar: Mapping the world in 3d",
        "Visualization and labeling of point clouds in virtual reality",
        "Prodigy: Improving the memory latency of data-indirect irregular workloads using hardwaresoftware co-design",
        "International archives of photogrammetry remote sensing and spatial information sciences",
        "Dynamic graph cnn for learning on point clouds",
        "CMOS VLSI design: a circuits and systems perspective",
        "Fixynn: Efficient hardware for mobile computer vision via transfer learning",
        "Autonomous navigation using a real-time 3d point cloud",
        "Fpga-based kmeans clustering using tree-based data structures",
        "Approximating warps with intra-warp operand value similarity",
        "3d shapenets: A deep representation for volumetric shapes",
        "Tigris: Architecture and algorithms for 3d perception in point clouds",
        "Ganax: A unified mimd-simd acceleration for generative adversarial networks",
        "Differentiable surface splatting for point-based geometry processing",
        "Point-x: A spatial-locality-aware architecture for energy-efficient graph-based point-cloud deep learning",
        "Linked dynamic graph cnn: Learning on point cloud via linking hierarchical features",
        "Characterizing and demystifying the implicit convolution algorithm on commercial matrix-multiplication accelerators",
        "Target-driven visual navigation in indoor scenes using deep reinforcement learning"
    ],
    "63fec3cd90e50fcafdd70322": [
        "Catherine de Vulpilli?res, and H?l?ne Sauz?on. 2022. Conversational agents for fostering curiosity-driven learning in children",
        "Plato-xl: Exploring the large-scale pre-training of dialogue generation",
        "PLATO-K: Internal and External Knowledge Enhanced Dialogue Generation",
        "Revisiting Pre-Trained Models for Chinese Natural Language Processing",
        "Wizard of wikipedia: Knowledge-powered conversational agents",
        "Unified language model pretraining for natural language understanding and generation",
        "GLM: General Language Model Pretraining with Autoregressive Blank Infilling",
        "A knowledge-grounded neural conversation model",
        "Eva2. 0: Investigating opendomain chinese dialogue systems with large-scale pre-training",
        "EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training",
        "Dureader: a chinese machine reading comprehension dataset from real-world applications",
        "Survey of hallucination in natural language generation",
        "What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers",
        "Controlling Conditional Language Models without Catastrophic Forgetting",
        "Dataset and neural recurrent sequence labeling model for open-domain factoid question answering",
        "Towards Boosting the Open-Domain Chatbot with Human Feedback",
        "Godel: Large-scale pretraining for goal-directed dialog",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "DRCD: A Chinese machine reading comprehension dataset",
        "Dialogue in the wild: Learning from a deployed role-playing game with humans and bots",
        "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage",
        "Lamda: Language models for dialog applications",
        "Naturalconv: A chinese dialogue dataset towards multi-turn topic-driven conversation",
        "A large-scale chinese short-text conversation dataset",
        "Semiotic mediation, dialogue and the construction of knowledge",
        "Proactive human-machine conversation with explicit conversation goals",
        "NLP Chinese Corpus: Large Scale Chinese Corpus for NLP",
        "Augmenting end-to-end dialogue systems with commonsense knowledge",
        "XDAI: A Tuning-free Framework for Exploiting Pre-trained Language Models in Knowledge Grounded Dialogue Generation",
        "GLM-130B: An Open Bilingual Pre-trained Model",
        "Shulin Cao, and Xin Lv. 2023. A survey on complex factual question answering",
        "Personalizing Dialogue Agents: I have a dog, do you have pets too",
        "HOSMEL: A Hot-Swappable Modularized Entity Linking Toolkit for Chinese",
        "Knowledge-Grounded Dialogue Generation with Pre-trained Language Models",
        "Medical Dialogue Response Generation with Pivotal Information Recalling",
        "Dialoglm: Pre-trained model for long dialogue understanding and summarization",
        "Link the World: Improving Open-domain Conversation with Dynamic Spatiotemporal-aware Knowledge",
        "Kd-Conv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledgedriven Conversation"
    ],
    "6466faedd68f896efaeb70be": [
        "MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing",
        "Emergence of scaling in random networks",
        "Equivariant subgraph aggregation networks",
        "Beyond low-frequency information in graph convolutional networks",
        "Weisfeiler and lehman go topological: Message passing simplicial networks",
        "Neural sheaf diffusion: A topological perspective on heterophily and oversmoothing in gnns",
        "Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking",
        "Spectral networks and locally connected networks on graphs",
        "An optimal lower bound on the number of variables for graph identifications",
        "Adaptive universal generalized pagerank graph neural network",
        "Principal neighbourhood aggregation for graph nets",
        "Convolutional neural networks on graphs with fast localized spectral filtering",
        "Graph neural networks as gradient flows",
        "Fast graph representation learning with pytorch geometric",
        "Neural message passing for quantum chemistry",
        "Color refinement and its applications",
        "Inductive representation learning on large graphs",
        "PyTorch Geometric Signed Directed: A Software Package on Graph Neural Networks for Signed and Directed Graphs",
        "Multilayer feedforward networks are universal approximators",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "edgnn: a simple and powerful GNN for directed labeled graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Directed graph auto-encoders",
        "Finding global homophily in graph neural networks when meeting heterophily",
        "Gated graph sequence neural networks",
        "Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods",
        "Revisiting heterophily for graph neural networks",
        "Is homophily a necessity for graph neural networks?",
        "Spectral-based graph convolutional network for directed graphs",
        "Encoding sentences with graph convolutional networks for semantic role labeling",
        "Improving graph neural networks with simple architecture design",
        "Motifnet: A motif-based graph convolutional network for directed graphs",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Revisiting graph neural networks: All we have is low-pass filters",
        "Geom-gcn: Geometric graph convolutional networks",
        "A critical look at the evaluation of GNNs under heterophily: Are we really making progress?",
        "Gradient gating for deep multi-rate learning on graphs",
        "Discrete signal processing on graphs",
        "The Graph Neural Network Model",
        "Modeling relational data with graph convolutional networks",
        "Collective classification in network data",
        "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains",
        "Digraph inception convolutional networks",
        "Directed graph convolutional network. arXiv",
        "Understanding over-squashing and bottlenecks on graphs via curvature",
        "Composition-based multi-relational graph convolutional networks",
        "Graph attention networks",
        "The reduction of a graph to canonical form and the algebra which appears therein",
        "Representation learning on graphs with jumping knowledge networks",
        "How powerful are graph neural networks?",
        "Magnet: A neural network for directed graphs",
        "Graph neural networks: A review of methods and applications",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "None",
        "None",
        "None",
        "None",
        "None"
    ],
    "6459ac6bd68f896efa659285": [
        "Large language models in machine translation",
        "A review: Knowledge reasoning over knowledge graph",
        "Named entity recognition without gazetteers",
        "Exploring various knowledge in relation extraction",
        "A survey on semantic parsing",
        "Language models are few-shot learners",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "World's poorest nations left behind in reaching sustainable development goals, delegates stress as second committee begins general debate",
        "Strategic perspectives of corporate sustainability management to develop a sustainable organization",
        "Rebel: Relation extraction by end-to-end language generation",
        "Gpt-4 technical report",
        "Relation classification via convolutional deep neural network",
        "BART: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension",
        "Training language models to follow instructions with human feedback",
        "Proximal policy optimization algorithms",
        "2022 global sustainability study: The growth potential of environmental change",
        "Esg information extraction with cross-sectoral and multi-source adaptation based on domain-tuned language models",
        "Automated esg report analysis by joint entity and relation extraction",
        "Challenges and opportunities in esg investments",
        "None",
        "Entity linking with a knowledge base: Issues, techniques, and solutions",
        "Owl web ontology language overview",
        "Prompt Engineering Guide",
        "A practical framework for evaluating the quality of knowledge graph"
    ],
    "635753cc90e50fcafdddd9f5": [
        "Tensorflow: A system for large-scale machine learning",
        "Chameleon: Adaptive code optimization for expedited deep neural network compilation",
        "An asymptotic cost model for autoscheduling sparse tensor programs",
        "Compiler transformations for high-performance computing",
        "A deep learning based cost model for automatic code optimization",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "Loop transformations for restructuring compilers: the foundations",
        "nGraph-HE: a graph compiler for deep learning on homomorphically encrypted data",
        "Xgboost: A scalable tree boosting system",
        "TVM: An automated end-to-end optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "Efficient primitives for deep learning",
        "Cache-conscious structure layout",
        "Compiler driven data layout optimization for regular/irregular array access patterns",
        "Automatic generation of efficient sparse tensor format conversion routines",
        "Automatic memory layout transformations to optimize spatial locality in parameterized loop nests",
        "An exploration of ARM system-level cache and GPU side channels",
        "Intel nGraph: An intermediate representation, compiler, and executor for deep learning",
        "Pretraining of deep bidirectional transformers for language understanding",
        "Distilling BERT for natural language understanding",
        "IOS: Inter-operator scheduler for CNN acceleration",
        "Building an on-chip deep learning memory hierarchy brick by brick",
        "Cortex: A compiler for recursive deep learning models",
        "The CoRa tensor compiler: Compilation for ragged tensors with minimal padding",
        "An abstraction for automatic tensorized program optimization",
        "An empirical study of the effect of source-level loop transformations on compiler stability",
        "XNNPACK: Highly optimized library of floating-point neural network inference operators for ARM, WebAssembly, and x86 platforms",
        "Loop transformation recipes for code generation and autotuning",
        "Learning spatio-temporal features with 3d residual networks for action recognition",
        "Deep residual learning for image recognition",
        "A survey and critique of multiagent deep reinforcement learning",
        "Video diffusion models",
        "MKL-DNN",
        "None",
        "TASO: Optimizing deep learning computation with automatic generation of graph substitutions",
        "Reduction of cache coherence overhead by compiler data layout and loop transformation",
        "Enhancing spatial locality via data layout optimizations",
        "MLIR: Scaling compiler infrastructure for domain specific computation",
        "XLA: Tensorflow, compiled",
        "Automatic horizontal fusion for GPU kernels",
        "Optimizing memory efficiency for deep convolutional neural networks on GPUs",
        "Analytical characterization and design space exploration for optimization of CNNs",
        "CoCoPIE: Making mobile ai sweet as pie-compression-compilation co-design goes a long way",
        "Optimizing CNN model inference on CPUs",
        "Data layout transformation for enhancing data locality on NUCA chip multiprocessors",
        "Rammer: Enabling holistic deep learning compiler optimizations with rtasks",
        "Data-driven spatial locality",
        "Understanding the impact of memory access patterns in intel processors",
        "Advanced compiler design implementation",
        "DNNFusion: accelerating deep neural networks execution with advanced operator fusion",
        "None",
        "None",
        "Pytorch: An imperative style, high-performance deep learning library",
        "A flexible approach to autotuning multi-pass machine learning compilers",
        "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Structure layout optimization for multithreaded programs",
        "Relay: A new IR for machine learning frameworks",
        "Graph lowering compiler techniques for neural networks",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Proximal policy optimization algorithms",
        "Data layout optimization for portable performance",
        "Nimble: Efficiently compiling dynamic neural networks for model inference",
        "Integrating data layout transformations with the polyhedral model",
        "An affine scheduling framework for integrating data layout and loop transformations",
        "Value learning for throughput optimization of deep learning workloads",
        "Value learning for throughput optimization of deep learning workloads",
        "CODE: Compiler-based neuron-aware ensemble training",
        "Unity: Accelerating DNN training through joint optimization of algebraic transformations and parallelization",
        "Joint scheduling and layout optimization to enable multi-level vectorization",
        "Tensor comprehensions: Framework-agnostic high-performance machine learning abstractions",
        "PET: Optimizing tensor programs with partially equivalent transformations and automated corrections",
        "Unifying data, model and hybrid parallelism in deep learning via tensor tiling",
        "Tuna: A static analysis approach to optimizing deep neural networks",
        "UNIT: Unifying tensorized instruction compilation",
        "Bolt: Bridging the gap between auto-tuners and hardware-native performance",
        "Equality saturation for tensor graph superoptimization",
        "SparseTIR: Composable abstractions for sparse compilation in deep learning",
        "Lorien: Efficient deep learning workloads delivery",
        "Optimizing FPGA-based accelerator design for deep convolutional neural networks",
        "Automatic partition-based operator fusion through layer by layer optimization",
        "AKG: automatic kernel generation for neural processing units using polyhedral transformations",
        "DietCode: Automatic optimization for dynamic tensor programs",
        "Ansor: generating high-performance tensor programs for deep learning",
        "Guihai Chen USENIX Symposium on Operating Systems Design and Implementation (OSDI)",
        "Alpa: Automating inter-and Intra-Operator parallelism for distributed deep learning",
        "Tenset: A large-scale program performance dataset for learned tensor compilers",
        "OLLIE: Derivation-based tensor program optimizer",
        "Deep-learning model sparsity via tensor-with-sparsity-attribute",
        "AMOS: enabling automatic mapping for tensor computations on spatial accelerators with hardware abstraction",
        "FlexTensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "AStitch: enabling a new multi-dimensional optimization space for memory-intensive ml training and inference on modern simt architectures",
        "ROLLER: Fast and efficient tensor compilation for deep learning"
    ],
    "63a2794890e50fcafd29405f": [
        "Language models are few-shot learners",
        "Model compression",
        "Palm: Scaling language modeling with pathways",
        "Training verifiers to solve math word problems",
        "Language models show human-like content effects on reasoning",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Unified language model pre-training for natural language understanding and generation",
        "Intuition and reasoning: A dual-process perspective",
        "Making pre-trained language models better few-shot learners",
        "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
        "Knowledge distillation: A survey",
        "Pretrained transformers improve out-of-distribution robustness",
        "Distilling the knowledge in a neural network",
        "Training compute-optimal large language models",
        "Learning to solve arithmetic word problems with verb categorization",
        "Large language models can self-improve",
        "Sequencelevel knowledge distillation",
        "Large language models are zero-shot reasoners",
        "Parsing algebraic word problems into equations",
        "Mawps: A math word problem repository",
        "Explanations from large language models make small reasoners better",
        "On the advance of making language models better reasoners",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Zero-Shot Knowledge Transfer via Adversarial Belief Matching, chapter",
        "Zero-shot knowledge distillation in deep networks",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Training language models to follow instructions with human feedback",
        "Are nlp models really able to solve simple math word problems? arXiv preprint",
        "Improving language understanding by generative pre-training",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Impact of pretraining term frequencies on few-shot reasoning",
        "Solving general arithmetic word problems",
        "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
        "Automatically identifying words that can serve as labels for few-shot text classification",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "2021b. It's not just size that matters: Small language models are also few-shot learners",
        "Progressive network grafting for few-shot knowledge distillation",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Training language models to follow instructions with human feedback",
        "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
        "Attention is all you need",
        "Rationaleaugmented ensembles in language models",
        "Self-consistency improves chain of thought reasoning in language models",
        "Emergent abilities of large language models. Transactions on Machine Learning Research",
        "Chain of thought prompting elicits reasoning in large language models",
        "Gpt3mix: Leveraging large-scale language models for text augmentation",
        "Star: Bootstrapping reasoning with reasoning",
        "Calibrate before use: Improving few-shot performance of language models",
        "Understanding knowledge distillation in nonautoregressive machine translation"
    ],
    "63b3f1f890e50fcafdea0718": [
        "Alder Lake Extends Battery Life",
        "Benefits of the big.LITTLE Architecture",
        "Appropriate allocation of workloads on performance asymmetric multicore architectures via deep learning algorithms",
        "Rapid development of OS support with PMCSched for scheduling on asymmetric multicore systems",
        "A Case for NUMA-Aware Contention Management on Multicore Systems",
        "Intel Architecture Day 2021: Alde Lake, Golden Cove and Gracemont Detailed",
        "Application-to-core mapping policies to reduce memory system interference in multi-core systems",
        "Fairness via source throttling: a configurable and highperformance fairness substrate for multi-core memory systems",
        "Perf &amp; Fair: a Progress-Aware Scheduler to Enhance Performance and Fairness in SMT Multicores",
        "Contention-Aware Fair Scheduling for Asymmetric Single-ISA Multicore Systems",
        "HeteroMates: Providing high dynamic power range on client devices using heterogeneous core groups",
        "The WEKA data mining software: an update",
        "Contention-Aware Scheduling Policies for Fairness and Throughput",
        "Intel? 64 and IA-32 Architectures Software Developer's Manual Volume",
        "Optimizing software for x86 Hybrid Archiecture",
        "Bias Scheduling in Heterogeneous Multi-core Architectures",
        "Single-ISA Heterogeneous Multi-Core Architectures for Multithreaded Workload Performance",
        "Exploring Machine Learning for Thread Characterization on Heterogeneous Multiprocessors",
        "Operating system support for overlapping-ISA heterogeneous multi-core architectures",
        "A Survey of Techniques for Architecting and Managing Asymmetric Multicore Processors",
        "A Machine Learning Approach for Performance Prediction and Scheduling on Heterogeneous CPUs",
        "Thermal: Introduce the Hardware Feedback Interface for thermal and performance management",
        "Octopus-Man: QoS-driven task management for heterogeneous multicores in warehouse-scale computers",
        "Power-performance modeling on asymmetric multicores",
        "PMCTrack: Delivering Performance Monitoring Counter Support to the OS Scheduler",
        "Towards completely fair scheduling on asymmetric single-ISA multicore processors",
        "Enabling Performance Portability of Data-Parallel OpenMP Applications on Asymmetric Multicore Processors",
        "Online Energy-Efficient Fair Scheduling for Heterogeneous Multi-Cores Considering Shared Resource Contention",
        "HASS: a Scheduler for Heterogeneous Multicore Systems",
        "Scheduling heterogeneous multi-cores through Performance Impact Estimation (PIE)",
        "Fairness-aware scheduling on single-ISA heterogeneous multi-cores",
        "Providing Fairness on Shared-memory Multiprocessors via Process Scheduling",
        "A Metric-Guided Method for Discovering Impactful Features and Architectural Insights for Skylake-Based Processors",
        "COLAB: A Collaborative Multi-Factor Scheduler for Asymmetric Multicore Processors",
        "Cross-architecture Prediction Based Scheduling for Energy Efficient Execution on single-ISA Heterogeneous Chip-multiprocessors"
    ],
    "6466fafbd68f896efaeb77ac": [
        "Can language models encode perceptual structure without grounding? a case study in color",
        "Program synthesis with large language models",
        "Probing classifiers: Promises, shortcomings, and advances",
        "Analysis methods in neural language processing: A survey",
        "Climbing towards nlu: On meaning, form, and understanding in the age of data",
        "Leveraging grammar and reinforcement learning for neural program synthesis",
        "Evaluating large language models trained on code",
        "Execution-guided neural program synthesis",
        "Latent execution for neural program synthesis beyond domainspecific languages",
        "Syntactic structures",
        "Constructive design of a hierarchy of semantics of a transition system by abstract interpretation",
        "Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints",
        "Neural program meta-induction",
        "The compositionality papers",
        "Incoder: A generative model for code infilling and synthesis",
        "Measuring coding challenge competence with apps",
        "Trace-based teaching in early programming courses",
        "Designing and interpreting probes with control tasks",
        "Evaluating distributional distortion in neural language modeling",
        "Cognitive processes in program comprehension",
        "Speaking: From intention to articulation",
        "Implicit representations of meaning in neural language models",
        "Emergent world representations: Exploring a sequence model trained on a synthetic task",
        "None",
        "Competition-level code generation with alphacode",
        "Holistic evaluation of language models",
        "Further evidence of a relationship between explaining, tracing and writing skills in introductory programming",
        "Mind's eye: Grounded language model reasoning through simulation",
        "Relationships between reading, tracing and writing skills in introductory programming",
        "Language model evaluation beyond perplexity",
        "Provable limitations of acquiring meaning from ungrounded form: What will future language models understand?",
        "What do nlp researchers believe? results of the nlp community metasurvey",
        "A roadmap towards machine intelligence",
        "The debate over understanding in AI's large language models",
        "Codegen: An open large language model for code with multi-turn program synthesis",
        "Mapping language models to grounded conceptual spaces",
        "Karel the robot: a gentle introduction to the art of programming",
        "Does string-based neural MT learn source syntax?",
        "Improving neural program synthesis with inferred execution traces",
        "Notional machines and introductory programming education",
        "Neural program synthesis from diverse demonstration videos",
        "Chess as a testbed for language model state tracking",
        "Attention is all you need",
        "The formal semantics of programming languages: an introduction",
        "Transformers: State-of-the-art natural language processing"
    ],
    "646c3addd68f896efa5d165d": [
        "Language models are few-shot learners",
        "Relational multi-task learning: Modeling relations between data and tasks",
        "Meta relational learning for few-shot link prediction in knowledge graphs",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Ogb-lsc: A large-scale challenge for machine learning on graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Strategies for pre-training graph neural networks",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "Graph meta learning via local subgraphs",
        "Few-shot relational reasoning via connection subgraph pretraining",
        "Semi-supervised classification with graph convolutional networks",
        "A robustly optimized BERT pretraining approach",
        "Gcc: Graph contrastive coding for graph neural network pre-training",
        "Identifying possible rumor spreaders on twitter: A weak supervised learning approach",
        "MPNet: Masked and Permuted Pre-training for Language Understanding",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "One-shot relation learning for knowledge graphs via neighborhood aggregation and paths encoding",
        "None",
        "Task-adaptive few-shot node classification",
        "Task-adaptive few-shot node classification",
        "Graph neural networks in recommender systems: A survey",
        "One-shot relational learning for knowledge graphs",
        "One-shot relational learning for knowledge graphs",
        "Graph contrastive learning with augmentations",
        "Few-shot knowledge graph completion"
    ],
    "64702deed68f896efa51ffa0": [
        "A review on language models as knowledge bases",
        "Transfer finetuning: A BERT case study",
        "Tensor factorization for knowledge graph completion",
        "The unified medical language system (umls): integrating biomedical terminology",
        "Translating embeddings for modeling multirelational data. Advances in neural information processing systems",
        "Language models are few-shot learners",
        "Incorporating commonsense knowledge graph in pretrained models for social commonsense tasks",
        "A survey on knowledge graph embedding: Approaches, applications and benchmarks",
        "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
        "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
        "Convolutional 2d knowledge graph embeddings",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Collaborative policy learning for open knowledge graph reasoning",
        "Embedding logical queries on knowledge graphs",
        "Mining frequent patterns without candidate generation",
        "Neural knowledge acquisition via mutual attention between knowledge graph and text",
        "An endto-end model for question answering over knowledge base with cross-attention combining global knowledge",
        "Knowledge graphs. ACM Comput. Surv",
        "Metapad: Meta pattern discovery from massive text corpora",
        "How can we know what language models know?",
        "Multi-task learning for knowledge graph completion with pre-trained language models",
        "Truepie: Discovering reliable patterns in pattern-based information extraction",
        "Learning entity and relation embeddings for knowledge graph completion",
        "Self-alignment pretraining for biomedical entity representations",
        "A robustly optimized bert pretraining approach",
        "A robustly optimized bert pretraining approach",
        "Differentiating concepts and instances for knowledge graph embedding",
        "Do pretrained models benefit knowledge graph completion? a reliable evaluation and a reasonable approach",
        "Variational information bottleneck for effective low-resource fine-tuning",
        "Language models as knowledge bases? arXiv preprint",
        "Language models as knowledge bases?",
        "Okapi at trec-3",
        "Automated phrase mining from massive text corpora",
        "Open-world knowledge graph completion",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "Complex embeddings for simple link prediction",
        "Complex embeddings for simple link prediction",
        "Towards empty answers in sparql: approximating querying with rdf embedding",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Rcnet: A general framework for incorporating knowledge into word representations",
        "Luke: Deep contextualized entity representations with entity-aware self-attention",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Kgbert: Bert for knowledge graph completion",
        "QA-GNN: Reasoning with language models and knowledge graphs for question answering",
        "Empower entity set expansion via language model probing",
        "Interactive recommender system via knowledge graph-enhanced reinforcement learning",
        "Modeling polypharmacy side effects with graph convolutional networks",
        "? ? ? ? Patterns mined with FP-Growth Patterns selected by MetaPAD's contexual segmentation",
        "None",
        "None",
        "None",
        "None",
        "None",
        "None",
        "'s setting Our setting (edim, rdim, filter) Ratio",
        "None",
        "None",
        "None",
        "None",
        "None",
        "None",
        "Table 8: Performance of knowledge graph embedding models on FB60K-NYT10 and UMLS-PubMed. \"edim\" and \"rdim\" denotes the embedding size of entity and relation respectively"
    ],
    "632630ff90e50fcafdf67436": [
        "Championship value prediction",
        "Iatac: a smart predictor to turn-off l2 cache lines",
        "The GAP benchmark suite",
        "Maximizing cache performance under uncertainty",
        "A study of replacement algorithms for a virtualstorage computer",
        "Improving cache management policies using dynamic reuse distances",
        "Leeway: Addressing variability in dead-block prediction for last-level caches",
        "A dueling segmented LRU replacement algorithm with adaptive bypassing",
        "Timekeeping in the memory system: predicting and optimizing memory behavior",
        "Memory Systems: Cache, DRAM, Disk",
        "Linearizing irregular memory accesses for improved correlated prefetching",
        "Back to the future: Leveraging Belady's algorithm for improved cache replacement",
        "Rethinking Belady's algorithm to accommodate prefetching",
        "High performance cache replacement using re-reference interval prediction (RRIP)",
        "Multiperspective reuse prediction",
        "Caching strategies to improve disk system performance",
        "Cache decay: exploiting generational behavior to reduce cache leakage power",
        "Cache replacement based on reuse-distance prediction",
        "Sampling dead block prediction for last-level caches",
        "Counter-based cache replacement algorithms",
        "Dead-block prediction &amp; dead-block correlating prefetchers",
        "On the existence of a spectrum of policies that subsumes the Least Recently Used (LRU) and Least Frequently Used (LFU) policies",
        "An imitation learning approach for cache replacement",
        "Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency",
        "Best-offset hardware prefetching",
        "The LRU-K page replacement algorithm for database disk buffering",
        "Bouquet of instruction pointers: Instruction pointer classifier based hardware prefetching",
        "Instructionbased reuse distance prediction replacement policy",
        "Adaptive insertion policies for high performance caching",
        "Emulating optimal replacement with a shepherd cache",
        "The evicted-address filter: A unified mechanism to address both cache pollution and thrashing",
        "Automatically characterizing large scale program behavior",
        "Applying deep learning to the cache replacement problem",
        "EELRU: simple and effective adaptive page replacement",
        "Adaptive caches: Effective shaping of cache behavior to workloads",
        "Learning to predict by the methods of temporal differences",
        "Inter-reference gap distribution replacement: an improved replacement algorithm for setassociative caches",
        "Perceptron learning for reuse prediction",
        "Modified LRU policies for improving second-level cache behavior",
        "SHiP: Signature-based hit predictor for high performance caching",
        "Temporal prefetching without the off-chip metadata"
    ],
    "6456389bd68f896efacf6b14": [
        "Language models are few-shot learners",
        "Palm: Scaling language modeling with pathways",
        "Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models",
        "Imagenet: A large-scale hierarchical image database",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "UCI machine learning repository",
        "Openagi: When llm meets domain experts",
        "Datasheets for datasets",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Dense passage retrieval for open-domain question answering",
        "Natural Questions: a benchmark for question answering research",
        "Microsoft coco: Common objects in context",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Model cards for model reporting",
        "Gpt-4 technical report",
        "Automatic multi-step reasoning and tool-use for large language models",
        "Interactive-chain-prompting: Ambiguity resolution for crosslingual conditional generation with interaction",
        "Learning transferable visual models from natural language supervision",
        "None",
        "Susannah Young, et al. 2021. Scaling language models: Methods, analysis &amp; insights from training gopher",
        "-context retrieval-augmented language models",
        "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface",
        "Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model",
        "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
        "Matching networks for one shot learning",
        "Self-consistency improves chain of thought reasoning in language models",
        "Emergent abilities of large language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Visual chatgpt: Talking, drawing and editing with visual foundation models",
        "Unified perceptual parsing for scene understanding",
        "An explanation of in-context learning as implicit bayesian inference",
        "Star: Bootstrapping reasoning with reasoning",
        "Knowing more about questions can help: Improving calibration in question answering",
        "Passage-mask: A learnable regularization strategy for retriever-reader models",
        "Can gpt-4 perform neural architecture search? arXiv preprint"
    ],
    "648697e6d68f896efaa87966": [
        "The Surprising Power of Graph Neural Networks with Random Node Initialization",
        "Shortest Path Networks for Graph Property Prediction",
        "Breaking the Limits of Message Passing Graph Neural Networks",
        "The logical expressiveness of graph neural networks",
        "Directional Graph Networks",
        "Equivariant Subgraph Aggregation Networks",
        "Weisfeiler and Lehman Go Cellular: CW Networks",
        "Message Passing Simplicial Networks",
        "Protein function prediction via graph kernels",
        "Graph Kernels: State-of-the-Art and Future Challenges",
        "Shortest-Path Kernels on Graphs",
        "Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting",
        "Residual Gated Graph Con-vNets",
        "On the equivalence between graph isomorphism testing and function approximation with GNNs",
        "Principal Neighbourhood Aggregation for Graph Nets",
        "Reconstruction for Powerful Graph Representations",
        "Coloring Graph Neural Networks for Node Disambiguation",
        "A note on two problems in connexion with graphs",
        "Distinguishing Enzyme Structures from Non-enzymes Without Alignments",
        "Benchmarking Graph Neural Networks",
        "Long Range Graph Benchmark",
        "crowds, and markets: Reasoning about a highly connected world",
        "A Fair Comparison of Graph Neural Networks for Graph Classification",
        "How Powerful are K-hop Message Passing Graph Neural Networks",
        "Scalable kernels for graphs with continuous attributes",
        "Hierarchical Inter-Message Passing for Learning on Molecular Graphs",
        "Expressiveness and Approximation Properties of Graph Neural Networks",
        "Neural Message Passing for Quantum Chemistry",
        "Inductive Representation Learning on Large Graphs",
        "On the approximation capability of recurrent neural networks",
        "Long short-term memory",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
        "RAW-GNN: RAndom Walk Aggregation based Graph Neural Network",
        "Semi-supervised classification with graph convolutional networks",
        "Flag: Adversarial Data Augmentation for Graph Neural Networks",
        "Geodesic Graph Neural Network for Efficient Graph Representation Learning",
        "A survey on graph kernels",
        "Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning",
        "Provably Powerful Graph Networks",
        "Invariant and Equivariant Graph Networks",
        "Agent-based Graph Neural Networks",
        "Geometric deep learning on graphs and manifolds using mixture model CNNs",
        "Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks",
        "TUDataset: A collection of benchmark datasets for learning with graphs",
        "Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings",
        "Relational Pooling for Graph Representations",
        "Geometric Random Walk Graph Neural Networks via Implicit Layers",
        "Neural Networks",
        "Graph Kernels: A Survey",
        "Random Dropouts Increase the Expressiveness of Graph Neural Networks",
        "Random Features Strengthen Graph Neural Networks",
        "Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs",
        "A deep learning approach to antibiotic discovery",
        "Structure-aware Path Aggregation Graph Neural Network",
        "Graph Learning with 1D Convolutions on Random Walks",
        "Graph attention networks",
        "Building powerful and equivariant graph neural networks with structural message-passing",
        "Comparison of descriptor spaces for chemical compound retrieval and classification",
        "Moleculenet: a benchmark for molecular machine learning",
        "A Comprehensive Survey on Graph Neural Networks",
        "How Powerful are Graph Neural Networks?",
        "Deep Graph Kernels",
        "Do Transformers Really Perform Bad for Graph Representation?",
        "Hierarchical Graph Representation Learning with Differentiable Pooling",
        "Position-aware Graph Neural Networks",
        "Identity-aware graph neural networks",
        "Nested Graph Neural Networks",
        "An End-to-End Deep Learning Architecture for Graph Classification",
        "Persistence Enhanced Graph Neural Network",
        "Graph neural networks: A review of methods and applications"
    ],
    "648697e6d68f896efaa8781e": [
        "Double wins: Boosting accuracy and efficiency of graph neural networks by reliable knowledge distillation",
        "Laplacian eigenmaps and spectral techniques for embedding and clustering",
        "On self-distilling graph neural network",
        "Freekd: Freedirection knowledge distillation for graph neural networks",
        "An automatic citation indexing system",
        "Knowledge distillation: A survey",
        "Inductive representation learning on large graphs",
        "Distilling the knowledge in a neural network",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Redundancy-free computation for graph neural networks",
        "On representation knowledge distillation for graph neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "Deep geometric knowledge distillation with graphs",
        "Towards deeper graph neural networks",
        "Automating the construction of internet portals with machine learning",
        "Uniform manifold approximation and projection for dimension reduction",
        "Multi-task selfdistillation for graph-based semi-supervised learning",
        "Collective classification in network data",
        "Pitfalls of graph neural network evaluation",
        "Graph attention networks",
        "Deep graph library: A graph-centric, highly-performant package for graph neural networks",
        "Graphmixup: Improving class-imbalanced node classification on graphs by self-supervised context prediction",
        "Selfsupervised on graphs: Contrastive, generative, or predictive",
        "Knowledge distillation improves graph structure augmentation for graph neural networks",
        "Teaching yourself: Graph self-distillation on neighborhood for node classification",
        "Beyond homophily and homogeneity assumption: Relation-based frequency adaptive graph neural networks",
        "Extracting low-/high-frequency knowledge from graph neural networks and injecting it into mlps: An effective gnn-tomlp distillation framework",
        "A comprehensive survey on graph neural networks",
        "Learning efficient graph neural networks",
        "Revisiting over-smoothing in deep gcns",
        "Extract the knowledge of graph neural networks and go beyond it: An effective knowledge distillation framework",
        "Distilling knowledge from graph convolutional networks",
        "Iterative graph self-distillation",
        "Graph-less neural networks",
        "Reliable data distillation on graph convolutional network",
        "Graph neural networks: A review of methods and applications"
    ],
    "6389d70490e50fcafdffd95e": [
        "Tmo: Transparent memory offloading in datacenters",
        "Memory-harvesting vms in cloud platforms",
        "Software-defined far memory in warehouse-scale computers",
        "Pinnacle: Ibm mxt in a memory controller chip",
        "Linearly compressed pages: A low-complexity, low-latency main memory compression framework",
        "Compresso: Pragmatic main memory compression",
        "A robust main-memory compression scheme",
        "Buri: Scaling big-memory computing with hardware-based memory expansion",
        "Cmh: Compression management for improving capacity in the hybrid memory cube",
        "Transparent dual memory compression architecture",
        "Data compression accelerator on ibm power9 and z15 processors",
        "Bit-plane compression: Transforming data for better compression in many-core architectures",
        "Memzip: Exploring unconventional benefits from memory compression",
        "A case for toggle-aware compression for gpu systems",
        "CRAM: efficient hardware-based memory compression for bandwidth enhancement",
        "Interactions between compression and prefetching in chip multiprocessors",
        "Lossless and lossy memory i/o link compression for improving performance of gpgpu workloads",
        "A case for core-assisted bottleneck acceleration in gpus: Enabling flexible data compression with assist warps",
        "Enabling transparent memory-compression for commodity memory systems",
        "Attach?: Towards ideal memory compression by mitigating metadata bandwidth overheads",
        "Big data systems: A software engineering perspective",
        "Performance analysis of the memory management unit under scale-out workloads",
        "Prefetched address translation",
        "Every Walk's a Hit: Making Page Walks Single-Access Cache Hits",
        "Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism",
        "Compendia: Reducing virtualmemory costs via selective densification",
        "Perforated page: Supporting fragmented memory allocation for large pages",
        "Colt: Coalesced large-reach tlbs",
        "The gem5 simulator",
        "Graphbig: Understanding graph computing in the context of industrial solutions",
        "Last accessed on",
        "Skylake (server) -microarchitectures -intel",
        "Memory and cache latency comparisons",
        "What is memory compression in windows 10",
        "Memory allocation among processes",
        "zram: Compressed ram based block devices",
        "Memory compression brings ram doubler to os x mavericks",
        "Security Guidelines for IBM Power Systems",
        "The Linux Kernel documentation",
        "LWN.net, Last accessed on",
        "Intel 64 and IA-32 Architectures Software Developer's Manual Combined Volumes: 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D and 4. Intel",
        "Protect data of virtual machines with mktme on kvm",
        "High bandwidth decompression of variable length encoded data streams",
        "Asap7: A 7-nm finfet predictive process design kit",
        "Synopsys Design Compiler Ultra",
        "Verilator",
        "The parsec benchmark suite: Characterization and architectural implications",
        "Spec cpu2017: Next-generation compute benchmark",
        "Sparkbench: A comprehensive benchmarking suite for in memory data analytic platform spark",
        "The DaCapo benchmarks: Java benchmarking development and analysis",
        "Renaissance: A modern benchmark suite for parallel applications on the jvm",
        "Base-delta-immediate compression: Practical data compression for on-chip caches",
        "Cpack: A high-performance microprocessor cache compression algorithm",
        "Ramulator: A fast and extensible dram simulator",
        "Standard Performance Evaluation Corporation",
        "DRAMA: Exploiting DRAM Addressing for Cross-CPU Attacks",
        "Zen 3 -microarchitectures -amd",
        "Quantifying memory underutilization in hpc systems and using it to improve performance via architecture support",
        "Quantifying server memory frequency margin and using it to improve performance in hpc systems",
        "None",
        "HaRMony: Heterogeneous-Reliability Memory and QoS-Aware Energy Management on Virtualized Servers",
        "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines"
    ],
    "64389992d6db87a146dd25d0": [
        "Intel Performance Tuning Utility 3.2 Update",
        "Avoiding and identifying false sharing among threads",
        "ComDetective: A lightweight communication detection tool for threads",
        "C2C -False sharing detection in Linux perf",
        "LASER: Light, accurate sharing detection and repair",
        "ScaAnalyzer: A tool to identify memory scalability bottlenecks in parallel programs",
        "Cheetah: Detecting false sharing efficiently and effectively",
        "Featherlight on-the-fly false-sharing detection",
        "Remix: Online detection and repair of cache contention for the JVM",
        "PerfMemPlus: A tool for automatic discovery of memory performance problems",
        "A tool to analyze the performance of multithreaded programs on NUMA architectures",
        "Memphis: Finding and fixing NUMA-related performance problems on multi-core platforms",
        "MemProf: A memory profiler for NUMA multicore systems",
        "Reuse-Tracker: Fast yet accurate multicore reuse distance analyzer",
        "StructSlim: A lightweight profiler to guide structure splitting",
        "Lightweight detection of cache conflicts",
        "Simics: A full system simulation platform",
        "The gem5 simulator",
        "An infrastructure for adaptive dynamic optimization",
        "Pin: Building customized program analysis tools with dynamic instrumentation",
        "Intel microarchitecture codename Nehalem performance monitoring unit programming guide",
        "ScaAnalyzer: A tool to identify memory scalability bottlenecks in parallel programs",
        "Watching for software inefficiencies with witch",
        "Instruction-based sampling: A new performance analysis technique for AMD family 10h processors",
        "Continuous profiling: Where have all the cycles gone?",
        "An introduction to analysis and optimization with AMD codeanalyst TM performance analyzer",
        "Advanced micro devices, inc",
        "Pinpointing data locality problems using data-centric analysis",
        "IBM POWER7 performance modeling, verification, and evaluation",
        "Statistical profiling extension for ARMv8-A",
        "Arm Neoverse TM N1 Core. Version R3P1, ARM",
        "A RISC-V simulator and benchmark suite for designing and evaluating vector architectures",
        "Supporting RISC-V performance counters through performance analysis tools for Linux (perf)",
        "A tool for inter-thread/inter-core communication analysis based on HPC Toolkits",
        "Intel 64 and IA-32 Architectures Software Developer's Manual -Volume 3B: System Programming Guide, Part 2. Order Number 253669",
        "Pro-fileMe: Hardware support for instruction-level profiling on out-of-order processors",
        "AMD64 Technology. AMD64 Architecture Programmer's Manual Volume",
        "AMD research instruction based sampling toolkit",
        "Arm forge user guide version 21.0, 2021",
        "Intel X86 encoder decoder software library",
        "Extended ASM -Assembler instructions with C expression operands",
        "Perf examples",
        "Linux profiling with performance counters",
        "HPCTOOLKIT: Tools for performance analysis of optimized parallel programs",
        "Featherlight reuse-distance measurement",
        "Re: Error : IBS profiling is disabled in your BIOS",
        "Re: IBS not available on EPYC 7451 ?",
        "Rodinia: A benchmark suite for heterogeneous computing",
        "Fine-grained estimation of memory bandwidth utilization",
        "On the applicability of PEBS based online memory access tracking for heterogeneous memory management at scale",
        "On the precision of precise event based sampling",
        "Tip: Time-proportional instruction profiling",
        "Quantitative evaluation of Intel PEBS overhead for online system-noise analysis",
        "Can we trust profiling results? Understanding and fixing the inaccuracy in modern profilers",
        "Can hardware performance counters be trusted?",
        "Non-determinism and overcount on modern hardware performance counter implementations"
    ],
    "6482a38fd68f896efa8db695": [
        "Deep learning using rectified linear units (relu)",
        "Publicly Available Clinical BERT Embeddings",
        "SciBERT: A Pretrained Language Model for Scientific Text",
        "The fifth pascal recognizing textual entailment challenge",
        "Language models are few-shot learners",
        "Editing factual knowledge in language models",
        "Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation",
        "The pascal recognising textual entailment challenge",
        "PubMed 200k RCT: a dataset for sequential sentence classification in medical abstracts",
        "None",
        "Deep Bidirectional Transformers for Language Understanding",
        "Zen: Pre-training chinese text encoder enhanced by n-gram representations",
        "Taming pre-trained language models with n-gram representations for lowresource domain adaptation",
        "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models",
        "Automatically constructing a corpus of sentential paraphrases",
        "Ki-bert: Infusing knowledge context for better language and domain understanding",
        "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity",
        "Making pre-trained language models better few-shot learners",
        "Transformer feed-forward layers are key-value memories",
        "The third PASCAL recognizing textual entailment challenge",
        "Demix layers: Disentangling domains for modular language modeling",
        "Don't stop pretraining: Adapt language models to domains and tasks",
        "The second pascal recognising textual entailment challenge",
        "Bert-mk: Integrating graph contextualized knowledge into pretrained language models",
        "2021a. Towards a unified view of parameter-efficient transfer learning",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Parameter-Efficient Transfer Learning for NLP",
        "LoRA: Low-Rank Adaptation of Large Language Models",
        "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission",
        "First quora dataset release: Question pairs. data. quora. com",
        "2022a. Continual training of language models for few-shot learning",
        "Adapting a language model while preserving its general knowledge",
        "ChemProt-3.0: a global chemical biology diseases mapping",
        "Informing unsupervised pretraining with external linguistic knowledge",
        "BioBERT: A Pre-Trained Biomedical Language Representation Model for Biomedical Text Mining",
        "The winograd schema challenge",
        "Sensebert: Driving some sense into bert",
        "Base layers: Simplifying training of large, sparse models",
        "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation",
        "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
        "Kagnet: Knowledge-aware graph networks for commonsense reasoning",
        "2021a. Pretrain, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
        "K-bert: Enabling language representation with knowledge graph",
        "Zhilin Yang, and Jie Tang. 2021b. GPT Understands, Too",
        "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
        "Rodney Kinney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus",
        "Decoupled weight decay regularization",
        "Learning word vectors for sentiment analysis",
        "Locating and Editing Factual Associations in GPT",
        "True few-shot learning with language models. Advances in Neural Information Processing Systems",
        "Knowledge enhanced contextual word representations",
        "Adapterfusion: Non-destructive task composition for transfer learning",
        "Adapterhub: A framework for adapting transformers",
        "MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Hash layers for large sparse models",
        "It's not just size that matters: Small language models are also fewshot learners",
        "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer",
        "Editable neural networks",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "None",
        "Ernie: Enhanced representation through knowledge integration",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "FEVER: a large-scale dataset for fact extraction and VERification",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "2021a. K-adapter: Infusing knowledge into pre-trained models with adapters",
        "Kepler: A unified model for knowledge embedding and pre-trained language representation",
        "Adamix: Mixtureof-adaptations for parameter-efficient model tuning",
        "Neural network acceptability judgments",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model",
        "M6-t: Exploring sparse expert models and beyond",
        "StyleDGPT: Stylized Response Generation with Pretrained Language Models. ACL Anthology",
        "Learning and evaluating general linguistic intelligence",
        "DIALOGPT: Large-Scale Generative Pre-training for Conversational Response Generation",
        "Ernie: Enhanced language representation with informative entities",
        "Modifying memories in transformer models",
        "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books",
        "Taming sparsely activated transformer with stochastic experts"
    ],
    "640e949e90e50fcafd114d4b": [
        "Eigenvalues and expanders",
        "Explicit expanders of every degree and size",
        "On the bottleneck of graph neural networks and its practical implications",
        "Directional graph networks",
        "Weisfeiler and lehman go cellular: Cw networks",
        "Improving graph neural network expressivity via subgraph isomorphism counting",
        "Residual gated graph convnets",
        "Structureaware transformer for graph representation learning",
        "Nagphormer: Neighborhood aggregation graph transformer for node classification in large graphs",
        "Rethinking attention with performers",
        "Principal neighbourhood aggregation for graph nets",
        "Expander graph propagation",
        "Convolutional neural networks on graphs with fast localized spectral filtering. Advances in neural information processing systems",
        "A generalization of transformer networks to graphs",
        "Benchmarking graph neural networks",
        "Graph neural networks with learnable structural and positional representations",
        "Long range graph benchmark",
        "Hierarchical intermessage passing for learning on molecular graphs",
        "A largescale database for graph representation learning",
        "A proof of Alon's second eigenvalue conjecture",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "OGB-LSC: A large-scale challenge for machine learning on graphs",
        "Edgeaugmented graph transformers: Global self-attention is enough for graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Rethinking graph transformers with spectral attention",
        "Ramanujan graphs",
        "Inferring from references with differences for semi-supervised node classification on graphs",
        "Explicit group-theoretic constructions of combinatorial schemes and their applications in the construction of expanders and concentrators",
        "Encoding graph structure in transformers",
        "Weisfeiler and leman go neural: Higher-order graph neural networks",
        "Relational pooling for graph representations",
        "Query-driven active surveying for collective classification",
        "Graph neural networks exponentially lose expressive power for node classification",
        "Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec",
        "Recipe for a general, powerful, scalable graph transformer",
        "Random features strengthen graph neural networks",
        "Pitfalls of graph neural network evaluation",
        "Efficient transformers: A survey",
        "Graph learning with 1d convolutions on random walks",
        "Understanding over-squashing and bottlenecks on graphs via curvature",
        "Attention is all you need",
        "Graph attention networks",
        "How powerful are graph neural networks?",
        "Do transformers really perform bad for graph representation?",
        "Are transformers universal approximators of sequence-to-sequence functions?",
        "O(n) connections are expressive enough: Universal approximability of sparse transformers",
        "Big bird: Transformers for longer sequences",
        "Graph-bert: Only attention is needed for learning graph representations",
        "Gophormer: Ego-graph transformer for node classification",
        "Learning on large-scale text-attributed graphs via variational inference",
        "From stars to subgraphs: Uplifting any GNN with local structure awareness"
    ],
    "63dcdb422c26941cf00b6136": [
        "Open source parallel corpus of opus",
        "Massively multilingual neural machine translation in the wild: Findings and challenges",
        "What is the state of neural network pruning? Proceedings of machine learning and systems",
        "Language models are few-shot learners",
        "The lottery ticket hypothesis for pre-trained bert networks",
        "Sparsity winning twice: Better robust generalization from more efficient training",
        "Hotprotein: A novel framework for protein thermostability prediction and editing",
        "On lazy training in differentiable programming",
        "Scaling language modeling with pathways",
        "Progressive skeletonization: Trimming more fat from a network at initialization",
        "Imagenet: A large-scale hierarchical image database",
        "Sparse networks from scratch: Faster training without losing performance",
        "A winning hand: Compressing deep networks can improve out-of-distribution robustness",
        "Learning to prune deep neural networks via layer-wise optimal brain surgeon",
        "Rigging the lottery: Making all tickets winners",
        "Improving model selection by nonconvergent methods",
        "The lottery ticket hypothesis: Finding sparse, trainable neural networks",
        "The early phase of neural network training",
        "Pruning neural networks at initialization: Why are we missing the mark?",
        "M-fac: Efficient matrix-free approximations of second-order information",
        "The state of sparsity in deep neural networks",
        "Sparse dnns with improved adversarial robustness",
        "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",
        "Second order derivatives for network pruning: Optimal brain surgeon",
        "Distilling the knowledge in a neural network",
        "Learning inverse folding from millions of predicted structures",
        "Meltome atlas-thermal proteome stability across the tree of life",
        "Towards more effective and economic sparsely-activated model",
        "Adam: A method for stochastic optimization",
        "Mawps: A math word problem repository",
        "Learning multiple layers of features from tiny images",
        "The optimal bert surgeon: Scalable and accurate second-order pruning for large language models",
        "Soft threshold weight reparameterization for learnable sparsity",
        "Block pruning for faster transformers",
        "Race: Large-scale reading comprehension dataset from examinations",
        "The mnist database of handwritten digits",
        "Optimal brain damage",
        "SNIP: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY",
        "The winograd schema challenge",
        "Dynamic model pruning with feedback",
        "Ten lessons we have learned in the new\" sparseland\": A short handbook for sparse neural network researchers",
        "Deep ensembling with no overhead for either training or testing: The all-round blessings of dynamic sparsity",
        "Sparse training via boosting pruning plasticity with neuroregeneration",
        "Do we actually need dense over-parameterization? in-time over-parameterization in sparse training",
        "The unreasonable effectiveness of random pruning: Return of the most naive baseline for sparse training",
        "A robustly optimized bert pretraining approach",
        "Multilingual denoising pre-training for neural machine translation",
        "Rethinking the value of network pruning",
        "Learning sparse neural networks through l 0 regularization",
        "Autopruner: An end-to-end trainable filter pruning method for efficient deep model inference",
        "A kernel-based view of language model fine-tuning",
        "A diverse corpus for evaluating and developing english math word problem solvers",
        "Studying the plasticity in deep convolutional neural networks using random pruning",
        "Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science",
        "Variational dropout sparsifies deep neural networks",
        "Pruning convolutional neural networks for resource efficient inference",
        "Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization",
        "Using relevance to reduce network size automatically",
        "What is being transferred in transfer learning? Advances in neural information processing systems",
        "fairseq: A fast, extensible toolkit for sequence modeling",
        "Training adversarially robust sparse networks via bayesian connectivity sampling",
        "Are nlp models really able to solve simple math word problems? arXiv preprint",
        "Hierarchical textconditional image generation with clip latents",
        "Evaluating protein transfer learning with tape",
        "Comparing rewinding and fine-tuning in neural network pruning",
        "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences",
        "Winogrande: An adversarial winograd schema challenge at scale",
        "Movement pruning: Adaptive sparsity by fine-tuning",
        "Winning the lottery with continuous sparsification",
        "Powerpropagation: A sparsity inducing weight reparameterisation",
        "Woodfisher: Efficient second-order approximation for neural network compression",
        "Super-convergence: Very fast training of neural networks using large learning rates. In Artificial intelligence and machine learning for multi-domain operations applications",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
        "Pruning neural networks without any data by iteratively conserving synaptic flow",
        "Multilingual translation with extensible multilingual pretraining and finetuning",
        "Attention is all you need",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "Eigendamage: Structured pruning in the kronecker-factored eigenbasis",
        "Picking winning tickets before training by preserving gradient flow",
        "Chain of thought prompting elicits reasoning in large language models",
        "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time",
        "Rethinking network pruning-under the pre-train and fine-tune paradigm",
        "Lottery pools: Winning more by interpolating tickets without increasing training or inference cost",
        "Coca: Contrastive captioners are image-text foundation models",
        "Prune once for all: Sparse pre-trained language models",
        "Mlprune: Multi-layer pruning for automated neural network compression",
        "Scaling vision transformers",
        "Can subnetwork structure be the key to out-of-distribution generalization",
        "Graphto-tree learning for solving math word problems",
        "Platon: Pruning large transformer models with upper confidence bound of weight importance",
        "When do you need billions of words of pretraining data?",
        "To prune, or not to prune: exploring the efficacy of pruning for model compression",
        "fc1.weight L.5.fc2.weight L.6.self_attn.k_proj.weight L.6.self_attn.v_proj.weight L.6.self_attn.q_proj.weight L.6.self_attn.out_proj.weight L.6.fc1.weight L.6.fc2.weight L.7.self_attn.k_proj.weight L.7.self_attn.v_proj.weight L.7.self_attn.q_proj.weight L.7.self_attn.out_proj.weight L.7.fc1.weight L.7.fc2.weight L.8.self_attn"
    ],
    "6464b048d68f896efa35a285": [
        "Masked siamese networks for label-efficient learning",
        "Data2vec: A general framework for self-supervised learning in speech, vision and language",
        "Beit: Bert pre-training of image transformers",
        "Blind super-resolution kernel estimation using an internal-gan",
        "Representation learning: A review and new perspectives",
        "Learning deep architectures for ai",
        "Greedy layer-wise training of deep networks",
        "Began: Boundary equilibrium generative adversarial networks",
        "Emerging properties in self-supervised vision transformers",
        "Adversarial text generation via feature-mover's distance",
        "Generative pretraining from pixels",
        "A simple framework for contrastive learning of visual representations",
        "Context autoencoder for self-supervised representation learning",
        "An empirical study of training self-supervised vision transformers",
        "Stargan: Unified generative adversarial networks for multi-domain image-to-image translation",
        "Adversarial feature learning",
        "Cswin transformer: A general vision transformer backbone with cross-shaped windows",
        "Peco: Perceptual codebook for bert pre-training of vision transformers",
        "Bootstrapped masked autoencoders for vision bert pretraining",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Stacked convolutional denoising autoencoders for feature representation",
        "Are large-scale datasets necessary for self-supervised pre",
        "Maskgan: Better text generation via filling in the",
        "Large-scale adversarial training for visionand-language representation learning",
        "Generative adversarial networks",
        "Bootstrap your own latent-a new approach to self-supervised learning",
        "Masked autoencoders are scalable vision learners",
        "Momentum contrast for unsupervised visual representation learning",
        "Mask r-cnn",
        "Deep residual learning for image recognition",
        "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "Benchmarking neural network robustness to common corruptions and perturbations",
        "Natural adversarial examples",
        "Reducing the dimensionality of data with neural networks",
        "Image-to-image translation with conditional adversarial networks",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Adam: A method for stochastic optimization",
        "Learning representations for automatic colorization",
        "Photorealistic single image super-resolution using a generative adversarial network",
        "Mpvit: Multi-path vision transformer for dense prediction",
        "Unicoder-vl: A universal encoder for vision and language by cross-modal pre-training",
        "Visualbert: A simple and performant baseline for vision and language",
        "Benchmarking detection transfer learning with vision transformers",
        "High-resolution photorealistic image translation in real-time: A laplacian pyramid translation network",
        "Feature pyramid networks for object detection",
        "Microsoft coco: Common objects in context",
        "Pd-gan: Probabilistic diverse gan for image inpainting",
        "A robustly optimized bert pretraining approach",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Sgdr: Stochastic gradient descent with warm restarts",
        "Least squares generative adversarial networks",
        "Towards robust vision transformer",
        "Unsupervised learning of visual representations by solving jigsaw puzzles",
        "Context encoders: Feature learning by inpainting",
        "Unsupervised representation learning with deep convolutional generative adversarial networks",
        "Improving language understanding by generative pre-training",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Three things everyone should know about vision transformers",
        "Recent advances in autoencoder-based representation learning",
        "Attention is all you need",
        "Extracting and composing robust features with denoising autoencoders",
        "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",
        "Learning robust global representations by penalizing local predictive power",
        "Masked feature prediction for self-supervised visual pre-training",
        "Tedigan: Text-guided diverse face image generation and manipulation",
        "Unified perceptual parsing for scene understanding",
        "Image denoising and inpainting with deep neural networks",
        "Simmim: A simple framework for masked image modeling",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Colorful image colorization",
        "Adversarial feature matching for text generation",
        "Energybased generative adversarial networks",
        "General facial representation learning in a visual-linguistic manner",
        "Scene parsing through ade20k dataset",
        "ibot: Image bert pre-training with online tokenizer"
    ],
    "63dcdb422c26941cf00b613b": [
        "Diffusion-convolutional neural networks",
        "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
        "Scaling graph neural networks with approximate pagerank",
        "Geometric deep learning: going beyond euclidean data",
        "GRAND: graph neural diffusion",
        "Beltrami flow and neural diffusion on graphs",
        "NAGphormer: A tokenized graph transformer for node classification in large graphs",
        "Simple and deep graph convolutional networks",
        "Neural ordinary differential equations",
        "A simple framework for contrastive learning of visual representations",
        "Iterative deep graph learning for graph neural networks: Better and robust node embeddings",
        "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Rethinking attention with performers",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "A generalization of transformer networks to graphs",
        "PDE-GCN: novel architectures for graph neural networks motivated by partial differential equations",
        "Slaps: Self-supervision improves structure learning for graph neural networks",
        "Learning discrete structures for graph neural networks",
        "Diffusion processes on graphs and the averaging principle. The Annals of probability",
        "Learning dynamical systems from data: A simple crossvalidation perspective, part i: Parametric kernel flows",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Kernelbased inference of functions over graphs",
        "Semi-supervised learning with graph learning-convolutional networks",
        "Transformers are rnns: Fast autoregressive transformers with linear attention",
        "Semi-supervised classification with graph convolutional networks",
        "Diffusion improves graph learning",
        "Artificial neural networks for solving ordinary and partial differential equations",
        "Variational inference for training graph neural networks in low-data regime through joint structure-label estimation",
        "A unified view on graph neural networks as graph signal denoising",
        "The nonlinear heat equation on dense graphs and graph limits",
        "Scikit-learn: Machine learning in python",
        "Meta pseudo labels",
        "Convex analysis",
        "The Laplacian on a Riemannian manifold: an introduction to analysis on manifolds",
        "Pytorch geometric temporal: Spatiotemporal signal processing with neural machine learning models",
        "The graph neural network model",
        "Collective classification in network data",
        "Adaptive graph diffusion networks",
        "GRAND++: graph neural diffusion with a source term",
        "Netlsd: Hearing the shape of a graph",
        "Attention is all you need",
        "Graph attention networks",
        "Dissecting the diffusion process in linear graph convolutional networks",
        "Dynamic graph CNN for learning on point clouds",
        "ACMP: Allen-cahn message passing with attractive and repulsive forces for graph neural networks",
        "Deep learning via semisupervised embedding",
        "Simplifying graph convolutional networks",
        "Handling distribution shifts on graphs: An invariance perspective",
        "Nodeformer: A scalable graph structure learning transformer for node classification",
        "Graph convolutional networks using heat kernel for semi-supervised learning",
        "Geometric knowledge distillation: Topology compression for graph neural networks",
        "Graph neural networks are inherently good generalizers: Insights by bridging GNNs and MLPs",
        "Graph neural networks inspired by classical iterative algorithms",
        "Revisiting semi-supervised learning with graph embeddings",
        "Do transformers really perform bad for graph representation?",
        "Big bird: Transformers for longer sequences",
        "Graphsaint: Graph sampling based inductive learning method",
        "Graph-bert: Only attention is needed for learning graph representations",
        "Scalegcn: Efficient and effective graph convolution via channel-wise scale transformation",
        "Bayesian graph convolutional neural networks for semi-supervised classification",
        "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting",
        "Learning with local and global consistency",
        "Semi-supervised learning using gaussian fields and harmonic functions",
        "A FURTHER RELATED WORKS AND CONNECTION WITH OURS We discuss more related works that associate with ours from different aspects to properly position this paper with different areas. Based on this, we further shed more lights on the technical contributions of our work and its potential impact in different communities",
        "(2021a) and its follow-ups (Chamberlain et al., 2021b; Thorpe et al., 2022) reveal the analogy between the discretization of diffusion process and GNNs' feedforward rules, and devise new (continuous) models on graphs whose training requires PDE-solving tools. A concurrent work (Wang et al., 2023) explores how to derive neural networks from gradient flows and proposes Allen-Cahn Message Passing that combines attractive and repulsive effects"
    ],
    "648000a9d68f896efaa12362": [
        "None",
        "Emergence of scaling in random networks",
        "Graph convolution for semisupervised classification: Improved linear separability and out-of-distribution generalization",
        "Effects of graph convolutions in deep networks",
        "A theory of learning from different domains",
        "Domain adaptation-can quantity compensate for quality?",
        "Size-invariant graph representations for graph classification extrapolations",
        "Displacement interpolation using lagrangian mass transport",
        "Graph domain adaptation: A generative view",
        "Machine learning on graphs: A model and comprehensive taxonomy",
        "Tree mover's distance: Bridging graph metrics and stability of graph neural networks",
        "Joint distribution optimal transportation for domain adaptation",
        "Contextual stochastic block models",
        "Domain-adversarial training of neural networks",
        "A kernel two-sample test",
        "A graph out-of-distribution benchmark",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then propagate: Graph neural networks meet personalized pagerank",
        "Wilds: A benchmark of in-the-wild distribution shifts",
        "Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark",
        "Lamda: Label matching deep domain adaptation",
        "Learning transferable features with deep adaptation networks",
        "Conditional adversarial domain adaptation",
        "Subgroup generalization and fairness of graph neural networks",
        "Is homophily a necessity for graph neural networks",
        "Chembl: towards direct deposition of bioassay data",
        "M?moire sur la th?orie des d?blais et des remblais",
        "Collective classification in network data",
        "Wasserstein distance guided representation learning for domain adaptation",
        "Arnetminer: extraction and mining of academic social networks",
        "Graph attention networks",
        "Unsupervised domain adaptive graph convolutional networks",
        "Handling distribution shifts on graphs: An invariance perspective",
        "How powerful are graph neural networks?",
        "Learning substructure invariance for out-of-distribution molecular representations",
        "Learning substructure invariance for out-of-distribution molecular representations",
        "From local structures to size generalization in graph neural networks",
        "Graph domain adaptation via theory-grounded spectral regularization",
        "Central moment discrepancy (cmd) for domain-invariant representation learning",
        "Graphsaint: Graph sampling based inductive learning method",
        "Domain adaptive network embedding",
        "On learning invariant representations for domain adaptation",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Shift-robust gnns: Overcoming the limitations of localized graph training data",
        "Table 6: Full result of supervised node classification. We report mean and standard deviation on Micro and Macro F1",
        "1 Macro-F1 Micro-F1 Macro-F1 Micro-F1 Macro-F1 Base model 68.1 ? 2.1 68.2 ? 2",
        "None",
        "Table 7: Additional Time and Space Complexity of GCONDA"
    ],
    "6385788590e50fcafdf49aef": [
        "Language Models are Few-Shot Learners",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "A neural multi-digraph model for Chinese NER with gazetteers",
        "Rethinking boundaries: End-to-end recognition of discontinuous mentions with pointer networks",
        "None",
        "A Lexicon-Based Graph Neural Network for Chinese NER",
        "MDETR-modulated detection for endto-end multi-modal understanding",
        "Nested Named Entity Recognition Revisited",
        "UNIFIEDQA: Crossing Format Boundaries with a Single QA System",
        "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data",
        "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "The Third International Chinese Language Processing Bakeoff: Word Segmentation and Named Entity Recognition",
        "A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition",
        "Unified named entity recognition as wordword relation classification",
        "Unified named entity recognition as wordword relation classification",
        "2022c. Grounded language-image pre-training",
        "FLAT: Chinese NER Using Flat-Lattice Transformer",
        "2021a. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter",
        "An Encoding Strategy Based Word-Character LSTM for Chinese NER",
        "Decoupled Weight Decay Regularization",
        "12-in-1: Multi-task vision and language representation learning",
        "2022a. A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
        "What Makes Pre-trained Language Models Better Zero/Few-shot Learners?",
        "Simplify the Usage of Lexicon in Chinese NER",
        "SDA: Simple Discrete Augmentation for Contrastive Sentence Representation Learning",
        "In-BoXBART: Get Instructions into Biomedical Multi-Task Learning",
        "Towards Robust Linguistic Analysis using OntoNotes",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition",
        "NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task-Next Sentence Prediction",
        "TNT: Text Normalization based Pre-training of Transformers for Content Moderation",
        "BERT-Beta: A Proactive Probabilistic Approach to Text Moderation",
        "Attention is all you need",
        "Super-NaturalInstructions:Generalization via Declarative Instructions on 1600+ Tasks",
        "An explanation of in-context learning as implicit bayesian inference",
        "CLUENER2020: finegrained named entity recognition dataset and benchmark for chinese",
        "TENER: adapting transformer encoder for named entity recognition",
        "A Unified Generative Framework for Various NER Subtasks",
        "Named Entity Recognition as Dependency Parsing",
        "Domain-Specific NER via Retrieving Correlated Samples",
        "Chinese NER Using Lattice LSTM"
    ],
    "6391890790e50fcafd2b45f2": [
        "Gremlin",
        "TinkerPop",
        "GraphLearn",
        "TensorFlow: A System for Large-Scale Machine Learning",
        "Balanced graph partitioning",
        "A Computational Study of the Job-Shop Scheduling Problem",
        "Giraph: Large-scale graph processing infrastructure on hadoop",
        "A faster algorithm for betweenness centrality",
        "DGCL: an efficient communication library for distributed GNN training",
        "A Review of Machine Scheduling: Complexity, Algorithms and Approximability",
        "G-Miner: an efficient task-oriented graph mining system",
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Stochastic Training of Graph Convolutional Networks with Variance Reduction",
        "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning",
        "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks",
        "Resource central: Understanding and predicting workloads for improved resource management in large cloud platforms",
        "Work-Efficient Parallel GPU Methods for Single-Source Shortest Paths",
        "Paragon: QoS-aware scheduling for heterogeneous datacenters",
        "Quasar: resource-efficient and QoS-aware cluster management",
        "Fast Graph Representation Learning with PyTorch Geometric",
        "MapGraph: A High Level API for Fast Development of High Performance Graph Analytics on GPUs",
        "P3: Distributed Deep Graph Learning at Scale",
        "Utilising Graph Machine Learning within Drug Discovery and Development",
        "Firmament: Fast, centralized cluster scheduling at scale",
        "Better Approximation Guarantees for Job-shop Scheduling",
        "PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs",
        "Multi-resource packing for cluster schedulers",
        "Altruistic scheduling in multi-resource clusters",
        "GRAPHENE: Packing and Dependency-Aware Scheduling for Data-Parallel Clusters",
        "Inductive Representation Learning on Large Graphs",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "FeatGraph: A Flexible and Efficient Backend for Graph Neural Network Systems",
        "Adaptive Sampling Towards Fast Graph Representation Learning",
        "Quincy: fair scheduling for distributed computing clusters",
        "Accelerating graph sampling for graph machine learning using GPUs",
        "Improving the Accuracy, Scalability, and Performance of Graph Neural Networks with Roc",
        "Beyond Data and Model Parallelism for Deep Neural Networks",
        "Improving resource utilization by timely fine-grained scheduling",
        "MIFO: A Query-Semantic Aware Resource Allocation Policy",
        "A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs",
        "CuSha: vertex-centric graph processing on GPUs",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Fast Haar Transforms for Graph Neural Networks",
        "Graph Neural Network Based Coarse-Grained Mapping Prediction",
        "PaGraph: Scaling GNN training on large graphs via computation-aware caching",
        "Elasecutor: Elastic Executor Scheduling in Data Analytics Systems",
        "NeuGraph: Parallel Deep Neural Network Computation on Large Graphs",
        "Pregel: a system for largescale graph processing",
        "The More You Know: Using Knowledge Graphs for Image Classification",
        "Scalable GPU graph traversal",
        "Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks",
        "Do We Need Specialized Graph Databases? Benchmarking Real-Time Social Networking Applications",
        "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN",
        "DeepWalk: online learning of social representations",
        "Autopilot: workload autoscaling at Google",
        "Few-Shot Learning with Graph Neural Networks",
        "Scalable Graph Neural Network Training: The Case for Sampling",
        "ROSE: Cluster Resource Scheduling via Speculative Over-Subscription",
        "Dorylus: Affordable, Scalable, and Accurate GNN Training with Distributed CPU Servers and Serverless Threads",
        "FENNEL: streaming graph partitioning for massive scale graphs",
        "TetriSched: global rescheduling with adaptive plan-ahead in dynamic heterogeneous clusters",
        "Graph Attention Networks",
        "Microsoft Academic Graph: When experts are not enough",
        "Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs",
        "Gunrock: a high-performance graph processing library on the GPU",
        "Deep Reasoning with Knowledge Graph for Social Relationship Understanding",
        "Vertex-Centric Visual Programming for Graph Neural Networks",
        "Seastar: vertex-centric programming for graph neural networks",
        "How Powerful are Graph Neural Networks?",
        "Blogel: A Block-Centric Framework for Distributed Computation on Real-World Graphs",
        "The Thirty-First Innovative Applications of Artificial Intelligence Conference",
        "OpERA: opportunistic and efficient resource allocation in Hadoop YARN by harnessing idle resources",
        "Graph Convolutional Neural Networks for Web-Scale Recommender Systems",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "AGL: A Scalable System for Industrial-purpose Graph Machine Learning",
        "DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs",
        "Medusa: Simplified Graph Processing on GPUs",
        "AliGraph: A Comprehensive Graph Neural Network Platform",
        "Gemini: A Computation-Centric Distributed Graph Processing System"
    ],
    "64893b17d68f896efa9826b7": [
        "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
        "Semantic parsing on freebase from question-answer pairs",
        "Language models are few-shot learners",
        "Evaluation of text generation: A survey",
        "Palm: Scaling language modeling with pathways",
        "GLM: General language model pretraining with autoregressive blank infilling",
        "ELI5: Long Form Question Answering",
        "Retrieval augmented language model pre-training",
        "Instruction induction: From few examples to natural language task descriptions",
        "Unsupervised Dense Information Retrieval with Contrastive Learning",
        "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
        "Few-shot learning with retrieval augmented language models",
        "Survey of hallucination in natural language generation",
        "Dense Passage Retrieval for Open-Domain Question Answering",
        "Natural questions: a benchmark for question answering research",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Rouge: A package for automatic evaluation of summaries",
        "The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
        "Self-supervised learning: Generative or contrastive",
        "GPT understands, too",
        "Chatterbots, tinymuds, and the turing test: Entering the loebner prize competition",
        "Noisy Channel Language Model Prompting for Few-Shot Text Classification",
        "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? arXiv preprint",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
        "Training language models to follow instructions with human feedback",
        "Bleu: a method for automatic evaluation of machine translation",
        "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
        "How Much Knowledge Can You Pack Into the Parameters of a Language Model",
        "Learning To Retrieve Prompts for In-Context Learning",
        "A survey of evaluation metrics used for NLG systems",
        "Bloom: A 176b-parameter open-access multilingual language model",
        "Learning to summarize with human feedback",
        "Selective annotation makes language models better few-shot learners",
        "An Explanation of In-context Learning as Implicit Bayesian Inference",
        "Glm-130b: An open bilingual pre-trained model",
        "Opt: Open pre-trained transformer language models",
        "BERTScore: Evaluating Text Generation with BERT",
        "Calibrate before use: Improving few-shot performance of language models",
        "In some cases, state officials wanted the capital located in the geographic center of their states. Jefferson City and Pierre were chosen as capitals of Missouri and South Dakota respectively for this reason. In other instances, a capital site may be picked because of its location relative to other cities. Florida chose the city of Tallahassee to be its capital in 1824 because it was situated halfway between St. Augustine and Pensacola, the state's two largest cities at the time. Some capital locations were picked because they were centers of trade and transportation",
        "Ottawa and Washington became capital cities. Sometimes, the location of a new capital city was chosen to terminate actual or potential squabbling between various entities",
        "However a country decides on its capital, that city becomes an important symbol of nationhood",
        "State capitals are important because they house the governments of their states, with a meeting place for the state legislature. Many meeting buildings are called capitols, which are distinguished from capitals in that capitol refers to buildings while capital always references a city. Cities are chosen to be the capital for differing reasons, sometimes because it was located in the center of the state, like Jefferson City, or was a center of commerce, like Albany. Today, many capitals are not the largest city in their states and can be overshadowed by bigger cities",
        "Capital cities: How are they chosen and what do they represent?",
        "Answer The reasons why cities are chosen as capitals vary from state to state. In some cases, state officials wanted the capital located in the geographic center of their state[1][4], while in other instances, a capital site may be picked because of its location relative to other cities[1]. Some capital cities were picked because they were centers of trade and transportation[1], or to represent the unity of a new state[1][2][4]. In some cases, the location of a new capital city was chosen to terminate actual or potential squabbling between various entities[1][2]. Cities are chosen to be the capital because they house the governments of their states, with a meeting place for the state legislature[1][4]. Today, many capitals are not the largest city in their states and can be overshadowed by bigger cities",
        "References from Perplexity AI [1] Sigma bond is a chemical bond formed by the linear or co-axial overlapping of the atomic orbitals of two atoms. A pi bond is a type of covalent bond",
        "The sigma bond is stronger than the Pi bond, according to quantum mechanics, since the orbital paths of Pi bonds are parallel, resulting in less overlap between",
        "A ? bond has cylindrical symmetry; a ? bond has a nodal plane that includes the bond axis",
        "What is the difference between Sigma Bond and pi Bond? ? Sigma bonds are formed by head to head overlapping of orbitals, whereas pi bonds are formed by the lateral overlapping. ? Sigma bonds are stronger than pi bonds. ? Sigma bonds can be formed between both s and p orbitals whereas pi bonds are mostly formed between p and d orbitals. ? The single covalent bonds between atoms are sigma bonds. When there are multiple bonds between atoms, pi bonds can be seen. ? pi bonds result in unsaturated molecules",
        "is a bond formed by the overlap of orbitals in an end-to-end fashion, with the electron density concentrated between the nuclei of the bonding atoms. A pi bond (? bond) is a bond formed by the overlap of orbitals in a side-by-side fashion with the electron density",
        "the plane of electron density), where electron density is greatest. The end-to-end axial overlap of electrons attracts the nuclei to form a strong bond. In a pi bond, the p-orbitals overlap side-to-side above and below the nuclei (equatorial plane), so this attraction is more of a \"sideways"
    ],
    "646aeca9d68f896efa05a572": [
        "Language models are few-shot learners",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Adaptive recursive neural network for target-dependent Twitter sentiment classification",
        "On the robustness of aspect-based sentiment analysis: Rethinking model, data, and training",
        "2022a. Mutual disentanglement learning for joint fine-grained sentiment classification and controllable text generation",
        "2022b. Inheriting the wisdom of predecessors: A multiplex cascade framework for unified aspect-based sentiment analysis",
        "Retrofitting structure-aware transformer language model for end tasks",
        "2021a. Nonautoregressive encoder-decoder neural framework for end-to-end aspect-based sentiment triplet extraction",
        "2021b. Enriching contextualized language model from knowledge graph for biomedical information extraction",
        "Lasuie: Unifying information extraction with latent adaptive structure-aware generative language model",
        "Matching structure for dual learning",
        "Latent emotion memory for multi-label emotion classification",
        "Complexity-based prompting for multi-step reasoning",
        "Transformation networks for target-oriented sentiment classification",
        "On the advance of making language models better reasoners",
        "Learning implicit sentiment in aspect-based sentiment analysis with supervised contrastive pre-training",
        "Generated knowledge prompting for commonsense reasoning",
        "Training language models to follow instructions with human feedback",
        "Opinion mining and sentiment analysis",
        "Prompting contrastive explanations for commonsense reasoning tasks",
        "Knowing what, how and why: A near complete solution for aspect-based sentiment analysis",
        "SemEval-2014 task 4: Aspect based sentiment analysis",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Adapt or get left behind: Domain adaptation through BERT language model finetuning for aspect-target sentiment classification",
        "SemEval-2015 task 9: CLIPEval implicit polarity of events. In Proceedings of the 9th International Workshop on Semantic Evaluation",
        "Effective token graph modeling using a novel labeling strategy for structured sentiment analysis",
        "Relational graph attention network for aspect-based sentiment analysis",
        "2022a. Causal intervention improves implicit sentiment analysis",
        "Coupled multi-layer attentions for co-extraction of aspect and opinion terms",
        "Selfconsistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Mastering the explicit opinion-role interaction: Syntax-aided neural transition system for unified opinion role labeling",
        "Learn from syntax: Improving pair-wise aspect and opinion terms extraction with rich syntactic knowledge",
        "Aspect based sentiment analysis with gated convolutional networks",
        "Automatic chain of thought prompting in large language models",
        "Least-to-most prompting enables complex reasoning in large language models",
        "A Qualitative Results Here we present several pieces of real testing examples. We compare THOR with the vanilla prompting method, and the zero-shot CoT method (Prompt + 'Lets think step by step')"
    ],
    "64741c33d68f896efaa7b708": [
        "Using large language models to simulate multiple humans and replicate human subject studies",
        "Concrete problems in ai safety",
        "Language models as agent models",
        "Out of one, many: Using language models to simulate human samples",
        "A general language assistant as a laboratory for alignment",
        "Training a helpful and harmless assistant with reinforcement learning from human feedback",
        "Constitutional ai: Harmlessness from ai feedback",
        "On the opportunities and risks of foundation models",
        "Language models are few-shot learners",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Deep reinforcement learning from human preferences",
        "Reward tampering problems and solutions in reinforcement learning: A causal influence diagram perspective",
        "Artificial intelligence, values, and alignment. Minds and machines",
        "Scaling laws for reward model overoptimization",
        "Simple contrastive learning of sentence embeddings",
        "RealTox-icityPrompts: Evaluating neural toxic degeneration in language models",
        "Improving alignment of dialogue agents via targeted human judgements",
        "Problems of monetary management: the UK experience",
        "Pile of law: Learning responsible data filtering from the law and a 256gb open-source legal dataset",
        "Ai safety via debate",
        "Human-centric dialog training via offline reinforcement learning",
        "Alignment of language agents",
        "Siamese neural networks for one-shot image recognition",
        "Avoiding side effects by considering future tasks. In Hugo Larochelle, Marc'Aurelio Ranzato",
        "Socially situated artificial intelligence enables learning from human interaction",
        "A human blueprint for ai coexistence",
        "The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities",
        "Scalable agent alignment via reward modeling: a research direction",
        "TruthfulQA: Measuring how models mimic human falsehoods",
        "Chain of hindsight aligns language models with feedback",
        "Mitigating political bias in language models through reinforced calibration",
        "Quantifying and alleviating political bias in language models",
        "Second thoughts are best: Learning to re-align with human values from text edits",
        "Training language models to follow instructions with human feedback",
        "The effects of reward misspecification: Mapping and mitigating misaligned models",
        "Social simulacra: Creating populated prototypes for social computing systems",
        "Generative agents: Interactive simulacra of human behavior",
        "None",
        "Discovering language model behaviors with model-written evaluations",
        "Choosing for changing selves",
        "Loss functions for preference levels: Regression with discrete ordered labels",
        "Facenet: A unified embedding for face recognition and clustering",
        "Goal misgeneralization: Why correct specifications aren't enough for correct goals",
        "Defining and characterizing reward hacking",
        "Varshini Subhash. Can large language models change user preference adversarially? ArXiv preprint",
        "Understanding the capabilities, limitations, and societal impact of large language models",
        "Stanford alpaca: An instruction-following llama model",
        "Alignment for advanced machine learning systems",
        "Llama: Open and efficient foundation language models",
        "A study of implicit bias in pretrained language models against people with disabilities",
        "Self-instruct: Aligning language model with self generated instructions",
        "Taxonomy of risks posed by language models",
        "Fundamental limitations of alignment in large language models",
        "Bot-adversarial dialogue for safe conversational agents",
        "Rrhf: Rank responses to align language models with human feedback without tears"
    ],
    "629b0af15aee126c0fbc9a00": [
        "Precision medicine: opportunities, possibilities, and challenges for patients and providers",
        "Big data hurdles in precision medicine and precision public health",
        "Knowledge graph-based recommendation framework identifies drivers of resistance in EGFR mutant non-small cell lung cancer",
        "From big data to precision medicine",
        "Individualized knowledge graph: a viable informatics path to precision medicine",
        "Computational approaches to phenotyping: high-throughput phenomics",
        "Deep learning solutions to computational phenotyping in health care",
        "Deep computational phenotyping",
        "Protein interactions and disease: computational approaches to uncover the etiology of diseases",
        "Computational methods for identifying similar diseases",
        "Computational intelligence technique for early diagnosis of heart disease",
        "Computational intelligence for heart disease diagnosis: a medical knowledge driven approach",
        "Effective diagnosis of genetic disease by computational phenotype analysis of the disease-associated genome",
        "Multi-scale computational models of pro-angiogenic treatments in peripheral arterial disease",
        "DR2DI: a powerful computational tool for predicting novel drug-disease associations",
        "DrugNet: Network-based drug-disease prioritization by integrating heterogeneous data",
        "NEDD: a network embedding based method for predicting drug-disease associations",
        "Simulations of symptomatic treatments for alzheimer's disease: computational analysis of pathology and mechanisms of drug action",
        "Computational drug repositioning through heterogeneous network clustering",
        "Exploiting drug-disease relationships for computational drug repositioning",
        "Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing",
        "A review on applications of computational methods in drug screening and design",
        "A survey on the computational approaches to identify drug targets in the postgenomic era",
        "Data-driven prediction of drug effects and interactions",
        "Using machine learning to identify adverse drug effects posing increased risk to women",
        "A computational approach for identifying synergistic drug combinations",
        "Developing a search engine for precision medicine",
        "Building a PubMed knowledge graph",
        "Knowledge graph-enabled cancer data analytics",
        "Construction of a knowledge graph for diabetes complications from expert-reviewed clinical evidences",
        "KGen: a knowledge graph generator from biomedical scientific literature",
        "PharmKG: a dedicated knowledge graph benchmark for bomedical data mining",
        "Knowledge-driven drug repurposing using a comprehensive drug knowledge graph",
        "An integrative knowledge graph for rare diseases, derived from the genetic and rare diseases information center (GARD)",
        "Integrating biomedical research and electronic health records to create knowledgebased biologically meaningful machine-readable embeddings",
        "Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development",
        "Artificial intelligence in COVID-19 drug repurposing",
        "Systematic integration of biomedical knowledge prioritizes drugs for repurposing",
        "Network medicine framework for identifying drug-repurposing opportunities for COVID-19",
        "A global network of biomedical relationships derived from text",
        "Scientific language models for biomedical knowledge base completion: an empirical study",
        "Open Graph Benchmark: Datasets for machine learning on graphs",
        "KGHC: a knowledge graph for hepatocellular carcinoma",
        "The Monarch Initiative in 2019: an integrative data and analytic platform connecting phenotypes to genotypes across species",
        "The Human Phenotype Ontology in 2017",
        "The Unified Medical Language System (UMLS): integrating biomedical terminology",
        "Human Disease Ontology 2018 update: classification, content and workflow expansion",
        "Orphanet: a european database for rare diseases",
        "OMIM.org: leveraging knowledge across phenotype-gene relationships",
        "International statistical classification of diseases and related health problems, 10th revision, 2nd edition edn (World Health Organization",
        "PhenoDB: an integrated client/server database for linkage and population genetics",
        "MedDRA (medical dictionary for regulatory activities)",
        "MedGen: NCBI's portal to information on medical conditions with a genetic component",
        "ORDO: an ontology connecting rare disease, epidemiology and genetic data",
        "Mayo foundation for medical education and research",
        "A multidimensional precision medicine approach identifies an autism subtype characterized by dyslipidemia",
        "Comorbidity clusters in autism spectrum disorders: an electronic health record time-series analysis",
        "MEDIC: a practical disease vocabulary used at the Comparative Toxicogenomics. Database. Database",
        "Linking entities through an ontology using word embeddings and syntactic re-ranking",
        "Drkg -drug repurposing knowledge graph for covid",
        "Drug repurposing for covid-19 via knowledge graph completion",
        "Baricitinib as potential treatment for 2019-nCoV acute respiratory disease",
        "Clinical knowledge extraction via sparse embedding regression (KESER) with multi-center large scale electronic health record data",
        "The human disease network",
        "Human symptoms-disease network",
        "The IDeaS initiative: pilot study to assess the impact of rare diseases on patients and healthcare systems",
        "Scientific evidence based rare disease research discovery with research funding data in knowledge graph",
        "CORD-19: The COVID-19 Open Research Dataset",
        "AWS CORD-19 search: A neural search engine for COVID-19 literature",
        "Covidex: Neural Ranking Models and Keyword Search Infrastructure for the COVID-19 Open Research Dataset",
        "Network bioinformatics analysis provides insight into drug repurposing for COVID-19",
        "Drug target discovery using knowledge graph embeddings",
        "Discovering protein drug targets using knowledge graph embeddings",
        "A literature-based knowledge graph embedding method for identifying drug repurposing opportunities in rare diseases",
        "Neural networks for link prediction in realistic biomedical graphs: a multidimensional evaluation of graph embedding-based approaches",
        "Pre-training graph neural networks for link prediction in biomedical networks",
        "OpenBioLink: a benchmarking framework for large-scale biomedical link prediction",
        "The DisGeNET knowledge platform for disease genomics: 2019 update",
        "The Bgee suite: integrated curated expression atlas and comparative transcriptomics in animals",
        "DrugBank 5.0: a major update to the DrugBank database for 2018",
        "Comparative Toxicogenomics Database (CTD): update 2021",
        "Beautiful soup documentation",
        "DrugCentral 2021 supports drug discovery and repositioning",
        "Entrez Gene: gene-centered information at NCBI",
        "GOATOOLS: A python library for gene ontology analyses",
        "The Gene Ontology resource: enriching a GOld mine",
        "Uncovering disease-disease relationships through the incomplete interactome",
        "TRANSFAC: transcriptional regulation, from patterns to profiles",
        "MINT, the molecular interaction database: 2009 update",
        "The IntAct molecular interaction database in 2010",
        "Corum: the comprehensive resource of mammalian protein complexes-2019",
        "The BioGRID database: A comprehensive biomedical resource of curated protein, genetic, and chemical interactions",
        "The string database in 2021: customizable protein-protein networks, and functional characterization of useruploaded gene/measurement sets",
        "A reference map of the human binary protein interactome",
        "The Reactome pathway knowledgebase",
        "The SIDER database of drugs and side effects",
        "STITCH 5: augmenting protein-chemical interaction networks with tissue and affinity data",
        "an integrative multi-species anatomy ontology",
        "Challenges in clinical natural language processing for automated disorder normalization",
        "The igraph software package for complex network research",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Building a knowledge graph to enable precision medicine",
        "Importance of studying heterogeneity in autism",
        "Disentangling the heterogeneity of autism spectrum disorder through genetic findings",
        "Heterogeneity within autism spectrum disorders: What have we learned from neuroimaging studies?",
        "COMET: Commonsense transformers for automatic knowledge graph construction",
        "Deep communicating agents for abstractive summarization",
        "Commonsense knowledge base completion with structural and semantic context",
        "Discourse-aware neural rewards for coherent text generation",
        "Lexicon infused phrase embeddings for named entity resolution",
        "An entity resolution approach based on word embeddings and knowledge bases for microblog texts",
        "DeepER -deep entity resolution",
        "Publicly available clinical BERT embeddings",
        "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "MIMIC-III, a freely accessible critical care database",
        "Drug repurposing: progress, challenges and recommendations",
        "Graph representation learning in biomedicine and healthcare"
    ],
    "63e1c14790e50fcafd2dd585": [
        "Can language models encode perceptual structure without grounding? a case study in color",
        "None",
        "Flamingo: a visual language model for few-shot learning",
        "Learning to understand goal specifications by modelling reward",
        "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data",
        "Experience Grounds Language",
        "Distributional semantics and linguistic theory",
        "Language models are few-shot learners",
        "A review of abstract concept learning in embodied agents and robots",
        "Integration of action and language knowledge: A roadmap for developmental robotics",
        "Babyai: A platform to study the sample efficiency of grounded language learning",
        "None",
        "Language as a cognitive tool to imagine goals in curiositydriven exploration",
        "Textworld: A learning environment for text-based games",
        "Collaborating with language models for embodied reasoning",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Building open-ended embodied agents with internet-scale knowledge",
        "Foundation models for semantic novelty in reinforcement learning",
        "The symbol grounding problem",
        "Distributional Structure",
        "Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads",
        "Chris Apps, Demis Hassabis, and Phil Blunsom",
        "Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text",
        "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
        "Inner monologue: Embodied reasoning through planning with language models",
        "A Systematic Survey of Text Worlds as Embodied Natural Language Environments",
        "General robot manipulation with multimodal prompts",
        "Scaling laws for neural language models",
        "Adam: A method for stochastic optimization",
        "Pre-trained language models for interactive decision-making",
        "Code as policies: Language model programs for embodied control",
        "Aw-opt: Learning robotic skills with imitation and reinforcement at scale",
        "A survey of reinforcement learning informed by natural language",
        "Dissociating language and thought in large language models: a cognitive perspective",
        "Exploration through learned language abstraction",
        "Mapping instructions and visual observations to actions with reinforcement learning",
        "Training language models to follow instructions with human feedback",
        "Mapping language models to grounded conceptual spaces",
        "None",
        "Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization",
        "Zero-shot text-to-image generation",
        "Can wikipedia help offline reinforcement learning?",
        "Mar'ia Grandury, Mario vSavsko",
        "Proximal policy optimization algorithms",
        "Alfworld: Aligning text and embodied environments for interactive learning",
        "Learning to summarize from human feedback",
        "On the effect of pre-training for transformer in different modality on offline reinforcement learning",
        "On the importance of a rich embodiment in the grounding of concepts: Perspectives from embodied cognitive science and computational linguistics",
        "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)",
        "Scienceworld: Is your agent smarter than a 5th grader?",
        "Emergent abilities of large language models",
        "Computer vision and natural language processing: Recent approaches in multimedia and robotics",
        "React: Synergizing reasoning and acting in language models",
        "A new foundation model for computer"
    ],
    "64927546d68f896efa88a31b": [
        "MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing",
        "Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering",
        "Size-invariant graph representations for graph classification extrapolations",
        "Predicting the Silent Majority on Graphs: Knowledge Transferable Graph Neural Network",
        "Geometric deep learning: going beyond Euclidean data",
        "Iterative deep graph learning for graph neural networks: Better and robust node embeddings",
        "Adaptive universal generalized pagerank graph neural network",
        "Variational inference for graph convolutional networks in the absence of graph data and adversarial settings",
        "Probabilistic Model-Agnostic Meta-Learning",
        "Learning discrete structures for graph neural networks",
        "Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping",
        "Pyramid Graph Neural Network: a Graph Sampling and Filtering Approach for Multi-scale Disentangled Representations",
        "Inductive representation learning on large graphs",
        "Categorical Reparameterization with Gumbel-Softmax",
        "Semi-supervised learning with graph learning-convolutional networks",
        "Graph neural network for traffic forecasting: A survey",
        "How to Learn a Graph from Smooth Signals",
        "Semi-supervised classification with graph convolutional networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Variational Inference for Training Graph Neural Networks in Low-Data Regime through Joint Structure-Label Estimation",
        "Adaptive graph convolutional neural networks",
        "Beyond Low-Pass Filters: Adaptive Feature Propagation on Graphs",
        "GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs",
        "New Benchmarks for Learning on Non-Homophilous Graphs",
        "Subgroup generalization and fairness of graph neural networks",
        "Is Homophily a Necessity for Graph Neural Networks?",
        "Domain Generalization via Invariant Feature Representation",
        "Cosine similarity metric learning for face verification",
        "Learning to simulate complex physics with graph networks",
        "Xiangnan He, and Tat-Seng Chua. 2022. Causal attention for interpretable and generalizable graph classification",
        "Policy Gradient Methods for Reinforcement Learning with Function Approximation",
        "Social structure of facebook networks",
        "Attention is All you Need",
        "Graph attention networks",
        "Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning",
        "Energy-based Out-of-Distribution Detection for Graph Neural Networks",
        "Towards open-world feature extrapolation: An inductive graph learning approach",
        "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion",
        "Towards open-world recommendation: An inductive model-based collaborative filtering approach",
        "Handling distribution shifts on graphs: An invariance perspective",
        "Node-Former: A Scalable Graph Structure Learning Transformer for Node Classification",
        "Graph Information Bottleneck",
        "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
        "Representation Learning on Graphs with Jumping Knowledge Networks",
        "Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs",
        "Geometric Knowledge Distillation: Topology Compression for Graph Neural Networks",
        "Learning substructure invariance for out-of-distribution molecular representations",
        "MoleRec: Combinatorial Drug Recommendation with Substructure-Aware Molecular Representation Learning",
        "Revisiting semisupervised learning with graph embeddings",
        "Bayesian graph convolutional neural networks for semi-supervised classification",
        "Robust graph representation learning via neural sparsification",
        "Graph neural networks with heterophily",
        "Beyond homophily in graph neural networks: Current limitations and effective designs",
        "Shift-robust gnns: Overcoming the limitations of localized graph training data",
        "Deep Graph Structure Learning for Robust Representations: A Survey"
    ],
    "6482a38ed68f896efa8db612": [
        "Fundamentals of music processing: Audio, analysis, algorithms, applications",
        "Sensitivity to musical structure in the human brain",
        "Divergence in the functional organization of human and macaque auditory cortex revealed by fmri responses to harmonic tones",
        "A cookbook of selfsupervised learning",
        "Open and efficient foundation language models",
        "A survey on neural speech synthesis",
        "High fidelity neural audio compression",
        "Text-free prosodyaware generative spoken language modeling",
        "Textually guided audio generation",
        "Generating music from text",
        "Generating musical accompaniments from singing",
        "Neural codec language models are zero-shot text to speech synthesizers",
        "Attention is all you need",
        "Soundstream: An end-to-end neural audio codec",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Scaling instruction-finetuned language models",
        "Audioldm: Text-to-audio generation with latent diffusion models",
        "Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models",
        "I hear your true colors: Image guided audio generation",
        "Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation",
        "None",
        "FlashAttention: Fast and memory-efficient exact attention with IO-awareness",
        "xformers: A modular and hackable transformer modelling library",
        "Decoupled weight decay regularization",
        "Learning-rate-free learning by d-adaptation",
        "Hierarchical neural story generation",
        "Riffusion-stable diffusion for real-time music generation",
        "Mo\\?usai: Text-to-music generation with long-context latent diffusion",
        "Noise2music: Text-conditioned music generation with diffusion models",
        "Fr\\'echet audio distance: A metric for evaluating music enhancement algorithms",
        "Efficient training of audio transformers with patchout",
        "Crowdmos: An approach for crowdsourcing mean opinion score studies",
        "Algorithms to measure audio programme loudness and true-peak audio level",
        "On generative spoken language modeling from raw audio",
        "Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment",
        "Unsupervised symbolic music segmentation using ensemble temporal prediction errors",
        "A study on lstm networks for polyphonic music sequence modelling",
        "A comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions",
        "Jukebox: A generative model for music",
        "Foley music: Learning to generate music from videos",
        "A joint embedding of music audio and natural language",
        "High fidelity music synthesis on a shoestring budget",
        "Highresolution image synthesis with latent diffusion models",
        "Discrete diffusion model for text-to-sound generation",
        "Learning transferable visual models from natural language supervision",
        "Music source separation in the waveform domain"
    ],
    "6433f67f90e50fcafd6db326": [
        "Automatic extraction of facts from press releases to generate news stories",
        "Layer normalization",
        "The automatic content extraction (ACE) program -tasks, data, and evaluation",
        "Deep biaffine attention for neural dependency parsing",
        "Span-based joint entity and relation extraction with transformer pre-training",
        "Twenty-five years of information extraction",
        "SOTR: segmenting objects with transformers",
        "A joint many-task model: Growing a neural network for multiple NLP tasks",
        "Axial attention in multidimensional transformers",
        "DEGREE: A data-efficient generation-based event extraction model",
        "Bidirectional LSTM-CRF models for sequence tagging",
        "Generalizing natural language analysis through span-relation representations",
        "GENIA corpus -a semantically annotated corpus for bio-textmining",
        "Zero-shot relation extraction via reading comprehension",
        "A span-based model for joint overlapped and discontinuous named entity recognition",
        "Unified named entity recognition as word-word relation classification",
        "A unified MRC framework for named entity recognition",
        "A joint neural model for information extraction with global features",
        "Event extraction as machine reading comprehension",
        "Decoupled weight decay regularization",
        "Text2event: Controllable sequence-tostructure generation for end-to-end event extraction",
        "Unified structure generation for universal information extraction",
        "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
        "A general framework for information extraction using dynamic span graphs",
        "Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons",
        "Cross-task instance representation interactions and label dependencies for joint information extraction with graph convolutional networks",
        "C?cero Nogueira dos Santos, Bing Xiang, and Stefano Soatto. 2021. Structured prediction as translation between augmented natural languages",
        "Semeval-2014 task 4: Aspect based sentiment analysis",
        "Towards robust linguistic analysis using ontonotes",
        "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
        "From light to rich ERE: annotation of entities, relations, and events",
        "Creating a large benchmark for open information extraction",
        "Roformer: Enhanced transformer with rotary position embedding",
        "Document-level relation extraction with adaptive focal loss and knowledge distillation",
        "Attention is all you need",
        "Entity, relation, and event extraction with contextualized span representations",
        "Ace 2005 multilingual training corpus. Linguistic Data Consortium",
        "Pre-training entity relation encoder with intra-span and inter-span information",
        "Unire: A unified label space for entity relation extraction",
        "2021a. A unified generative framework for various NER subtasks",
        "An embarrassingly easy but strong baseline for nested named entity recognition",
        "2021b. A partition filter network for joint entity and relation extraction",
        "Packed levitated marker for entity and relation extraction",
        "Joint extraction of entities and relations based on a novel decomposition strategy",
        "Named entity recognition as dependency parsing",
        "Extracting relational facts by an end-to-end neural model with copy mechanism",
        "Joint extraction of entities and relations based on a novel tagging scheme",
        "A frustratingly easy approach for entity and relation extraction",
        "Document-level relation extraction with adaptive thresholding and localized context pooling",
        "Boundary smoothing for named entity recognition"
    ],
    "64a29612d68f896efa28bcf5": [
        "Processor Programming Reference (PPR) for AMD Family 19h Model 21h, Revision B0 Processors",
        "None",
        "Continuous Profiling: Where Have All the Cycles Gone?",
        "ARM Architecture Reference Manual Supplement Statistical Profiling Extension",
        "Arm Neoverse N2 Core Technical Reference Manual",
        "Redefining the Role of the CPU in the Era of CPU-GPU Integration",
        "BayesPerf: Minimizing Performance Monitoring Errors Using Bayesian Statistics",
        "Profile-Guided Meta-Programming",
        "Using HPM-Sampling to Drive Dynamic Compilation",
        "Genus Synthesis Solution",
        "Joules RTL Power Solution",
        "Accurate and Practical Profile-Driven Compilation Using the Profile Buffer",
        "Using Branch Handling Hardware to Support Profile-Driven Optimization",
        "Input-Sensitive Profiling",
        "Coz: Finding Code That Counts with Causal Profiling",
        "Domain-Specific Hardware Accelerators",
        "RAPL: Memory Power Estimation and Capping",
        "ProfileMe: Hardware Support for Instruction-Level Profiling on Out-of-Order Processors",
        "Instruction-Based Sampling: A New Performance Analysis Technique for AMD Family 10h Processors",
        "A Performance Counter Architecture for Computing Accurate CPI Components",
        "None",
        "TIP: Time-Proportional Instruction Profiling",
        "TraceDoctor: Versatile High-Performance Tracing for FireSim",
        "Gprof: A Call Graph Execution Profiler",
        "Performance Debugging in the Large via Mining Millions of Stack Traces",
        "Automating Vertical Profiling",
        "Vertical Profiling: Understanding the Behavior of Object-Priented Applications",
        "Accelerator-Level Parallelism. Commun",
        "POWER9 Performance Monitor Unit User's Guide",
        "Intel 64 and IA-32 architectures software developer's manual combined volumes: 1",
        "VTune Profiler User Guide",
        "Performance Monitoring Event Reference",
        "Firesim: FPGA-Accelerated Cycle-Exact Scale-out System Simulation in the Public Cloud",
        "FirePerf: FPGA-Accelerated Full-System Hardware/Software Performance Profiling and Co-Design",
        "IntroPerf: Transparent Context-Sensitive Multi-Layer Performance Inference Using System Stack Traces",
        "A Survey and Taxonomy of On-Chip Monitoring of Multicore Systems-on-Chip",
        "LLVM: A Compilation Framework for Lifelong Program Analysis &amp; Transformation",
        "None",
        "Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation",
        "Evaluating the Accuracy of Java Profilers",
        "Time Interpolation: So Many Metrics, So Few Registers",
        "Valgrind: a Framework for Heavyweight Dynamic Binary Instrumentation",
        "What-If Analysis of Page Load Time in Web Browsers Using Causal Profiling",
        "The CSI Framework for Compiler-Inserted Program Instrumentation",
        "EPIC: An Energy-Efficient, High-Performance GPGPU Computing Research Infrastructure",
        "SPEC CPU",
        "Using Hardware Performance Monitors to Understand the Behavior of Java Applications",
        "Binary Analysis for Measurement and Attribution of Program Performance",
        "Demystifying Page Load Performance with WProf",
        "Can Hardware Performance Counters be Trusted?",
        "Non-Determinism and Overcount on Modern Hardware Performance Counter Implementations",
        "A Portable Sampling-Based Profiler for Java Virtual Machines",
        "Can We Trust Profiling Results? Understanding and Fixing the Inaccuracy in Modern Profilers",
        "A Top-Down Method for Performance Analysis and Counters Architecture",
        "Parallelism-Centric What-If and Differential Analyses",
        "Algorithmic Profiling",
        "Accuracy of Performance Counter Measurements",
        "Sonic-BOOM: The 3rd Generation Berkeley Out-of-Order Machine",
        "Accurate Profiling in the Presence of Dynamic Compilation",
        "Accurate, Efficient, and Adaptive Calling Context Profiling"
    ],
    "646c3addd68f896efa5d1805": [
        "Learning sparse masks for diffusion-based image inpainting",
        "The augmented image prior: Distilling 1000 classes by extrapolating from a single image",
        "Synthetic data from diffusion models improves imagenet classification",
        "Robust and resource-efficient data-free knowledge distillation by generative pseudo replay",
        "Large scale gan training for high fidelity natural image synthesis",
        "Revisiting label smoothing and knowledge distillation compatibility: What was missing?",
        "Online knowledge distillation with diverse peers",
        "Data-free learning of student networks",
        "Distilling knowledge via knowledge review",
        "Improved feature distillation via projector ensemble",
        "Data-free network quantization with adversarial knowledge distillation",
        "Imagenet: A large-scale hierarchical image database",
        "Diffusion models beat gans on image synthesis",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Up to 100x faster data-free knowledge distillation",
        "Contrastive model inversion for data-free knowledge distillation",
        "Generative adversarial networks",
        "The knowledge within: Methods for data-free model compression",
        "Deep residual learning for image recognition",
        "Is synthetic data from generative models ready for image recognition",
        "Is synthetic data from generative models ready for image recognition",
        "Distilling the knowledge in a neural network",
        "Denoising diffusion probabilistic models",
        "Cascaded diffusion models for high fidelity image generation",
        "Paraphrasing complex network: Network compression via factor transfer",
        "Self-knowledge distillation with progressive refinement of targets",
        "Learning multiple layers of features from tiny images",
        "Srdiff: Single image super-resolution with diffusion probabilistic models",
        "Online knowledge distillation via multi-branch diversity enhancement",
        "Curriculum temperature for knowledge distillation",
        "Online knowledge distillation for efficient pose estimation",
        "Structured knowledge distillation for semantic segmentation",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Data-free knowledge distillation for deep neural networks",
        "Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps",
        "Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models",
        "Repaint: Inpainting using denoising diffusion probabilistic models",
        "Large-scale generative data-free distillation",
        "Shufflenet v2: Practical guidelines for efficient cnn architecture design",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "Improved denoising diffusion probabilistic models",
        "A visual vocabulary for flower classification",
        "Restoring vision in adverse weather conditions with patch-based denoising diffusion models",
        "Relational knowledge distillation",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Scalable diffusion models with transformers",
        "Switchable online knowledge distillation",
        "Hierarchical text-conditional image generation with clip latents",
        "Zero-shot text-to-image generation",
        "High-resolution image synthesis with latent diffusion models",
        "Hints for thin deep nets",
        "Photorealistic text-toimage diffusion models with deep language understanding",
        "Image super-resolution via iterative refinement",
        "Very deep convolutional networks for large-scale image recognition",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Score-based generative modeling through stochastic differential equations",
        "None",
        "Effective data augmentation with diffusion models",
        "Intra-class feature variation distillation for semantic segmentation",
        "Imagereward: Learning and evaluating human preferences for text-to-image generation",
        "Knowledge distillation via softmax regression representation learning",
        "Practical guidelines for vit feature knowledge distillation",
        "Dreaming to distill: Data-free knowledge transfer via deepinversion",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer",
        "Fast human pose estimation",
        "Be your own teacher: Improve the performance of convolutional neural networks via self distillation",
        "Deep mutual learning",
        "Decoupled knowledge distillation",
        "Knowledge distillation by on-the-fly native ensemble"
    ],
    "635753d490e50fcafdddf4bd": [
        "Hifi++: a unified framework for neural vocoding, bandwidth extension and speech enhancement",
        "Common voice: A massively-multilingual speech corpus",
        "Speech analysis and synthesis by linear prediction of the speech wave",
        "None",
        "End-to-end optimized image compression",
        "Integer networks for data compression with latent-variable models",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "Adaptive multi-rate wideband speech codec based on celp algorithm: architectural study, implementation &amp; performance analysis",
        "The mtg-jamendo dataset for automatic music tagging",
        "Single channel voice separation for unknown number of speakers under reverberant and noisy settings",
        "Visqol v3: An open source production ready objective speech and audio metric",
        "Global -2021 forecast highlights -cisco",
        "Fast and accurate deep network learning by exponential linear units (elus)",
        "Music source separation in the waveform domain",
        "Real time speech enhancement in the waveform domain",
        "Differentiable model compression via pseudo quantization noise",
        "Jukebox: A generative model for music",
        "The challenge of realistic music generation: modelling raw audio at scale",
        "Overview of the evs codec architecture",
        "Icassp 2022 deep noise suppression challenge",
        "Fsd50k: an open dataset of human-labeled sound events",
        "Low bit-rate speech coding with vq-vae and a wavenet decoder",
        "Audio set: An ontology and human-labeled dataset for audio events",
        "It's raw! audio generation with state-space models",
        "Vector quantization",
        "A new model-based speech analysis/synthesis system",
        "A spectral energy distance for parallel speech synthesis",
        "Visqol: The virtual speech quality objective listener",
        "Self-supervised speech representation learning by masked prediction of hidden units",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Categorical reparameterization with gumbel-softmax",
        "Architecture for variable bitrate neural speech codec with configurable computation complexity",
        "End-to-end neural speech coding for real-time communications",
        "Nal Kalchbrenner et al. Efficient Neural Audio Synthesis",
        "Text-free prosody-aware generative spoken language modeling",
        "Wavenet based low rate speech coding",
        "Generative speech coding with predictive variance regularization",
        "Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis",
        "Textless speech emotion conversion using decomposed and discrete representations",
        "Melgan: Generative adversarial networks for conditional waveform synthesis",
        "On generative spoken language modeling from raw audio",
        "Direct speech-to-speech translation with discrete units",
        "Textless speech-to-speech translation on real data",
        "Variable bitrate discrete neural representations via causal self-attention",
        "Real-time speech frequency bandwidth extension",
        "Robust low rate speech coding based on cloned networks and wavenet",
        "Speech enhancement for low bit rate speech codec",
        "Conv-tasnet: Surpassing ideal time-frequency magnitude masking for speech separation",
        "A 2.4 kbit/s melp coder candidate for the new us federal standard",
        "Speech coding based on a multi-layer neural network",
        "Voice separation with an unknown number of multiple speakers",
        "Robin Algayres, Benoit Sagot, Abdelrahman Mohamed, et al. Generative spoken dialogue language modeling",
        "Disentangling speech from surroundings in a neural audio codec",
        "Wavenet: A generative model for raw audio",
        "Source coding algorithms for fast data compression",
        "Abdelrahman Mohamed, and Emmanuel Dupoux. Speech resynthesis from discrete disentangled self-supervised representations",
        "Enhanced direct speech-to-speech translation using self-supervised pre-training and data augmentation",
        "Generating diverse high-fidelity images with vq-vae-2. Advances in neural information processing systems",
        "Learned video compression",
        "Universal modeling and coding",
        "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
        "Method for the subjective assessment of intermediate quality level of audio systems",
        "Improving opus low bit rate quality with neural speech synthesis",
        "Seanet: A multi-modal speech enhancement network",
        "Lpcnet: Improving neural speech synthesis through linear prediction",
        "A real-time wideband neural vocoder at 1.6 kb/s using lpcnet",
        "Definition of the opus audio codec",
        "Neural discrete representation learning",
        "A review of vector quantization techniques",
        "Attention is all you need",
        "Statistical theory of quantization",
        "Parallel wavegan: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram",
        "Parallel wavegan: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram",
        "Gan vocoder: Multi-resolution discriminator is all you need",
        "Soundstream: An end-to-end neural audio codec"
    ],
    "649a5e2ad68f896efad8460f": [
        "Construction of the Literature Graph in Semantic Scholar",
        "SciBERT: A Pretrained Language Model for Scientific Text",
        "Longformer: The longdocument transformer",
        "Description based text classification with reinforcement learning",
        "Large-Scale Multi-Label Text Classification on EU Legislation",
        "Importance of Semantic Representation: Dataless Classification",
        "A simple framework for contrastive learning of visual representations",
        "Dataless text classification with descriptive LDA",
        "SPECTER: Document-level Representation Learning using Citationinformed Transformers",
        "Medical subject headings used to search the biomedical literature",
        "FullMeSH: improving large-scale MeSH indexing with full text",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "Generalized Zero-Shot Extreme Multi-label Learning",
        "Heterogeneous graph transformer",
        "Extreme multilabel loss functions for recommendation, tagging, ranking &amp; other missing label applications",
        "MeSH indexing based on automatically generated summaries",
        "Patton: Language Model Pretraining on Text-Rich Networks",
        "Dense Passage Retrieval for Open-Domain Question Answering",
        "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
        "Effective document labeling with very few seed words: A topic model approach",
        "Dataless text classification: A topic modeling approach with document manifold",
        "MeSHLabeler: improving the accuracy of large-scale MeSH indexing by integrating diverse evidence",
        "OAG-BERT: Towards a Unified Backbone Language Model for Academic Knowledge Services",
        "Roberta: A robustly optimized bert pretraining approach",
        "S2ORC: The Semantic Scholar Open Research Corpus",
        "Decoupled Weight Decay Regularization",
        "PubMed and beyond: a survey of web tools for searching biomedical literature",
        "Contextualized Weak Supervision for Text Classification",
        "META: Metadata-Empowered Weak Supervision for Text Classification",
        "Weakly-supervised neural text classification",
        "Weakly-supervised hierarchical text classification",
        "Text Classification Using Label Names Only: A Language Model Self-Training Approach",
        "All-in text: Learning document, label, and word representations jointly",
        "Predicting unseen labels using label hierarchies in large-scale multi-label learning",
        "Multi-stage document ranking with bert",
        "None",
        "LIME: Weakly-Supervised Text Classification without Seeds",
        "DeepMeSH: deep semantic representation for improving large-scale MeSH indexing",
        "Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising. In WWW",
        "Few-shot and zero-shot multi-label learning for structured label spaces",
        "TaxoClass: Hierarchical Multi-Label Text Classification Using Only Class Names",
        "A Web-scale system for scientific knowledge exploration",
        "On dataless hierarchical text classification",
        "Co-author relationship prediction in heterogeneous bibliographic networks",
        "Pathsim: Meta path-based top-k similarity search in heterogeneous information networks",
        "Attention is all you need",
        "Graph Attention Networks",
        "Microsoft academic graph: When experts are not enough",
        "X-Class: Text Classification with Extremely Weak Supervision",
        "Towards Robust Prediction on Tail Labels",
        "Extreme Zero-Shot Learning for Extreme Text Classification",
        "MeSHProbeNet: a self-attentive probe net for MeSH indexing",
        "GraphFormers: GNN-nested transformers for representation learning on textual graph",
        "LinkBERT: Pretraining Language Models with Document Links",
        "Beyond Text: Incorporating Metadata and Label Structure for Multi-Label Document Classification using Heterogeneous Graphs",
        "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach",
        "BERTMeSH: deep contextual representation learning for large-scale highperformance MeSH indexing with full text",
        "Attentionxml: Label tree-based attention-aware deep model for high-performance extreme multi-label text classification",
        "Heterogeneous graph neural network",
        "Oag: Toward linking large-scale heterogeneous entity graphs",
        "Integrating Semantic Knowledge to Tackle Zero-shot Text Classification",
        "Weaklysupervised Text Classification Based on Keyword Graph",
        "Hierarchical Metadata-Aware Document Categorization under Weak Supervision",
        "Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding",
        "Motifclass: Weakly supervised text classification with higher-order metadata information",
        "The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study. In WWW'23",
        "MATCH: Metadata-Aware Text Classification in A Large Hierarchy",
        "Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification. In WWW'22",
        "HiGitClass: Keyword-Driven Hierarchical Classification of GitHub Repositories"
    ],
    "6225978c5aee126c0f2d4a7c": [
        "dcompiler/loca: Program Locality Analysis Tools",
        "Harmonic Progression",
        "None",
        "Retrieved on 1 February",
        "HPCToolkit: Tools for performance analysis of optimized parallel programs",
        "PPT-SASMM: Scalable analytical shared memory model: Predicting the performance of multicore caches from a single-threaded execution trace",
        "StatCache: A probabilistic approach to efficient and accurate data locality analysis",
        "Fast data-locality profiling of native execution",
        "Reuse distance as a metric for cache behavior",
        "The PARSEC benchmark suite: Characterization and architectural implications",
        "Estimating cache misses and locality using stack distances",
        "Formalizing data locality in task parallel applications",
        "Rodinia: A benchmark suite for heterogeneous computing",
        "Predicting inter-thread cache contention on a chip multi-processor architecture",
        "A Composable Model for Analyzing Locality of Multi-threaded Programs",
        "Reuse Distance Analysis",
        "Predicting whole-program locality through reuse distance analysis",
        "Instruction-based Sampling: A New Performance Analysis Technique for AMD Family 10h Processors",
        "Improving cache management policies using dynamic reuse distances",
        "StatCC: A Statistical Cache Contention Model",
        "Fast modeling of shared caches in multicore systems",
        "StatStack: Efficient modeling of LRU caches",
        "More than you ever wanted to know about synchronization: Synchrobench, measuring the impact of the synchronization on concurrent algorithms",
        "Optimizing Application Performance on Intel Core Microarchitecture Using Hardware-Implemented Prefetchers",
        "Fast miss ratio curve modeling for storage cache",
        "Intel Microarchitecture Codename Nehalem Performance Monitoring Unit Programming Guide",
        "A probability model of calculating L2 cache misses",
        "Using the first-level cache stack distance histograms to predict multilevel LRU cache misses",
        "An artificial neural network model of LRU-cache misses on out-of-order embedded processors",
        "Is reuse distance applicable to data locality analysis on chip multiprocessors?",
        "Some requirements for architectural support of software debugging",
        "Concurrent reading and writing",
        "Performance Analysis Guide for Intel Core i7 Processor and Intel Xeon 5500 Processors. Retrieved from",
        "Fast modeling L2 cache reuse distance histograms using combined locality information from software traces",
        "Analytical modeling the multi-core shared cache behavior with considerations of data-sharing and coherence",
        "Linux Man Page",
        "Fast and accurate exploration of multi-level caches using hierarchical reuse distance",
        "Evaluation techniques for storage hierarchies",
        "Guidelines for creating a debuggable processor",
        "Debugging and Performance Tuning with Library Interposers",
        "PinPlay: A framework for deterministic replay and reproducible analysis of parallel programs",
        "Scalable analysis of multicore data reuse and sharing",
        "PIN: A binary instrumentation tool for computer architecture research and education",
        "PIN: A binary instrumentation tool for computer architecture research and education",
        "Dynamic decentralized cache schemes for mimd parallel processors",
        "Analytical miss rate calculation of L2 cache from the RD profile of L1 cache",
        "Analytical derivation of concurrent reuse distance profile for multithreaded application running on chip multi-processor",
        "Accelerating multicore reuse distance analysis with sampling and parallelization",
        "Multicore-aware reuse distance analysis",
        "Reuse-based online models for caches. SIGMETRICS Perform",
        "Accurate Approximation of Locality from Time Distance Histograms",
        "Locality approximation using time",
        "IBM POWER7 performance modeling, verification, and evaluation",
        "Simultaneous multithreading: Maximizing on-chip parallelism",
        "Trends in data locality abstractions for HPC systems",
        "TiDA: High-level programming abstractions for data locality management",
        "Modeling superscalar processor memory-level parallelism",
        "Intel Memory Latency Checker v3.9",
        "Random sampling with a reservoir",
        "A data-sharing aware and scalable cache miss rates model for multi-core processors with multi-level cache hierarchies",
        "Featherlight reuse-distance measurement",
        "Watching for software inefficiencies with witch",
        "Watching for software inefficiencies with witch",
        "Coherent profiles: Enabling efficient reuse distance analysis of multicore scaling for loop-based parallel programs",
        "HOTL: A higher order theory of locality",
        "Program locality analysis using reuse distance"
    ],
    "6427029c90e50fcafd5d6c03": [
        "1st instruction prefetching championship",
        "2nd cache replacement championship",
        "3rd data prefetching championship",
        "The champsim simulator",
        "Pin-a dynamic binary instrumentation tool",
        "Spec cpu2017 benchmark suite",
        "Exploring high bandwidth pipelined cache architecture for scaled technology",
        "P-opt: Practical optimal cache replacement for graph analytics",
        "The gap benchmark suite",
        "A study of replacement algorithms for a virtual-storage computer",
        "Pseudo-lifo: The foundation of a new family of replacement policies for last-level caches",
        "Microarchitecture optimizations for exploiting memory-level parallelism",
        "Improving cache management policies using dynamic reuse distances",
        "Domain-specialized cache ment for graph analytics",
        "A dueling segmented lru replacement algorithm with adaptive bypassing",
        "Mlp yes! ilp no,\" ASPLOS Wild and Crazy Idea Session",
        "Back to the future: leveraging belady's algorithm for improved cache replacement",
        "Rethinking belady's algorithm to accommodate prefetching",
        "High performance cache replacement using re-reference interval prediction (rrip)",
        "Multiperspective reuse prediction",
        "Cache replacement based on reuse-distance prediction",
        "Lacs: A locality-aware cost-sensitive cache replacement algorithm",
        "Counter-based cache replacement and bypassing algorithms",
        "Lockup-free instruction fetch/prefetch cache organization",
        "Dead-block prediction &amp; deadblock correlating prefetchers",
        "Lrfu: A spectrum of policies that subsumes the least recently used and least frequently used policies",
        "Cache bursts: A new approach for eliminating dead blocks and increasing cache efficiency",
        "A study on modeling and optimization of memory systems",
        "Lpm: A systematic methodology for concurrent data access pattern optimization from a matching perspective",
        "Apac: An accurate and adaptive prefetch framework with concurrent memory access analysis",
        "Premier: A concurrency-aware pseudopartitioning framework for shared last-level cache",
        "Using simpoint for accurate and efficient simulation",
        "Adaptive insertion policies for high performance caching",
        "A case for mlp-aware cache replacement",
        "The v-way cache: demand-based associativity via global replacement",
        "Emulating optimal replacement with a shepherd cache",
        "On high-bandwidth data cache design for multi-issue processors",
        "Data cache management using frequency-based replacement",
        "The evictedaddress filter: A unified mechanism to address both cache pollution and thrashing",
        "Designing a cost-effective cache replacement policy using machine learning",
        "Effective mimicry of belady's min policy",
        "Applying deep learning to the cache replacement problem",
        "Spec cpu2006 benchmark tools",
        "Concurrent average memory access time",
        "Perceptron learning for reuse prediction",
        "Scalable cache miss handling for high memory-level parallelism",
        "Modified lru policies for improving secondlevel cache behavior",
        "Ship: Signature-based hit predictor for high performance caching",
        "Pacman: prefetch-aware cache management for high performance caching",
        "Hitting the memory wall: implications of the obvious",
        "Pipp: Promotion/insertion pseudo-partitioning of multi-core shared caches",
        "Copim: a concurrency-aware pim workload offloading architecture for graph applications",
        "Ship++: Enhancing signature-based hit predictor for improved cache performance"
    ],
    "629435a25aee126c0f2fecb3": [
        "The input/output complexity of sorting and related problems",
        "Modeling long-range interactions without attention",
        "The long-document transformer",
        "An updated set of basic linear algebra subprograms (blas)",
        "Language models are few-shot learners",
        "Neural legal judgment prediction in English",
        "Nikolaos Aletras, Ion Androutsopoulos, and Prodromos Malakasiotis. Paragraph-level rationale extraction through regularization: A case study on european court of human rights cases",
        "Scatterbrain: Unifying sparse and low-rank attention",
        "Training deep nets with sublinear memory cost",
        "Generating long sequences with sparse transformers",
        "Rethinking attention with performers",
        "Revisiting transformer-based models for long document classification",
        "Transformer-XL: Attentive language models beyond a fixed-length context",
        "Learning fast algorithms for linear transforms using butterfly factorizations",
        "Kaleidoscope: An efficient, learnable representation for all structured linear maps",
        "Pixelated butterfly: Simple and efficient sparse training for neural network models",
        "Monarch: Expressive structured matrices for efficient and accurate training",
        "Smyrf-efficient attention using asymmetric clustering",
        "A two-pronged progress in structured dense matrix vector multiplication",
        "The working set model for program behavior",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Learning to prune deep neural networks via layer-wise optimal brain surgeon",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "On a new class of structured matrices",
        "Parameterized Complexity Theory",
        "The lottery ticket hypothesis: Finding sparse, trainable neural networks",
        "Stabilizing the lottery ticket hypothesis",
        "Linear mode connectivity and the lottery ticket hypothesis",
        "It's raw! audio generation with state-space models",
        "None",
        "Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals",
        "Evaluating derivatives: principles and techniques of algorithmic differentiation",
        "Hippo: Recurrent memory with optimal polynomial projections",
        "Combining recurrent, convolutional, and continuous-time models with linear state space layers",
        "Efficiently modeling long sequences with structured state spaces",
        "Learning both weights and connections for efficient neural networks",
        "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",
        "Memory hierarchy design. Computer Architecture: A Quantitative Approach",
        "The hardware lottery",
        "Transformer quality in linear time",
        "Data movement is all you need: A case study on optimizing transformers",
        "Dissecting the Ampere GPU architecture via microbenchmarking",
        "Dissecting the nvidia Volta GPU architecture via microbenchmarking",
        "Dissecting the graphcore IPU architecture via microbenchmarking",
        "Mimic-iii, a freely accessible critical care database. Scientific data",
        "In-datacenter performance analysis of a tensor processing unit",
        "Displacement ranks of matrices and linear equations",
        "Transformers are RNNs: Fast autoregressive transformers with linear attention",
        "Reformer: The efficient transformer",
        "Albert: A lite BEDRT for self-supervised learning of language representations",
        "The deep learning compiler: A comprehensive survey",
        "Sub-linear memory: How to make performers slim",
        "Runtime neural pruning",
        "A robustly optimized bert pretraining approach",
        "Linear unified nested attention",
        "Mlperf training benchmark",
        "Scalability! but at what {COST}?",
        "Tesla V100 GPU architecture",
        "Nvidia A100 tensor core GPU architecture",
        "Nvidia H100 tensor core GPU architecture",
        "Random butterfly transformations with applications in computational linear algebra",
        "Pytorch: An imperative style, highperformance deep learning library",
        "Self-attention does not need ? (? 2 ) memory",
        "Language models are unsupervised multitask learners",
        "Do transformers need deep long-range memory?",
        "Compressive transformers for long-range sequence modelling",
        "Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines",
        "Database management systems",
        "Parallel stochastic gradient algorithms for large-scale matrix completion",
        "Combiner: Full attention transformer with sparse computation cost",
        "Efficient content-based sparse attention with routing transformers",
        "XLA: Compiling machine learning for peak performance",
        "Movement pruning: Adaptive sparsity by fine-tuning",
        "Megatron-LM: Training multi-billion parameter language models using model parallelism",
        "Structured transforms for small-footprint deep learning",
        "Adaptive attention span in transformers",
        "Long range arena: A benchmark for efficient transformers",
        "Efficient transformers: A survey",
        "Attention is all you need",
        "Deepnet: Scaling transformers to 1,000 layers",
        "Linformer: Self-attention with linear complexity",
        "Roofline: an insightful visual performance model for multicore architectures",
        "A data locality optimizing algorithm",
        "Transformers: State-of-the-art natural language processing",
        "Optimal space lower bounds for all frequency moments",
        "Pay less attention with lightweight and dynamic convolutions",
        "Nystr?mformer: A nyst?m-based algorithm for approximating self-attention",
        "Tokens-to-token vit: Training vision transformers from scratch on imagenet",
        "Big bird: Transformers for longer sequences",
        "An attention free transformer",
        "Long-short transformer: Efficient transformers for language and vision"
    ],
    "64a78f10d68f896efa01dee3": [
        "DeepSpeed-Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale",
        "Pathways: Asynchronous Distributed Dataflow for ML",
        "The Datacenter as a Computer: Designing Warehouse-Scale Machines",
        "Alec Radford, Ilya Sutskever, and Dario Amodei",
        "PaLM: Scaling Language Modeling with Pathways",
        "Cloud TPU pricing",
        "ShiDianNao: Shifting Vision Processing Closer to the Sensor",
        "A Configurable Cloud-Scale DNN Processor for Real-Time AI",
        "GitHub Copilot Your AI pair programmer",
        "ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks",
        "Ten Lessons From Three Generations Shaped Google's TPUv4i : Industrial Product",
        "A domain-specific supercomputer for training deep neural networks",
        "Enabling interposer-based disintegration of multi-core processors",
        "Moonwalk: NRE Optimization in ASIC Clouds",
        "Graphcore Colossus Mk2 IPU",
        "The best prices for cloud GPUs",
        "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
        "AI Compute Chip from Enflame",
        "ASIC Clouds: Specializing the Datacenter",
        "Turing-NLG: A 17-billion-parameter language model by Microsoft",
        "10 Google Search Statistics You Need to Know in 2023",
        "Pioneering Chiplet Technology and Design for the AMD EPYC? and Ryzen? Processor Families : Industrial Product",
        "Efficient large-scale language model training on GPU clusters using megatron-LM",
        "None",
        "Introducing ChatGPT",
        "Efficiently Scaling Transformer Inference",
        "A 1.17-pJ/b, 25-Gb/s/pin Ground-Referenced Single-Ended Serial Link for Off-and On-Package Communication Using a Process-and Temperature-Adaptive Voltage Regulator",
        "SambaNova SN10 RDU:Accelerating Software 2.0 with Dataflow",
        "Language Models are Unsupervised Multitask Learners",
        "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale",
        "Simba: Scaling Deep-Learning Inference with Multi-Chip-Module-Based Architecture",
        "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism",
        "Zion: Facebook Next-Generation Large Memory Training Platform",
        "Wafer-Scale Deep Learning",
        "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference",
        "NN-Baton: DNN Workload Orchestration and Chiplet Granularity Exploration for Multichip Accelerators",
        "Ground-referenced signaling for intra-chip and short-reach chip-to-chip interconnects",
        "Attention Is All You Need",
        "Scalable Multi-Chip-Module-Based Deep Neural Network Accelerator Designed with A High-Productivity VLSI Methodology",
        "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning",
        "A 28nm 27.5TOPS/W Approximate-Computing-Based Transformer Processor with Asymptotic Sparsity Speculating and Out-of-Order Computing",
        "COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning"
    ],
    "6346305e90e50fcafda07ab8": [
        "Defining benchmarks for continual few-shot learning",
        "One-shot unsupervised cross domain translation",
        "Language models are few-shot learners",
        "Language models are few-shot learners",
        "Dark experience for general continual learning: a strong, simple baseline",
        "Lifelong machine learning",
        "Lifelong language knowledge distillation",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Pathnet: Evolution channels gradient descent in super neural networks",
        "Making pre-trained language models better few-shot learners",
        "Neural snowball for few-shot relation learning",
        "Psycholinguistics meets continual learning: Measuring catastrophic forgetting in visual question answering",
        "Ppt: Pre-trained prompt tuning for few-shot learning",
        "Online continual learning through mutual information maximization",
        "Demix layers: Disentangling domains for modular language modeling",
        "a. Don't stop pretraining: adapt language models to domains and tasks",
        "2020b. Don't stop pretraining: Adapt language models to domains and tasks",
        "Towards a unified view of parameter-efficient transfer learning",
        "Overcoming catastrophic interference using conceptor-aided backpropagation",
        "Distilling the knowledge in a neural network",
        "None",
        "Parameter-efficient transfer learning for NLP",
        "Few-shot charge prediction with discriminative legal attributes",
        "Continual learning for text classification with information disentanglement based regularization",
        "Learn continually, generalize rapidly: Lifelong knowledge accumulation for fewshot learning",
        "Measuring the evolution of a scientific field through citation frames",
        "2021a. Achieving forgetting prevention and knowledge transfer in continual learning",
        "Classic: Continual and contrastive learning of aspect sentiment classification tasks",
        "Adapting bert for continual learning of a sequence of aspect sentiment classification tasks",
        "Regularized training objective for continued training for domain adaptation in neural machine translation",
        "Overcoming catastrophic forgetting in neural networks",
        "The power of scale for parameter-efficient prompt tuning",
        "Compositional language continual learning",
        "Continual learning for sentence representations using conceptors",
        "An-An Liu, Bernt Schiele, and Qianru Sun. 2020a. Mnemonics training: Multiclass incremental learning without forgetting",
        "A robustly optimized BERT pretraining approach",
        "Exploring fine-tuning techniques for pre-trained cross-lingual models via continual learning",
        "S2ORC: the semantic scholar open research corpus",
        "Gradient episodic memory for continual learning",
        "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
        "Continual learning in task-oriented dialogue systems",
        "Catastrophic interference in connectionist networks: The sequential learning problem",
        "An empirical investigation of the role of pre-training in lifelong learning",
        "LFPT5: A unified framework for lifelong few-shot language learning based on prompt tuning of T5",
        "ELLE: efficient lifelong pre-training for emerging data",
        "None",
        "icarl: Incremental classifier and representation learning",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Continual learning in generative adversarial nets",
        "Overcoming catastrophic forgetting with hard attention to the task",
        "A progressive model to enable continual learning for semantic slot filling",
        "Continual learning with deep generative replay",
        "Using deepspeed and megatron to train megatron-turing NLG 530b, A large-scale generative language model",
        "How to fine-tune bert for text classification",
        "Lamol: Language modeling is all you need for lifelong language learning",
        "Few-shot learning through an information retrieval lens",
        "Three scenarios for continual learning",
        "Efficient meta lifelonglearning with limited memory",
        "Incremental few-shot text classification with multi-round new classes: Formulation, dataset and system",
        "BERT post-training for review reading comprehension and aspect-based sentiment analysis",
        "Contintin: Continual learning from task instructions",
        "Character-level convolutional networks for text classification"
    ],
    "6327dda690e50fcafd67dea3": [
        "Asad: A twitter-based benchmark arabic sentiment analysis dataset",
        "Xlm-t: A multilingual language model toolkit for twitter",
        "SemEval 2018 task 2: Multilingual emoji prediction",
        "Enriching word vectors with subword information",
        "Translating embeddings for modeling multirelational data. Advances in neural information processing systems",
        "Heterogeneous network embedding via deep architectures",
        "Task-guided and pathaugmented heterogeneous network embedding for author identification",
        "A simple framework for contrastive learning of visual representations",
        "Can cascades be predicted?",
        "ELECTRA: pretraining text encoders as discriminators rather than generators",
        "Unsupervised cross-lingual representation learning at scale",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "metapath2vec: Scalable representation learning for heterogeneous networks",
        "2022a. Graph-based representation learning for web-scale recommender systems",
        "2022b. knnembed: Locally smoothed embedding mixtures for multi-interest candidate retrieval",
        "Twhin: Embedding the twitter heterogeneous information network for personalized recommendation",
        "Product quantization for nearest neighbor search",
        "Billion-scale similarity search with gpus",
        "Pytorch-biggraph: A largescale graph embedding system",
        "K-bert: Enabling language representation with knowledge graph",
        "Oag-bert: Towards a unified backbone language model for academic knowledge services",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Timelms: Diachronic language models from twitter",
        "COCO-LM: correcting and contrasting text sequences for language model pretraining",
        "Language models are few-shot butlers",
        "Non-parametric temporal adaptation for social media topic classification",
        "Bertweet: A pre-trained language model for english tweets",
        "Semeval-2020 task 9: Overview of sentiment analysis of code-mixed tweets",
        "Deep contextualized word representations",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Semeval-2017 task 4: Sentiment analysis in twitter",
        "Inf-vae: A variational autoencoder framework to integrate homophily and influence in diffusion prediction",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "Mining heterogeneous information networks: a structural analysis approach",
        "Filtering method for twitter streaming data using human-in-the-loop machine learning",
        "Pte: Predictive text embedding through large-scale heterogeneous text networks",
        "LINE: large-scale information network embedding",
        "Complex embeddings for simple link prediction",
        "Attention is all you need",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Embedding of embedding (eoe) joint embedding for coupled heterogeneous networks",
        "Xlnet: Generalized autoregressive pretraining for language understanding"
    ],
    "6260bd7f5aee126c0fc6bba4": [
        "The process of structure-based drug design",
        "Syntax-directed variational autoencoder for structured data",
        "An implicit generative model for small molecular graphs",
        "Non-linear independent components estimation",
        "Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug",
        "Torsional geometric generation of molecular 3d conformer ensembles",
        "Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules",
        "TorsionNet: A reinforcement learning approach to sequential conformer search",
        "Automatic chemical design using a data-driven continuous representation of molecules",
        "Generative adversarial nets",
        "A kernel two-sample test",
        "Generating valid euclidean distance matrices",
        "3d convolutional neural networks for human action recognition",
        "Junction tree variational autoencoder for molecular graph generation",
        "Highly accurate protein structure prediction with alphafold",
        "Glow: Generative flow with invertible 1x1 convolutions",
        "Auto-encoding variational bayes",
        "Directional message passing for molecular graphs",
        "Universal directional graph neural networks for molecules",
        "Grammar variational autoencoder",
        "RDKit: Open-source cheminformatics",
        "Learning deep generative models of graphs",
        "Molecular graph generation with energy-based models",
        "Spherical message passing for 3d molecular graphs",
        "Forging the basis for developing protein-ligand interaction scoring functions",
        "A 3d generative model for drug design",
        "Predicting molecular conformation via dynamic graph score matching",
        "An autoregressive flow model for 3d molecular geometry generation from scratch",
        "A discrete flow model for molecular graph generation",
        "An invertible flow model for generating molecular graphs",
        "Molecular geometry prediction using a deep generative graph neural network",
        "Gnina 1.0: molecular docking with deep learning",
        "DMolNet: a generative network for molecular structures",
        "Open babel: An open chemical toolbox",
        "Masked autoregressive flow for density estimation",
        "Protein-ligand scoring with convolutional neural networks",
        "Generating 3d molecules conditional on receptor binding sites with deep generative models",
        "Quantum chemistry structures and properties of 134 kilo molecules",
        "UFF, a full periodic table force field for molecular mechanics and molecular dynamics simulations",
        "Variational inference with normalizing flows",
        "E(n) equivariant normalizing flows for molecule generation in 3d",
        "Modeling relational data with graph convolutional networks",
        "GraphAF: a flow-based autoregressive model for molecular graph generation",
        "Learning gradient fields for molecular conformation generation",
        "A generative model for molecular distance geometry",
        "Reinforcement learning molecular design guided by quantum mechanics",
        "GraphVAE: Towards generation of small graphs using variational autoencoders",
        "AutoDock Vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading",
        "Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules",
        "Flow-based deep generative models. lilianweng. github. io/lil-log",
        "An end-to-end framework for molecular conformation generation via bilevel programming",
        "Generating realistic graphs with deep auto-regressive models",
        "MoFlow: an invertible flow model for generating molecular graphs"
    ],
    "62b2888c5aee126c0fbc731c": [
        "Artificial macrocycles by ugi reaction and passerini ring closure",
        "Customizable de novo design strategies for DOCK: Application to HIVgp41 and other therapeutic targets",
        "New substructure filters for removal of pan assay interference compounds (PAINS) from screening libraries and for their exclusion in bioassays",
        "Quantifying the chemical beauty of drugs",
        "Antifungal chemistry review",
        "Optimol: Optimization of binding affinities in chemical space for drug discovery",
        "A review on machine learning approaches and trends in drug discovery",
        "Rigorous Free Energy Simulations in Virtual Screening",
        "Syntaxdirected variational autoencoder for structured data",
        "An implicit generative model for small molecular graphs",
        "Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions",
        "Glide: a new approach for rapid, accurate docking and scoring. 1. method and assessment of docking accuracy",
        "Differentiable scaffolding tree for molecular optimization",
        "The statistical-thermodynamic basis for computation of binding affinities: a critical review",
        "Automatic chemical design using a data-driven continuous representation of molecules",
        "Fpocket: An open source platform for ligand pocket detection",
        "Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models",
        "Graph energybased model for substructure preserving molecular design",
        "Automation of absolute protein-ligand binding free energy calculations for docking refinement and compound evaluation",
        "Principles of early drug discovery",
        "Importance and synthesis of benzannulated medium-sized and macrocyclic rings (BMRs)",
        "ZINC: A free tool to discover chemistry for biology",
        "Are we opening the door to a new era of medicinal chemistry or being collapsed to a chemical singularity?",
        "Autonomous molecule generation using reinforcement learning and docking to develop potential novel inhibitors",
        "Junction tree variational autoencoder for molecular graph generation",
        "Learning multimodal graph-to-graph translation for molecular optimization",
        "Hierarchical generation of molecular graphs using structural motifs",
        "Multi-objective molecule generation using interpretable substructures",
        "An advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico",
        "Auto-encoding variational bayes",
        "Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation",
        "Grammar variational autoencoder",
        "Multi-objective de novo drug design with conditional graph generative model",
        "Scaffold-based molecular design with a graph generative model",
        "Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings",
        "BindingDB: a web-accessible database of experimentally determined protein-ligand binding affinities",
        "A 3d generative model for structure-based drug design",
        "A discrete flow model for molecular graph generation",
        "Constrained generation of semantically valid graphs via regularizing variational autoencoders",
        "Learning to extend molecular scaffolds with structural motifs",
        "Inceptionism: Going deeper into neural networks",
        "Augmenting genetic algorithms with deep neural networks for exploring the chemical space",
        "Improving black-box optimization in vae latent space using decoder uncertainty",
        "Open babel: An open chemical toolbox",
        "Molecular de-novo design through deep reinforcement learning",
        "How to improve r&amp;d productivity: the pharmaceutical industry's grand challenge",
        "Estimation of the size of drug-like chemical space based on GDB-17 data",
        "Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models",
        "Molecu-larRNN: Generating realistic molecular graphs with optimized properties",
        "Extended-connectivity fingerprints",
        "Accelerating AutoDock4 with GPUs and gradient-based local search",
        "Deep molecular dreaming: inverse machine learning for denovo molecular design and interpretability with surjective representations",
        "GraphAF: A flow-based autoregressive model for molecular graph generation",
        "GraphVAE: Towards generation of small graphs using variational autoencoders",
        "Autogrow4: an opensource genetic algorithm for de novo drug design and lead optimization",
        "Sample-efficient optimization in the latent space of deep generative models via weighted retraining",
        "Fsp3: A new parameter for drug-likeness",
        "SMILES, a chemical language and information system. 1. introduction to methodology and encoding rules",
        "MARS: Markov molecular sampling for multiobjective drug discovery",
        "ADMETlab 2.0: an integrated online platform for accurate and comprehensive predictions of ADMET properties",
        "Graph convolutional policy network for goal-directed molecular graph generation",
        "MoFlow: An invertible flow model for generating molecular graphs",
        "Deep learning enables rapid identification of potent ddr1 kinase inhibitors",
        "Optimization of molecules via deep reinforcement learning"
    ],
    "6385788690e50fcafdf4a0f3": [
        "The graph neural network model",
        "Gated graph sequence neural networks",
        "Semi-supervised classification with graph convolutional networks",
        "How powerful are graph neural networks?",
        "Graph attention networks",
        "Deepinf: Social influence prediction with deep learning",
        "Predicting path failure in time-evolving graphs",
        "Predicting multicellular function through multi-layer tissue networks",
        "Attention based spatialtemporal graph convolutional networks for traffic flow forecasting",
        "Graph convolutional neural networks for web-scale recommender systems",
        "Deconstructing lottery tickets: Zeros, signs, and the supermask",
        "What's hidden in a randomly weighted neural network?",
        "Pruning randomly initialized neural networks with iterative randomization",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "The lottery ticket hypothesis: Finding sparse, trainable neural networks",
        "A unified lottery ticket hypothesis for graph neural networks",
        "To prune, or not to prune: exploring the efficacy of pruning for model compression",
        "The state of sparsity in deep neural networks",
        "Sparse training via boosting pruning plasticity with neuroregeneration",
        "Inductive representation learning on large graphs",
        "Simplifying graph convolutional networks",
        "Variational graph auto-encoders",
        "Deepgcns: Can gcns go as deep as cnns?",
        "Geometrically principled connections in graph neural networks",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Representation learning on graphs with jumping knowledge networks",
        "Towards deeper graph neural networks",
        "Simple and deep graph convolutional networks",
        "Understanding and resolving performance degradation in graph convolutional networks",
        "Tackling oversmoothing for general graph convolutional networks",
        "Towards deep graph convolutional networks on node classification",
        "Supermasks in superposition",
        "Drawing robust scratch tickets: Subnetworks with inborn robustness are found within randomly initialized networks",
        "Representation learning on graphs: Methods and applications",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science",
        "Sparse evolutionary deep learning with over one million artificial neurons on commodity hardware",
        "Rigging the lottery: Making all tickets winners",
        "Soft threshold weight reparameterization for learnable sparsity",
        "Sparse networks from scratch: Faster training without losing performance",
        "Bag of tricks for training deeper graph neural networks: A comprehensive benchmark study",
        "Geom-gcn: Geometric graph convolutional networks",
        "Moleculenet: a benchmark for molecular machine learning",
        "Deep residual learning for image recognition",
        "Measuring and relieving the over-smoothing problem for graph neural networks from the topological view",
        "Graph posterior network: Bayesian predictive uncertainty for node classification",
        "Do transformers really perform bad for graph representation? arXiv preprint"
    ],
    "6466fafbd68f896efaeb7607": [
        "Alzheimer's disease neuroimaging initiative (adni): clinical characterization",
        "The national alzheimer's coordinating center (nacc) database: the uniform data set",
        "Open access series of imaging studies (oasis): cross-sectional mri data in young, middle aged, nondemented, and demented older adults",
        "Learning transferable visual models from natural language supervision",
        "Blip: Bootstrapping language-image pretraining for unified vision-language understanding and generation",
        "Blip-2: Bootstrapping language-image pretraining with frozen image encoders and large language models",
        "Vlmo: Unified vision-language pre-training with mixtureof-modality-experts",
        "A simple baseline for zero-shot semantic segmentation with pre-trained vision-language model",
        "Contrastive learning from unpaired medical images and text",
        "Biomedlm: a domain-specific large language model for biomedical text",
        "Low-rank adaptation of large language models",
        "The australian imaging, biomarkers and lifestyle (aibl) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of alzheimer's disease",
        "Miriad-public release of a multiple time point alzheimer's mr imaging dataset",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm",
        "Align before fuse: Vision and language representation learning with momentum distillation",
        "Momentum contrast for unsupervised visual representation learning",
        "Coca: Contrastive captioners are image-text foundation models",
        "Expertlevel detection of pathologies from unannotated chest x-ray images via self-supervised learning",
        "Learning to exploit temporal structure for biomedical vision-language processing",
        "Visualgpt: Data-efficient adaptation of pretrained language models for image captioning",
        "Multimodal few-shot learning with frozen language models",
        "Flamingo: a visual language model for few-shot learning",
        "Scaling instruction-finetuned language models",
        "Opt: Open pre-trained transformer language models",
        "Grounding language models to images for multimodal generation",
        "Scaling language modeling with pathways",
        "Palm-e: An embodied multimodal language model",
        "OpenAI. Gpt-4 technical report",
        "Chatcad: Interactive computer-aided diagnosis on medical image using large language models",
        "Open-ended medical visual question answering through prefix tuning of language models",
        "Hugging face",
        "Documenting the english colossal clean crawled corpus",
        "The pile: An 800gb dataset of diverse text for language modeling",
        "Exploring the limits of masked visual representation learning at scale",
        "Biogpt: generative pre-trained transformer for biomedical text generation and mining"
    ],
    "622577a75aee126c0f008d4a": [
        "Classification-based anomaly detection for general data",
        "Improving unsupervised defect segmentation by applying structural similarity to autoencoders",
        "Lof: identifying density-based local outliers",
        "Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission",
        "Node-gam: Neural generalized additive model for interpretable deep learning",
        "How interpretable and trustworthy are gams?",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Deep anomaly detection using geometric transformations",
        "Pidforest: Anomaly detection via partial identification",
        "large minibatch sgd: Training imagenet in 1 hour",
        "Robust random cut forest based anomaly detection on streams",
        "Cutpaste: Self-supervised learning for anomaly detection and localization",
        "Copod: copula-based outlier detection",
        "Feature selection by sparse forests",
        "2008 eighth ieee international conference on data mining",
        "Lpexplain: Local pictorial explanation for outliers",
        "Explainable deep one-class classification",
        "Toward Explainable Deep Anomaly Detection",
        "Deep anomaly detection with deviation networks",
        "Deep anomaly detection with deviation networks",
        "Sparse sequenceto-sequence models",
        "Neural transformation learning for deep anomaly detection beyond images",
        "Deep one-class classification",
        "Deep semi-supervised anomaly detection",
        "Estimating the support of a highdimensional distribution",
        "Anomaly detection for tabular data with internal contrastive learning",
        "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
        "Learning and evaluating representations for deep one-class classification",
        "Novelty detection via contrastive learning on distributionally shifted instances",
        "Distill-andcompare: Auditing black-box models using transparent model distillation",
        "Discovering outlying aspects in large datasets",
        "Optimizing classifier performance via an approximation to the wilcoxon-mann-whitney statistic",
        "Extending the success of self-and semi-supervised learning to tabular domain",
        "Extending the success of self-and semi-supervised learning to tabular domain",
        "Deep autoencoding gaussian mixture model for unsupervised anomaly detection"
    ],
    "64741c33d68f896efaa7b7a1": [
        "On the summarization of consumer health questions",
        "Multimodal biomedical ai",
        "Flamingo: a visual language model for few-shot learning",
        "Publicly available clinical BERT embeddings",
        "Publicly available clinical bert embeddings. NAACL HLT",
        "None",
        "Constitutional ai: Harmlessness from ai feedback",
        "A cookbook of self-supervised learning",
        "Meteor: An automatic metric for mt evaluation with improved correlation with human judgments",
        "Bert pre-training of image transformers",
        "Beit: BERT pre-training of image transformers",
        "On the opportunities and risks of foundation models",
        "Language models are few-shot learners",
        "Biomedbert: A pre-trained biomedical language model for qa and ir",
        "Adapting pretrained vision-language foundational models to medical imaging domains",
        "Parameter-efficient fine-tuning design spaces",
        "Towards a single unified model for effective detection, segmentation, and diagnosis of eight major cancers using a large collection of ct scans",
        "Pix2seq: A language modeling framework for object detection",
        "A unified sequence interface for vision tasks",
        "Multimodal masked autoencoders for medical vision-and-language pre-training",
        "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
        "Electra: Pre-training text encoders as discriminators rather than generators",
        "Randaugment: Practical automated data augmentation with a reduced search space",
        "Learning to evaluate image captioning",
        "Coatnet: Marrying convolution and attention for all data sizes",
        "Vilmedic: a framework for research at the intersection of vision and language in medical ai",
        "Preparing a collection of radiology examinations for distribution and retrieval",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Parameter-efficient fine-tuning of large-scale pre-trained language models",
        "Multiple metamodel quantifying for medical visual question answering",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Diabetic retinopathy detection",
        "Does clip benefit visual question answering in the medical domain as much as it does in the general domain",
        "Pubmedclip: How much does clip benefit visual question answering in the medical domain?",
        "Taming transformers for high-resolution image synthesis",
        "Diabetes care",
        "Decoderonly or encoder-decoder? interpreting language model as a regularized encoder-decoder",
        "Making pre-trained language models better few-shot learners",
        "Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Towards general purpose vision systems: An end-to-end task-agnostic vision-language architecture",
        "Pathvqa: 30000+ questions for medical visual question answering",
        "Cytoimagenet: A large-scale pretraining dataset for bioimage transfer learning",
        "Gloria: A multimodal globallocal representation learning framework for label-efficient medical image recognition",
        "Self-supervised learning for medical image classification: a systematic review and implementation guidelines",
        "Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison",
        "Two public chest x-ray datasets for computer-aided screening of pulmonary diseases. Quantitative imaging in medicine and surgery",
        "Categorical reparameterization with gumbel-softmax",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "On the automatic generation of medical imaging reports",
        "Mimic-iii, a freely accessible critical care database. Scientific data",
        "Scaling laws for neural language models",
        "Rethinking positional encoding in language pre-training",
        "Mmbert: multimodal bert pretraining for improved medical vqa",
        "Re-evaluating automatic metrics for image captioning",
        "Semantic annotation of consumer health questions",
        "Vilt: Vision-and-language transformer without convolution or region supervision",
        "Constituency parsing with a self-attentive encoder",
        "Breaking the dilemma of medical image-to-image translation",
        "Medical concept prediction from clinical narratives",
        "Self-supervised learning in medicine and healthcare",
        "The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Toward automatic simulation of aging effects on face images",
        "A dataset of clinically generated visual questions and answers about radiology images",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Do we still need clinical language models? arXiv preprint",
        "The power of scale for parameter-efficient prompt tuning",
        "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Uni-perceiver v2: A generalist model for large-scale vision and vision-language tasks",
        "A comparison of pre-trained vision-and-language models for multimodal representation learning across medical images and reports",
        "Scaling down to scale up: A guide to parameterefficient fine-tuning",
        "Rouge: A package for automatic evaluation of summaries",
        "The unified medical language system",
        "Slake: a semantically-labeled knowledge-enhanced dataset for medical visual question answering",
        "Exploring and distilling posterior and prior knowledge for radiology report generation",
        "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "A robustly optimized bert pretraining approach",
        "Annotated high-throughput microscopy image sets for validation",
        "Decoupled weight decay regularization",
        "Unified-io: A unified model for vision, language, and multi-modal tasks",
        "Biogpt: generative pre-trained transformer for biomedical text generation and mining",
        "The concrete distribution: A continuous relaxation of discrete random variables",
        "Medvit: A robust vision transformer for generalized medical image classification",
        "Unsupervised and self-supervised deep learning approaches for biomedical text mining",
        "Overcoming data limitation in medical visual question answering",
        "A decade survey of transfer learning",
        "Natural language processing of mimic-iii clinical notes for identifying diagnosis and procedures with neural networks",
        "Wavenet: A generative model for raw audio",
        "Training language models to follow instructions with human feedback",
        "Self-evolving vision transformer for chest x-ray diagnosis through knowledge distillation",
        "Radiology objects in context (roco): a multimodal image dataset",
        "Transfer learning in biomedical natural language processing: An evaluation of bert and elmo on ten benchmarking datasets",
        "An empirical study of multi-task learning on bert for biomedical text mining",
        "Alec Peltekian, and Gr?goire Altan-Bonnet. Scifive: a text-to-text transformer model for biomedical literature",
        "Psychovisual issues in the display of medical images",
        "Adaptive histogram equalization and its variations. Computer vision, graphics, and image processing",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Learning transferable visual models from natural language supervision",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Transfusion: Understanding transfer learning for medical imaging",
        "Med-bert: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction",
        "Jost Tobias Springenberg, et al. A generalist agent",
        "Lessons from natural language inference in the clinical domain",
        "A patient-centric dataset of images and metadata for identifying melanomas using clinical context",
        "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
        "Comparing encoder-only and encoderdecoder transformers for relation extraction from biomedical texts: An empirical study on ten benchmark datasets",
        "It's not just size that matters: Small language models are also few-shot learners",
        "Medical image captioning via generative pretrained transformers",
        "Neural machine translation of rare words with subword units",
        "Indian movie face database: a benchmark for face recognition under wide variations",
        "Transformers in medical imaging: A survey",
        "Normformer: Improved transformer pretraining with extra normalization",
        "Dropout: a simple way to prevent neural networks from overfitting",
        "Medicat: A dataset of medical images, captions, and textual references",
        "Sequence to sequence learning with neural networks",
        "Rethinking the inception architecture for computer vision",
        "A voting-based ensemble deep learning method focusing on image augmentation and preprocessing variations for tuberculosis detection",
        "Medical transformer: Gated axial-attention for medical image segmentation",
        "Neural discrete representation learning",
        "Attention is all you need",
        "Cider: Consensus-based image description evaluation",
        "Git: A generative image-to-text transformer for vision and language",
        "Ofa: Unifying architectures, tasks, and modalities through a simple sequence-tosequence learning framework",
        "Contrastive learning from unpaired medical images and text",
        "Simvlm: Simple visual language model pretraining with weak supervision",
        "Finetuned language models are zero-shot learners",
        "Image data resource: a bioimage data integration and publication platform",
        "E2e-vlp: End-to-end vision-language pre-training enhanced by visual learning",
        "Clinical-bert: Vision-language pre-training for radiograph diagnosis and reports generation",
        "Deeplesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning",
        "scbert as a large-scale pretrained deep language model for cell type annotation of single-cell rna-seq data",
        "Prompt tuning for generative multimodal pretrained models",
        "Medmnist v2: A large-scale lightweight benchmark for 2d and 3d biomedical image classification",
        "Biobart: Pretraining and evaluation of a biomedical generative language model",
        "Cutmix: Regularization strategy to train strong classifiers with localizable features",
        "Graph transformer networks",
        "Meddialog: Large-scale medical dialogue datasets",
        "Medical visual question answering via conditional reasoning",
        "mixup: Beyond empirical risk minimization",
        "Large-scale domain-specific pretraining for biomedical vision-language processing",
        "Contrastive learning of medical visual representations from paired images and text",
        "Random erasing data augmentation",
        "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
        "Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports"
    ],
    "63e312f590e50fcafdc1a1bb": [
        "Measuring the stability of spectral clustering",
        "Spectral Graph Theory. CBMS Regional Conference Series in Mathematics Number 92",
        "Simple, direct and efficient multi-way spectral clustering. Information and Inference: A",
        "Co-Clustering Documents and Words Using Bipartite Spectral Graph Partitioning",
        "The Geometry of Algorithms with Orthogonality Constraints",
        "Matrix Methods in Data Mining and Pattern Recognition, Second Edition. SIAM",
        "Psychometrika",
        "Algebraic Connectivity of Graphs",
        "Community detection in networks: A user guide",
        "SIAM",
        "Multiway spectral partitioning and higher-order Cheeger inequalities",
        "Many sparse cuts via higher eigenvalues",
        "Multiway cuts and spectral clustering",
        "Matrix Analysis and Applied Linear Algebra. SIAM, Philadelphia",
        "Multiway pspectral graph cuts on Grassmann manifolds",
        "Partitioning well-clustered graphs: Spectral clustering works",
        "Partitioning Sparse Matrices with Eigenvectors of Graphs",
        "Objective criteria for the evaluation of clustering methods",
        "First-principles multiway spectral partitioning of graphs",
        "Multi-Scale attributed node embedding",
        "Normalized cuts and image segmentation",
        "Depth-First Search and Linear Graph Algorithms",
        "A tutorial on spectral clustering",
        "Collective dynamics of 'small-world' networks",
        "Understanding regularized spectral clustering via graph conductance",
        "Multiway Spectral Clustering: A Margin-Based Perspective"
    ],
    "6487e9fad68f896efa482c3a": [
        "Spatio-temporal data mining: A survey of problems and methods",
        "STG2Seq: Spatial-Temporal Graph to Sequence Model for Multi-step Passenger Demand Forecasting",
        "Adaptive graph convolutional recurrent network for traffic forecasting",
        "Freeway Performance Measurement System: Mining Loop Detector Data",
        "A Unified Lottery Ticket Hypothesis for Graph Neural Networks",
        "TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting",
        "Z-GCNETs: Time Zigzags at Graph Convolutional Networks for Time Series Forecasting",
        "Graph Neural Controlled Differential Equations for Traffic Forecasting",
        "Learning Sparse Neural Networks through L 0 Regularization",
        "Combating Distribution Shift for Accurate Time Series Forecasting via Hypernetworks",
        "Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting",
        "LSGCN: Long Short-Term Traffic Prediction with Graph Convolutional Networks",
        "Adam: A Method for Stochastic Optimization. International Conference on Learning Representations",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Adaptive spatial-temporal graph attention networks for traffic flow forecasting",
        "SGCN: A Graph Sparsifier Based on Graph Convolutional Networks",
        "Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting",
        "Dissecting Ethereum Blockchain Analytics: What We Learn from Topology and Geometry of the Ethereum Graph?",
        "Diffusion convolutional recurrent neural network: Data-driven traffic forecasting",
        "Collective Classification in Network Data",
        "Structured Sequence Modeling with Graph Convolutional Recurrent Networks",
        "Attention is all you need",
        "Graph Attention Networks",
        "A comprehensive survey on graph neural networks",
        "Graph Wavenet for Deep Spatial-Temporal Graph Modeling",
        "Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition",
        "Early-Bird GCNs: Graph-Network Co-optimization towards More Efficient GCN Training and Inference via Drawing Early-Bird Lottery Tickets",
        "Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting",
        "Robust Graph Representation Learning via Neural Sparsification"
    ],
    "63fec3ce90e50fcafdd70610": [
        "The past, present, and future for software architecture",
        "A general model of software architecture design derived from five industrial approaches",
        "Towards process centered architecting for quantum software systems",
        "The lonesome architect",
        "Intelligent software engineering: Synergy between ai and software engineering",
        "Applications of ai in classical software engineering",
        "How to design a program repair bot? insights from the repairnator project",
        "Towards improving software architecture degradation mitigation by machine learning",
        "Chatgpt as a support tool for online behavioral task programming",
        "Engineering education in the era of chatgpt: Promise and pitfalls of generative ai for education",
        "Chatgpt and software testing education: Promises &amp; perils",
        "An analysis of the automatic bug fixing performance of chatgpt",
        "A survey on software architecture analysis methods",
        "What industry needs from architectural languages: A survey",
        "Replication package for the paper: Towards human-bot collaborative software architecting with chatgpt",
        "Software architecture in a changing world",
        "A categorical archive of chatgpt failures",
        "The rise of chatgpt and the fall of the software developer -is this the beginning of the end?"
    ],
    "63aa623e90e50fcafd978bc2": [
        "Overview of the medical question answering task at TREC 2017 LiveQA",
        "Bridging the Gap Between Consumers' Medication Questions and Trusted Answers",
        "Large Language Models are Zero-Shot Clinical Information Extractors",
        "Pathways: Asynchronous distributed dataflow for ML",
        "A pretrained language model for scientific text",
        "Health literacy interventions and outcomes: an updated systematic review",
        "Large Scale Autoregressive Language Modeling with Mesh-Tensorflow version 1.0. If you use this software, please cite it using these metadata",
        "Best practices for developing and validating scales for health, social, and behavioral research: a primer",
        "None",
        "On the opportunities and risks of foundation models",
        "Language Models are Changing AI: The Need for Holistic Evaluation",
        "Language models are few-shot learners",
        "Ethical machine learning in healthcare",
        "Scaling language modeling with pathways",
        "Scaling instruction-finetuned language models",
        "A benchmark for information-seeking question answering in typologically diverse languages",
        "Training verifiers to solve math word problems",
        "The Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision-Making Systems",
        "Glam: Efficient scaling of language models with mixture-of",
        "Health inequities and the inappropriate use of race in nephrology",
        "Deep learning-enabled medical computer vision",
        "Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models",
        "Counterfactual fairness in text classification through robustness in",
        "Datasheets for datasets",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Ppt: Pre-trained prompt tuning for few-shot learning",
        "Ethics and governance of artificial intelligence for health",
        "Ptr: Prompt tuning with rules for text classification",
        "Measuring massive multitask language understanding",
        "Training Compute-Optimal Large Language Models",
        "Bigger is Not Always Better",
        "Moving beyond \"algorithmic bias is a data problem",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "A dataset for biomedical research question answering",
        "A large scale distantly supervised challenge dataset for reading comprehension",
        "Language models (mostly) know what they know",
        "Scaling laws for neural language models",
        "Identifying credible sources of health information in social media: Principles and attributes",
        "Algorithmic monoculture and social welfare",
        "Large Language Models are Zero-Shot Reasoners",
        "Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery",
        "Rethinking Explainability as a Dialogue: A Practitioner's Perspective",
        "Can language models learn from explanations in context? arXiv preprint",
        "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "The power of scale for parameter-efficient prompt tuning",
        "Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the",
        "Solving quantitative reasoning problems with language models",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Holistic evaluation of language models",
        "Can large language models reason about medical questions? arXiv preprint",
        "Teaching Models to Express Their Uncertainty in Words",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "GPT understands, too",
        "The medical algorithmic audit",
        "Decoupled weight decay regularization",
        "BioGPT: generative pre-trained transformer for biomedical text generation and mining",
        "Medical Journals Blind to Racism as Health Crisis, Critics Say",
        "None",
        "Model cards for model reporting in Proceedings of the conference on fairness, accountability, and transparency",
        "Scale development: ten main limitations and recommendations to improve future research practices",
        "Show your work: Scratchpads for intermediate computation with language models",
        "The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People",
        "Training language models to follow instructions with human feedback",
        "MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for",
        "A large corpus for question answering on electronic medical records",
        "DARE: Data augmented relation extraction with gpt-2",
        "Bleu: a method for automatic evaluation of machine translation in",
        "Perturbation sensitivity analysis to detect unintended model biases",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic",
        "Development of a Transparency Artifact for Health Datasets",
        "A 176B-Parameter Open-Access Multilingual Language Model",
        "Expert discussions improve comprehension of difficult cases in medical image assessment",
        "Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model",
        "Larger biomedical domain language model",
        "Development of the Patient Education Materials Assessment Tool (PEMAT): a new measure of understandability and actionability for print and audiovisual patient information",
        "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
        "A Large Language Model for Science",
        "Language models for dialog applications",
        "Use of deep learning to develop continuous-risk models for adverse event prediction from electronic health records",
        "Towards reliability using pretrained large model extensions",
        "An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition",
        "Attention is all you need",
        "Hidden in plain sight-reconsidering the use of race correction in clinical algorithms",
        "Measuring harm in healthcare: optimizing adverse event review",
        "Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters",
        "Self-consistency improves chain of thought reasoning in language models",
        "Finetuned language models are zero-shot learners",
        "Emergent abilities of large language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Ethical and social risks of harm from language models",
        "The reliability of AHRQ Common Format Harm Scales in rating patient safety events",
        "Deep bidirectional languageknowledge graph pretraining",
        "Pretraining Language Models with Document Links",
        "None",
        "Predicting conversion to wet age-related macular degeneration using deep learning",
        "Hurtful words: quantifying biases in clinical contextual word embeddings in proceedings of the ACM Conference on Health, Inference, and Learning",
        "OPT: Open pre-trained transformer language models",
        "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
    ],
    "63f2e4ae90e50fcafd283025": [
        "Structured denoising diffusion models in discrete state-spaces",
        "Geom: Energy-annotated molecular conformations for property prediction and molecular generation",
        "Layer normalization",
        "Equivariant energy-guided sde for inverse molecular design",
        "Geometric and physical quantities improve e (3) equivariant message passing",
        "Principal neighbourhood aggregation for graph nets",
        "Diffdock: Diffusion steps, twists, and turns for molecular docking",
        "Molgensurvey: A systematic survey in machine learning models for molecule design",
        "A generalization of transformer networks to graphs",
        "Gemnet: Universal directional graph neural networks for molecules",
        "Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules",
        "Diffusion models for graphs benefit from discrete state spaces",
        "A decade of fragment-based drug design: strategic advances and lessons learned",
        "Denoising diffusion probabilistic models",
        "Argmax flows and multinomial diffusion: Learning categorical distributions",
        "Equivariant diffusion for molecule generation in 3d",
        "Mudiff: Unified diffusion for complete molecule generation",
        "Graphgdp: Generative diffusion processes for permutation invariant graph generation",
        "Mdm: Molecular diffusion model for 3d molecule generation",
        "Equivariant 3d-conditional diffusion models for molecular linker design",
        "Illuminating protein space with a programmable generative model",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Spatial transformer networks",
        "Hierarchical generation of molecular graphs using structural motifs",
        "Score-based generative modeling of graphs via the system of stochastic differential equations",
        "Equivariance with learned canonicalization functions",
        "Efficient graph generation with graph recurrent attention networks",
        "Equiformer: Equivariant graph attention transformer for 3d atomistic graphs",
        "Constrained graph variational autoencoders for molecule design",
        "Fast graph generative model via spectral diffusion",
        "Graphnvp: An invertible flow model for generating molecular graphs",
        "Learning to extend molecular scaffolds with structural motifs",
        "Graph networks for molecular design",
        "Geometry-complete diffusion for 3d molecule generation",
        "Open babel: An open chemical toolbox",
        "Moldiff: Addressing the atom-bond inconsistency problem in 3d molecule diffusion generation",
        "E(n) equivariant normalizing flows",
        "E (n) equivariant normalizing flows",
        "E (n) equivariant graph neural networks",
        "Structure-based drug design with equivariant diffusion models",
        "Protein sequence and structure co-design with equivariant translation",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Generative modeling by estimating gradients of the data distribution",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "Attention is all you need",
        "Top-n: Equivariant set and graph generation without exchangeability",
        "Digress: Discrete denoising diffusion for graph generation",
        "Retrieval-based controllable molecule generation",
        "Broadly applicable and accurate protein design by integrating structure prediction networks and diffusion generative models",
        "Protein structure generation via folding diffusion",
        "Moleculenet: a benchmark for molecular machine learning",
        "Geodiff: A geometric diffusion model for molecular conformation generation",
        "Set norm and equivariant skip connections: Putting the deep in deep sets"
    ],
    "64be53113fda6d7f06326238": [
        "Ext5: Towards extreme multi-task scaling for transfer learning",
        "Query focused abstractive summarization: Incorporating query relevance, multi-document coverage, and summary length constraints into seq2seq models",
        "The long-document transformer",
        "Low cost evaluation in information retrieval",
        "Scaling instruction-finetuned language models",
        "A dataset of information-seeking questions and answers anchored in research papers",
        "Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
        "Questions and challenges for the new psychology of reasoning",
        "Long form question answering",
        "Question asking during tutoring",
        "Mechanisms that generate questions. Questions and information systems",
        "Retrieval augmented language model pre-training",
        "Unnatural instructions: Tuning language models with (almost) no human labor",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Few-shot learning with retrieval augmented language models",
        "Dense passage retrieval for open-domain question answering",
        "Automatically generating datasets for querybased multi-document summarization",
        "Natural questions: A benchmark for question answering research",
        "Natural questions: A benchmark for question answering research",
        "Reasoning in vector space: An exploratory study of question answering",
        "Rouge: A package for automatic evaluation of summaries",
        "Dense hierarchical retrieval for open-domain question answering",
        "S2ORC: The semantic scholar open research corpus",
        "emrqa: A large corpus for question answering on electronic medical records",
        "Bioread: A new dataset for biomedical reading comprehension",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Learning end-to-end goal-oriented dialog with multiple answers",
        "Squad: 100,000+ questions for machine comprehension of text",
        "Know what you don't know: Unanswerable questions for squad",
        "Multitask prompted training enables zero-shot task generalization",
        "Large language models encode clinical knowledge",
        "Biomrc: A dataset for biomedical machine reading comprehension",
        "Factoid questions meet long-form answers",
        "A large language model for science",
        "Language models for dialog applications",
        "Newsqa: A machine comprehension dataset",
        "Neural correlates of dual-task effect on belief-bias syllogistic reasoning: a near-infrared spectroscopy study",
        "Squality: Building a long-document summarization dataset the hard way",
        "Self-instruct: Aligning language model with self generated instructions",
        "Dual processes in reasoning?",
        "Finetuned language models are zero-shot learners",
        "Towards aicomplete question answering: A set of prerequisite toy tasks",
        "How do we answer complex questions: Discourse structure of long-form answers",
        "A critical evaluation of evaluations for long-form question answering",
        "QMSum: A new benchmark for querybased multi-domain meeting summarization"
    ],
    "64a63bddd68f896efaec64af": [
        "Realistic reevaluation of knowledge graph completion methods: An experimental study",
        "Translating embeddings for modeling multirelational data",
        "ICEWS Coded Event Data",
        "Language models are few-shot learners",
        "Knowledge is flat: A seq2seq generative framework for various knowledge graph completion",
        "MLMLM: link prediction with mean likelihood masked language model",
        "Hyte: Hyperplane-based temporally aware knowledge graph embedding",
        "Convolutional 2d knowledge graph embeddings",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "Learning sequence encoders for temporal knowledge graph completion",
        "Diachronic embedding for temporal knowledge graph completion",
        "Explaining and harnessing adversarial examples",
        "Time-dependent entity embedding is not all you need: A re-evaluation of temporal knowledge graph completion models under a unified framework",
        "Multi-task learning for knowledge graph completion with pre-trained language models",
        "Tensor decompositions for temporal knowledge base completion",
        "Deriving validity time in knowledge graph",
        "The power of scale for parameter-efficient prompt tuning",
        "Sk2: Integrating implicit sentiment knowledge and explicit syntax knowledge for aspect-based sentiment analysis",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Learning entity and relation embeddings for knowledge graph completion",
        "P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks",
        "Decoupled weight decay regularization",
        "Do pretrained models benefit knowledge graph completion? a reliable evaluation and a reasonable approach",
        "Towards deep learning models resistant to adversarial attacks",
        "Adversarial training methods for semisupervised text classification",
        "A three-way model for collective learning on multi-relational data",
        "Sequence-to-sequence knowledge graph completion and question answering",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "Observed versus latent features for knowledge base and text inference",
        "Complex embeddings for simple link prediction",
        "Composition-based multirelational graph convolutional networks",
        "Universal adversarial triggers for attacking and analyzing NLP",
        "2021a. Structure-augmented text representation learning for efficient knowledge graph completion. In WWW '21: The Web Conference 2021, Virtual Event / Ljubljana",
        "KEPLER: A unified model for knowledge embedding and pre-trained language representation",
        "PromDA: Prompt-based data augmentation for lowresource NLU tasks",
        "Knowledge graph embedding by translating on hyperplanes",
        "BERT4GCN: Using BERT intermediate layers to augment GCN for aspect-based sentiment classification",
        "From discrimination to generation: Knowledge graph completion with generative transformer",
        "Temporal knowledge graph embedding model based on additive time series decomposition",
        "Tero: A time-aware knowledge graph embedding via temporal rotation",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "KG-BERT: BERT for knowledge graph completion",
        "Big bird: Transformers for longer sequences",
        "We also compare CSProm-KG against several competitive PLM-based methods"
    ],
    "64cc77b33fda6d7f06aebd0d": [
        "Generating music from text",
        "Deep learning techniques for music generation",
        "Extracting training data from diffusion models",
        "Vggsound: A large-scale audio-visual dataset",
        "Hts-at: A hierarchical token-semantic audio transformer for sound classification and detection",
        "Clap learning audio concepts from natural language supervision",
        "The machine learning algorithm as creative musical tool",
        "Riffusion -Stable diffusion for real-time music generation",
        "Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour",
        "Audioclip: Extending clip to image, text and audio",
        "Deep residual learning for image recognition",
        "Cnn architectures for large-scale audio classification",
        "Denoising diffusion probabilistic models",
        "Classifier-free diffusion guidance",
        "Noise2music: Text-conditioned music generation with diffusion models",
        "Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models",
        "Adam: A method for stochastic optimization",
        "Auto-encoding variational bayes",
        "HifiGAN: Generative adversarial networks for efficient and high fidelity speech synthesis",
        "Panns: Large-scale pretrained audio neural networks for audio pattern recognition",
        "Diffwave: A versatile diffusion model for audio synthesis",
        "AudioGen: Textually guided audio generation",
        "Gradient-based learning applied to document recognition",
        "AudioLDM: Text-to-audio generation with latent diffusion models",
        "A robustly optimized bert pretraining approach",
        "Mubert: A simple notebook demonstrating prompt-based music generation",
        "Film: Visual reasoning with a general conditioning layer",
        "ESC: dataset for environmental sound classification",
        "Hierarchical text-conditional image generation with clip latents",
        "FastSpeech 2: Fast and high-quality end-to-end text to speech",
        "Highresolution image synthesis with latent diffusion models",
        "A dataset and taxonomy for urban sound research",
        "Diffusion art or digital forgery? investigating data replication in diffusion models",
        "Denoising diffusion implicit models",
        "End-to-end text to speech synthesis with human-level quality",
        "Musical genre classification of audio signals",
        "Attention is all you need",
        "Wav2clip: Learning robust audio representations from clip",
        "Large-scale contrastive language-audio pretraining with feature fusion and keywordto-caption augmentation",
        "Discrete diffusion model for text-to-sound generation",
        "Mixup: Beyond empirical risk minimization. Proc. ICLR",
        "Beat transformer: Demixed beat and downbeat tracking with dilated self-attention"
    ],
    "64a29621d68f896efa28fd65": [
        "Quantitative evaluation of intel pebs overhead for online system-noise analysis",
        "A dynamic multithreading processor",
        "Memory hierarchy for web search",
        "Dependence analysis",
        "Rock you like a hurricane: Taming skew in large scale analytics",
        "Performance of Boost context switch",
        "An infrastructure for adaptive dynamic optimization",
        "Isolation in Rust: What is Missing?",
        "Profile-guided automatic inline expansion for C programs",
        "AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications",
        "Taming hardware event samples for precise and versatile feedback directed optimizations",
        "A VLIW architecture for a trace scheduling compiler",
        "Coz: Finding code that counts with causal profiling",
        "Context switch overheads for Linux on ARM platforms",
        "When Idling is Ideal: Optimizing Tail-Latency for Highly-Dispersed Datacenter Workloads with Persephone",
        "Compiler support for lightweight context switching",
        "Kotlin coroutines: design and implementation",
        "A state of the art review of intelligent scheduling",
        "ait: Worst-case execution time prediction by static program analysis",
        "Trace scheduling: A technique for global microcode compaction",
        "Neptune: Scheduling suspendable tasks for unified stream/batch applications",
        "Propeller: Profile Guided Optimizing Large Scale LLVMbased Relinker",
        "CoroBase: coroutine-oriented main-memory database engine",
        "Maximized performance: Comparing the effects of Hyper-Threading, software updates",
        "A case against (most) context switches",
        "Intel Accelerator Engines",
        "Apt-get: Profile-guided timely software prefetching",
        "Exploiting coroutines to attack the\" killer nanoseconds",
        "RustBelt: Securing the foundations of the Rust programming language",
        "Shinjuku: Preemptive scheduling for ?second-scale tail latency",
        "Profiling a warehouse-scale computer",
        "Intel Xeon Sapphire Rapids Shows Built-in Accelerators at Innovation 2022",
        "I-spy: Context-driven conditional instruction prefetching with coalescing",
        "Advanced usage of last branch records",
        "An introduction to last branch records",
        "fiber_handle-fibers without scheduler",
        "Language-Based Security: Invited Lecture",
        "Quantifying the cost of context switch",
        "The multiflow trace scheduling compiler",
        "Language-based isolation of untrusted Javascript",
        "Optimal basic block instruction scheduling for multiple-issue processors using constraint programming",
        "The rust language",
        "Efficient and exact data dependence analysis",
        "Revisiting coroutines",
        "Register liveness analysis of executable code",
        "C++ Extensions for Coroutines",
        "On the applicability of PEBS based online memory access tracking for heterogeneous memory management at scale",
        "Optimizing function placement for large-scale data-center applications",
        "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads",
        "Bolt: a practical binary optimizer for data centers and beyond",
        "Lightning bolt: powerful, fast, and scalable binary optimization",
        "Register liveness analysis for optimizing dynamic binary translation",
        "Interleaving with coroutines: a practical approach for robust index joins",
        "Guest editorial: A review of worst-case execution-time analysis",
        "Applications of thread prioritization in SMT processors",
        "Google-wide profiling: A continuous profiling infrastructure for data centers",
        "A languagebased approach to security",
        "Adapting software fault isolation to contemporary CPU architectures",
        "Modern processor design: fundamentals of superscalar processors",
        "Operating system concepts",
        "Overcoming the challenges to feedbackdirected optimization (keynote talk)",
        "Softsku: Optimizing server architectures for microservice diversity@ scale",
        "Efficient coroutines for the Java platform",
        "Operating systems internals and design principles",
        "Principles and implementation techniques of software-based fault isolation",
        "Collecting performance data with PAPI-C",
        "Handling long-latency loads in a simultaneous multithreading processor",
        "Performance insights to Intel? hyper-threading technology",
        "Efficient software-based fault isolation",
        "Spark: Cluster computing with working sets",
        "Riffle: Optimized shuffle service for large-scale data analytics",
        "The demikernel datapath os architecture for microsecond-scale datacenter systems"
    ],
    "63969ba790e50fcafdcf1d53": [
        "Efficient large scale language modeling with mixtures of experts",
        "wav2vec 2.0: A framework for self-supervised learning of speech representations",
        "Dota 2 with large scale deep reinforcement learning",
        "What is the state of neural network pruning? Proceedings of machine learning and systems",
        "Language models are few-shot learners",
        "Net2net: Accelerating learning via knowledge transfer",
        "Scaling language modeling with pathways",
        "Unified scaling laws for routed language models",
        "None",
        "The efficiency misnomer",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Towards adaptive residual network training: A neural-ode perspective",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Glam: Efficient scaling of language models with mixture-of-experts",
        "Rigging the lottery: Making all tickets winners",
        "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity",
        "The state of sparsity in deep neural networks",
        "Efficient training of bert by progressively stacking",
        "On the transformer growth for progressive bert training",
        "DEMix layers: Disentangling domains for modular language modeling",
        "Masked autoencoders are scalable vision learners",
        "Highly accurate protein structure prediction with alphafold",
        "Imagenet classification with deep convolutional neural networks",
        "Albert: A lite bert for self-supervised learning of language representations",
        "Optimal brain damage",
        "Gshard: Scaling giant models with conditional computation and automatic sharding",
        "BASE layers: Simplifying training of large, sparse models",
        "Shallow-to-deep training for neural machine translation",
        "M6-10t: A sharing-delinking paradigm for efficient multi-trillion parameter pretraining",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Multimodal contrastive learning with limoe: the language-image mixture of experts",
        "Do transformer modifications transfer across implementations and applications?",
        "Evomoe: An evolutional mixture-of-experts training framework via dense-to-sparse gate",
        "Training language models to follow instructions with human feedback",
        "Learning transferable visual models from natural language supervision",
        "Scaling language models: Methods, analysis &amp; insights from training gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Scaling vision with sparse mixture of experts",
        "Scaling up models and data with t5x and seqio",
        "Hash layers for large sparse models",
        "Mastering atari, go, chess and shogi by planning with a learned model",
        "Adafactor: Adaptive learning rates with sublinear memory cost",
        "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer",
        "Staged training for transformer language models",
        "Revisiting unreasonable effectiveness of data in deep learning era",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Superglue: A stickier benchmark for general-purpose language understanding systems",
        "Finetuned language models are zero-shot learners",
        "Transformers: State-of-the-art natural language processing",
        "Residual mixture of experts",
        "Progressively stacking 2.0: A multi-stage layerwise training method for bert training speedup",
        "Speeding up deep model training by sharing weights and then unsharing",
        "Coca: Contrastive captioners are image-text foundation models",
        "Scaling vision transformers",
        "Moefication: Transformer feed-forward layers are mixtures of experts",
        "Mixture-of-experts with expert choice routing",
        "Designing effective sparse expert models",
        "Moebert: from bert to mixture-of-experts via importance-guided adaptation"
    ],
    "64893b17d68f896efa982789": [
        "Visionlanguage model for visual question answering in medical imagery",
        "Neural summarization by extracting sentences and words",
        "Vicuna: An opensource chatbot impressing gpt-4",
        "Preparing a collection of radiology examinations for distribution and retrieval",
        "Medalpaca-an open-source collection of medical conversational ai models and training data",
        "A comprehensive survey of deep learning for image captioning",
        "Mimic-cxr, a de-identified publicly available database of chest radiographs with free-text reports",
        "Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge",
        "Q2atransformer: Improving medical vqa via an answer querying decoder",
        "Multiscale feature extraction and fusion of image and text in vqa",
        "Video-chatgpt: Towards detailed video understanding via large vision and language models",
        "Summarunner: A recurrent neural network based sequence model for extractive summarization of documents",
        "None",
        "Gpt-4 technical report",
        "Stanford alpaca: An instruction-following llama model",
        "Llama: Open and efficient foundation language models",
        "Medclip: Contrastive learning from unpaired medical images and text",
        "Pmc-llama: Further finetuning llama on medical papers",
        "Doctorglm: Fine-tuning your chinese doctor is not a herculean task",
        "From recognition to cognition: Visual commonsense reasoning",
        "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
        "Adding conditional control to text-to-image diffusion models",
        "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
    ],
    "64a29612d68f896efa28bca5": [
        "SPECjbb",
        "Speedometer",
        "Apache cassandra",
        "Apache kafka",
        "Apache Solr",
        "Apache tomcat",
        "TPC-C",
        "Exploring Predictive Replacement Policies for Instruction Cache and Branch Target Buffer",
        "A Novel Methodology Using Genetic Algorithms for the Design of Caches and Cache Replacement Policy",
        "The Rocket Chip Generator",
        "AsmDB: Understanding and Mitigating Front-End Stalls in Warehouse-Scale Computers",
        "A study of replacement algorithms for a virtual-storage computer",
        "QEMU, a Fast and Portable Dynamic Translator",
        "The Gem5 Simulator. SIGARCH Comput. Archit. News",
        "Proceedings of the 21st Annual ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages, and Applications",
        "OLTP-Bench: An Extensible Testbed for Benchmarking Relational Databases",
        "Improving cache management policies using dynamic reuse distances",
        "Clearing the Clouds: A Study of Emerging Scale-out Workloads on Modern Hardware. SIGPLAN Not",
        "Evolution of the samsung exynos cpu microarchitecture",
        "Virtualization with KVM",
        "Instruction fetch unit with early instruction fetch mechanism",
        "Rebasing Instruction Prefetching: An Industry Perspective",
        "Reestablishing Fetch-Directed Instruction Prefetching: An Industry Perspective",
        "Back to the Future: Leveraging Belady's Algorithm for Improved Cache Replacement",
        "High performing cache hierarchies for server workloads: Relaxing inclusion to capture the latency benefits of exclusive caches",
        "High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)",
        "Cost-sensitive cache replacement algorithms",
        "Cache replacement algorithms with nonuniform miss costs",
        "TailBench: A benchmark suite and evaluation methodology for latency-critical applications",
        "Twig: Profile-guided btb prefetching for data center applications",
        "Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications",
        "LACS: A locality-aware cost-sensitive cache replacement algorithm",
        "Counter-based cache replacement and bypassing algorithms",
        "Blasting through the frontend bottleneck with shotgun",
        "Boomerang: A metadata-free architecture for control flow delivery",
        "A large, fast instruction window for tolerating cache misses",
        "McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures",
        "An Imitation Learning Approach for Cache Replacement",
        "A survey of techniques for approximate computing",
        "The misprediction recovery cache",
        "Criticality aware tiered cache hierarchy: a fundamental relook at multi-level cache hierarchies",
        "Fido: A cache that learns to fetch",
        "BOLT: A Practical Binary Optimizer for Data Centers and Beyond",
        "Renaissance: Benchmarking Suite for Parallel Applications on the JVM",
        "ANALYSIS OF CACHE REPLACEMENT-ALGORITHMS",
        "Adaptive Insertion Policies for High Performance Caching",
        "A case for MLP-aware cache replacement",
        "A Scalable Front-End Architecture for Fast Instruction Delivery",
        "Fetch directed instruction prefetching",
        "Optimizations enabled by a decoupled front-end architecture. Computers",
        "The Entangling Instruction Prefetcher",
        "Locality vs. criticality",
        "Benchmark synthesis using the LRU cache hit function",
        "A top-down method for performance analysis and counters architecture"
    ],
    "621454435aee126c0f1d702f": [
        "Conditional channel gated networks for task-aware continual learning",
        "Ilya Sutskever, and Dario Amodei",
        "Exponentially increasing the capacity-to-computation ratio for conditional computation in deep learning",
        "CoAtNet: Marrying convolution and attention for all data sizes",
        "Transformer-XL: Attentive language models beyond a fixed-length context",
        "Language modeling with gated convolutional networks",
        "None",
        "Tricks for training sparse translation models",
        "An iterative procedure for obtaining i-projections onto the intersection of convex sets. The annals of Probability",
        "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity",
        "NAS-FPN: learning scalable feature pyramid architecture for object detection",
        "Hard mixtures of experts for large scale weakly supervised vision",
        "Deep residual learning for image recognition",
        "Identity mappings in deep residual networks",
        "Gaussian error linear units (GELUs)",
        "None",
        "A brief survey on power gating design",
        "Gpipe: Efficient training of giant neural networks using pipeline parallelism",
        "A domain-specific supercomputer for training deep neural networks",
        "Scaling laws for neural language models",
        "GShard: Scaling giant models with conditional computation and automatic sharding",
        "Base layers: Simplifying training of large, sparse models",
        "Conditional computation for continual learning",
        "Pipedream: Generalized pipeline parallelism for dnn training",
        "Scalable transfer learning with expert models",
        "Improving language understanding by generative pre-training",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Hash layers for large sparse models",
        "None",
        "Mesh-tensorflow: Deep learning for supercomputers",
        "Outrageously large neural networks: The sparsely-gated mixture-ofexperts layer",
        "Adafactor: Adaptive learning rates with sublinear memory cost",
        "Megatron-lm: Training multi-billion parameter language models using model parallelism",
        "Superglue: A stickier benchmark for general-purpose language understanding systems",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "GSPMD: general and scalable parallelization for ML computation graphs"
    ],
    "64ae66f63fda6d7f0684abc0": [
        "A review on language models as knowledge bases",
        "Dbpedia: A nucleus for a web of open data",
        "Probing pre-trained language models for semantic attributes and their values",
        "Transformer networks of human conceptual knowledge. Psychological review",
        "Resource description framework (rdf) model and syntax specification",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "OpenPrompt: An open-source framework for promptlearning",
        "What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models",
        "Resource description framework (rdf)",
        "Probing linguistic systematicity",
        "The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
        "Reasoning with transformer-based models: Deep learning, but shallow reasoning",
        "Designing and interpreting probes with control tasks",
        "A structural probe for finding syntax in word representations",
        "Sparql query language for rdf",
        "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
        "How can we know what language models know?",
        "Putting words in BERT's mouth: Navigating contextualized vector spaces with pseudowords",
        "Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly",
        "Contrastive selfsupervised learning for commonsense reasoning",
        "None",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Does BERT know that the IS-a relation is transitive?",
        "Generated knowledge prompting for commonsense reasoning",
        "Gpt understands, too",
        "Roberta: A robustly optimized bert pretraining approach",
        "Exploring BERT's sensitivity to lexical cues using tests from semantic priming",
        "Ontological constitutions for classes and properties",
        "Copen: Probing conceptual knowledge in pre-trained language models",
        "How context affects language models' factual predictions",
        "Language models as knowledge bases?",
        "Information-theoretic probing for linguistic structure",
        "Relational World Knowledge Representation in Contextual Language Models: A Review",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Automatic word sense discrimination",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge",
        "Wikidata: a free collaborative knowledgebase",
        "Probing pretrained language models for lexical semantics",
        "Knowledge graph embedding: A survey of approaches and applications",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Word knowledge dimensions in l2 lexical inference: Testing vocabulary knowledge and partial word knowledge"
    ],
    "62a7fc635aee126c0ff5e394": [
        "Analytical molecular surface calculation",
        "A general and robust ray-casting-based algorithm for triangulating surfaces at the nanoscale",
        "NanoShaper-VMD interface: Computing and visualizing surfaces, pockets and channels in molecular systems",
        "The interpretation of protein structures: estimation of static accessibility",
        "Kernel modeling for molecular surfaces using a uniform solution",
        "Geometric Detection Algorithms for Cavities on Protein Surfaces in Molecular Graphics: A Survey: Detection Algorithms for Cavities",
        "On the definition and the construction of pockets in macromolecules",
        "Computational methods and tools for binding site recognition between proteins and small molecules: From classical geometrical approaches to modern machine learning strategies",
        "CAVIAR: A method for automatic cavity detection, description and decomposition into subcavities",
        "LIGSITE csc : Predicting ligand binding sites using the Connolly surface and degree of conservation",
        "The ConSurf-HSSP database: The mapping of evolutionary conservation among homologs onto PDB structures",
        "Fpocket: An open source platform for ligand pocket detection",
        "Identifying and Characterizing Binding Sites and Assessing Druggability",
        "Druggability Indices for Protein Targets Derived from NMR-Based Screening Data",
        "fpocket: scalable high performance pocket detection",
        "Understanding and Predicting Druggability. A High-Throughput Method for Detection of Drug Binding Sites",
        "Combining Global and Local Measures for Structure-Based Druggability Predictions",
        "Structure-based maximal affinity model predicts small-molecule druggability",
        "P2Rank: Machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure",
        "Structure-based druggability assessment-identifying suitable targets for small molecule therapeutics",
        "DeepSite: Protein-binding site predictor using 3D-convolutional neural networks",
        "A Critical Comparative Assessment of Predictions of Protein-Binding Sites for Biologically Relevant Organic Compounds",
        "SHREC 2020: Multi-domain protein shape retrieval challenge",
        "SHREC 2021: Retrieval and classification of protein surfaces equipped with physical and chemical properties",
        "SHREC 2020: Classification in cryo-electron tomograms",
        "Will the Real Cryptic Pocket Please Stand Out?",
        "Structural Biology and Drug Discovery of Difficult Targets: The Limits of Ligandability",
        "Probabilistic pocket druggability prediction via one-class learning",
        "A one-class classification decision tree based on kernel density estimation",
        "Import Vector Domain Description: A Kernel Logistic One-Class Learning Algorithm",
        "Fast Incremental SVDD Learning Algorithm with the Gaussian Kernel",
        "Isolation Forest",
        "Binding MOAD, a high-quality protein ligand database",
        "MOAD Ligand Finder",
        "Web servers and services for electrostatics calculations with APBS and PDB2PQR",
        "Analyzing the Topology of Active Sites: On the Prediction of Pockets and Subpockets",
        "Attention is all you need",
        "Point transformer",
        "Mesh enhancement: selected elliptic methods, foundations and applications",
        "U-net: Convolutional networks for biomedical image segmentation",
        "Structural biology and drug discovery of difficult targets: the limits of ligandability",
        "A density-based algorithm for discovering clusters in large spatial databases with noise",
        "P2rank: Knowledge-based ligand binding site prediction using aggregated local features",
        "Characterization of local geometry of protein surfaces with the visibility criterion",
        "Detection of multiscale pockets on protein surfaces using mathematical morphology",
        "Semi-supervised classification with graph convolutional networks",
        "Protein docking model evaluation by graph neural networks",
        "DeepSurf: a surface-based deep learning approach for the prediction of ligand binding sites on proteins",
        "Development and evaluation of a deep learning model for protein-ligand binding affinity prediction",
        "sc-PDB: a 3D-database of ligandable binding sites-10 years on",
        "DeepSurf: A surface-based deep learning approach for the prediction of ligand binding sites on proteins",
        "SURFNET: A program for visualizing molecular surfaces, cavities, and intermolecular interactions",
        "LIGSITE: Automatic and efficient detection of potential small molecule-binding sites in proteins",
        "PocketPicker: Analysis of ligand binding-sites with shape descriptors",
        "A novel and efficient tool for locating and characterizing protein cavities and binding sites",
        "CASTp 3.0: Computed atlas of surface topography of proteins"
    ],
    "63d9d87390e50fcafd57d878": [
        "A new way in sound synthesis",
        "HTS-AT: A hierarchical token-semantic audio transformer for sound classification and detection",
        "Wavegrad: Estimating gradients for waveform generation",
        "Improving diffusion models for vocoder by considering inference in training",
        "Resgrad: Residual denoising diffusion probabilistic models for text to speech",
        "Diffusion models beat gans on image synthesis",
        "Clotho: an audio captioning dataset",
        "Differentiable digital signal processing",
        "AudioSet: An ontology and human-labeled dataset for audio events",
        "PSLA: Improving audio tagging with pretraining, sampling, labeling, and aggregation",
        "CNN architectures for largescale audio classification",
        "Classifier-free diffusion guidance",
        "Denoising diffusion probabilistic models",
        "Imagen video: High definition video generation with diffusion models",
        "Image-toimage translation with conditional adversarial networks",
        "Digital synthesis of pluckedstring and drum timbres",
        "Fr?chet audio distance: A reference-free metric for evaluating music enhancement algorithms",
        "Audiocaps: Generating captions for audios in the wild",
        "A method for stochastic optimization",
        "Auto-encoding variational bayes",
        "Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis",
        "Large-scale pretrained audio neural networks for audio pattern recognition",
        "Decoupling magnitude and phase estimation with deep resunet for music source separation",
        "Diffwave: A versatile diffusion model for audio synthesis",
        "Textually guided audio generation",
        "Audio super resolution using neural networks",
        "Bilateral denoising diffusion models",
        "Priorgrad: Improving conditional denoising diffusion models with data-driven adaptive prior",
        "Binauralgrad: A two-stage conditional diffusion probabilistic model for binaural audio synthesis",
        "Toward general speech restoration with neural vocoder",
        "Neural vocoder is all you need for speech superresolution",
        "Ontology-aware learning and evaluation for audio tagging",
        "Learning the spectrogram temporal resolution for audio classification",
        "Compositional visual generation with composable diffusion models",
        "Conditional sound generation using neural discrete time-frequency representation learning",
        "Simple pooling front-ends for efficient audio classification",
        "Separate what you describe: language-queried audio source separation",
        "A robustly optimized BERT pretraining approach",
        "Improved denoising diffusion probabilistic models",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "A generative model for raw audio",
        "Full-band general audio synthesis with score-based diffusion",
        "Film: Visual reasoning with a general conditioning layer",
        "Grad-tts: A diffusion probabilistic model for text-to-speech",
        "Learning transferable visual models from natural language supervision",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Hierarchical text-conditional image generation with clip latents",
        "High-resolution image synthesis with latent diffusion models",
        "Image super-resolution via iterative refinement",
        "Photorealistic text-to-image diffusion models with deep language understanding",
        "A dataset and taxonomy for urban sound research",
        "Make-a-video: Textto-video generation without text-video data",
        "D2c: Diffusion-decoding models for few-shot conditional generation",
        "Denoising diffusion implicit models",
        "Score-based generative modeling through stochastic differential equations",
        "End-to-end text to speech synthesis with human-level quality",
        "Lsgm: Score-based generative modeling in latent space",
        "Towards robust speech superresolution",
        "Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation",
        "CSTR VCTK corpus: English multi-speaker corpus for cstr voice cloning toolkit",
        "Discrete diffusion model for textto-sound generation",
        "Audio-to-image crossmodal generation"
    ],
    "643e0ad10746dc40e34197a9": [
        "Training language models to follow instructions with human feedback",
        "Leveraging gpt-4 for post hoc transformation of free-text radiology reports into structured reporting: A multilingual feasibility study",
        "The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations",
        "Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine",
        "Covid-19 open research dataset challenge (cord-19)",
        "Aligning ai with shared human values",
        "Measuring massive multitask language understanding",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "Detecting causal language use in science findings",
        "Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge",
        "Stanford alpaca: An instruction-following llama model",
        "Lora: Low-rank adaptation of large language models",
        "-bit matrix multiplication for transformers at scale",
        "8-bit optimizers via block-wise quantization",
        "Llama: Open and efficient foundation language models",
        "Peft: State-of-the-art parameter-efficient finetuning methods",
        "Language models are few-shot learners"
    ],
    "6334268390e50fcafd6a5a91": [
        "GLUE: A multitask benchmark and analysis platform for natural language understanding",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "A robustly optimized bert pretraining approach",
        "Electra: Pre-training text encoders as discriminators rather than generators",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Language models are few-shot learners",
        "Transfer learning in biomedical natural language processing: An evaluation of BERT and ELMo on ten benchmarking datasets",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "Gpt-3 models are poor few-shot learners in the biomedical domain",
        "Thinking about gpt-3 in-context learning for biomedical ie? think again",
        "BioCreative V CDR task corpus: a resource for chemical disease relation extraction",
        "Discovering drug-target interaction knowledge from biomedical literature",
        "The ddi corpus: An annotated corpus with pharmacological substances and drug-drug interactions",
        "Pubmedqa: A dataset for biomedical research question answering",
        "Automatic semantic classification of scientific literature according to the hallmarks of cancer",
        "SciBERT: A pretrained language model for scientific text",
        "Mimic-iii, a freely accessible critical care database. Scientific data",
        "Electramed: a new pre-trained language representation model for biomedical nlp",
        "Dare: Data augmented relation extraction with gpt-2",
        "Large language models are zero-shot clinical information extractors",
        "Global-to-local neural networks for document-level relation extraction",
        "Rebel: Relation extraction by end-to-end language generation",
        "A sequence-tosequence approach for document-level relation extraction",
        "Qanet: Combining local convolution with global self-attention for reading comprehension",
        "deep contextualized entity representations with entity-aware self-attention",
        "BioELECTRA:pretrained biomedical text encoder using discriminators",
        "Linkbert: Pretraining language models with document links",
        "An overview of the bioasq large-scale biomedical semantic indexing and question answering competition",
        "Results of the seventh edition of the bioasq challenge",
        "Specter: Document-level representation learning using citation-informed transformers",
        "Relation classification via convolutional deep neural network",
        "Attention-based bidirectional long short-term memory networks for relation classification",
        "Joint type inference on entities and relations via graph convolutional networks",
        "A relation-specific attention network for joint entity and relation extraction",
        "Attention as relation: learning supervised multi-head self-attention for relation extraction",
        "A novel cascade binary tagging framework for relational triple extraction",
        "Graphrel: Modeling text as relational graphs for joint entity and relation extraction",
        "Single-stage joint extraction of entities and relations through token pair linking",
        "A partition filter network for joint entity and relation extraction",
        "Extracting relational facts by an end-toend neural model with copy mechanism",
        "Minimize exposure bias of seq2seq models in joint entity and relation extraction",
        "Joint entity and relation extraction with set prediction networks",
        "Reinforced mnemonic reader for machine reading comprehension",
        "Neural machine translation of rare words with subword units",
        "Attention is all you need",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "fairseq: A fast, extensible toolkit for sequence modeling",
        "Adam: A method for stochastic optimization",
        "Transformers: State-of-the-art natural language processing",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Erol Bahadroglu, Alec Peltekian, and Gr?goire Altan-Bonnet. Scifive: a text-to-text transformer model for biomedical literature"
    ],
    "64a29621d68f896efa28fd4a": [
        "XuCode: An Innovative Technology for Implementing Complex Instruction Flows",
        "None",
        "Data Plane Development Kit",
        "eBPF -Introduction, tutorials and community resources",
        "Storage Performance Development Kit",
        "Synopsys Standard Cell Libraries",
        "Yosys Open SYnthesis Suite",
        "Control-Flow Integrity",
        "Secure Virtual Machine Architecture Reference Manual",
        "Trustzone: Integrated Hardware and Software Security",
        "Arm Architecture Reference Manual for A-profile architecture",
        "Hardware Is the New Software",
        "Intel SGX explained",
        "Sanctum: Minimal Hardware Extensions for Strong Software Isolation",
        "The Origin of the VM/370 Time-Sharing System",
        "The Xerox Alto Part 2: Microcode",
        "Transactional Locking II",
        "PALcode for Alpha Microprocessors: System Design Guide",
        "Control Jujutsu: On the Weaknesses of Fine-Grained Control Flow Integrity",
        "The Implementation of Prolog via VAX 8600 Microcode",
        "In a first, researchers extract secret key used to encrypt Intel CPU code",
        "Virtualizing the VAX Architecture",
        "Millicode in an IBM zSeries processor",
        "IBM System/38 Support for Capability-Based Addressing",
        "PowerISA Version 3.0 B",
        "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "Intel Trust Domain Extensions",
        "AMD Memory Encryption",
        "Performance and Security Lessons Learned from Virtualizing the Alpha Processor",
        "Spectre Attacks: Exploiting Speculative Execution",
        "An Exploratory Analysis of Microcode as a Building Block for System Defenses",
        "Reverse Engineering x86 Processor Microcode",
        "Sanctorum: A lightweight security monitor for secure enclaves",
        "Capability-based Computer Systems",
        "Linus Torvalds. x86 -why unite when you can fragment?",
        "Meltdown: Reading Kernel Memory from User Space",
        "CCFI: Cryptographically Enforced Control Flow Integrity",
        "MIPS64 Architecture for Programmers. Volume IV-I: Virtualization Module of the MIPS64 Architecture",
        "Practical, Transparent Operating System Support for Superpages",
        "SmashGuard: A Hardware Solution to Prevent Security Attacks on the Function Return Address",
        "None",
        "The L4 Microkernel on Alpha, Design and Implementation",
        "SPARC JPS2: Common Specification",
        "ERIM: Secure, Efficient in-Process Isolation with Protection Keys (MPK)",
        "The CHERI Capability Model: Revisiting RISC in an Age of Risk"
    ],
    "640a9ffc90e50fcafd03ca47": [
        "TensorFlow: Large-scale machine learning on heterogeneous systems",
        "Active learning: A survey",
        "Named entity disambiguation at scale",
        "Active learning for natural language processing",
        "Scaling to very very large corpora for natural language disambiguation",
        "Neural networks for entity matching: A survey",
        "Signature verification using a \"siamese\" time delay neural network",
        "Siamese neural networks: An overview. Artificial neural networks",
        "The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation",
        "A comparison of personal name matching: Techniques and practical issues",
        "A comparison of string distance metrics for name-matching tasks",
        "A survey on semi-supervised learning",
        "The elements of statistical learning: data mining, inference, and prediction",
        "Deepal: Deep active learning in python",
        "End-to-end neural entity linking",
        "A comprehensive benchmark framework for active learning methods in entity matching",
        "A guided tour to approximate string matching",
        "Learning text similarity with siamese recurrent networks, in: Proceedings of the 1st Workshop on Representation Learning for NLP",
        "Scikit-learn: Machine learning in Python",
        "TF-IDF Character N-grams versus word embedding-based models for fine-grained event classification: a preliminary study",
        "The performance of text similarity algorithms",
        "A survey of deep active learning",
        "Toponym matching through deep neural networks",
        "Supervised classification algorithms in machine learning: A survey and review",
        "Active learning literature survey",
        "Beyond neural scaling laws: beating power law scaling via data pruning",
        "A comparative evaluation of string similarity metrics for ontology alignment",
        "Attention is all you need. Advances in neural information processing systems 30",
        "A comparative survey of deep active learning",
        "A brief introduction to weakly supervised learning"
    ],
    "628304515aee126c0f6f0c83": [
        "A single-cell map of intratumoral changes during anti-pd1 treatment of patients with breast cancer",
        "Single cell omics: from assay design to biomedical application",
        "Animal models in translational medicine: Validation and prediction",
        "Molecular and pharmacological modulators of the tumor immune contexture revealed by deconvolution of rna-seq data",
        "Ovarian cancer cells direct monocyte differentiation through a non-canonical pathway",
        "Batch effects in singlecell rna-sequencing data are corrected by matching mutual nearest neighbors",
        "Integrated analysis of multimodal single-cell data",
        "Harnessing the predictive power of preclinical models for oncology drug development",
        "Massively parallel single-cell rna-seq for marker-free decomposition of tissues into cell types",
        "Machine learning for perturbational single-cell omics",
        "Mathematical methods of organizing and planning production",
        "Finding groups in data: an introduction to cluster analysis",
        "The technology and biology of single-cell rna sequencing",
        "Po-ru Loh, and Soumya Raychaudhuri. Fast, sensitive and accurate integration of single-cell data with harmony",
        "Deep generative modeling for single-cell transcriptomics",
        "scgen predicts single-cell perturbation responses",
        "Compositional perturbation autoencoder for single-cell response modeling",
        "Fda requirements for preclinical studies",
        "Umap: Uniform manifold approximation and projection for dimension reduction",
        "An optimized protocol for human m2 macrophages using m-csf and il-4/il-10/tgf-? yields a dominant immunosuppressive phenotype",
        "Parsing clinical success rates",
        "Robust enumeration of cell subsets from tissue expression profiles",
        "A pan-cancer blueprint of the heterogeneous tumor microenvironment revealed by single-cell profiling",
        "Neuroscience: Standard model",
        "Are animal models predictive for humans? Philosophy, ethics, and humanities in medicine",
        "Causal imputation via synthetic interventions",
        "Simultaneous epitope and transcriptome measurement in single cells",
        "Animal research: too much faith in models clouds judgement",
        "Human in vivo-generated monocyte-derived dendritic cells and macrophages cross-present antigens through a vacuolar pathway",
        "Clinical development success rates 2006-2015",
        "From louvain to leiden: guaranteeing well-connected communities",
        "Evaluation of tools for highly variable gene discovery from single-cell rna-seq data",
        "Clonal replacement of tumor-specific t cells following pd-1 blockade",
        "Cell types in the mouse cortex and hippocampus revealed by single-cell rna-seq",
        "Single-cell analyses reveal key immune cell subsets associated with response to pd-l1 blockade in triple-negative breast cancer"
    ],
    "646c3addd68f896efa5d1972": [
        "Geom, energyannotated molecular conformations for property prediction and molecular generation",
        "Geometric and physical quantities improve e(3) equivariant message passing",
        "Guacamol: benchmarking models for de novo molecular design",
        "Language gans falling short",
        "Multiscale planar graph generation",
        "Syntaxdirected variational autoencoder for structured data",
        "Molgan: An implicit generative model for small molecular graphs",
        "Relational attention: Generalizing transformers for graph-structured tasks",
        "Xor-cd: Linearly convergent constrained structure generation",
        "Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug design",
        "Multi-constraint molecule sampling for molecule optimization",
        "Symmetryadapted generation of 3d point sets for the targeted discovery of molecules",
        "Molecular dynamics simulations",
        "Exposure bias versus self-recovery: Are distortions really incremental for autoregressive text generation",
        "Denoising diffusion probabilistic models",
        "Argmax flows and multinomial diffusion: Learning categorical distributions",
        "Equivariant diffusion for molecule generation in 3d",
        "Junction tree variational autoencoder for molecular graph generation",
        "Learning multimodal graph-to-graph translation for molecular optimization",
        "Hierarchical graph-to-graph translation for molecules",
        "Hierarchical generation of molecular graphs using structural motifs",
        "Torsional diffusion for molecular conformer generation",
        "A solution for the best rotation to relate two sets of vectors",
        "Equivariant flows: exact likelihood generative learning for symmetric densities",
        "Grammar variational autoencoder",
        "Molgrow: A graph normalizing flow for hierarchical molecular generation",
        "Efficient learning of non-autoregressive graph variational autoencoders for molecular graph generation",
        "From streamlined combinatorial search to efficient constructive procedures",
        "Learning deep generative models of graphs",
        "Multi-objective de novo drug design with conditional graph generative model",
        "Structure-based de novo drug design using 3d deep generative models",
        "Constrained graph variational autoencoders for molecule design",
        "A 3d generative model for structure-based drug design",
        "An autoregressive flow model for 3d molecular geometry generation from scratch",
        "Hdmapgen: A hierarchical graph generative model of high definition maps",
        "A graph vae and graph transformer approach to generating molecular graphs",
        "Pocket2mol: Efficient molecular sampling based on 3d protein pockets",
        "Generating realistic molecular graphs with optimized properties",
        "Fragmentbased ligand generation guided by geometric deep learning on protein-ligand structure",
        "Generating realistic 3d molecules with an equivariant conditional likelihood model",
        "E(n) equivariant graph neural networks",
        "None",
        "Generalization in generation: A closer look at exposure bias",
        "A continuousfilter convolutional neural network for modeling quantum interactions",
        "Generating focused molecule libraries for drug discovery with recurrent neural networks",
        "Threedimensional compound comparison methods and their application in drug discovery",
        "Graphvae: Towards generation of small graphs using variational autoencoders",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "Score-based generative modeling in latent space",
        "Top-n: Equivariant set and graph generation without exchangeability",
        "Regularized molecular conformation fields",
        "Deep convolutional networks on 3d point clouds",
        "Hierarchical recurrent neural networks for graph generation",
        "Markov molecular sampling for multi-objective drug discovery",
        "Protein homology detection through alignment of markov random fields: using MR-Falign",
        "A geometric diffusion model for molecular conformation generation",
        "Molecule generation for drug design: a graph learning perspective",
        "Diffusion probabilistic modeling for video generation",
        "Hit and lead discovery with explorative rl and fragment-based molecule generation",
        "Misc-gan: A multiscale generative model for graphs",
        "Uni-mol: A universal 3d molecular representation learning framework"
    ],
    "6423ac7790e50fcafd55eacf": [
        "TuckER: Tensor factorization for knowledge graph completion",
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Translating embeddings for modeling multirelational data",
        "COMET: Commonsense transformers for automatic knowledge graph construction",
        "HittER: Hierarchical transformers for knowledge graph embeddings",
        "Multilingual knowledge graph completion via ensemble knowledge transfer",
        "MLMLM: Link prediction with mean likelihood masked language model",
        "Inductive entity representations from text via link prediction",
        "Convolutional 2d knowledge graph embeddings",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Relational knowledge: The foundation of higher cognition",
        "A survey on knowledge graphs: Representation, acquisition, and applications",
        "Advances in neural information processing systems, 31. Vid Kocijan and Thomas Lukasiewicz. 2021. Knowledge base completion meets transfer learning",
        "Analysis of the impact of negative sampling on link prediction in knowledge graphs",
        "Pytorch-biggraph: A large scale graph embedding system",
        "Decoupled weight decay regularization",
        "StATIK: Structure and text for inductive knowledge graph completion",
        "Wordnet: a lexical database for english",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Knowledge enhanced contextual word representations",
        "You can teach an old dog new tricks! on training knowledge graph embeddings",
        "Sequence-to-sequence knowledge graph completion and question answering",
        "Yago: a core of semantic knowledge",
        "Open domain question answering using early fusion of knowledge bases and text",
        "A benchmarking study of embedding-based entity alignment for knowledge graphs",
        "Rotate: Knowledge graph embedding by relational rotation in complex space",
        "A reevaluation of knowledge graph completion methods",
        "Inductive relation prediction by subgraph reasoning",
        "Observed versus latent features for knowledge base and text inference",
        "Complex embeddings for simple link prediction",
        "Wikidata: a free collaborative knowledgebase",
        "Knowledge graph embedding: A survey of approaches and applications",
        "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation",
        "Knowledge graph and text jointly embedding",
        "Transformers: State-of-the-art natural language processing",
        "Representation learning of knowledge graphs with entity descriptions",
        "Embedding entities and relations for learning and inference in knowledge bases",
        "Kgbert: Bert for knowledge graph completion",
        "Deep bidirectional language-knowledge graph pretraining"
    ],
    "63b3f1fc90e50fcafdea3697": [
        "TensorFlow: A system for large-scale machine learning",
        "Learning to optimize Halide with tree search and random programs",
        "Bringing TVM into TensorFlow for optimizing neural machine translation on GPU",
        "Amazon EC2 G4 instances",
        "End-to-end speech recognition in English and Mandarin",
        "Tiramisu: A polyhedral compiler for expressing fast and portable code",
        "XGBoost: A scalable tree boosting system",
        "None",
        "MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems",
        "TVM: An automated end-toend optimizing compiler for deep learning",
        "Learning to optimize tensor programs",
        "Efficient primitives for deep learning",
        "Pre-training of deep bidirectional transformers for language understanding",
        "ETO: Accelerating optimization of DNN operators by high-performance tensor program reuse",
        "Cortex: A compiler for recursive deep learning models",
        "Low latency RNN inference with cellular batching",
        "ProTuner: Tuning programs with monte carlo tree search",
        "Deep residual learning for image recognition",
        "TASO: optimizing deep learning computation with automatic generation of graph substitutions",
        "A tool to generate tensor algebra kernels",
        "Packing: Towards 2x NLP BERT acceleration",
        "MLIR: Scaling compiler infrastructure for domain specific computation",
        "Deep learning with dynamic computation graphs",
        "The dynamic neural network toolkit",
        "CUDA fundamental optimization, part 1",
        "NVIDIA T4 70W low profile PCIe GPU accelerator",
        "Programming guide :: CUDA toolkit documentation",
        "CUDA toolkit archive",
        "Developer guide :: NVIDIA deep learning cuDNN documentation",
        "Intel Xeon Platinum 8259CL @ 2.50GHz",
        "An imperative style, high-performance deep learning library",
        "Scikit-learn: Machine learning in Python",
        "Decoupling algorithms from schedules for high-performance image processing",
        "Glow: Graph lowering compiler techniques for neural networks",
        "XLA: Compiling machine learning for peak performance",
        "The cost of training NLP models: A concise overview",
        "Nimble: Efficiently compiling dynamic neural networks for model inference",
        "The next 700 accelerated layers: From mathematical expressions of network computation graphs to accelerated GPU kernels, automatically",
        "Attention is all you need",
        "Evolutionary algorithms: A critical review and its future prospects",
        "RFC] dynamic shape support -graph dispatching",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "Cavs: An efficient runtime system for dynamic neural networks",
        "RFC][AutoTVM] selective tuning",
        "Towards latency-aware DNN optimization with GPU runtime analysis and tail effect elimination",
        "Generating high-performance tensor programs for deep learning",
        "FlexTensor: An automatic schedule exploration and optimization framework for tensor computation on heterogeneous system",
        "DISC: A dynamic shape compiler for machine learning workloads",
        "Neural architecture search with reinforcement learning"
    ],
    "648fd298d68f896efa163bfb": [
        "Pre-training of deep bidirectional transformers for language understanding",
        "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Language models are few-shot learners",
        "Scaling language modeling with pathways",
        "Language models for dialog applications",
        "Training language models to follow instructions with human feedback",
        "The potential impact of chatgpt in clinical and translational medicine",
        "The ai revolution in medicine: Gpt-4 and beyond",
        "Foundation models for generalist medical artificial intelligence",
        "On the dangers of stochastic parrots: Can language models be too big?",
        "Multi-scale attentive interaction networks for chinese medical question answer selection",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "Two large-scale medical dialogue datasets",
        "Browser-assisted question-answering with human feedback",
        "Learning to summarize with human feedback",
        "A 176b-parameter open-access multilingual language model",
        "Low-rank adaptation of large language models",
        "Zero: Memory optimizations toward training trillion parameter models",
        "Glm-130b: An open bilingual pre-trained model",
        "Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models",
        "A 176b-parameter open-access multilingual language model",
        "Bleu: a method for automatic evaluation of machine translation",
        "Rouge: A package for automatic evaluation of summaries"
    ],
    "6456385ad68f896efacf20ac": [
        "Openai. introducing chatgpt",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Lmflow: An extensible toolkit for finetuning and inference of large foundation models",
        "Low-rank adaptation of large language models",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "A dataset for biomedical research question answering",
        "S2ORC: The semantic scholar open research corpus",
        "Decoupled weight decay regularization",
        "Peft: State-of-the-art parameter-efficient fine-tuning methods",
        "Foundation models for generalist medical artificial intelligence",
        "Capabilities of gpt-4 on medical challenge problems",
        "OpenAI. Gpt-4 technical report",
        "Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering",
        "Language models are unsupervised multitask learners",
        "Large language models encode clinical knowledge",
        "Stanford alpaca: An instruction-following llama model",
        "Open and efficient foundation language models"
    ],
    "64c78ba13fda6d7f06dba840": [
        "Use of simd vector operations to accelerate application code performance on low-powered arm and intel platforms",
        "Stackguard: Automatic adaptive detection and prevention of bufferoverflow attacks",
        "Pointguardtm: Protecting pointers from buffer overflow vulnerabilities",
        "Valgrind: A framework for heavyweight dynamic binary instrumentation",
        "AddressSanitizer: A fast address sanity checker",
        "NSan: A floating-point numerical sanitizer",
        "Executable assertions -an aid to reliable software",
        "Applying 'design by contract'",
        "Assert use in github projects",
        "High system-code security with low overhead",
        "Intel? oneapi math kernel library",
        "Smp alternatives",
        "Practical dynamic software updating for c",
        "From global to local quiescence: Wait-free code patching of multi-threaded processes",
        "Multiverse: Compiler-assisted management of dynamic variability in low-level system software",
        "CMake -Cross platform make",
        "Elf(5) -format of exectuable and linking format (ELF) files, Linux Progammer's Manual",
        "None",
        "Big. little processing with arm cortexa15 &amp; cortex-a7: Improving energy efficiency in highperformance mobile platforms",
        "Harnessing energy efficiency of heterogeneous-isa platforms",
        "HECTOR-V: A heterogeneous CPU architecture for a secure RISC-V execution environment",
        "Exploring heterogeneous-isa core architectures for high-performance and energy-efficient mobile socs",
        "Operating system support for overlapping-isa heterogeneous multi-core architectures",
        "Flick: Fast and lightweight isa-crossing call for heterogeneous-isa environments",
        "Popcorn: Bridging the programmability gap in heterogeneous-isa platforms",
        "Gprof: A call graph execution profiler",
        "Memtier benchmark on github",
        "Sok: Sanitizing for security",
        "Taming undefined behavior in llvm",
        "Sysbench -scriptable database and system performance benchmark",
        "Experimental study of memory allocation for high-performance query processing",
        "Dymos: A dynamic modification system",
        "Dynamic software updating",
        "Segmentation and the design of multiprogrammed computer systems",
        "Intel? 64 and ia-32 architectures software developer's manual, combined volumes: 1",
        "Immediate multithreaded dynamic software updates using stack reconstruction",
        "Getting started with As-pectJ",
        "Pin -a dynamic binary instrumentation tool",
        "Pwin -pwning intel pin: Why dbi is unsuitable for security applications",
        "The risc-v instruction set manual, volume i: Unpriviledged isadocument version",
        "An automatic overlay generator",
        "Operating systems: Program overlay techniques",
        "A performance model and code overlay generator for scratchpad enhanced embedded processors",
        "Automatic code overlay generation and partially redundant code fetch elimination",
        "Aspectoriented programming",
        "Dynamic weaving for aspect-oriented programming",
        "Dynamic aspectc++: Generic advice at any time",
        "Function multi-versioning in gcc 6",
        "Creating fat binary programs",
        "Mac OS X Internals: A Systems Approach: A Systems Approach",
        "Universal binaries for linux",
        "Something common about ms-dos and cp/m",
        "Method and apparatus for architecture independent executable files",
        "Method and apparatus for architecture independent executable files",
        "Platform-independent programs",
        "Pe format -win32 apps, en-us"
    ],
    "64c78b9f3fda6d7f06db9a87": [
        "The 2nd jilp championship branch prediction competition (cbp-2)",
        "The 3rd jilp championship branch prediction competition",
        "The 4th jilp championship branch prediction competition (cbp-4)",
        "The 5th jilp championship branch prediction competition (cbp-5)",
        "the microarchitecture of intel, amd and via cpus",
        "sightglass: a benchmark suite and tool to compare different implementations of the same primitives",
        "WASI: The WebAssembly system interface",
        "None",
        "Open Source Security Inc. the amd branch (mis)predictor: Just set it and forget it",
        "New branch prediction vulnerabilities in openssl and necessary software countermeasures",
        "On the power of simple branch prediction analysis",
        "Predicting secret keys via branch prediction",
        "Muontrap: Preventing cross-domain spectre-like attacks by capturing speculative state",
        "Shielding speculative data from microarchitectural covert channels",
        "Preventing timing leaks through transactional branching instructions",
        "Smotherspectre: exploiting speculative execution through port contention",
        "A systematic evaluation of transient execution attacks and defenses",
        "Fallout: Leaking data on meltdownresistant cpus",
        "RFC: Speculative load hardening (a Spectre variant #1 mitigation",
        "Fact: A flexible, constant-time programming language",
        "Sgxpectre: Stealing intel secrets from sgx enclaves via speculative execution",
        "Branchspec: Information leakage attacks exploiting speculative branch instruction executions",
        "None",
        "Enable index masking by default",
        "Covert channels through branch predictors: a feasibility study",
        "Jump over aslr: Attacking branch predictors to bypass aslr",
        "Understanding and mitigating covert channels through branch predictors",
        "Branchscope: A new side-channel attack on directional branch predictor",
        "Spectreguard: An efficient data-centric defense mechanism against spectre attacks",
        "Flush+ flush: a fast and stealthy cache attack",
        "Spectector: Principled detection of speculative information flows",
        "Hardwaresoftware contracts for secure speculation",
        "Bringing the web up to speed with WebAssembly",
        "Spec cpu2006 benchmark descriptions",
        "Reading privileged memory with a side-channel",
        "Understanding contention-based channels and using them for defense",
        "Power9 processor user's manual",
        "Intel analysis of speculative execution side channels",
        "Single thread indirect branch predictors",
        "Intel? C++ Compiler 19.1 Developer Guide and Reference",
        "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "Fast path-based neural branch prediction",
        "Piecewise linear branch prediction",
        "Dynamic branch prediction with perceptrons",
        "???????, ?? ????????: Sfi safety for native-compiled wasm",
        "Speculative buffer overflows: Attacks and defenses",
        "Spectre attacks: Exploiting speculative execution",
        "Spectre returns! speculation attacks using the return stack buffer",
        "Mitigating spectre attacks using cfi informed speculation",
        "Branch prediction strategies and branch target buffer design",
        "Inferring fine-grained control flow inside {SGX} enclaves with branch shadowing",
        "Make page coloring more efficient on slice-based three-level cache",
        "Conditional speculation: An effective approach to safeguard out-oforder execution against spectre attacks",
        "Meltdown: Reading kernel memory from user space",
        "Combining branch predictors",
        "lmbench: Portable tools for performance analysis",
        "A ppm-like, tag-based branch predictor",
        "Demystifying intel branch predictors",
        "Rocksalt: better, faster, stronger sfi for the x86",
        "Dynamic path-based branch correlation",
        "Swivel: Hardening {WebAssembly} against spectre",
        "Going beyond the limits of sfi: Flexible and secure hardwareassisted in-process isolation with hfi",
        "Introduction to cache allocation technology in the intel? xeon? processor e5 v4 family",
        "You shall not bypass: Employing data dependencies to prevent bounds check bypass",
        "{SpecFuzz}: Bringing spectre-type vulnerabilities to the surface",
        "Improving the accuracy of dynamic branch prediction using branch correlation",
        "Amd vs intel market share",
        "I see dead ?ops: Leaking secrets via intel/amd micro-op caches",
        "Cleanupspec: An\" undo\" approach to safe speculation",
        "Context: Leakage-free transient execution",
        "Netspectre: Read arbitrary memory over network",
        "The o-gehl branch predictor. JILP-Championship Branch Prediction",
        "Analysis of the o-geometric history length branch predictor",
        "A 256 kbits l-tage branch predictor",
        "A new case for the tage branch predictor",
        "Tage-sc-l branch predictors",
        "Tage-sc-l branch predictors again",
        "Design tradeoffs for the alpha ev8 conditional branch predictor",
        "A case for (partially) tagged geometric history length branch prediction",
        "Restricting control flow during speculative execution with venkman",
        "Latest intel security news: Updated firmware available for 6th, 7th and 8th generation intel core processors, intel xeon scalable processors and more",
        "A study of branch prediction strategies",
        "Spectre side channels",
        "Secsmt: Securing SMT processors against contention-based covert channels",
        "Contextsensitive fencing: Securing speculative execution via microcode customization",
        "Efficient cache attacks on AES, and countermeasures",
        "Simultaneous multithreading: Maximizing on-chip parallelism",
        "Retpoline: a software construct for preventing branchtarget-injection",
        "Microbenchmarks and mechanisms for reverse engineering of modern branch predictor units",
        "Experiment flows and microbenchmarks for reverse engineering of branch predictor structures",
        "LVI: Hijacking Transient Execution through Microarchitectural Load Value Injection",
        "RIDL: Rogue in-flight data load",
        "Automatically eliminating speculative leaks from cryptographic code with Blade",
        "Nda: Preventing speculative execution attacks at their source",
        "A case for reversible coherence protocol",
        "Invisispec: Making speculative execution invisible in the cache hierarchy",
        "{FLUSH+ RELOAD}: A high resolution, low noise, l3 cache {Side-Channel} attack",
        "Coloris: a dynamic cache partitioning system using page coloring",
        "Native client: A sandbox for portable, untrusted x86 native code",
        "Two-level adaptive training branch prediction",
        "Alternative implementations of two-level adaptive branch prediction",
        "Speculative data-oblivious execution: Mobilizing safe prediction for safe and efficient speculative execution",
        "Speculative taint tracking (stt) a comprehensive protection for speculatively accessed data",
        "Mars: A 64-core armv8 processor",
        "Exploring branch predictors for constructing transient execution trojans",
        "A lightweight isolation mechanism for secure branch predictors",
        "Speculation invariance (invarspec): Faster safe execution through program analysis"
    ],
    "6389d6fb90e50fcafdffbdc3": [
        "Hitting the memory wall: Implications of the obvious",
        "Reflections on the memory wall",
        "A survey of recent prefetching techniques for processor caches",
        "The AMD \"Zen 2\" Processor",
        "Knights landing: Second-generation intel xeon phi product",
        "The ibm blue gene/q compute chip",
        "Evolution of the samsung exynos cpu microarchitecture",
        "The ibm system/360 model 91: Machine philosophy and instruction-handling",
        "Architecture of the ibm system/370",
        "Performance analysis guide for Intel Core i7 processor and Intel Xeon 5500 processors",
        "The microarchitecture of the pentium 4 processor",
        "Power5 system microarchitecture",
        "Power4 system microarchitecture",
        "Path confidence based lookahead prefetching",
        "Efficiently prefetching complex address patterns",
        "Perceptron-based prefetch filtering",
        "Best-offset hardware prefetching",
        "Dspatch: Dual spatial pattern prefetcher",
        "Spatial memory streaming",
        "Access map pattern matching for data cache prefetch",
        "Bingo spatial data prefetcher",
        "Temporal prefetching without the off-chip metadata",
        "Efficient metadata management for irregular data prefetching",
        "Domino temporal data prefetcher",
        "Exploiting spatial locality in data caches using spatial footprints",
        "Linearizing irregular memory accesses for improved correlated prefetching",
        "Pythia: A customizable hardware prefetching framework using online reinforcement learning",
        "Spatio-temporal memory streaming",
        "Bump: Bulk memory access prediction and streaming",
        "Augury: Using data memory-dependent prefetchers to leak data at rest",
        "Prefetch side-channel attacks: Bypassing smap and kernel aslr",
        "Leaking control flow information via the hardware prefetcher",
        "Advanced concepts on address translation, appendix L in 'Computer Architecture: A Quantitative Approach' by hennessy and patterson",
        "Efficient virtual memory for big memory servers",
        "Large-reach memory management unit caches",
        "The interaction of architecture and operating system design",
        "Using the simos machine simulator to study complex computer systems",
        "Profiling a warehouse-scale computer",
        "Clearing the clouds: A study of emerging scaleout workloads on modern hardware",
        "Memory hierarchy for web search",
        "Blasting through the front-end bottleneck with shotgun",
        "Translation ranger: Operating system support for contiguity-aware tlbs",
        "Exploiting page table locality for agile tlb prefetching",
        "Trident: Harnessing architectural resources for all page sizes in x86 processors",
        "Enhancing and exploiting contiguity for fast memory virtualization",
        "Redundant memory mappings for fast access to large memories",
        "Energy-efficient address translation",
        "Computer Architecture: A Quantitative Approach",
        "Architectural and Operating System Support for Virtual Memory",
        "On the effectiveness of address-space randomization",
        "Address space layout permutation (aslp): Towards fine-grained randomization of commodity software",
        "Enhanced operating system security through efficient and fine-grained address space randomization",
        "Wsclock-a simple and effective algorithm for virtual memory management",
        "The Art of Computer Programming",
        "Intel ? 64 and IA-32 Architectures Optimization Reference Manual",
        "Translation Caching: Skip, Don'T Walk (the Page Table)",
        "TLBs Paging-Structure Caches and Their Invalidation.pdf",
        "Kernel address space layout randomization",
        "Breaking kernel address space layout randomization with intel tsx",
        "Transparent Huge Pages",
        "Practical, transparent operating system support for superpages",
        "Intel ? 64 and IA-32 Architectures Software Developer Manuals",
        "AMD-V ? Nested Paging -White Paper",
        "Database Tuning on Linux OS: Reference Guide for AMD EPYC ? 7002 Series Processors",
        "Virtual memory support, armv4 and armv5",
        "Proactively breaking large pages to improve memory overcommitment performance in vmware esxi",
        "SPEC CPU2006 Benchmark Descriptions",
        "SPEC CPU 2017",
        "The GAP benchmark suite",
        "Intel Xeon Gold",
        "Mlpack: A scalable c++ machine learning library",
        "Championship Value Prediction (CVP)",
        "Adaptive insertion policies for high performance caching",
        "The amd opteron northbridge architecture",
        "Intel 5-Level Paging and 5-Level EPT",
        "Prefetched address translation",
        "Libhugetlbfs",
        "Temporal instruction fetch streaming",
        "Sequential program prefetching in memory hierarchies",
        "Effectiveness of hardwarebased stride and sequential prefetching in shared-memory multiprocessors",
        "Arm Architecture Reference Manual for A-profile Architecture",
        "An effective on-chip preloading scheme to reduce data access penalty",
        "Bouquet of instruction pointers: Instruction pointer classifier-based spatial hardware prefetching",
        "Proactive instruction fetch",
        "ARM Cortex-A55 Core Technical Reference Manual r1p0",
        "Morrigan: A composite instruction tlb prefetcher",
        "Page-collect -Capturing Process Memory Usage Under Linux",
        "ChampSim",
        "CVE-2021-4002 Vulnerability",
        "Merging analysis and gshare indexing in perceptron branch prediction",
        "AMD Ryzen Threadripper 3990X",
        "Using simpoint for accurate and efficient simulation",
        "CHiRP: Control-flow history reuse prediction",
        "Multiperspective reuse prediction"
    ],
    "6426ed4590e50fcafd444b1b": [
        "2nd data prefetching championship",
        "Champsim simulator",
        "3rd data prefetching championship",
        "Domino Temporal Data Prefetcher",
        "Bingo spatial data prefetcher",
        "Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning",
        "DSPatch: Dual Spatial Pattern Prefetcher",
        "Perceptron-based prefetch filtering",
        "Stream chaining: Exploiting multiple levels of correlation in data prefetching",
        "Coordinated control of multiple prefetchers in multi-core systems",
        "Stride directed prefetching in scalar processors",
        "Learning Memory Access Patterns",
        "Near-side prefetch throttling: adaptive prefetching for highperformance many-core processors",
        "SPEC CPU2006 Benchmark Descriptions",
        "Linearizing Irregular Memory Accesses for Improved Correlated Prefetching",
        "Making data prefetch smarter: adaptive prefetching on POWER7",
        "Path Confidence Based Lookahead Prefetching",
        "Division of Labor: A More Effective Approach to Prefetching",
        "Best-offset hardware prefetching",
        "AC/DC: an adaptive data cache prefetcher",
        "Data Cache Prefetching Using a Global History Buffer",
        "Bouquet of Instruction Pointers: Instruction Pointer Classifier-based Spatial Hardware Prefetching",
        "SPAC: A Synergistic Prefetcher Aggressiveness Controller for Multi-Core Systems",
        "Sandbox Prefetching: Safe run-time evaluation of aggressive prefetchers",
        "Efficiently prefetching complex address patterns",
        "A hierarchical neural model of data prefetching",
        "Spatial memory streaming",
        "Branch history guided instruction prefetching",
        "Practical off-chip meta-data for temporal memory streaming",
        "Temporal Streaming of Shared Memory",
        "Temporal Prefetching Without the Off-Chip Metadata",
        "Efficient metadata management for irregular data prefetching"
    ],
    "64e432bf3fda6d7f0600af81": [
        "N-gcn: Multi-scale graph convolution for semi-supervised node classification",
        "Dual lottery ticket hypothesis",
        "What is the state of neural network pruning? Proceedings of machine learning and systems",
        "Measuring and relieving the oversmoothing problem for graph neural networks from the topological view",
        "Fastgcn: fast learning with graph convolutional networks via importance sampling",
        "Simple and deep graph convolutional networks",
        "The lottery ticket hypothesis for pre-trained bert networks",
        "A unified lottery ticket hypothesis for graph neural networks",
        "Efficient bert training via early-bird lottery tickets",
        "Clustergcn: An efficient algorithm for training deep and large graph convolutional networks",
        "Adaptive universal generalized pagerank graph neural network",
        "Audio lottery: Speech recognition made ultra-lightweight, noise-robust, and transferable",
        "Provable and practical approximations for the degree distribution using sublinear graph samples",
        "Spectral networks and deep locally connected networks on graphs",
        "Rigging the lottery: Making all tickets winners",
        "The lottery ticket hypothesis: Finding sparse, trainable neural networks",
        "Linear mode connectivity and the lottery ticket hypothesis",
        "Graph u-nets",
        "Diffusion improves graph learning",
        "Neural message passing for quantum chemistry",
        "Inductive representation learning on large graphs",
        "Deep residual learning for image recognition",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Densely connected convolutional networks",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Going deeper with lean point networks",
        "Self-attention graph pooling",
        "Deepgcns: Can gcns go as deep as cnns?",
        "Deepergcn: All you need to train deeper gcns",
        "Deepgcns: Making gcns go as deep as cnns",
        "Deeper insights into graph convolutional networks for semi-supervised learning",
        "Towards deeper graph neural networks",
        "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Sanity checks for lottery tickets: Does your winning ticket really win the jackpot?",
        "Proving the lottery ticket hypothesis: Pruning is all you need",
        "Graph infoclust: Leveraging cluster-level node information for unsupervised graph representation learning",
        "Scattering gcn: Overcoming oversmoothness in graph convolutional networks",
        "Geom-gcn: Geometric graph convolutional networks",
        "Asap: Adaptive structure aware pooling for learning hierarchical graph representations",
        "Towards deep graph convolutional networks on node classification",
        "Structure-aware hierarchical graph pooling using information bottleneck",
        "Adaboosting graph convolutional networks into deep models",
        "Graph attention networks",
        "Graph attention networks",
        "Searching lottery tickets in graph neural networks: A dual perspective",
        "Simplifying graph convolutional networks",
        "Structural entropy guided graph hierarchical pooling",
        "A comprehensive survey on graph neural networks",
        "Representation learning on graphs with jumping knowledge networks",
        "How powerful are graph neural networks?",
        "Optimization of graph neural networks: Implicit acceleration by skip connections and more depth",
        "Hierarchical graph representation learning with differentiable pooling",
        "Gebt: Drawing early-bird tickets in graph convolutional network training",
        "Link prediction based on graph neural networks",
        "Inductive matrix completion based on graph neural networks",
        "Hierarchical multi-view graph pooling with structure learning",
        "Pairnorm: Tackling oversmoothing in gnns",
        "Layer-dependent importance sampling for training deep and large graph convolutional networks",
        "Node sparsity (NS) and edge sparsity (ES) of each layer when GCN+SnoHv2 achieves optimal performance under three small datasets",
        "% Table 11: Performance comparisons on 8, 16, 32 layer settings using SnoHv1(O), SnoHv1(IP), and SnoHv1(ReI) across three small graphs",
        "Dataset: Cora, 2-layer performance: GCN without BN = 85",
        "Dataset: citepseer, 2-layer performance: GCN without BN = 72",
        "Dataset: PubMed, 2-layer performance: GCN without BN = 86"
    ],
    "64c78b993fda6d7f06db5b90": [
        "Freebase: a collaboratively created graph database for structuring human knowledge",
        "Translating Embeddings for Modeling Multi-relational Data",
        "PIE: a parameter and inference efficient solution for large scale knowledge graph embedding reasoning",
        "Knowledge Is Flat: A Seq2Seq Generative Framework for Various Knowledge Graph Completion",
        "MLMLM: Link Prediction with Mean Likelihood Masked Language Model",
        "Autoregressive entity retrieval",
        "Convolutional 2D Knowledge Graph Embeddings",
        "Ogb-lsc: A large-scale challenge for machine learning on graphs",
        "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
        "Dense Passage Retrieval for Open-Domain Question Answering",
        "SimplE Embedding for Link Prediction in Knowledge Graphs",
        "Adam: A Method for Stochastic Optimization",
        "Parallel training of knowledge graph embedding models: a comparison of techniques",
        "Entity-Duet Neural Ranking: Understanding the Role of Knowledge Graph Semantics in Neural Information Retrieval",
        "Learning visual models using a knowledge graph as a trainer",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "The probabilistic relevance framework: BM25 and beyond",
        "Sequence-tosequence knowledge graph completion and question answering",
        "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space",
        "Observed versus latent features for knowledge base and text inference",
        "Complex Embeddings for Simple Link Prediction",
        "Attention is All you Need",
        "Wikidata: a free collaborative knowledgebase",
        "SimKGC: Simple contrastive knowledge graph completion with pre-trained language models",
        "KEPLER: A unified model for knowledge embedding and pre-trained language representation",
        "Towards Better Text Understanding and Retrieval through Kernel Entity Salience Modeling",
        "Embedding Entities and Relations for Learning and Inference in Knowledge Bases",
        "Knowledge graph contrastive learning for recommendation",
        "KG-BERT: BERT for knowledge graph completion",
        "Decaf: Joint decoding of answers and logical forms for question answering over knowledge bases",
        "Jaket: Joint pre-training of knowledge graph and language understanding",
        "Quaternion Knowledge Graph Embeddings",
        "GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding"
    ],
    "6323e96890e50fcafd8a40e6": [
        "None",
        "Virtual screening strategies in drug discovery: a critical review",
        "Defining and Exploring Chemical Spaces Trends Chem",
        "A 2013 Estimation of the size of drug-like chemical space based on GDB-17 data",
        "Generative Models for De Novo Drug Design",
        "Molecular design in drug discovery: a comprehensive review of deep generative models Brief",
        "L 2021 Structure-based de novo drug design using 3D deep generative models",
        "RELATION: A Deep Generative Model for Structure-Based De Novo Drug Design",
        "DockStream: a docking wrapper to enhance de novo molecular design"
    ],
    "64a407dcd68f896efaf1ba6d": [
        "SPEC CPU 2017",
        "A survey of computer architecture simulation techniques and tools",
        "X86-64 instruction usage among C/C++ applications",
        "Transparent control independence (TCI)",
        "Cotson: infrastructure for full system simulation",
        "Redefining the role of the CPU in the era of CPU-GPU integration",
        "The GAP benchmark suite",
        "Qemu, a fast and portable dynamic translator",
        "The gem5 simulator",
        "Building dynamic instrumentation tools with dynamorio",
        "Precise and accurate processor simulation",
        "An evaluation of high-level mechanistic core models",
        "Speculative path power estimation using trace-driven simulations during high-level design phase",
        "Fpga-accelerated simulation technologies (fast): Fast, full-system, cycle-accurate simulators",
        "Control flow optimization via dynamic reconvergence prediction",
        "Asim: A performance model framework",
        "Manycore graph workload analysis",
        "Enabling branch-mispredict level parallelism by selectively flushing instructions",
        "The championship simulator: Architectural simulation for education and competition",
        "Cmp$im: A pin-based on-the-fly multi-core cache simulator",
        "Zesto: A cycle-level simulator for highly detailed microarchitecture exploration",
        "Pin: building customized program analysis tools with dynamic instrumentation",
        "Simics: A full system simulation platform",
        "An analysis of the performance impact of wrong-path memory references on out-of-order and runahead execution processors",
        "Marss: A full system simulator for multicore x86 cpus",
        "Using simpoint for accurate and efficient simulation",
        "Intel alder lake cpu architectures",
        "Control independence in trace processors",
        "The impact of wrong-path memory references in cache-coherent multiprocessor systems",
        "Quantifying and reducing the effects of wrong-path memory references in cache-coherent multiprocessor systems",
        "Ramp gold: an fpga-based architecture simulator for multiprocessors",
        "A comprehensive survey on graph neural networks",
        "Cambricon-S: Addressing irregularity in sparse neural networks through a cooperative software/hardware approach"
    ],
    "63ed9f3290e50fcafd0f10bd": [
        "Recent applications of deep learning and machine intelligence on in silico drug discovery: methods, tools and databases",
        "How to improve r&amp;d productivity: the pharmaceutical industry's grand challenge",
        "Artificial intelligence-enabled de novo design of novel compounds that are synthesizable",
        "Chembl: towards direct deposition of bioassay data",
        "Pubchem 2023 update",
        "Deep learning for molecular design-a review of the state of the art",
        "De novo molecular drug design benchmarking",
        "Advances in de novo drug design: From conventional to machine learning methods",
        "Auto-encoding variational bayes",
        "Automatic chemical design using a data-driven continuous representation of molecules",
        "Generative adversarial networks",
        "Molgan: An implicit generative model for small molecular graphs",
        "Masked graph modeling for molecule generation",
        "A graph vae and graph transformer approach to generating molecular graphs",
        "Conditional vae for de novo molecular generation",
        "De novo direct inverse qspr/qsar: Chemical variational autoencoder and gaussian mixture regression models",
        "drugan: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico",
        "Helixgan a deep learning methodology for conditional de novo design of ?-helix structures",
        "Randomized smiles strings improve the quality of molecular generative models",
        "Reinvent 2.0: an ai tool for de novo drug design",
        "Petrans: De novo drug design with protein-specific encoding based on transfer learning",
        "Molgpt: Molecular generation using a transformer-decoder model",
        "Designing optimized drug candidates with generative adversarial network",
        "Deep generative models for ligand-based de novo design applied to multi-parametric optimization",
        "Generating 3d molecules for target protein binding",
        "Relation: A deep generative model for structure-based de novo drug design",
        "Inverse design of 3d molecular structures with conditional generative neural networks",
        "Pocket2drug: An encoder-decoder deep neural network for the target-based drug design",
        "Exploiting pretrained biochemical language models for targeted drug design",
        "Semi-equivariant continuous normalizing flows for target-aware molecule generation",
        "Generative deep learning enables the discovery of a potent and selective ripk1 inhibitor",
        "Universal approach to de novo drug design for target proteins using deep reinforcement learning",
        "Attention is all you need",
        "Semi-supervised classification with graph convolutional networks",
        "Targeting akt in hepatocellular carcinoma and its tumor microenvironment",
        "Inference of macromolecular assemblies from crystalline state",
        "Rcsb protein data bank: biological macromolecular structures enabling research and education in fundamental biology, biomedicine, biotechnology and energy",
        "Regulation of the akt kinase by interacting proteins",
        "Discovery of 4-amino-n-[(1 s)-1-(4-chlorophenyl)-3-hydroxypropyl]-1-(7 h-pyrrolo [2, 3-d] pyrimidin-4-yl) piperidine-4carboxamide (azd5363), an orally bioavailable, potent inhibitor of akt kinases",
        "Drugbank 5.0: a major update to the drugbank database for 2018",
        "Greg Landrum. Rdkit documentation. Release",
        "Automated docking with selective receptor flexibility",
        "Evaluating the effects of cutoffs and treatment of long-range electrostatics in protein folding simulations",
        "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks",
        "A generalization of transformer networks to graphs",
        "Digress: Discrete denoising diffusion for graph generation",
        "Wasserstein generative adversarial networks",
        "Improved training of wasserstein gans",
        "Properties of known drugs. 2. side chains",
        "Molecular sets (moses): a benchmarking platform for molecular generation models",
        "Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings",
        "Molecular properties that influence the oral bioavailability of drug candidates",
        "New substructure filters for removal of pan assay interference compounds (pains) from screening libraries and for their exclusion in bioassays",
        "Protein and ligand preparation: parameters, protocols, and influence on virtual screening enrichments",
        "None",
        "Plip 2021: expanding the scope of the protein-ligand interaction profiler to dna and rna",
        "Extra precision glide: Docking and scoring incorporating a model of hydrophobic enclosure for protein-ligand complexes",
        "The PyMOL molecular graphics system, version 2.4.1",
        "Deepscreen: high performance drug-target interaction prediction with convolutional neural networks using 2-d structural compound representations",
        "Global cancer statistics 2020: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries",
        "Recent advances in systemic therapy for hepatocellular carcinoma",
        "Ythdf1 promotes hepatocellular carcinoma progression via activating pi3k/akt/mtor signaling pathway and inducing epithelialmesenchymal transition",
        "Kinmap: a web-based tool for interactive navigation through human kinome data",
        "Objective-reinforced generative adversarial networks (organ) for sequence generation models",
        "Taming sparsely activated transformer with stochastic experts",
        "Multi-constraint molecular generation based on conditional transformer, knowledge distillation and reinforcement learning",
        "Efficient learning of non-autoregressive graph variational autoencoders for molecular graph generation",
        "Visualizing data using t-sne",
        "Extended-connectivity fingerprints",
        "Crossbar: comprehensive resource of biomedical relations with knowledge graph representations"
    ],
    "642702aa90e50fcafd5de13d": [
        "On-demand flash cache management for cloud computing",
        "Improving virtualized storage performance with Sky",
        "Explicit block device plugging",
        "Analysis on heterogeneous SSD configuration with quadruple-level cell (QLC) NAND flash memory",
        "BORG: Block-reORGanization for self-optimizing storage systems",
        "A study of integrated prefetching and caching strategies",
        "Automatic I/O hint generation through speculative execution",
        "Essential roles of exploiting internal parallelism of flash memory based solid state drives in high-speed data processing",
        "Analyzing and improving GNOME startup time",
        "The BFQ I/O scheduler",
        "Diskseen: Exploiting disk layout and access history to enhance I/O prefetch",
        "The performance of PC solidstate disks (SSDs) as a function of bandwidth, concurrency, device architecture, and system organization",
        "Reducing DRAM footprint with NVM in Facebook",
        "Preload-An adaptive prefetching daemon",
        "On the design of a new Linux readahead framework",
        "FastTrack: Foreground app-aware I/O management for improving user experience of Android smartphones",
        "A file is not a file: Understanding the I/O behavior of Apple desktop applications",
        "Informed mobile prefetching",
        "The automatic improvement of locality in storage systems",
        "On faster application startup times: Cache stuffing, seek profiling, adaptive preloading",
        "Boosting quasiasynchronous I/O for better responsiveness in mobile devices",
        "Improving application launch times with hybrid disks",
        "Rapid prototyping and evaluation of intelligence functions of active storage devices",
        "FAST: Quick application launch on solid-state drives",
        "Improving application launch performance on SSDs",
        "Revisiting storage for smartphones",
        "Disk schedulers for solid state drivers",
        "C-miner: Mining block correlations in storage systems",
        "Prefetch: Linux solution for prefetching necessary data during application and system startup",
        "Don't get caught in the cold, warm-up your JVM: Understand and eliminate JVM warm-up overhead in data-parallel systems",
        "Intel?Turbo Memory: Nonvolatile disk caches in the storage hierarchy of mainstream computer systems",
        "Improving smartphone responsiveness through I/O optimizations",
        "Linux 2.6 performance improvement through readahead optimization",
        "Practical prediction and prefetch for faster access to applications on mobile phones",
        "HMB-SSD: Framework for efficient exploiting of the host memory buffer in the NVMe SSD",
        "Informed prefetching and caching",
        "Windows Internals, Part 2, 6th ed",
        "Professional Linux Kernel Architecture",
        "Exploiting SSD parallelism to accelerate application launch on SSDs",
        "Reducing seek overhead with application-directed prefetching",
        "Barrier-enabled IO stack for flash storage",
        "Fastapp launching for mobile devices using predictive user context",
        "Improving file system performance of mobile storage systems using a decoupled defragmenter",
        "End the senseless killing: Improving memory management for mobile operating systems",
        "Acclaim: Adaptive memory reclaim to improve user experience in Android systems",
        "ADATA Ultimate SU630 960GB",
        "Storage Game Loading Test: PCIe 4.0 SSD vs. PCIe 3.0 vs. SATA vs. HDD",
        "Samsung's 860 QVO 1-TB SSD re",
        "mm: map few pages around fault address if they are in page cache",
        "The size of Iphone's top apps has increased by 1,000% in four years",
        "Intel? Smart Response Technology: Technology Brief",
        "None",
        "Zoned storage for the zettabyte age",
        "None",
        "Spending Moore's dividend. Communications of the",
        "None"
    ],
    "63f2e4aa90e50fcafd2820a9": [
        "Alimentary tract and metabolism B. Blood and blood forming organs C. Cardiovascular system D. Dermatologicals G. Genito urinary system and sex hormones H. System hormonal preparations, excluding sex hormones and insulins J. Anti-infective for systemic use L. Anti-neoplastic and immunomodulating agents P. Anti-parasitic products, insecticides and repellents N. Nervous system M. Musculo-skeletal system V. Various",
        "Atc/ddd index 2022",
        "Adrml: anticancer drug response prediction using manifold learning",
        "A community computational challenge to predict the activity of pairs of compounds",
        "Relational inductive biases, deep learning, and graph networks",
        "Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking",
        "Net-GAN: Generating graphs via random walks",
        "Cancer drug response profile scan (cdrscan): a deep learning model that predicts drug effectiveness from cancer genomic signature",
        "Machine learning-based prediction of drug-drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties",
        "Drug-drug adverse effect prediction with graph co-attention",
        "Neural message passing for quantum chemistry",
        "Generative adversarial nets",
        "Indi: a computational framework for inferring drug interactions and their associated recommendations",
        "Inductive representation learning on large graphs",
        "Variational inference for sparse and undirected models",
        "Auto-encoding variational bayes",
        "Variational graph auto-encoders",
        "Semi-supervised classification with graph convolutional networks",
        "Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks",
        "Efficient graph generation with graph recurrent attention networks",
        "Learning entity and relation embeddings for knowledge graph completion",
        "Molecular fingerprints are a simple yet effective solution to the drug-drug interaction problem",
        "A three-way model for collective learning on multi-relational data",
        "Ssi-ddi: substructure-substructure interactions for drug-drug interaction prediction",
        "Tensors for data mining and data fusion: Models, applications, and scalable algorithms",
        "Online learning of social representations",
        "Deep learning improves prediction of drug-drug and drug-food interactions",
        "The graph neural network model",
        "Graphvae: Towards generation of small graphs using variational autoencoders",
        "Predicting cancer drug response using a recommender system",
        "Visualizing data using t-sne",
        "Graph Attention Networks",
        "Drug-drug interaction through molecular structure similarity analysis",
        "Gognn: Graph of graphs neural network for predicting structured entity interactions",
        "Deepdds: deep graph neural network with attention mechanism to predict synergistic drug combinations",
        "Improved anticancer drug response prediction in cell lines using matrix factorization with similarity regularization",
        "Comprehensive anticancer drug response prediction based on a simple cell line-drug complex network model",
        "Stochastic normalizing flows",
        "Mr-gnn: Multi-resolution and dual graph neural network for predicting structured entity interactions",
        "Deepdrug: A general graph-based deep learning framework for drug-drug interactions and drug-target interactions prediction. biorxiv",
        "Predicting multicellular function through multi-layer tissue networks",
        "Modeling polypharmacy side effects with graph convolutional networks",
        "Deep mining heterogeneous networks of biomedical linked data to predict novel drug-target associations"
    ],
    "62466dd35aee126c0f8b7b62": [
        "Alphafold at casp13",
        "Cormorant: Covariant molecular neural networks",
        "Structured denoising diffusion models in discrete state-spaces",
        "Geom: Energyannotated molecular conformations for property prediction and molecular generation",
        "Gfn2-xtb-an accurate and broadly parametrized self-consistent tightbinding quantum chemical method with multipole electrostatics and density-dependent dispersion contributions",
        "A two-step graph convolutional for molecule generation",
        "Molgan: An implicit generative model for small molecular graphs",
        "Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data",
        ")transformers: 3d roto-translation equivariant attention networks",
        "Torsional geometric generation of molecular 3d conformer ensembles",
        "Generating equilibrium molecules with deep neural networks",
        "Symmetryadapted generation of 3d point sets for the targeted discovery of molecules",
        "Inverse design of 3d molecular structures with conditional generative neural networks",
        "Neural message passing for quantum chemistry",
        "Energy-inspired molecular conformation optimization",
        "Denoising diffusion probabilistic models",
        "Generating valid euclidean distance matrices",
        "Argmax flows and multinomial diffusion: Learning categorical distributions",
        "Variational diffusion models",
        "Directional message passing for molecular graphs",
        "Equivariant flows: Exact likelihood generative learning for symmetric densities",
        "Conditional set generation with transformers",
        "Gggan: A geometric graph generative adversarial network",
        "Efficient graph generation with graph recurrent attention networks",
        "Constrained graph variational autoencoders for molecule design",
        "Predicting molecular conformation via dynamic graph score matching. Advances in Neural Information Processing Systems",
        "A graph vae and graph transformer approach to generating molecular graphs",
        "Improved denoising diffusion probabilistic models",
        "Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning",
        "Quantum chemistry structures and properties of 134 kilo molecules",
        "E(n) equivariant normalizing flows. Advances in Neural Information Processing Systems",
        "E (n) equivariant graph neural networks",
        "Linear representations of finite groups",
        "Learning gradient fields for molecular conformation generation",
        "A generative model for molecular distance geometry",
        "Symmetry-aware actor-critic for 3d molecular design",
        "Graphvae: Towards generation of small graphs using variational autoencoders",
        "Deep unsupervised learning using nonequilibrium thermodynamics",
        "Generative modeling by estimating gradients of the data distribution",
        "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
        "Top-n: Equivariant set and graph generation without exchangeability",
        "An end-to-end framework for molecular conformation generation via bilevel programming",
        "Geodiff: A geometric diffusion model for molecular conformation generation",
        "Anytime sampling for autoregressive models via ordered autoencoding",
        "Graph convolutional policy network for goal-directed molecular graph generation"
    ],
    "6459ac57d68f896efa657eec": [
        "Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks",
        "Few-shot Text Classification with Distributional Signatures",
        "Language models are few-shot learners",
        "DEKR: description enhanced knowledge graph for machine learning method recommendation",
        "MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification",
        "Knowprompt: Knowledge-aware prompttuning with synergistic optimization for relation extraction",
        "Model-agnostic metalearning for fast adaptation of deep networks",
        "Making Pre-trained Language Models Better Few-shot Learners",
        "Inductive representation learning on large graphs",
        "Pre-trained models: Past, present and future",
        "Ptr: Prompt tuning with rules for text classification",
        "FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation",
        "Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification",
        "Strategies for Pre-training Graph Neural Networks",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
        "Heterogeneous graph attention networks for semi-supervised short text classification",
        "Content to node: Selftranslation network embedding",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
        "GPT understands, too",
        "Roberta: A robustly optimized bert pretraining approach",
        "Aixin Sun, and Chunyan Miao. 2021b. Pre-training graph transformer with multimodal side information for recommendation",
        "Learning to pre-train graph neural networks",
        "Automating the Construction of Internet Portals with Machine Learning",
        "Automating the construction of internet portals with machine learning",
        "Efficient estimation of word representations in vector space",
        "Noisy Channel Language Model Prompting for Few-Shot Text Classification",
        "Adversarial Training Methods for Semi-Supervised Text Classification. In ICLR. OpenReview.net",
        "Justifying recommendations using distantly-labeled reviews and fine-grained aspects",
        "Deepwalk: Online learning of social representations",
        "Learning How to Ask: Querying LMs with Mixtures of Soft Prompts",
        "Learning transferable visual models from natural language supervision",
        "Improving language understanding by generative pre-training",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction",
        "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference",
        "Neural Machine Translation of Rare Words with Subword Units",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "Improved deep metric learning with multi-class n-pair loss objective",
        "Gppt: Graph pre-training and prompt tuning to generalize graph neural networks",
        "NSP-BERT: A Promptbased Zero-Shot Learner Through an Original Pre-training Task-Next Sentence Prediction",
        "MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators",
        "Rethinking few-shot image classification: a good embedding is all you need",
        "Attention is all you need",
        "Graph Attention Networks",
        "Deep Graph Infomax. ICLR",
        "Joint Embedding of Words and Labels for Text Classification",
        "Graph few-shot learning with attribute matching",
        "Yuchen Guo, and Zhiguo Gong. 2021. Zero-shot node classification with decomposed graph prototype network",
        "Generalizing graph neural network across graphs and time",
        "Meta-inductive node classification across graphs",
        "Transformers: State-of-the-art natural language processing",
        "Selfsupervised learning on graphs: Contrastive, generative, or predictive",
        "A comprehensive survey on graph neural networks",
        "Unsupervised data augmentation for consistency training",
        "Open-world learning and application to product classification",
        "How Powerful are Graph Neural Networks?",
        "Revisiting semisupervised learning with graph embeddings",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Graph convolutional networks for text classification",
        "Diverse Few-Shot Text Classification with Multiple Metrics",
        "Aspect Sentiment Quad Prediction as Paraphrase Generation",
        "Contrastive learning of medical visual representations from paired images and text",
        "Learning on Large-scale Text-attributed Graphs via Variational Inference",
        "Factual Probing Is [MASK]: Learning vs. Learning to Recall",
        "Meta-gnn: On few-shot node classification in graph meta-learning",
        "Learning to prompt for vision-language models"
    ],
    "64a407dcd68f896efaf1ba4e": [
        "Hitting the memory wall: Implications of the obvious",
        "Performance characterization of a quad pentium pro smp using oltp workloads",
        "Dbmss on a modern processor: Where does time go?",
        "Scale-out processors",
        "Clearing the clouds: A study of emerging scale-out workloads on modern hardware",
        "Profiling a warehouse-scale computer",
        "Fetch directed instruction prefetching",
        "Rebasing instruction prefetching: An industry perspective",
        "A scalable front-end architecture for fast instruction delivery",
        "Confluence: Unified instruction supply for scale-out servers",
        "Boomerang: A metadata-free architecture for control flow delivery",
        "Blasting through the frontend bottleneck with shotgun",
        "Asmdb: Understanding and mitigating front-end stalls in warehouse-scale computers",
        "Design and evaluation of a compiler algorithm for prefetching",
        "Cooperative prefetching: compiler and hardware support for effective instruction prefetching in modern processors",
        "Software prefetching",
        "Autofdo: Automatic feedbackdirected optimization for warehouse-scale applications",
        "Re-establishing fetchdirected instruction prefetching: An industry perspective",
        "The Arm Neoverse N1 platform: Building blocks for the next-gen cloud-to-edge infrastructure SoC",
        "The ibm z15 high frequency mainframe branch predictor industrial product",
        "I-spy: Context-driven conditional instruction prefetching with coalescing",
        "The championship simulator: Architectural simulation for education and competition",
        "Zsim: Fast and accurate microarchitectural simulation of thousand-core systems",
        "The gem5 simulator",
        "Path confidence based lookahead prefetching",
        "Sequential program prefetching in memory hierarchies",
        "An effective on-chip preloading scheme to reduce data access penalty",
        "Branch history guided instruction prefetching",
        "Rdip: Return-address-stack directed instruction prefetching",
        "Fetch directed instruction prefetching",
        "Elastic instruction fetching",
        "Proactive instruction fetch",
        "Effective instruction prefetching in chip multiprocessors for modern commercial applications",
        "Shift: Shared history instruction fetch for lean-core server processors",
        "Temporal streaming of shared memory",
        "Divide and conquer frontend bottleneck",
        "Branch agnostic region searching algorithm"
    ],
    "64be63403fda6d7f063e57a7": [
        "On the theory of policy gradient methods: Optimality, approximation, and distribution shift",
        "On the generation of Markov decision processes",
        "Robust reinforcement learning using least squares policy iteration with provable performance guarantees",
        "First-order methods in optimization",
        "Fast algorithms for l ? -constrained s-rectangular robust MDPs",
        "Optimizing percentile criterion using robust MDPs",
        "Nonlinear Programming. Athena scientific",
        "On the linear convergence of policy gradient methods for finite MDPs",
        "Natural actor-critic algorithms",
        "Information-theoretic considerations in batch reinforcement learning",
        "Distributionally robust optimization for sequential decision-making",
        "On algorithms for simple stochastic games",
        "Independent policy gradient methods for competitive reinforcement learning",
        "Stochastic model-based minimization of weakly convex functions",
        "Real-time dynamic programming for Markov decision processes with imprecise probabilities",
        "Twice regularized MDPs and the equivalence between robustness and regularization",
        "Accelerated gradient methods for nonconvex nonlinear and stochastic programming",
        "Robust Markov decision processes: Beyond rectangularity",
        "First-order methods for Wasserstein distributionally robust MDPs",
        "Scalable first-order methods for robust MDPs",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
        "Fast bellman updates for robust MDPs",
        "Partial policy iteration for l1-robust Markov decision processes",
        "Robust dynamic programming",
        "What is local optimality in nonconvex-nonconcave minimax optimization",
        "Approximately optimal approximate reinforcement learning",
        "Robust modified policy iteration",
        "Actor-critic algorithms. Advances in neural information processing systems",
        "On fr?chet subdifferentials",
        "Robust, risk-sensitive, and data-driven control of Markov decision processes",
        "Global convergence of multi-agent policy gradient in Markov potential games",
        "First-order policy optimization for robust Markov decision process",
        "Reinforcement learning in robust markov decision processes",
        "On gradient descent ascent for nonconvex-concave minimax problems",
        "Distributionally robust q-learning",
        "Stochastic recursive gradient descent ascent for stochastic nonconvexstrongly-concave minimax problems",
        "Convergence of a stochastic gradient method with momentum for non-smooth nonconvex optimization",
        "Robust MDPs with k-rectangular uncertainty",
        "On the global convergence rates of softmax policy gradient methods",
        "A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach",
        "Robust control of Markov decision processes with uncertain transition matrices",
        "Solving a class of non-convex min-max games using iterative first order methods",
        "Sample complexity of robust reinforcement learning with a generative model",
        "Sample complexity of robust reinforcement learning with a generative model",
        "Robust reinforcement learning using offline data",
        "Approximate dynamic programming by minimizing distributionally robust bounds",
        "Raam: The benefits of robustness in approximating aggregated MDPs in reinforcement learning",
        "Safe policy improvement by minimizing robust baseline regret. Advances in Neural Information Processing Systems",
        "Policy gradient in Lipschitz Markov decision processes",
        "Foundations of stochastic inventory theory",
        "Markov decision processes: discrete stochastic dynamic programming",
        "Nonconvex min-max optimization: Applications, challenges, and recent theoretical advances",
        "Monotone operators and the proximal point algorithm",
        "Variational analysis",
        "Reinforcement learning under model mismatch",
        "Robust constrained-MDPs: Soft-constrained robust policy optimization under model uncertainty",
        "Beyond confidence regions: Tight Bayesian ambiguity sets for robust MDPs",
        "Risk-averse dynamic programming for Markov decision processes",
        "Approximate policy iteration schemes: a comparison",
        "Trust region policy optimization",
        "Proximal policy optimization algorithms",
        "Rectangular sets of probability measures",
        "Distributionally robust optimal control and MDP modeling",
        "Deterministic policy gradient algorithms",
        "Reinforcement learning: An introduction",
        "Policy gradient methods for reinforcement learning with function approximation",
        "Efficient algorithms for smooth minimax optimization",
        "Strong and weak convexity of sets and functions",
        "The geometry of robust value functions",
        "Online robust reinforcement learning with model uncertainty",
        "Policy gradient method for robust reinforcement learning",
        "Robust Markov decision processes",
        "Parametric regret in uncertain Markov decision processes",
        "Distributionally robust Markov decision processes",
        "Reinforcement learning algorithms with function approximation: Recent advances and applications"
    ],
    "6326f71890e50fcafdd04899": [
        "Scientific Reports |",
        "Scientific Reports |",
        "Synergistic drug combinations for cancer identified in a CRISPR screen for pairwise genetic interactions",
        "Predicting drug-drug interactions through drug structural similarities and interaction networks incorporating pharmacokinetics and pharmacodynamics knowledge",
        "DPDDI: A deep predictor for drug-drug interactions",
        "A multimodal deep learning framework for predicting drug-drug interaction events",
        "Drug-drug interaction prediction based on knowledge graph embeddings and convolutional-LSTM network",
        "Biological network analysis with deep learning",
        "A comprehensive survey on graph neural networks",
        "Biomedical data and computational models for drug repositioning: A comprehensive review",
        "INDI: A computational framework for inferring drug interactions and their associated recommendations",
        "Machine learning-based prediction of drug-drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties",
        "Machine learning-based prediction of drug-drug interactions for histamine antagonist using hybrid chemical features",
        "Similarity-based machine learning support vector machine predictor of drug-drug interactions with improved accuracies",
        "Manifold regularized matrix factorization for drug-drug interaction prediction",
        "Figure 10. A view of the second stage of the proposed method",
        "Detecting drug communities and predicting comprehensive drug-drug interactions via balance regularized semi-nonnegative matrix factorization",
        "ISCMF: Integrated similarity-constrained matrix factorization for drug-drug interaction prediction",
        "Learning Graph Representations with Global Structural Information",
        "Online learning of social representations",
        "struc2vec: Learning node representations from structural identity",
        "Drug-drug interaction analysis using heterogeneous biological information network",
        "Systematic prediction of pharmacodynamic drug-drug interactions through protein-protein-interaction network",
        "Identification of drug-target interaction by a random walk with restart method on an interactome network",
        "Structural deep network embedding",
        "LINE: Large-scale information network embedding",
        "Learning graph representation with generative adversarial nets",
        "Predicting drug-disease associations with graph representation learning on heterogeneous information networks",
        "MGRL: Predicting drug-disease associations based on multi-graph representation learning",
        "Biomedical knowledge graph embedding with capsule network for multi-label drug-drug interaction prediction",
        "Graph neural networks: A review of methods and applications",
        "Variational graph auto-encoders",
        "Auto-encoder based dimensionality reduction",
        "Learning graph representations with global structural information",
        "Learning multimodal graph-to-graph translation for molecular optimization",
        "Deep drug-target binding affinity prediction",
        "Predicting drug-drug interactions using multi-modal deep auto-encoders based network embedding and positive-unlabeled learning",
        "Knowledge Graph Neural Network for Drug-Drug Interaction Prediction (International Joint Conferences on Artificial Intelligence Organization",
        "Modeling polypharmacy side effects with graph convolutional networks",
        "Deep learning improves prediction of drug-drug and drug-food interactions",
        "A Graph Convolutional Network Framework for Predicting Multi-Type Drug-Drug Interactions",
        "Enhancing Drug-Drug Interaction Prediction Using Deep Attention Neural Networks",
        "CNN-DDI: A learning-based method for predicting drug-drug interactions using convolution neural networks",
        "MDNN: A multimodal deep neural network for predicting drug-drug interaction events",
        "DrugBank 5.0: A major update to the DrugBank database for 2018",
        "KEGG: New perspectives on genomes, pathways, diseases and drugs",
        "Representation learning for attributed multiplex heterogeneous network",
        "Very deep convolutional networks for large-scale image recognition",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Rectified linear units improve restricted Boltzmann machines",
        "Early stopping: But when?"
    ],
    "64f59fc23fda6d7f0648f1fb": [
        "Concrete problems in ai safety",
        "Palm: Scaling language modeling with pathways",
        "Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30",
        "Avoiding wireheading with value reinforcement learning",
        "Hierarchical neural story generation",
        "A survey of data augmentation approaches for NLP",
        "Reward learning for efficient reinforcement learning in extractive document summarisation",
        "Chatgpt outperforms crowd-workers for textannotation tasks",
        "Improving alignment of dialogue agents via targeted human judgements",
        "None",
        "A natural policy gradient. Advances in neural information processing systems",
        "Scaling laws for neural language models",
        "Reward design with language models",
        "Okapi: Instructiontuned large language models in multiple languages with reinforcement learning from human feedback",
        "Summary of chatgpt/gpt-4 research and perspective towards the future of large language models",
        "Self-refine: Iterative refinement with self-feedback",
        "An overview of bard: an early experiment with generative ai",
        "Tuning language models as training data generators for augmentation-enhanced few-shot learning",
        "Asynchronous methods for deep reinforcement learning",
        "Webgpt: Browser-assisted questionanswering with human feedback",
        "Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Large language models sensitivity to the order of options in multiple-choice questions",
        "Factually consistent summarization via reinforcement learning with textual entailment feedback",
        "Proximal policy optimization algorithms",
        "Adafactor: Adaptive learning rates with sublinear memory cost",
        "Learning to summarize with human feedback",
        "Policy gradient methods for reinforcement learning with function approximation",
        "Lamda: Language models for dialog applications",
        "Self-consistency improves chain of thought reasoning in language models",
        "Towards zero-label language learning",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
        "A study of reinforcement learning for neural machine translation",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "Learning to extract coherent summary via deep reinforcement learning",
        "Rlcd: Reinforcement learning from contrast distillation for language model alignment",
        "Fine-tuning language models from human preferences"
    ],
    "6459ac63d68f896efa658a19": [
        "Content-based information retrieval by named entity recognition and verb semantic role labelling",
        "Reading comprehension and reading strategies",
        "The effectiveness of reading strategies on reading comprehension",
        "Biomedical named entity recognition via knowledge guidance and question answering",
        "Unsupervised cross-lingual representation learning at scale",
        "Named entity recognition using BERT bilstm CRF for chinese electronic health records",
        "Fundamental factors of comprehension in reading",
        "Results of the WNUT2017 shared task on novel and emerging entity recognition",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "NCBI disease corpus: A resource for disease name recognition and concept normalization",
        "Event extraction by answering (almost) natural questions",
        "Spanner: Named entity re-/recognition as span prediction",
        "Deberta: decoding-enhanced bert with disentangled attention",
        "Regularization for long named entity recognition",
        "Neural architectures for named entity recognition",
        "A survey on data cleaning methods for improved machine learning model performance",
        "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
        "Zero-shot relation extraction via reading comprehension",
        "Biocreative V CDR task corpus: a resource for chemical disease relation extraction",
        "A survey on deep learning for named entity recognition",
        "A unified MRC framework for named entity recognition",
        "Entity-relation extraction as multi-turn question answering",
        "Xiangyang Liu, and Xipeng Qiu. 2021. A survey of transformers",
        "Event extraction as machine reading comprehension",
        "NER-BERT: A pre-trained model for lowresource entity tagging",
        "Gender and representation bias in GPT-3 generated stories",
        "Don't miss the labels: Label-semantic augmented meta-learner for few-shot text classification",
        "An analysis of social biases present in BERT variants across multiple languages",
        "Label semantic aware pre-training for few-shot text classification",
        "Bertweet: A pre-trained language model for english tweets",
        "Named entity recognition for social media texts with semantic augmentation",
        "Self-adaptive named entity recognition by retrieving unstructured knowledge",
        "Reinforcement-based denoising of distantly supervised NER with partial annotation",
        "Text chunking using transformation-based learning",
        "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
        "Multitask prompted training enables zero-shot task generalization",
        "Inferner: an attentive model leveraging the sentence-level information for named entity recognition in microblogs",
        "Bioflair: Pretrained pooled contextualized embeddings for biomedical sequence labeling tasks",
        "NER-MQMRC: formulating named entity recognition as multi question machine reading comprehension",
        "Results of the WNUT16 named entity recognition shared task",
        "Biomedical named entity recognition using BERT in the machine reading comprehension framework",
        "Reading comprehension, learning strategies and verbal reasoning: Possible relationships",
        "Named entity and relation extraction with multi-modal retrieval",
        "2021a. Automated concatenation of embeddings for structured prediction",
        "2021b. Improving named entity recognition by external context retrieving and cooperative learning",
        "Crossweigh: Training named entity tagger from imperfect annotations",
        "Crossweigh: Training named entity tagger from imperfect annotations",
        "Finetuned language models are zero-shot learners",
        "Coarse-to-fine pre-training for named entity recognition",
        "A survey on recent advances in named entity recognition from deep learning models",
        "LUKE: deep contextualized entity representations with entity-aware self-attention",
        "Zero-shot learners for natural language understanding via a unified multiple choice perspective",
        "HRCA+: advanced multiple-choice machine reading comprehension method",
        "Dual adversarial neural transfer for low-resource named entity recognition"
    ],
    "63d9d87390e50fcafd57d920": [
        "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
        "Regression transformer enables concurrent sequence regression and conditional generation for molecular language modeling",
        "a). Data-driven molecular design for discovery and synthesis of novel ligands: a case study on sars-cov-2",
        "Paccmannrl: De novo generation of hit-like anticancer molecules from transcriptomic data via reinforcement learning",
        "Language models are few-shot learners",
        "Evaluating large language models trained on code",
        "Scaling instruction-finetuned language models",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Reoptimization of mdl keys for use in drug discovery",
        "Translation between molecules and natural language",
        "Text2mol: Crossmodal molecule retrieval with natural language queries",
        "None",
        "Complexity-based prompting for multi-step reasoning",
        "Highly accurate protein structure prediction with alphafold",
        "Binary codes capable of correcting deletions, insertions, and reversals",
        "Solving quantitative reasoning problems with language models",
        "Can large language models reason about medical questions? arXiv preprint",
        "Rouge: A package for automatic evaluation of summaries",
        "Unified deep learning model for multitask reaction predictions with explanation",
        "Gt4sd: Generative toolkit for scientific discovery",
        "Nextmove software pistachio",
        "Training language models to follow instructions with human feedback",
        "Ai-driven robotic laboratories show promise",
        "Bleu: a method for automatic evaluation of machine translation",
        "Fr?chet chemnet distance: a metric for generative models for molecules in drug discovery",
        "Improving language understanding by generative pre-training",
        "Language models are unsupervised multitask learners",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Hierarchical text-conditional image generation with clip latents",
        "Extended-connectivity fingerprints",
        "Photorealistic text-toimage diffusion models with deep language understanding",
        "Multitask prompted training enables zero-shot task generalization",
        "found in translation\": predicting outcomes of complex organic chemistry reactions using neural sequence-to-sequence models",
        "Molecular transformer: a model for uncertainty-calibrated chemical reaction prediction",
        "Predicting retrosynthetic pathways using transformer-based models and a hyper-graph exploration strategy",
        "Mapping the space of chemical reactions using attention-based neural networks",
        "Elementary mathematical theory of classification and prediction",
        "Unassisted noise reduction of chemical reaction datasets",
        "Attention is all you need",
        "Automated extraction of chemical synthesis actions from experimental procedures",
        "Chain of thought prompting elicits reasoning in large language models",
        "Language models are few-shot multilingual learners",
        "Transformers: State-of-the-Art Natural Language Processing"
    ],
    "64659ad1d68f896efa87539f": [
        "Openai. introducing chatgpt",
        "Flamingo: a visual language model for few-shot learning",
        "The medical segmentation decathlon",
        "None",
        "Overview of the vqa-med task at imageclef 2021: Visual question answering and generation in the medical domain",
        "Multi-modal masked autoencoders for medical vision-and-language pre-training",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Scaling language modeling with pathways",
        "Optimal gradient checkpoint search for arbitrary computation graphs",
        "The Pile: An 800gb dataset of diverse text for language modeling",
        "Domain-specific language model pretraining for biomedical natural language processing",
        "Towards visual question answering on pathology images",
        "What disease does this patient have? a large-scale open domain question answering dataset from medical exams",
        "Peir digital library: Online resources and authoring system",
        "Chaos challengecombined (ct-mr) healthy abdominal organ segmentation",
        "Towards visual dialog for radiology",
        "Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models",
        "A dataset of clinically generated visual questions and answers about radiology images",
        "Blip-2: Bootstrapping languageimage pre-training with frozen image encoders and large language models",
        "Pmc-clip: Contrastive language-image pre-training using biomedical documents",
        "Medical visual question answering: A survey",
        "Contrastive pre-training and representation distillation for medical visual question answering based on radiology images",
        "Slake: A semanticallylabeled knowledge-enhanced dataset for medical visual question answering",
        "Decoupled weight decay regularization",
        "Overcoming data limitation in medical visual question answering",
        "Capabilities of gpt-4 on medical challenge problems",
        "OpenAI. Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Radiology objects in context (roco): a multimodal image dataset",
        "Learning transferable visual models from natural language supervision",
        "Pubmed central: The genbank of the published literature",
        "Large language models encode clinical knowledge",
        "Medicat: A dataset of medical images, captions, and textual references",
        "Stanford alpaca: An instruction-following llama model",
        "Llama: Open and efficient foundation language models",
        "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases",
        "Pmc-llama: Further finetuning llama on medical papers",
        "Opt: Open pre-trained transformer language models",
        "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
    ],
    "6427029c90e50fcafd5d6cf3": [
        "Redis",
        "Applications of web query mining",
        "The parsec benchmark suite: Characterization and architectural implications",
        "Coordinated management of multiple interacting resources in chip multiprocessors: A machine learning approach",
        "Interference and locality-aware task scheduling for mapreduce applications in virtual clusters",
        "Workloads in the clouds",
        "Alita: comprehensive performance isolation through bias resource management for public clouds",
        "Parties: Qos-aware resource partitioning for multiple interactive services",
        "Benchmarking cloud serving systems with ycsb",
        "Paragon: Qos-aware scheduling for heterogeneous datacenters",
        "Quasar: Resource-efficient and qosaware cluster management",
        "Bolt: I know what you did last summer... in the cloud",
        "The mnist database of handwritten digit images for machine learning research [best of the web]",
        "Kpart: A hybrid cache partitioning-sharing technique for commodity multicores",
        "Workload modeling for computer systems performance evaluation",
        "Caladan: Mitigating interference at microsecond timescales",
        "Intel? 64 and ia-32 architectures software developer's manual",
        "Who limits the resource efficiency of my datacenter: an analysis of alibaba datacenter traces",
        "Improving real-time performance by utilizing cache allocation technology",
        "Measuring interference between live datacenter applications",
        "Rubik: Fast analytical power management for latency-critical systems",
        "Ubik: Efficient cache sharing with strict qos for latency-critical workloads",
        "Tailbench: a benchmark suite and evaluation methodology for latency-critical applications",
        "Moses: Open source toolkit for statistical machine translation",
        "Cuttlesys: Data-driven resource management for interactive services on reconfigurable multicores",
        "Towards energy proportionality for large-scale latency-critical workloads",
        "Heracles: Improving resource efficiency at scale",
        "Cache craftiness for fast multicore key-value storage",
        "Stretch: Balancing qos and throughput for colocated server workloads on smt cores",
        "Bubbleup: Increasing utilization in modern warehouse scale computers via sensible co-locations",
        "Directly characterizing cross core interference through contention synthesis",
        "Memory bandwidth and machine balance in current high performance computers",
        "Twig: Multiagent task management for colocated latency-critical cloud services",
        "Sturgeon: Preference-aware co-location for improving utilization of power constrained computers",
        "Copart: Coordinated partitioning of last-level cache and memory bandwidth for fairness-aware workload consolidation on commodity servers",
        "Clite: Efficient and qos-aware co-location of multiple latency-critical jobs for warehouse scale computers",
        "Phase-aware cache partitioning to target both turnaround time and system performance",
        "Fact: a framework for adaptive contention-aware thread migrations",
        "Application clustering policies to address system fairness with intel's cache allocation technology",
        "A mathematical theory of communication",
        "Symbiotic job scheduling for a simultaneous multithreaded processor",
        "Unfair data centers for fun and profit",
        "The application slowdown model: Quantifying and controlling the impact of inter-application interference at shared caches and main memory",
        "The rise of high-throughput computing",
        "Parallel data, tools and interfaces in opus",
        "Speedy transactions in multicore in-memory databases",
        "Optimal markovian dynamic control of interference-prone server farms",
        "Modeling and analysis of performance under interference in the cloud",
        "The chips are down for moore's law",
        "Sphinx-4: A flexible open source framework for speech recognition",
        "Effective capacity modulation as an explicit control knob for public cloud profitability",
        "Small is better: Avoiding latency traps in virtualized data centers",
        "Bubble-flux: Precise online qos management for increased utilization in warehouse scale computers",
        "Spark: Cluster computing with working sets",
        "Cpi2: Cpu performance isolation for shared compute clusters",
        "Sinan: Ml-based and qos-aware resource management for cloud microservices",
        "Rhythm: component-distinguishable workload deployment in datacenters"
    ],
    "634d805590e50fcafd4e05f7": [
        "GhostMinion: A strictness-ordered cache system for Spectre mitigation",
        "Chisel: constructing hardware in a Scala embedded language",
        "Hardware specification with temporal logic: An example",
        "The Essence of Bluespec: A core language for rule-based hardware design",
        "Kami: A platform for high-level parametric hardware specification and its modular verification",
        "High-level synthesis for FPGAs: From prototyping to deployment",
        "None",
        "Z3: an efficient SMT solver",
        "Type-directed scheduling of streaming accelerators",
        "An axiomatic basis for computer programming",
        "Timing-abstract circuit design in transactionlevel Verilog",
        "Dynamically scheduled high-level synthesis",
        "Replacing testing with formal verification in Intel ? CoreTM i7 processor execution engine validation",
        "Automated pipeline design",
        "Rapid generation of high-quality RISC-V processors from functional instruction set specifications",
        "Predictable accelerator design with time-sensitive affine types",
        "Bluespec System Verilog: Efficient, correct RTL from high level specifications",
        "Automatic pipelining from transactional datapath specifications",
        "MachSuite: Benchmarks for accelerator design and customized architectures",
        "End-to-end verification of processors with ISA-Formal",
        "Jade: A high-level, machine-independent language for parallel programming",
        "What you simulate is what you synthesize: Designing a processor core from C++ specifications",
        "Design of a microcontroller-based artificial pacemaker: An internal pacing device",
        "FreePDK: An open-source variation-aware design kit",
        "Typestate: A Programming Language Concept for Enhancing Software Reliability",
        "The Verilog? hardware description language",
        "An efficient algorithm for exploiting multiple arithmetic units",
        "The RISC-V instruction set manual",
        "CACTI: An enhanced cache access and cycle time model",
        "The Cost of application-class processing: Energy and performance analysis of a Linux-ready 1.7-GHz 64-Bit RISC-V core in 22-nm FDSOI technology",
        "A Hardware Design Language for Timing-Sensitive Information-Flow Security",
        "Synthesizing environment invariants for modular hardware verification"
    ],
    "64a63bbad68f896efaec478f": [
        "Efficient top-k shortest-path distance queries on large networks by pruned landmark labeling",
        "Unsupervised inductive graph-level representation learning via graph-graph proximity",
        "Language models are few-shot learners",
        "Multi-level graph convolutional networks for crossplatform anchor link prediction",
        "BrainNet: Epileptic Wave Detection from SEEG with Hierarchical Graph Diffusion Learning",
        "Prompt Tuning for Graph Neural Networks",
        "Making Pre-trained Language Models Better Few-shot Learners",
        "Inductive representation learning on large graphs. Advances in neural information processing systems",
        "A Multi-Strategy based Pre-Training Method for Cold-Start Recommendation",
        "GraphMAE: Self-Supervised Masked Graph Autoencoders",
        "Strategies For Pre-training Graph Neural Networks",
        "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning",
        "Self-supervised learning on graphs: Deep insights and new direction",
        "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "Predicting path failure in time-evolving graphs",
        "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
        "Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
        "Recent advances in natural language processing via large pre-trained language models: A survey",
        "Exploring low-dimensional intrinsic task subspace via prompt tuning",
        "Getting closer to AI complete question answering: A set of prerequisite real tasks",
        "Pitfalls of graph neural network evaluation",
        "Towards out-of-distribution generalization: A survey",
        "Masked label prediction: Unified message passing model for semisupervised classification",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "GPPT: Graph pre-training and prompt tuning to generalize graph neural networks",
        "Self-supervised Hypergraph Representation Learning for Sociological Analysis",
        "Multi-level hyperedge distillation for social linking prediction on sparsely observed networks",
        "Structure Learning Via Meta-Hyperedge for Dynamic Rumor Detection",
        "Rethinking Graph Neural Networks for Anomaly Detection",
        "Graph Attention Networks",
        "Afec: Active forgetting of negative transfer in continual learning",
        "Semi-supervised classification with graph convolutional networks",
        "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation",
        "Graph contrastive learning with augmentations",
        "Graph transformer networks",
        "Factual Probing Is [MASK]: Learning vs. Learning to Recall",
        "Efficient single-source shortest path and distance queries on large graphs",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "63a1751790e50fcafd1f49ce": [
        "SemEval-2012 task 6: A pilot on semantic textual similarity",
        "Task-aware retrieval with instructions",
        "MS MARCO: A human generated machine reading comprehension dataset",
        "Toshiaki bnghvtcf Nakazawa, Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20)",
        "A large annotated corpus for learning natural language inference",
        "SemEval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation",
        "SPECTER: Document-level representation learning using citation-informed transformers",
        "SentEval: An evaluation toolkit for universal sentence representations",
        "Supervised learning of universal sentence representations from natural language inference data",
        "Simple english Wikipedia: a new text simplification task",
        "Wizard of Wikipedia: Knowledge-powered conversational agents",
        "T-rex: A large scale alignment of natural language with knowledge base triples",
        "SummEval: Re-evaluating summarization evaluation",
        "Open question answering over curated and extracted knowledge bases",
        "ELI5: long form question answering",
        "Experts, errors, and context: A large-scale study of human evaluation for machine translation",
        "Unsupervised corpus aware language model pre-training for dense passage retrieval",
        "SimCSE: Simple contrastive learning of sentence embeddings",
        "AmazonQA: A review-based question answering task",
        "Don't stop pretraining: Adapt language models to domains and tasks",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "CLIPScore: A reference-free evaluation metric for image captioning",
        "CQADupStack: A benchmark data set for community question-answering research",
        "Code-SearchNet challenge: Evaluating the state of semantic code search",
        "Unsupervised dense information retrieval with contrastive learning",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
        "Dense passage retrieval for open-domain question answering",
        "2022a. Bidimensional leaderboards: Generate and evaluate language hand in hand",
        "2022b. Transparent human evaluation for image captioning",
        "GooAQ: Open question answering with diverse answer types",
        "GENIE: Toward reproducible and standardized human evaluation for text generation",
        "Skip-thought vectors",
        "Wik-iHow: A large scale text summarization dataset",
        "Natural questions: a benchmark for question answering research",
        "Zero-shot relation extraction via reading comprehension",
        "PAQ: 65 million probably-asked questions and what you can do with them",
        "INTERVIEW: NPR media dialog transcripts",
        "Semantic matching against a corpus: New methods and applications",
        "Microsoft COCO: common objects in context",
        "What makes good in-context examples for GPT-3?",
        "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Rodney Kinney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus",
        "An efficient framework for learning sentence representations",
        "A SICK cure for the evaluation of compositional distributional semantic models",
        "MetaICL: Learning to learn in context",
        "Learning to match using local and distributed representations of text for web search",
        "MTEB: Massive text embedding benchmark",
        "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
        "Sentence-T5: Scalable sentence encoders from pre-trained text-to-text models",
        "Large dual encoders are generalizable retrievers",
        "Training language models to follow instructions with human feedback",
        "MedMCQA: A large-scale multi-subject multi-choice dataset for medical domain question answering",
        "KILT: a benchmark for knowledge intensive language tasks",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
        "Vmeasure: A conditional entropy-based external cluster evaluation measure",
        "Learning to retrieve prompts for in-context learning",
        "Multitask prompted training enables zero-shot task generalization",
        "BLEURT: Learning robust metrics for text generation",
        "Collective classification in network data",
        "Duplicate question detection in stack overflow: A reproducibility study",
        "Selective annotation makes language models better few-shot learners",
        "BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models",
        "Fever: a large-scale dataset for fact extraction and verification",
        "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model",
        "Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks",
        "Finetuned language models are zero-shot learners",
        "A broad-coverage challenge corpus for sentence understanding through inference"
    ],
    "64337e3190e50fcafd76ef32": [
        "None",
        "CommandSpace: Modeling the Relationships between Tasks, Descriptions and Features",
        "Power to the people: The role of humans in interactive machine learning",
        "Guidelines for human-AI interaction",
        "Rules of the Mind",
        "Electronic Arts",
        "Narrative in virtual environments-towards emergent narrative",
        "A design-centered framework for social human-robot interaction",
        "The Role of Emotion in Believable Agents",
        "Dota 2 with Large Scale Deep Reinforcement Learning",
        "Using cognitive psychology to understand GPT-3",
        "None",
        "I had a dream: AAAI presidential address",
        "On the Opportunities and Risks of Foundation Models",
        "Creating dynamic story plots with continual multiagent planning",
        "The Cog Project: Building a Humanoid Robot",
        "Language Models are Few-Shot Learners",
        "Sparks of artificial general intelligence: Early experiments with gpt-4",
        "Alice and Kev: The Story of Being Homeless in The Sims 3",
        "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
        "The psychology of human-computer interaction",
        "The keystrokelevel model for user performance time with interactive systems",
        "Tutorial presentation",
        "A Believable Agent for First-Person Shooter Games",
        "Understanding and using context. Personal and ubiquitous computing",
        "A Game AI Approach to Autonomous Control of Virtual Characters",
        "Networks, crowds, and markets: Reasoning about a highly connected world",
        "The Proposed USCF Rating System",
        "Interactive machine learning",
        "Augur: Mining human behaviors from fiction to power interactive systems",
        "The Wekinator: a system for real-time, interactive machine learning in music",
        "An Introduction to Qualitative Research",
        "CueFlik: Interactive Concept Learning in Image Search",
        "Query-feature graphs: bridging user vocabulary and system functionality",
        "The Minecraft Experiment, day 1: Chasing Waterfalls",
        "Procedural Generation of Interactive Stories using Language Models",
        "Making Pre-trained Language Models Better Few-shot Learners",
        "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
        "Interactive Fiction Games: A Colossal Adventure",
        "My Liner Notes for Spore",
        "TrueSkill?: A Bayesian Skill Rating System",
        "Fluid concepts and creative analogies: computer models of the fundamental mechanisms of thought",
        "STEAMER: An Interactive Inspectable Simulation-Based Training System",
        "A simple sequentially rejective multiple test procedure. Scandinavian",
        "Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?",
        "Principles of mixed-initiative user interfaces",
        "Inner Monologue: Embodied Reasoning through Planning with Language Models",
        "Consistency of personality in interactive characters: verbal cues, non-verbal cues, and user characteristics",
        "PromptMaker: Prompt-Based Prototyping with Large Language Models",
        "The GOMS family of user interface analysis techniques: Comparison and contrast",
        "Automated Intelligent Pilots for Combat Flight Simulation",
        "Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP",
        "Introduction to Behavior Trees",
        "Socially situated artificial intelligence enables learning from human interaction",
        "Use of ranks in one-criterion variance analysis",
        "Phaser Labs. no date provided",
        "It Knows What You're Going To Do: Adding Anticipation to a Quakebot",
        "Human-Level AI's Killer Application: Interactive Computer Games",
        "It Knows What You're Going To Do: Adding Anticipation to a QUAKEBOT",
        "The Soar Cognitive Architecture",
        "A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence",
        "Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Interleaving Learning, Problem Solving, and Execution in the Icarus Architecture",
        "PixelTone: A Multimodal Interface for Image Editing",
        "What Makes Good In-Context Examples for",
        "Opal: Multimodal Image Generation for News Illustration",
        "Artificial Life Meets Entertainment: Lifelike Autonomous Agents",
        "Comme il Faut: A System for Simulating Social Games Between Autonomous Characters",
        "Prom Week: Social Physics as Gameplay",
        "Prom Week",
        "Comme il faut: A System for Authoring Playable Social Models",
        "Draft of a proposal to ARPA for research on artificial intelligence at MIT",
        "Developing Game AI Agent Behaving Like Human by Mixing Reinforcement Learning and Supervised Learning",
        "Game AI is dead. Long live game AI!",
        "Unified Theories of Cognition",
        "So what is 'the metaverse', exactly? Ars Technica",
        "Training language models to follow instructions with human feedback",
        "Social Simulacra: Creating Populated Prototypes for Social Computing Systems",
        "Modeling Human and Organizational Behavior: Applications to Military Simulations",
        "Coordinating Agents with Behavior Trees: Synchronizing Multiple Agents in CryEngine",
        "Prolific: Quickly Find Research Participants You Can Trust",
        "The media equation: How people treat computers, television, and new media like real people and places",
        "Interactive narrative: A novel application of artificial intelligence for computer games",
        "An Objective Character Believability Evaluation Procedure for Multi-Agent Story Generation Systems",
        "None",
        "The Fight for $15: The Right Wage for a Working America",
        "Codemend: Assisting interactive programming with bimodal embedding",
        "Human-centered AI",
        "Direct manipulation vs. interface agents. interactions",
        "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
        "An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels",
        "Toward virtual humans",
        "Intelligent agents for interactive simulation environments",
        "A General Inductive Approach for Analyzing Qualitative Evaluation Data",
        "Disney Animation: The Illusion of Life",
        "Believable and Effective AI Agents in Virtual Worlds: Current State and Future Perspectives",
        "A Dictionary of Statistics",
        "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
        "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
        "The computer for the 21st century",
        "The Computer for the 21st Century",
        "ELIZA-a computer program for the study of natural language communication between man and machine",
        "Procedures as a Representation for Data in a Computer Program for Understanding Natural Language",
        "Recursively Summarizing Books with Human Feedback",
        "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",
        "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts",
        "Reexamining whether, why, and how human-AI interaction is uniquely difficult to design",
        "Game AI revisited",
        "Game AI revisited",
        "Towards implementation of social interaction"
    ],
    "63bfce0790e50fcafd0a10d0": [
        "2nd Cache Replacement Championship",
        "2nd Data Prefetching Championship",
        "3rd Data Prefetching Championship",
        "6th Generation Intel? Processor Family",
        "AMD Gives More Zen Details: Ryzen",
        "AMD Ryzen Threadripper 3990X",
        "AMD Zen2 EPYC 7702P",
        "Caching of Temporal vs. Non-Temporal Data -Intel? 64 and IA-32 Architectures Developer's Manual",
        "ChampSim",
        "Golden Cove -Microarchitectures -Intel",
        "Golden Cove Microarchitecture (P-Core) Examined",
        "Hermes -Wikipedia",
        "Hermes GitHub repository",
        "Hermes Zenodo repository",
        "Intel Core i5-12600K DDR4 Alder Lake CPU Review",
        "Intel Details Golden Cove",
        "Intel Xeon Gold 6258R",
        "L3 Cache Latency Comparison at Base Frequency",
        "MOVNTI -x86 ISA",
        "PARSEC",
        "Second Championship Value Prediction (CVP-2)",
        "SPEC CPU",
        "SPEC CPU 2017",
        "Surprisingly High Latency Discovered in Alder Lake",
        "The Intel 12th Gen Core i9-12900K Review",
        "An E ective On-chip Preloading Scheme to Reduce Data Access Penalty",
        "Domino Temporal Data Prefetcher",
        "Bingo Spatial Data Prefetcher",
        "Reducing Memory Reference Energy with Opportunistic Virtual Caching",
        "Managing Wire Delay in Large Chip-Multiprocessor Caches",
        "Correlated Load-Address Predictors",
        "Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning",
        "DSPatch: Dual Spatial Pattern Prefetcher",
        "Slim NoC: A Low-diameter On-chip Network Topology for High Energy Efciency and Scalability",
        "Perceptron-Based Prefetch Filtering",
        "Virtual-Address Caches. Part 1: Problems and Solutions in Uniprocessors",
        "E ective Hardware-Based Data Prefetching for High-Performance Processors",
        "Improving Cache Performance by Selective Cache Bypass",
        "Dynamic Hot Data Stream Prefetching for General-Purpose Programs",
        "Low-cost Epoch-based Correlation Prefetching for Commercial Applications",
        "A Stateless, Content-Directed Data Prefetching Mechanism",
        "Improving Data Cache Performance by Pre-executing Instructions Under a Cache Miss",
        "Enhancing Last-Level Cache Performance by Block Bypassing and Early Miss Determination",
        "Last-touch Correlated Data Streaming",
        "Spatial Memory Streaming with Rotated Patterns",
        "Stride Directed Prefetching in Scalar Processors",
        "Bit-level Perceptron Prediction for Indirect Branches",
        "Bypass and Insertion Algorithms for Exclusive Last-Level Caches",
        "Evolution of the Samsung Exynos CPU Microarchitecture",
        "Reactive NUCA: Near-Optimal Block Placement and Replication in Distributed Caches",
        "Continuous Runahead: Transparent Hardware Acceleration for Memory Intensive Workloads",
        "Filtered Runahead Execution with a Runahead Bu er",
        "Timekeeping in the Memory System: Predicting and Optimizing Memory Behavior",
        "TCP: Tag Correlating Prefetchers",
        "E ective Stream-Based and Execution-Based Data Prefetching",
        "Access Map Pattern Matching for Data Cache Prefetch",
        "Linearizing Irregular Memory Accesses for Improved Correlated Prefetching",
        "Back to the Future: Leveraging Belady's Algorithm for Improved Cache Replacement",
        "High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)",
        "Reducing Load Latency with Cache Level Prediction",
        "Dynamic Branch Prediction with Perceptrons",
        "Fast Path-Based Neural Branch Prediction",
        "Dead Block Replacement and Bypass with a Sampling Predictor",
        "Neural Methods for Dynamic Branch Prediction",
        "Multiperspective Reuse Prediction",
        "Run-Time Adaptive Cache Management",
        "Run-Time Cache Bypassing",
        "Run-Time Adaptive Cache Hierarchy Management via Reference Analysis",
        "Prefetching using Markov Predictors",
        "Improving Direct-mapped Cache Performance by the Addition of a Small Fully-associative Cache and Prefetch Bu ers",
        "A Prefetching Technique for Irregular Accesses to Linked Data Structures",
        "Sampling Dead Block Prediction for Last-Level Caches",
        "Counter-Based Cache Replacement and Bypassing Algorithms",
        "An Adaptive, Non-Uniform Cache Structure for Wire-Delay Dominated On-Chip Caches",
        "Path Con dence Based Lookahead Prefetching",
        "Division of Labor: A More E ective Approach to Prefetching",
        "Exploiting Spatial Locality in Data Caches using Spatial Footprints",
        "Mc-PAT: An Integrated Power, Area, and Timing Modeling Framework for Multicore and Manycore Architectures",
        "CRISP: Critical Slice Prefetching",
        "Cache Bursts: A New Approach for Eliminating Dead Blocks and Increasing Cache E ciency",
        "E ciently Enabling Conventional Block Sizes for Very Large Die-Stacked DRAM Caches",
        "A Logical Calculus of the Ideas Immanent in Nervous Activity",
        "Digital Western Research Laboratory",
        "Just Say No: Bene ts of Early Cache Miss Determination",
        "Best-O set Hardware Prefetching",
        "Trading Con ict and Capacity Aliasing in Conditional Branch Predictors",
        "Address-Value Delta (AVD) Prediction: Increasing the E ectiveness of Runahead Execution by Exploiting Regular Memory Allocation Patterns",
        "Techniques for E cient Processing in Runahead Execution Engines",
        "E cient Runahead Execution: Power-E cient Memory Latency Tolerance",
        "On Reusing the Results of Pre-Executed Instructions in a Runahead Execution Processor",
        "Runahead Execution: An Alternative to Very Large Instruction Windows for Out-of-order Processors",
        "Runahead Execution: An E ective Alternative to Large Instruction Windows",
        "Vector Runahead",
        "Bouquet of Instruction Pointers: Instruction Pointer Classi er-based Spatial Hardware Prefetching",
        "Computer Organization and Design: The Hardware Software Interface",
        "Bloom Filtering Cache Misses for Accurate Data Speculation and Prefetching",
        "Exploiting Single-Usage for E ective Memory Management",
        "Sandbox Prefetching: Safe Run-Time Evaluation of Aggressive Prefetchers",
        "Adaptive Insertion Policies for High Performance Caching",
        "Fundamental Latency Trade-o in Architecting DRAM Caches: Outperforming Impractical SRAM-Tags with a Simple and Practical Design",
        "Reducing Con icts in Direct-Mapped Caches with a Temporality-Based Design",
        "Utilizing Reuse Information in Data Cache Management",
        "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain",
        "The Direct-to-Data (D2D) Cache: Navigating the Cache Hierarchy with a Single Lookup",
        "A Split Cache Hierarchy for Enabling Data-Oriented Optimizations",
        "Multi-Lookahead O set Prefetching",
        "E ciently Prefetching Complex Address Patterns",
        "Ligra: A Lightweight Graph Processing Framework for Shared Memory",
        "Spatio-Temporal Memory Streaming",
        "Spatial Memory Streaming",
        "Feedback Directed Prefetching: Improving the Performance and Bandwidth-E ciency of Hardware Prefetchers",
        "Merging Path and Gshare Indexing in Perceptron Branch Prediction",
        "Perceptron Learning for Reuse Prediction",
        "A Modi ed Approach to Data Cache Management",
        "Managing Data Caches using Selective Cache Line Replacement",
        "Stream Floating: Enabling Proactive and Decentralized Cache Optimizations",
        "Practical O -chip Meta-data for Temporal Memory Streaming",
        "Making Address-Correlated Prefetching Practical",
        "Temporal Streaming of Shared Memory",
        "Modi ed LRU Policies for Improving Second-level Cache Behavior",
        "An In-Cache Address Translation Mechanism",
        "SHiP: Signature-based Hit Predictor for High Performance Caching",
        "E cient Metadata Management for Irregular Data Prefetching",
        "Temporal Prefetching Without the O -Chip Metadata",
        "Two-level Adaptive Training Branch Prediction",
        "Speculation Techniques for Improving Load Related Instruction Scheduling",
        "Slurm: Simple Linux Utility for Resource Management"
    ],
    "637aec2590e50fcafd92962b": [
        "Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks",
        "Proc. VLDB Endowment",
        "Conjugate gradients on multiple gpus",
        "Cusnmf: A sparse non-negative matrix factorization approach for large-scale collaborative filtering recommender systems on multi-gpu",
        "Prodigy: Improving the memory latency of data-indirect irregular workloads using hardware-software co-design",
        "Stream-based memory access specialization for general purpose processors",
        "A gpu implementation of inclusion-based points-to analysis",
        "Stream semantic registers: A lightweight risc-v isa extension achieving full compute utilization in single-issue cores",
        "Indirection stream semantic register architecture for efficient sparse-dense linear algebra",
        "Unlimited vector extension with data streaming support",
        "Impulse: building a smarter memory controller",
        "A novel hardware support for heterogeneous multi-core memory system",
        "Memory controller for vector processor",
        "Planar: a programmable accelerator for near-memory data rearrangement",
        "In-memory data rearrangement for irregular, data-intensive computing",
        "AMBA AXI and ACE Protocol Specification",
        "An open-source platform for high-performance noncoherent on-chip communication",
        "A \"new ara\" for vector computing: An open source highly efficient risc-v v 1.0 vector processor design",
        "The cost of application-class processing: Energy and performance analysis of a linux-ready 1.7-ghz 64-bit risc-v core in 22nm fdsoi technology",
        "The pagerank citation ranking : Bringing order to the web",
        "The university of florida sparse matrix collection"
    ],
    "64b60eaf3fda6d7f06eaf557": [
        "Gqa: Training generalized multi-query transformer models from multi-head checkpoints",
        "The long-document transformer",
        "Scatterbrain: Unifying sparse and low-rank attention",
        "Rethinking attention with performers",
        "FlashAttention: Fast and memory-efficient exact attention with IO-awareness",
        "Dissecting the Ampere GPU architecture via microbenchmarking",
        "Dissecting the nvidia Volta GPU architecture via microbenchmarking",
        "Transformers are RNNs: Fast autoregressive transformers with linear attention",
        "Reformer: The efficient transformer",
        "xformers: A modular and hackable transformer modelling library",
        "Online normalizer calculation for softmax",
        "OpenAI. Gpt-4 technical report",
        "Self-attention does not need ? (? 2 ) memory",
        "Efficient content-based sparse attention with routing transformers",
        "Fast transformer decoding: One write-head is all you need",
        "Megatron-LM: Training multi-billion parameter language models using model parallelism",
        "Triton: an intermediate language and compiler for tiled neural network computations",
        "Attention is all you need",
        "Linformer: Self-attention with linear complexity",
        "Big bird: Transformers for longer sequences"
    ],
    "64a407dcd68f896efaf1ba64": [
        "turing award lecture",
        "A survey of computer architecture simulation techniques and tools",
        "The gem5 simulator",
        "Advanced Computer Architecture and Compilation for High-Performance and Embedded Systems (ACACES-2012). High-Performance and Embedded Architecture and Compilation Network of",
        "Marss-x86: A qemu-based microarchitectural and systems simulator for x86 multicore processors",
        "Zsim: Fast and accurate microarchitectural simulation of thousand-core systems",
        "Instruction sets should be free: The case for risc-v",
        "Sst simulation",
        "dist-gem5: Distributed simulation of computer clusters",
        "Full speed ahead: Detailed architectural simulation at near-native speed",
        "Adaptive cache warming for faster simulations",
        "Smarts: Accelerating microarchitecture simulation via rigorous statistical sampling",
        "Using simpoint for accurate and efficient simulation",
        "Directed statistical warming through time traveling",
        "Slacksim: A platform for parallel simulations of cmps on cmps",
        "pd-gem5: Simulation infrastructure for parallel/distributed computer systems",
        "Firesim: Fpgaaccelerated cycle-exact scale-out system simulation in the public cloud",
        "Hasim: Fpgabased high-detail multicore simulation using time-division multiplexing",
        "Ramp: Research accelerator for multiple processors",
        "The gem5 simulator: Version 20.0+",
        "The future of architectural simulation",
        "Hase: a flexible high performance architecture simulator",
        "simcore: an event-driven simulation framework for performance evaluation of computer systems",
        "Barra: A parallel functional simulator for gpgpu",
        "Simics: A full system simulation platform",
        "Simplescalar: an infrastructure for computer system modeling",
        "The arm research starter kit: System modelling using gem5",
        "Parsec3.0: A multicore benchmark suite with network stacks and splash-2x",
        "Intel? vtune? profiler",
        "A top-down method for performance analysis and counters architecture",
        "None",
        "Reading m1 performance counters",
        "Apple mac m1 microarchitectural features",
        "Spec 2017 documentation",
        "Wait of a decade: Did spec cpu 2017 broaden the performance horizon?",
        "A workload characterization of the spec cpu2017 benchmark suite",
        "Firemarshal: Making hw/sw co-design reproducible and reliable",
        "Chipyard: Integrated design, simulation, and implementation framework for custom socs",
        "Profiling a warehouse-scale computer",
        "Organization and performance of a two-level virtual-real cache hierarchy",
        "Transparent hugepage support",
        "Intel optimizations for dynamic language runtimes",
        "Runtime performance optimization blueprint: Intel architecture optimization with large code pages",
        "A case for fame: Fpga architecture model execution",
        "Adaptive and speculative slack simulations of cmps on cmps",
        "Structural simulation toolkit (sst)",
        "Performance characterization of in-memory data analytics on a modern cloud server",
        "Deep-dive analysis of the data analytics workload in cloudsuite",
        "Fine-grain power breakdown of modern out-of-order cores and its implications on skylake-based systems",
        "Memory hierarchy for web search",
        "Tas: Tcp acceleration as an os service",
        "Data motifs: A lens towards fully understanding big data and ai workloads",
        "Understanding big data analytics workloads on modern processors",
        "How data volume affects spark based data analytics on a scale-up server",
        "Vbench: Benchmarking Video Transcoding in the Cloud",
        "Heterogeneous memory subsystem for natural graph analytics",
        "Toward an ideal ndn router on a commercial off-the-shelf computer"
    ],
    "6423ac7790e50fcafd55eaa0": [
        "Intrinsic dimensionality explains the effectiveness of language model fine-tuning",
        "Composable sparse finetuning for cross-lingual transfer",
        "Stronger generalization bounds for deep nets via a compression approach",
        "Layer normalization",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
        "Language models are few-shot learners",
        "Attention fusion: a light yet efficient late fusion mechanism for task adaptation in nlu",
        "Parameter-efficient fine-tuning design spaces",
        "Named tensor notation",
        "None",
        "None",
        "-bit matrix multiplication for transformers at scale",
        "The case for 4-bit precision: k-bit inference scaling laws",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models",
        "Decaf: A deep convolutional activation feature for generic visual recognition",
        "Krona: Parameter efficient tuning with kronecker adapter",
        "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity",
        "Learnto-share: A hardware-friendly transfer learning framework exploiting computation and parameter sharing",
        "Cross-attention is all you need: Adapting pretrained transformers for machine translation",
        "Parameter-efficient transfer learning with diff pruning",
        "Deep learning with limited numerical precision",
        "Warp: Word-level adversarial reprogramming",
        "2022a. Towards a unified view of parameter-efficient transfer learning",
        "Deep residual learning for image recognition",
        "2022b. SparseAdapter: An easy approach for improving the parameter-efficiency of adapters",
        "Nxmtransformer: Semistructured sparsification for natural language understanding via admm",
        "Parameter-efficient transfer learning for nlp",
        "Lora: Low-rank adaptation of large language models",
        "Compacter: Efficient low-rank hypercomplex adapter layers",
        "YaLM",
        "Adam: A method for stochastic optimization",
        "Fastfood: Approximate kernel expansions in loglinear time",
        "The power of scale for parameter-efficient prompt tuning",
        "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Measuring the intrinsic dimension of objective landscapes",
        "Prefixtuning: Optimizing continuous prompts for generation",
        "Few-shot parameterefficient fine-tuning is better and cheaper than in-context learning",
        "Gpt understands, too",
        "Rethinking parameter counting: Effective dimensionality revisted",
        "A kernel-based view of language model finetuning",
        "Unipelt: A unified framework for parameter-efficient language model tuning",
        "Kyunghyun Cho, and Iryna Gurevych. 2020a. Adapterfusion: Non-destructive task composition for transfer learning",
        "Modular deep learning",
        "Adapterhub: A framework for adapting transformers",
        "Exploring universal intrinsic task subspace via prompt tuning",
        "Language models are unsupervised multitask learners. Pranav Rajpurkar, Robin Jia, and Percy Liang",
        "Learning multiple visual domains with residual adapters",
        "Efficient parametrization of multi-domain deep neural networks",
        "A primer in BERTology: What we know about how BERT works",
        "Multitask prompted training enables zero-shot task generalization",
        "Trishala Neeraj, Urmish Thakker, Vikas Raunak, Xiang Tang, Zheng Xin Yong",
        "Outrageously large neural networks: The sparsely-gated mixtureof-experts layer",
        "Megatron-lm: Training multibillion parameter language models using model parallelism",
        "On transferability of prompt tuning for natural language understanding",
        "Lst: Ladder side-tuning for parameter and memory efficient transfer learning",
        "Training neural networks with fixed sparse masks",
        "Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models",
        "Attention is all you need",
        "Spot: Better frozen model adaptation through soft prompt transfer",
        "Efficient fine-tuning of bert models on the edge",
        "Superglue: A stickier benchmark for general-purpose language understanding systems",
        "Adamix: Mixture-ofadapter for parameter-efficient tuning of large language models",
        "Transformers: State-of-the-Art Natural Language Processing",
        "None",
        "Beyond fully-connected layers with quaternions: Parameterization of hypercomplex multiplications with 1/n parameters",
        "None",
        "Counterinterference adapter for multilingual machine translation"
    ],
    "6459ac63d68f896efa6588b4": [
        "Contextual string embeddings for sequence labeling",
        "Targetable named entity recognition in social media",
        "Improving language models by retrieving from trillions of tokens",
        "None",
        "Autoregressive entity retrieval",
        "USTC-NELSLIP at SemEval-2022 task 11: Gazetteer-adapted integration network for multilingual complex named entity recognition",
        "Scaling instructionfinetuned language models",
        "Unsupervised cross-lingual representation learning at scale",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Multi-CoNER v2: a Large Multilingual dataset for Finegrained and Noisy Named Entity Recognition",
        "Gazetteer Enhanced Named Entity Recognition for Code-Mixed Web Queries",
        "Dynamic gazetteer integration in multilingual models for cross-lingual and cross-domain named entity recognition",
        "Oleg Rokhlenko, and Shervin Malmasi. 2023b. SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2)",
        "Qtrade AI at SemEval-2022 task 11: An unified framework for multilingual NER task",
        "Generating a large-scale entity linking dictionary from Wikipedia link structure and article text",
        "Generalization through memorization: Nearest neighbor language models",
        "Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Fixing weight decay regularization in adam",
        "MultiCoNER: a Large-scale Multilingual dataset for Complex Named Entity Recognition",
        "2022b. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER)",
        "An inverted index implementation",
        "GEMNET: Effective gated gazetteer representations for recognizing complex entities in low-context input",
        "Training language models to follow instructions with human feedback",
        "Towards robust linguistic analysis using OntoNotes",
        "The probabilistic relevance framework: BM25 and beyond",
        "Introduction to the conll-2002 shared task: Language-independent named entity recognition",
        "TGIF: Tree-graph integrated-format parser for enhanced UD with twostage generic-to individual-language finetuning",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Named entity task definition, version 2.1",
        "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
        "Llama: Open and efficient foundation language models",
        "2023a. Gpt-ner: Named entity recognition via large language models",
        "Instructuie: Multi-task instruction tuning for unified information extraction",
        "2022a. Named entity and relation extraction with multi-modal retrieval",
        "2021a. Automated Concatenation of Embeddings for Structured Prediction",
        "2021b. Improving named entity recognition by external context retrieving and cooperative learning",
        "More embeddings, better sequence labelers?",
        "2022b. DAMO-NLP at SemEval-2022 task 11: A knowledge-based system for multilingual named entity recognition",
        "Zero-shot information extraction via chatting with chatgpt",
        "LUKE: Deep contextualized entity representations with entityaware self-attention",
        "None",
        "2022b. Entqa: Entity linking as question answering",
        "2022c. Domain-specific NER via retrieving correlated samples"
    ],
    "64741a3ad68f896efaa62202": [
        "Linear algebraic structure of word senses, with applications to polysemy",
        "Implicit regularization in deep matrix factorization",
        "A theoretical analysis of contrastive unsupervised representation learning",
        "Perfectly balanced: Improving transfer and robustness of supervised contrastive learning",
        "A Simple Framework for Contrastive Learning of Visual Representations",
        "Intriguing properties of contrastive losses",
        "Debiased Contrastive Learning",
        "Exploring deep neural networks via layer-peeled model: Minority collapse in imbalanced training",
        "Sparse coding in the primate cortex. The handbook of brain theory and neural networks",
        "Dissecting supervised constrastive learning",
        "Bootstrap your own latent: A new approach to self-supervised Learning",
        "Implicit regularization in matrix factorization",
        "Implicit bias of gradient descent on linear convolutional networks",
        "Neural collapse under mse loss: Proximity to and dynamics on the central path",
        "A theoretical study of inductive biases in contrastive learning",
        "Provable guarantees for self-supervised deep learning with spectral contrastive loss",
        "Deep residual learning for image recognition",
        "A fast learning algorithm for deep belief nets",
        "Limitations of neural collapse for understanding generalization in deep learning",
        "A broad study on the transferability of visual representations with contrastive learning",
        "The power of contrast for feature learning: A theoretical analysis",
        "The implicit bias of gradient descent on nonseparable data",
        "Sgd on neural networks learns functions of increasing complexity. Advances in neural information processing systems",
        "Supervised contrastive learning",
        "Learning multiple layers of features from tiny images",
        "Adaptive estimation of a quadratic functional by model selection",
        "Predicting what you already know helps: Provable self-supervised learning",
        "Addressing feature suppression in unsupervised visual representations",
        "Selfsupervised learning is more robust to dataset imbalance",
        "Neural collapse under crossentropy loss",
        "Gradient descent on two-layer nets: Margin maximization and simplicity bias",
        "Sparse modeling for image and vision processing",
        "Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research",
        "Convolutional neural networks analyzed via convolutional sparse coding",
        "Prevalence of neural collapse during the terminal phase of deep learning training",
        "Image sequence denoising via sparse and redundant representations",
        "Efficient learning of sparse representations with an energybased model",
        "Implicit regularization in deep learning may not be explainable by norms",
        "Can contrastive learning avoid shortcut solutions?",
        "An investigation of why overparameterization exacerbates spurious correlations",
        "Understanding contrastive learning requires incorporating inductive biases",
        "Probability for statisticians",
        "The implicit bias of gradient descent on separable data",
        "What makes for good views for contrastive learning?",
        "Contrastive estimation reveals topic posterior information to linear models",
        "Contrastive learning, multi-view redundancy, and linear models",
        "Self-supervised learning from a multi-view perspective",
        "Sparse coding and decorrelation in primary visual cortex during natural vision",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Toward understanding the feature learning process of self-supervised contrastive learning",
        "Towards understanding the generalization bias of two layer convolutional linear classifiers with gradient descent",
        "Linear spatial pyramid matching using sparse coding for image classification",
        "On the optimization landscape of neural collapse under mse loss: Global optimality with unconstrained features",
        "Are all losses created equal: A neural collapse perspective",
        "A geometric analysis of neural collapse with unconstrained features",
        "Understanding the generalization of adam in learning neural networks with proper regularization"
    ],
    "64a29621d68f896efa28fd54": [
        "Better handling for one-hit-wonder objects",
        "Memcached -a distributed memory object caching system",
        "None",
        "Workload Analysis of a Large-Scale Key-Value Store",
        "Caching with Delayed Hits",
        "Finer-LRU: A Scalable Page Management Scheme for HPC Manycore Architectures",
        "CAR: Clock with Adaptive Replacement",
        "LHD: Improving cache hit rate by maximizing hit density",
        "Talus: A simple way to remove cliffs in cache performance",
        "A study of replacement algorithms for a virtual-storage computer",
        "The CacheLib caching engine: Design and experiences at scale",
        "Towards Lightweight and Robust Machine Learning for CDN Caching",
        "RobinHood: Tail latency aware caching -dynamic reallocation from Cache-Rich to Cache-Poor",
        "Adapt-Size: Orchestrating the hot object memory cache in a content delivery network",
        "Hyperbolic caching: Flexible caching for web applications",
        "Web caching and Zipf-like distributions: evidence and implications",
        "Cost-Aware WWW Proxy Caching Algorithms",
        "FASTER: A Concurrent Key-Value Store with In-Place Updates",
        "Memshare: a dynamic multi-tenant key-value cache",
        "A paging experiment with the multics system",
        "Cooperative caching: Using remote client memory to improve file system performance",
        "The working set model for program behavior",
        "Working Set Analytics",
        "Garbage-first garbage collection",
        "LRFU: a spectrum of policies that subsumes the least recently used and least frequently used policies",
        "Replacing the cache replacement algorithm in memcached",
        "Emmanuel Cecchet, Snigdhaswin Kar, and Prabodh Mishra. The design and operation of CloudLab",
        "Crystal: a unified cache storage system for analytical databases",
        "Adaptive Software Cache Management",
        "TinyLFU: A Highly Efficient Cache Admission Policy",
        "Flashield: a hybrid key-value cache that controls flash write amplification",
        "Bandana: Using non-volatile memory for storing deep learning models",
        "It's time to revisit LRU vs. FIFO",
        "MemC3: Compact and concurrent MemCache with dumber caching and smarter hashing",
        "TriCache: A User-Transparent Block Cache Enabling High-Performance Out-of-Core Processing with In-Memory Programs",
        "FaasCache: keeping serverless computing alive with greedy-dual caching",
        "Raven: belady-guided, predictive (deep) learning for in-memory and content caching",
        "An analysis of Facebook photo caching",
        "CLOCK-Pro: an effective improvement of the CLOCK replacement",
        "DULO: an effective buffer cache management scheme to exploit both temporal and spatial locality",
        "LIRS: an efficient low inter-reference recency set replacement policy to improve buffer cache performance",
        "NetCache: Balancing keyvalue stores with fast in-network caching",
        "Q: A Low Overhead High Performance Buffer Management Replacement Algorithm",
        "Caching strategies to improve disk system performance",
        "I/o deduplication: Utilizing content similarity to improve i/o performance",
        "All-Flash Array Key-Value Cache for Large Objects",
        "An in-depth analysis of cloud block storage workloads in large-scale production",
        "CacheSifter: Sifting Cache Files for Boosted Mobile Performance and Lifetime",
        "DistCache: Provable load balancing for Large-Scale storage systems with distributed caching",
        "Algorithmic Nuggets in Content Delivery",
        "Kangaroo: Theory and practice of caching billions of tiny objects on flash",
        "ARC: A self-tuning, low overhead replacement cache",
        "Caching in video CDNs: building strong lines of defense",
        "SNIA IOTTA Trace Repository. Storage Networking Industry Association",
        "Write off-loading: Practical power management for enterprise storage",
        "Analysis of the generalized clock buffer replacement scheme for database transaction processing",
        "Analysis of garbage collection algorithms and memory management in java",
        "Frozenhot cache: Rethinking cache management for modern software",
        "EuroSys'23",
        "EC-Cache:load-balanced,low-latency cluster caching with online erasure coding",
        "Unifying the data center caching layer: Feasible? Profitable?",
        "Learning Cache Replacement with CACHEUS",
        "CliqueMap: productionizing an RMA-based distributed caching system",
        "EELRU: simple and effective adaptive page replacement",
        "Sequentiality and prefetching in database systems",
        "Arvind Krishnamurthy, Emmett Witchel, and others. Learning relaxed belady for content distribution network caching",
        "Footprint Descriptors: Theory and Practice of Cache Provisioning in a Global CDN",
        "RIPQ: Advanced photo caching on flash for facebook",
        "Driving cache replacement with ML-based LeCaR",
        "Efficient MRC construction with SHARDS",
        "Separating data via block invalidation time inference for write amplification reduction in {Log-Structured} storage",
        "Austere flash caching with deduplication and compression",
        "Enhancing the scalability of memcached",
        "None",
        "The storage hierarchy is not a hierarchy: Optimizing caching on modern storage devices with orthus",
        "Towards Latency Awareness for Content Delivery Network Caching. ATC'22",
        "Mithril: mining sporadic associations for cache prefetching",
        "C2DN: How to harness erasure codes at the edge for efficient content delivery",
        "A large scale analysis of hundreds of in-memory cache clusters at Twitter",
        "Segcache: a memoryefficient and scalable in-memory key-value cache for small objects",
        "CacheSack: Admission Optimization for Google Datacenter Flash Caches",
        "Optimal Data Placement for Heterogeneous Cache, Memory, and Storage Systems",
        "When is the Cache Warm? Manufacturing a Rule of Thumb",
        "Tencent block storage traces (SNIA IOTTA trace set 27917)",
        "OSCA: An Online-Model based cache allocation scheme in cloud block storage systems",
        "AutoSight: Distributed Edge Caching in Short Video Network",
        "LIRS2: an improved LIRS replacement algorithm",
        "Tencent photo cache traces (SNIA IOTTA trace set 27476)",
        "The multi-queue replacement algorithm for second level buffer caches"
    ],
    "64a29621d68f896efa28fd67": [
        "Graph 500 | large-scale benchmarks",
        "Introduction to Cache Allocation",
        "Nvidia Unified Memory",
        "SPEC Benchmarks and Tools",
        "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "Demystifying GPU UVM Cost with Deep Runtime and Workload Analysis",
        "Abstractors: Transformer Modules for Symbolic Message Passing and Relational Reasoning",
        "Workload Analysis of a Large-Scale Key-Value Store",
        "Classifying Memory Access Patterns for Prefetching",
        "Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning",
        "The CacheLib Caching Engine: Design and Experiences at Scale",
        "BINGO: braininspired learning memory",
        "Cognitive control over learning: creating, clustering, and generalizing task-set structure",
        "Contrastive Hebbian learning with random feedback weights",
        "Revisiting Fundamentals of Experience Replay",
        "Distributed caching with memcached",
        "Learning Memory Access Patterns",
        "Deep residual learning for image recognition",
        "Long Short-Term Memory",
        "Sparse Associative Memory",
        "None",
        "HeteroOS: OS Design for Heterogeneous Memory Management in Datacenter",
        "Measuring catastrophic forgetting in neural networks",
        "The Case for Learned Index Structures",
        "What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated",
        "GraphChi: Large-Scale Graph Computation on Just a PC",
        "MIND: In-Network Memory Management for Disaggregated Data Centers",
        "Overcoming catastrophic forgetting by incremental moment matching",
        "Training Quantized Nets: A Deeper Understanding",
        "Deep learning based data prefetching in CPU-GPU unified virtual memory",
        "Tpp: Transparent page placement for cxl-enabled tiered memory",
        "Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory",
        "Deciphering The Hippocampal Polyglot: the Hippocampus as a Path Integration System",
        "The PageRank citation ranking: Bringing order to the web",
        "The storage and recall of memories in the hippocampo-cortical system",
        "Pattern separation, completion, and categorisation in the hippocampus and neocortex",
        "RecShard: Statistical Feature-Based Memory Optimization for Industry-Scale Neural Recommendation",
        "Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider",
        "Legoos: A disseminated, distributed {OS} for hardware resource disaggregation",
        "A Hierarchical Neural Model of Data Prefetching",
        "Learning Relaxed Belady for Content Distribution Network Caching",
        "Parallel Multi-Dimensional LSTM, with Application to Fast Biomedical Volumetric Image Segmentation",
        "Perceptron learning for reuse prediction",
        "HW/SW Co-design for Reliable In-memory Brain-inspired Hyperdimensional Computing",
        "Attention is all you need",
        "Replay in minds and machines",
        "A Large-Scale Analysis of Hundreds of In-Memory Key-Value Cache Clusters at Twitter",
        "RRAM for compute-in-memory: From inference to training",
        "Brain-inspired Search Engine Assistant based on Knowledge Graph"
    ],
    "64be5e653fda6d7f063a95ce": [
        "Deep learning with differential privacy",
        "Robust testing and estimation under manipulation attacks",
        "Information-theoretic lower bounds on the oracle complexity of convex optimization",
        "cpsgd: Communication-efficient and differentially-private distributed sgd",
        "Byzantine-resilient non-convex stochastic gradient descent",
        "Fixing by mixing: A recipe for optimal byzantine ml under heterogeneity",
        "Faster rates of convergence to stationary points in differentially private optimization",
        "Private and polynomial time algorithms for learning gaussians and beyond",
        "A little is enough: Circumventing defenses for distributed learning",
        "Private empirical risk minimization: Efficient algorithms and tight error bounds",
        "Parallel and distributed computation: numerical methods",
        "Machine learning with adversaries: Byzantine tolerant gradient descent",
        "Practical secure aggregation for federated learning on user-held data",
        "Optimization methods for large-scale machine learning",
        "Fingerprinting codes and the price of approximate differential privacy",
        "Manipulation attacks in local differential privacy",
        "Robust estimation of discrete distributions under local differential privacy",
        "Differential privacyenabled federated learning for sensitive health data",
        "Byzantine-resilient highdimensional sgd with local iterations on heterogeneous data",
        "Large scale distributed deep networks",
        "Being robust (in high dimensions) can be practical",
        "Robust estimators in high-dimensions without the computational intractability",
        "Local privacy and statistical minimax rates",
        "Differential privacy and robust statistics",
        "The algorithmic foundations of differential privacy",
        "The hidden vulnerability of distributed learning in Byzantium",
        "on the protection of natural persons with regard to the processing of personal data and on the free movement of such data",
        "Byzantine machine learning made easy by resilient averaging of momentums",
        "Distributed robust learning",
        "Model inversion attacks that exploit confidence information and basic countermeasures",
        "Stochastic heavy ball",
        "Privacy induces robustness: Information-computation gaps and sparse mean estimation",
        "Differential privacy and Byzantine resilience in sgd: Do they add up?",
        "Fault-tolerance in distributed optimization: The case of redundancy",
        "Byzantine fault-tolerant distributed machine learning with norm-based comparative gradient elimination",
        "Deep models under the gan: Information leakage from collaborative deep learning",
        "Efficient mean estimation with pure differential privacy via a sum-ofsquares exponential mechanism",
        "Robustness implies privacy in statistical estimation",
        "Personalized federated learning with differential privacy",
        "Linear convergence of gradient and proximal-gradient methods under the polyak-?ojasiewicz condition",
        "Scaffold: Stochastic controlled averaging for federated learning",
        "Learning from history for Byzantine robust optimization",
        "Byzantine-robust learning on heterogeneous datasets via bucketing",
        "What can we learn privately?",
        "The Byzantine generals problem",
        "RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets",
        "On robustness and local differential privacy",
        "Approximate Byzantine fault-tolerance in distributed optimization",
        "Robust and differentially private mean estimation",
        "Differential privacy and robust statistics in high dimensions",
        "Private federated learning without a trusted server: Optimal algorithms for convex losses",
        "Private non-convex federated learning without a trusted server",
        "Differentially private Byzantine-robust federated learning",
        "Exploiting unintended feature leakage in collaborative learning",
        "R?nyi differential privacy",
        "Lectures on convex optimization",
        "Differentially private federated learning on heterogeneous data",
        "Privacy-preserving deep learning: Revisited and enhanced",
        "Some methods of speeding up the convergence of iteration methods",
        "Mathematical statistics and data analysis",
        "High dimensional statistics. Lecture notes for course 18S997",
        "Multivariate estimation with high breakdown point",
        "Minimizing finite sums with the stochastic average gradient",
        "Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data",
        "Membership inference attacks against machine learning models",
        "Is interaction necessary for distributed private learning?",
        "Robust learning: Information theory and algorithms",
        "Resilience: A criterion for learning in the presence of arbitrary outliers",
        "Between pure and approximate differential privacy",
        "Fault-tolerant multi-agent optimization: optimal iterative distributed algorithms",
        "Introduction to the non-asymptotic analysis of random matrices",
        "Subsampled r?nyi differential privacy and analytical moments accountant",
        "Beyond inferring class representatives: User-level privacy leakage from federated learning",
        "?-stochastic sign sgd: A Byzantine resilient and differentially private gradient compressor for federated learning",
        "Generalized Byzantinetolerant sgd",
        "Fall of empires: Breaking Byzantine-tolerant SGD by inner product manipulation",
        "Byzantinerobust distributed learning: Towards optimal statistical rates",
        "Opacus: Userfriendly differential privacy library in pytorch",
        "Improved deep leakage from gradients",
        "Robust estimation via generalized quasi-gradients. Information and Inference: A",
        "Bridging differential privacy and Byzantine-robustness via model aggregation"
    ],
    "64ba03413fda6d7f062732f5": [
        "Variational option discovery algorithms",
        "Hindsight experience replay",
        "The option-critic architecture",
        "None",
        "Exploration by random network distillation",
        "Explore, discover and learn: Unsupervised discovery of state-covering skills",
        "None",
        "Decision transformer: Reinforcement learning via sequence modeling",
        "Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings",
        "Maximum likelihood from incomplete data via the em algorithm",
        "Dynamics learning with cascaded variational inference for multi-step manipulation",
        "Dynamics learning with cascaded variational inference for multi-step manipulation",
        "Integrated task and motion planning",
        "Deep learning",
        "Generative adversarial networks",
        "Maniskill2: A unified benchmark for generalizable manipulation skills",
        "Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning",
        "Soft actorcritic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "Dream to control: Learning behaviors by latent imagination",
        "Mastering atari with discrete world models",
        "Temporal difference learning for model predictive control",
        "Provably efficient maximum entropy exploration",
        "None",
        "betavae: Learning basic visual concepts with a constrained variational framework",
        "Generative adversarial imitation learning",
        "Denoising diffusion probabilistic models",
        "A soft-body manipulation benchmark with differentiable physics",
        "Efficient planning in a compact latent action space",
        "Optimal control as a graphical model inference problem",
        "Sampling-based algorithms for optimal motion planning",
        "Auto-encoding variational bayes",
        "Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation",
        "One solution is not all you need: Few-shot extrapolation via structured maxent rl",
        "Reinforcement learning and control as probabilistic inference: Tutorial and review",
        "Hrl4in: Hierarchical reinforcement learning for interactive navigation with mobile manipulators",
        "Infogail: Interpretable imitation learning from visual demonstrations",
        "Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids",
        "Object-centric learning with slot attention",
        "Learning latent plans from play",
        "None",
        "Learning and adapting skills in imagination",
        "Discovering and achieving goals via world models",
        "Representing scenes as neural radiance fields for view synthesis",
        "The expectation-maximization algorithm",
        "Generalizable manipulation skill benchmark with large-scale demonstrations",
        "Near-optimal representation learning for hierarchical reinforcement learning",
        "Data-efficient hierarchical reinforcement learning",
        "Cs229 lecture notes",
        "Solving rubik's cube with a robot hand",
        "Hierarchical reinforcement learning via advantage-weighted information maximization",
        "Discovering diverse solutions in deep reinforcement learning by maximizing state-action-based mutual information",
        "An imperative style, high-performance deep learning library",
        "Large-scale reusable adversarial skill embeddings for physically simulated characters",
        "Accelerating reinforcement learning with learned skill priors",
        "A direct method for trajectory optimization of rigid bodies through contact",
        "Learning complex dexterous manipulation with deep reinforcement learning and demonstrations",
        "Zero-shot textto-image generation",
        "Black box variational inference",
        "Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting",
        "A generalist agent",
        "Variational inference with normalizing flows",
        "High-resolution image synthesis with latent diffusion models",
        "Mastering atari, go, chess and shogi by planning with a learned model",
        "Proximal policy optimization algorithms",
        "Planning to explore via self-supervised world models",
        "Learning robot skills with temporal variational inference",
        "Deterministic policy gradient algorithms",
        "Robot skill learning: From reinforcement learning to evolution strategies. Paladyn",
        "Reinforcement learning: An introduction",
        "Advances in neural information processing systems",
        "General duality between optimal control and estimation",
        "Robot trajectory optimization using approximate inference",
        "Attention is all you need",
        "Credit assignment techniques in stochastic computation graphs",
        "Sapien: A simulated part-based interactive environment",
        "Mastering atari games with limited data",
        "Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning",
        "Glipv2: Unifying localization and vision-language understanding",
        "Online decision transformer",
        "Unpaired image-to-image translation using cycle-consistent adversarial networks",
        "Modeling purposeful adaptive behavior with the principle of maximum causal entropy",
        "The agent controls the movement of a gripper with a 4 dof controller to move the ball into the basket. The agent only receives a reward of 1 when the ball is sufficiently close to the basket. The locations of the ball and the location of robots' fingertips are what we are concerned about. The episode length is 100, including 2 action repeats",
        "None",
        "we implemented according to the original paper and used the default hyperparameter provided by the authors. We use the abbreviation TDMPC(R), SAC(R) to represent that we add an intrinsic reward with scale 0.1 for exploration in environments with only sparse rewards",
        "we used the publically available official implementation and default hyperparameters provided by the authors at",
        "2explore with hyperparameters provided by the authors of the paper. For all baseline algorithms, we only change model update frequency to once every 5 environment steps. E. Visualization of the Multimodal Exploration We plot the trajectory of the agent in AntPush environment, evaluated at different numbers of training stages in Fig. 9. The agent learned to move forward and explored all directions that would decrease the l 2 distance. It found the left side was easier for moving up in the beginning, but at episode 360, it learned to explore all directions. Ultimately, it explored the left path to the upper room and converged on it. Figure 9. Exploration of AntPush"
    ],
    "6426ed4490e50fcafd443eef": [
        "Open Neural Network Exchange",
        "PIMFlow: Compiler and Runtime Support for CNN Models on Processing-in-Memory DRAM",
        "PIM-enabled instructions: A low-overhead, locality-aware processingin-memory architecture",
        "CACTI 7: New Tools for Interconnect Exploration in Innovative Off-Chip Memories",
        "Google Neural Network Models for Edge Devices: Analyzing and Mitigating Machine Learning Inference Bottlenecks",
        "Google Workloads for Consumer Devices: Mitigating Data Movement Bottlenecks",
        "The fast Fourier transform",
        "Online Scheduling of Task Graphs on Heterogeneous Platforms",
        "Understanding and Improving the Latency of DRAM-Based Memory Systems",
        "Understanding Latency Variation in Modern DRAM Chips: Experimental Characterization, Analysis, and Optimization. SIGMETRICS Perform",
        "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning",
        "Bring Your Own Codegen to Deep Learning Compiler",
        "Efficient primitives for deep learning",
        "Accelerating Bandwidth-Bound Deep Learning Inference with Main-Memory Accelerators",
        "McDRAM v2: In-Dynamic Random Access Memory Systolic Array Accelerator to Address the Large Model Problem in Deep Neural Networks on the Edge",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "The Architecture of the DIVA Processing-in-Memory Chip",
        "Processing in memory: the Terasys massively parallel PIM array",
        "Matrix computations",
        "DLUX: A LUT-based nearbank accelerator for data center deep learning training workloads",
        "Performance analysis of multi-level parallelism: inter-node, intra-node and hardware accelerators",
        "CAIRO: A compiler-assisted technique for enabling instruction-level offloading of processing-in-memory",
        "SIMDRAM: A Framework for Bit-Serial SIMD Processing Using DRAM",
        "Near-Data Processing in Memory Expander for DNN Acceleration on GPUs",
        "Deep Residual Learning for Image Recognition",
        "A DRAM-maker's Accelerator-in-Memory (AiM) Architecture for Machine Learning",
        "Transparent Offloading and Mapping (TOM): Enabling Programmer-Transparent near-Data Processing in GPU Systems",
        "Maskrnn: Instance level video object segmentation. Advances in neural information processing systems",
        "Adaptive heterogeneous scheduling for integrated GPUs",
        "AccelWattch: A Power Modeling Framework for Modern GPUs",
        "CUTLASS",
        "Accel-Sim: An Extensible Simulation Framework for Validated GPU Modeling",
        "Toward Standardized Near-Data Processing with Unrestricted Data Placement for GPUs",
        "Ramulator: A Fast and Extensible DRAM Simulator",
        "Fast Algorithms for Convolutional Neural Networks",
        "MVP: An Efficient CNN Accelerator with Matrix, Vector, and Processing-Near-Memory Units",
        "Kyomin Sohn, and Nam Sung Kim. 2021. Hardware Architecture and Software Stack for PIM Based on Commercial DRAM Technology : Industrial Product",
        "A 1ynm 1.25V 8Gb, 16Gb/s/pin GDDR6-based Accelerator-in-Memory supporting 1TFLOPS MAC Operation and Various Activation Functions for Deep-Learning Applications",
        "Hierarchical Task Scheduler for Interleaving Subtasks on Heterogeneous Multiprocessor Platforms",
        "Torchvision the Machine-Vision Package of Torch",
        "A Hierarchical Task Scheduler for Heterogeneous Computing",
        "Active Memory Cube: A processing-in-memory architecture for exascale systems",
        "Active Memory Cube: A processing-in-memory architecture for exascale systems",
        "Deep Learning Recommendation Model for Personalization and Recommendation Systems",
        "PiDRAM: A Holistic End-to-end FPGA-based Framework for Processing-in-DRAM",
        "Optimal task scheduling for partially heterogeneous systems",
        "Multilevel Granularity Parallelism Synthesis on FPGAs",
        "Scheduling techniques for GPU architectures with processing-inmemory capabilities",
        "You only look once: Unified, real-time object detection",
        "U-net: Convolutional networks for biomedical image segmentation",
        "MobileNetV2: Inverted Residuals and Linear Bottlenecks",
        "McDRAM: Low Latency and Energy-Efficient Matrix Computations in DRAM",
        "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "Maestro: Data Orchestration and Tuning for OpenCL Devices",
        "Optimal Latency-Throughput Tradeoffs for Data Parallel Pipelines",
        "MnasNet: Platform-Aware Neural Architecture Search for Mobile",
        "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
        "PIMProf: An Automated Program Profiler for Processing-in-Memory Offloading Decisions",
        "Tuning applications for efficient GPU offloading to in-memory processing",
        "Spacea: Sparse matrix vector multiplication on processing-in-memory accelerator",
        "Bolt: Bridging the Gap between Autotuners and Hardware-native Performance",
        "CoPIM: A Concurrency-aware PIM Workload Offloading Architecture for Graph Applications",
        "Selective Replication in Memory-Side GPU Caches"
    ],
    "638eb2ef90e50fcafd58b2af": [
        "Improving language models by retrieving from trillions of tokens",
        "Unitedqa: A hybrid approach for open domain question answering",
        "SPECTER: document-level representation learning using citation-informed transformers",
        "R2-D2: A modular baseline for open-domain question answering",
        "Condenser: a pretraining architecture for dense retrieval",
        "Unsupervised corpus aware language model pre-training for dense passage retrieval",
        "COIL: revisit exact lexical match in information retrieval with contextualized inverted list",
        "2021c. Simcse: Simple contrastive learning of sentence embeddings",
        "REALM: retrievalaugmented language model pre-training",
        "Cqadupstack: A benchmark data set for community question-answering research",
        "Towards unsupervised dense information retrieval with contrastive learning",
        "Distilling knowledge from reader to retriever for question answering",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Few-shot learning with retrieval augmented language models",
        "Billion-scale similarity search with gpus",
        "Dense passage retrieval for open-domain question answering",
        "Generalization through memorization: Nearest neighbor language models",
        "Relevance-guided supervision for openqa with colbert",
        "Colbert: Efficient and effective passage search via contextualized late interaction over BERT",
        "Natural questions: a benchmark for question answering research",
        "You only need one model for open-domain question answering",
        "2021b. Phrase retrieval learns passage retrieval, too",
        "Latent retrieval for weakly supervised open domain question answering",
        "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "Zero-shot neural passage retrieval via domain-targeted synthetic question generation",
        "Www'18 open challenge: Financial opinion mining and question answering",
        "MS MARCO: A human generated machine reading comprehension dataset",
        "From doc2query to doctttttquery",
        "Domain-matched pre-training tasks for dense retrieval",
        "The web is your oyster -knowledge-intensive NLP against a very large web corpus",
        "Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "The probabilistic relevance framework: BM25 and beyond",
        "End-to-end training of multi-document reader and retriever for open-domain question answering",
        "PLAID: an efficient engine for late interaction retrieval",
        "Nandan Thakur, Nils Reimers, Andreas R?ckl?, Abhishek Srivastava, and Iryna Gurevych",
        "An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition",
        "Attention is all you need",
        "TREC-COVID: constructing a pandemic information retrieval test collection",
        "Fact or fiction: Verifying scientific claims",
        "2021a. TSDAE: using transformer-based sequential denoising auto-encoderfor unsupervised sentence embedding learning",
        "Nils Reimers, and Iryna Gurevych. 2021b. GPL: generative pseudo labeling for unsupervised domain adaptation of dense retrieval",
        "Memorizing transformers",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Is retriever merely an approximator of reader?",
        "Training language models with memory augmentation",
        "Work Dense Retrieval Models Dense retrieval models can be categorized into two groups, passagelevel retrievers",
        "SimCSE (Gao et al., 2021c) obtains representations of the same input by passing through the model twice with different dropout masks and minimizes their distance. Contriever (Izacard et al., 2021) is trained by large-scale contrastive learning with random cropping of text spans sampled from Wikipedia and CCNet. GPL (Wang et al., 2021b) leverages query generators to obtain pseudo queries, and collect positive and negative documents by pseudo labeling using a cross-encoder. Retrieval Augmentation for Language Modeling Retrieval from external datastore to improve language modeling perplexity has been explored by many works, where additional tokens are retrieved during generation based on contextual representations"
    ],
    "63c8b59590e50fcafd90b721": [
        "Polarisation photometric stereo",
        "High-sensitivity analysis of polarization by surface reflection. Machine Vision and Applications",
        "Multi-view surface reconstruction using polarization",
        "Recovery of surface orientation from diffuse polarization",
        "Simultaneous acquisition of polarimetric svbrdf and normals",
        "Imagebased acquisition and modeling of polarimetric reflectance",
        "Intel RealSense Depth cameras",
        "Field Guide to Polarization",
        "Google scanned objects: A highquality dataset of 3d scanned household items",
        "Unambiguous determination of shape from photometric stereo with unknown light sources",
        "None",
        "None",
        "A 1280x720 back-illuminated stacked temporal contrast event-based vision sensor with 4.86?m pixels, 1.066geps readout, programmable eventrate controller and compressive data-formatting pipeline",
        "E-raft: Dense optical flow from event cameras",
        "Division of focal plane asynchronous polarization imager",
        "Shape and refractive index from single-view spectro-polarimetric images",
        "Mitsuba 3 renderer",
        "Learning monocular dense depth from events",
        "Polarized 3d: High-quality depth sensing with polarization cues",
        "Depth sensing using geometrically constrained po-larization normals",
        "Adam: A method for stochastic optimization. Int. Conf. Learn. Representations (ICLR)",
        "Polarized reflection removal with perfect alignment in the wild",
        "Shape from polarization for complex scenes in the wild",
        "A 128x128 120dB 30mW asynchronous vision sensor that responds to relative intensity change",
        "A 128?128 120 dB 15 ?s latency asynchronous temporal contrast vision sensor",
        "Direct method for shape recovery from polarization and shading",
        "Glass segmentation using intensity and spectral polarization cues",
        "Polarization-based inverse rendering from a single view",
        "Transparent surface modeling from a pair of polarization images",
        "Surface normal estimation of black specular objects from multiview polarization images",
        "Polarization imaging applied to 3D reconstruction of specular metallic surfaces",
        "ESL: Event-based structure light",
        "Diederik Paul Moeys, and Davide Scaramuzza. Event guided depth sensing",
        "Shape and light directions from shading and polarization",
        "PolarM polarization camera",
        "Lucid Vision Phoenix polarization camera",
        "Breakthrough Photography X4 Polarizer",
        "A QVGA 143 dB dynamic range frame-free PWM image sensor with lossless pixel-level video compression and timedomain CDS",
        "Prophesee Evaluation Kits",
        "Reconstruction of specular surfaces using polarization imaging",
        "ESIM: an open event camera simulator",
        "High speed and high dynamic range video with an event camera",
        "U-net: Convolutional networks for biomedical image segmentation",
        "Instant dehazing of images using polarization",
        "Generalized mosaicing: polarization panorama",
        "Height-from-polarisation with unknown lighting or albedo",
        "Hyunsurk Ryu, and Yongin Park. A 1280x960 Dynamic Vision Sensor with a 4.95-?m pixel pitch and motion artifact minimization",
        "Time lens++: Event-based frame interpolation with parametric non-linear flow and multi-scale fusion",
        "Polarized opticalflow gyroscope",
        "Polarization vision: a new sensory approach to image understanding",
        "Polarization image demosaicking using polarization channel difference prior",
        "Deep shape from polarization",
        "Unsupervised event-based optical flow using motion compensation",
        "Depth from a polarisa-tion+ rgb stereo pair"
    ],
    "64bb03bb3fda6d7f06002e9f": [
        "SMT: Software-defined memory tiering for heterogeneous computing systems with CXL memory expander",
        "Gen-Z: Communication at the speed of memory",
        "Scaling of memory performance and capacity with CXL memory expander",
        "Compute Express Link",
        "Nimble page management for tiered memory systems",
        "MULTI-CLOCK: Dynamic tiering for hybrid memory systems",
        "Pond: CXL-based memory pooling systems for cloud platforms",
        "Exploring the design space of page management for multi-tiered memory systems",
        "TPP: Transparent page placement for CXL-enabled tiered-memory",
        "TMO: Transparent memory offloading in datacenters",
        "3D-Xpath: High-density managed dram architecture with cost-effective alternative paths for memory transactions",
        "SPECCPU2006 benchmark descriptions",
        "The gap benchmark suite"
    ],
    "64cc25d83fda6d7f063be43e": [
        "5-Level Paging and 5-Level EPT",
        "Zettalinux: It's not too late to start",
        "Volume I: User-Level ISA, Document Version 2.2",
        "A New Golden Age for Computer Architecture",
        "The amd \"zen 2\" processor",
        "Intel Alder Lake CPU Architectures",
        "Don't use the page number, but a pointer to it",
        "Revisiting clustered microarchitecture for future superscalar cores: A case for wide issue clusters",
        "Dynamic cluster assignment mechanisms",
        "None",
        "Polybench: The polyhedral benchmark suite",
        "Standard Performance Evaluation Corporation",
        "The load slice core microarchitecture",
        "The alpha 21264 microprocessor"
    ],
    "6449e7fc582c1376bbfc600e": [
        "EV-SegNet: Semantic segmentation for event-based cameras",
        "Time-ordered recent event (tore) volumes for event cameras",
        "Alhabib Abbas, Eirina Bourtsoulatze, and Yiannis Andreopoulos. Graph-based object classification for neuromorphic vision sensing",
        "Alhabib Abbas, Eirina Bourtsoulatze, and Yiannis Andreopoulos. Graph-based spatio-temporal feature learning for neuromorphic vision sensing",
        "A differentiable recurrent surface for asynchronous event-based data",
        "Pseudo-labels for supervised learning on dynamic vision sensor data, applied to object detection under ego-motion",
        "Exponential-wrapped distributions on symmetric spaces",
        "Visualization of the channels of ERGO-12, min-max normalized in the range 0-255. The channels are ordered in row-major order, and the hyperparameters selected are shown in the top left of each subfigure",
        "Object detection with spiking neural networks on automotive event data. Int. Joint Conf",
        "A large scale event-based detection dataset for automotive",
        "A voxel graph cnn for object classification with event cameras",
        "Pstnet: Point spatio-temporal convolution on point cloud sequences",
        "Event-based vision: A survey",
        "End-to-end learning of representations for asynchronous event-based data",
        "photometric feature tracking using events and frames",
        "Pushing the limits of asynchronous graph-based object detection with event cameras. arXiv",
        "Recurrent vision transformers for object detection with event cameras",
        "Deep residual learning for image recognition",
        "Gryffin: An algorithm for bayesian optimization of categorical variables informed by expert knowledge",
        "Towards event-driven object detection with off-the-shelf deep learning",
        "Mixed frame-/event-driven fast pedestrian detection",
        "N-imagenet: Towards robust, fine-grained object recognition with event cameras",
        "HOTS: A hierarchy of event-based time-surfaces for pattern recognition",
        "Training deep spiking neural networks using backpropagation",
        "Yolov6: A single-stage object detection framework for industrial applications",
        "Graph-based asynchronous event processing for rapid object recognition",
        "Focal loss for dense object detection",
        "Microsoft COCO: Common objects in context",
        "Ssd: Single shot multibox detector",
        "Swin transformer v2: Scaling up capacity and resolution",
        "Event-based vision meets deep learning on steering prediction for self-driving cars",
        "Event-based asynchronous sparse convolutional networks",
        "Moving object detection for event-based vision using graph spectral clustering",
        "ICCVW",
        "Stereo depth from events cameras: Concentrate and focus on the future",
        "HFirst: A temporal approach to object recognition",
        "Intrinsic Statistics on Riemannian Manifolds: Basic Tools for Geometric Measurements",
        "Mapping from frame-driven to frame-free event-driven vision systems by low-rate rate coding and coincidence processing-application to feedforward ConvNets",
        "Learning to detect objects with a 1 megapixel event camera",
        "Gromov-Wasserstein Averaging of Kernel and Distance Matrices",
        "Point-Net++: Deep hierarchical feature learning on point sets in a metric space",
        "High speed and high dynamic range video with an event camera",
        "You only look once: Unified, real-time object detection",
        "Accurate single stage detector using recurrent rolling convolution",
        "Riemannian gaussian distributions on the space of symmetric positive definite matrices",
        "AEGNN: Asynchronous event-based graph neural networks",
        "EventNet: Asynchronous recursive event processing",
        "HATS: Histograms of averaged time surfaces for robust event-based object classification",
        "Event-based high dynamic range image and very high frame rate video generation using conditional generative adversarial networks",
        "Feedforward categorization on AER motion events using cortex-like features in a spiking neural network",
        "EV-FlowNet: Self-supervised optical flow estimation for event-based cameras",
        "Unsupervised event-based learning of optical flow, depth, and egomotion"
    ],
    "6523793e939a5f4082e182a2": [
        "Efficient Virtual Memory for Big Memory Servers",
        "Performance Analysis of the Memory Management Unit Under Scale-out Workloads",
        "Translation Caching: Skip, Don't Walk (the Page Table)",
        "Linux. 5 Level Paging",
        "Contiguitas: the Pursuit of Physical Memory Contiguity in Datacenters",
        "Radiant: Efficient Page Table Management for Tiered Memory Systems",
        "Characterizing the TLB Behavior of Emerging Parallel Workloads On Chip Multiprocessors",
        "Devirtualizing Memory in Heterogeneous Systems",
        "Hash, Don't Cache (the Page Table)",
        "Performance ImplicatiOns of Extended Page Tables On Virtualized X86 Processors",
        "A Study of Virtual Memory Usage and Implications for Large Memory",
        "AMD-V Nested Paging",
        "Compute Engine: Enabling Nested Virtualization for VM Instances",
        "Shared Last-Level TLBs for Chip Multiprocessors",
        "Scalable Distributed Last-Level TLBs Using Low-Latency Interconnects",
        "Improving GPU Multi-tenancy with Page Walk Stealing",
        "RethInking TLB Designs in Virtualized Environments: A Very Large Part-of-Memory TLB",
        "CSALT: Context Switch Aware Large TLB",
        "Comparisons of Memory Virtualization Solutions for Architectures with Software-Managed TLBs",
        "Improving Virtualization in the Presence of Software Managed Translation Lookaside Buffers",
        "Design Tradeoffs for Software-Managed TLBs",
        "A Look At Several Memory Management Units, TLB-Refill Mechanisms, and Page Table OrganizAtions",
        "Software-Controlled Caches in the VMP Multiprocessor",
        "Design Tradeoffs for Software-managed TLBs",
        "Software Prefetching and Caching for Translation Lookaside Buffers",
        "CACTI 7.0: A Tool to Model Large Caches. HP laboratories",
        "Criticality Aware Tiered Cache Hierarchy: A Fundamental Relook At Multi-Level Cache Hierarchies",
        "Clearing the Clouds: A Study of Emerging Scale-Out Workloads On Modern Hardware",
        "Harvesting L2 Caches in Server Processors",
        "DAMOV: A New Methodology and Benchmark Suite for Evaluating Data Movement Bottlenecks",
        "Domain-specialized Cache Management for Graph Analytics",
        "Analysis and Optimization of the Memory Hierarchy for Graph Processing Workloads",
        "Many-Core Graph Workload Analysis",
        "Accelerating Long-Latency Load Requests Via Perceptron-Based Off-Chip Load Prediction",
        "Line Distillation: Increasing Cache Capacity By Filtering Unused Words in Cache Lines",
        "Adaptive Spill-Receive for Robust high-performance Caching in CMPs",
        "Adaptive Insertion Policies for High Performance Caching",
        "A Scalable Processing-in-Memory Accelerator for Parallel Graph Processing",
        "Stream-based Memory Access Specialization for General Purpose Processors",
        "The Dynamic Granularity Memory System",
        "The Linux Kernel",
        "Sniper: Exploring the Level of Abstraction for Scalable and Accurate Parallel Multi-Core Simulations",
        "Victima -Github Repository",
        "GraphBIG: Understanding Graph Computing in the Context of Industrial Solutions",
        "A Simple Synchronous Distributed-Memory Algorithm for the HPCC RandomAccess Benchmark",
        "XSBench -The Development and Verification of a Performance Abstraction for Monte Carlo Reactor Analysis",
        "Deep Learning Recommendation Model for Personalization and Recommendation Systems",
        "GenomicsBench: A Benchmark Suite for Genomics",
        "Agile Paging: Exceeding the Best of Nested and Shadow Paging",
        "Intel Raptor Lake",
        "Breaking the Address Translation Wall By Accelerating Memory Replays",
        "Self-Paging in the Nemesis Operating System",
        "Memory Coherence in Shared Virtual Memory Systems",
        "Virtual Memory Primitives for User Programs",
        "Machine-independent Virtual Memory Management for Paged Uniprocessor and Multiprocessor Architectures",
        "Lightweight Recoverable Virtual Memory",
        "Generic Virtual Memory Management for Operating System Kernels",
        "WSCLOCK -A Simple and Effective Algorithm for Virtual Memory Management",
        "CRAMM: Virtual Memory Support for Garbage-Collected Applications",
        "Virtual Memory",
        "Virtual Memory System",
        "Survey of Virtual Machine Research",
        "A Comparative Study of Set Associative Memory Mapping Algorithms and Their Use for Cache and Main Memory",
        "An In-Cache Address Translation Mechanism",
        "A Simulation Based Study of TLB Performance",
        "Architecture Support for Single Address Space Operating Systems",
        "The Grand Unified Theory of Address Spaces",
        "Virtual Memory in Contemporary Microprocessors",
        "AVM: Application-Level Virtual Memory",
        "Architectural Support for Translation Table Management in Large Address Space Machines",
        "The Interaction of Architecture and Operating System Design",
        "Introduction and Overview of the Multics System",
        "Intel? 64 and ia-32 architectures software developer's manual",
        "Arm Architecture Reference Manual for A-profile Architecture",
        "WikiChip. Intel Cascade Lake",
        "Trident: Harnessing Architectural Resources for All Page Sizes in X86 Processors",
        "Transparent Huge Pages in 2",
        "Practical, Transparent Operating System Support for Superpages",
        "Hawkeye: Efficient Fine-grained Os Support for Huge Pages",
        "Translation Ranger: Operating System Support for Contiguity-Aware TLBs",
        "Konstantinos Nikas, Georgios Goumas, and Nectarios Koziris. Enhancing and Exploiting Contiguity for Fast Memory Virtualization",
        "TMO: Transparent Memory Offloading in Datacenters",
        "Memtrade: Marketplace for Disaggregated Memory Clouds",
        "Software-Defined Far Memory in Warehouse-Scale Computers",
        "Elastic Cuckoo Page Tables: Rethinking Virtual Memory Translation for Parallelism",
        "Memory-Efficient Hashed Page Tables",
        "Every Walk's a Hit: Making Page Walks Single-Access Cache Hits",
        "Parallel Virtualized Memory Translation with Nested Elastic Cuckoo Page Tables",
        "Linux",
        "Graphfire: Synergizing Fetch, Insertion, and Replacement Policies for Graph Analytics",
        "High Performance Cache Replacement Using Re-Reference Interval Prediction (RRIP)",
        "Neural Networks: a Comprehensive Foundation",
        "Intel? 64 and ia-32 architectures software developer's manual volume 2a: Instruction set reference",
        "A Case Against (Most) Context Switches",
        "XPC: Architectural Support for Secure and Efficient Cross Process Call",
        "Latr: Lazy Translation Coherence",
        "None",
        "Stride Directed Prefetching in Scalar Processors",
        "Effective Hardware-based Data Prefetching for High-performance Processors",
        "Transparent Hugepage Support",
        "Compendia: Reducing Virtual-Memory Costs Via Selective Densification",
        "Rebooting Virtual Memory with Midgard",
        "CHiRP: Control-Flow History Reuse Prediction",
        "Prediction-Based Superpage-Friendly TLB Designs",
        "Reducing TLB Power Requirements",
        "Reducing TLB and Memory Overhead Using Online Superpage Promotion",
        "Compiler-directed Physical Address Generation for Reducing dTLB Power",
        "SpecTLB: A Mechanism for Speculative Address Translation",
        "SIPT: Speculatively Indexed, Physically Tagged Caches",
        "Concurrent Support of Multiple Page Sizes on a Skewed Associative TLB",
        "Exploiting Page Table Locality for Agile TLB Prefetching",
        "Morrigan: A Composite Instruction TLB Prefetcher",
        "None",
        "Going the Distance for TLB Prefetching: An Application-driven Study",
        "Recency-based TLB Preloading",
        "Large-Reach Memory Management Unit Caches",
        "Dead Page and Dead Block Predictors: Cleaning TLBs and Caches Together",
        "Exploiting Parallelization On Address Translation: Shared Page Walk Cache",
        "Pinning Page Structure Entries to Last-Level Cache for Fast Address Translation",
        "Address Translation Conscious Caching and Prefetching for High Performance Cache Hierarchy",
        "Devirtualizing Virtual Memory for Heterogeneous Systems",
        "Mosaic Pages: Big TLB Reach with Small Pages",
        "Utopia: Fast and Efficient Address Translation via Hybrid Flexible &amp; Restrictive Virtual-to-Physical Address Mappings",
        "Near-Memory Address Translation",
        "Accelerating Pointer Chasing in 3D-stacked Memory: Challenges, Mechanisms, Evaluation",
        "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines",
        "Do-It-Yourself Virtual Memory Translation",
        "Space Efficient Hash Tables with Worst Case Constant Access Time",
        "Perforated Page: Supporting Fragmented Memory Allocation for Large Pages",
        "Tailored Page Sizes",
        "Coordinated and Efficient Huge Page Management with Ingens",
        "Tradeoffs in Supporting Two Page Sizes",
        "Making Huge Pages Actually Useful",
        "Large Pages and Lightweight Memory Management in Virtualized Environments: Can You Have It Both Ways?",
        "Mosaic: A GPU Memory Manager with Application-Transparent Support for Multiple Page Sizes",
        "Reevaluating Online Superpage Promotion with Hardware Support",
        "Increasing TLB Reach Using Superpages Backed By Shadow Memory",
        "Supporting Superpages in Non-Contiguous Physical Memory",
        "Surpassing the TLB Performance of Superpages with Less Operating System Support",
        "Supporting Superpage Allocation Without Additional Hardware Support",
        "Predicting Execution Times with Partial Simulations in Virtual Memory Research: Why and How",
        "General Purpose Operating System Support for Multiple Page Sizes",
        "Energy-Efficient Address Translation",
        "Redundant Memory Mappings for Fast Access to Large Memories",
        "Hybrid TLB Coalescing: Improving TLB Translation Coverage Under Diverse Fragmented Memory Allocations",
        "FlexPointer: Fast Address TranslatiOn Based On Range TLB and Tagged Pointers",
        "Aamer Jaleel, and Abhishek Bhattacharjee. CoLT: Coalesced Large-Reach TLBs",
        "Efficient Memory Virtualization: Reducing Dimensionality of Nested Page Walks",
        "Using TLB Speculation to Overcome Page Splintering in Virtual Machines",
        "Accelerating Two-Dimensional Page Walks for Virtualized Systems",
        "Hardware Translation Coherence for Virtualized Systems",
        "BabelFish: Fusing Address Translations for Containers",
        "PTEMagnet: FIne-graIned Physical Memory Reservation for Faster Page Walks in Public Clouds",
        "Fast Local Page-tables for Virtualized Numa Servers with vmitosis",
        "A New Perspective for Efficient Virtual-Cache Coherence",
        "SEESAW: Using Superpages to Improve VIPT Caches",
        "Reducing Memory Reference Energy with Opportunistic Virtual Caching",
        "Virtual-Address Caches Part 1: Problems and Solutions in Uniprocessors",
        "Coherency for Multiprocessor Virtual Address Caches",
        "Consistency Management for Virtually Indexed Caches",
        "Organization and Performance of a Two-Level Virtual-Real Cache Hierarchy",
        "Enigma: Architectural and Operating System Support for Reducing the Impact of Address Translation",
        "The Virtual Block Interface: A Flexible Alternative to the Conventional Virtual Memory Framework",
        "PowerPC Architecture Book",
        "Virtual-Address Caches Part 2: Multiprocessor Issues",
        "Slurm: Simple Linux Utility for Resource Management"
    ],
    "64c78ba33fda6d7f06dbcb16": [
        "Runtime dependency analysis for loop pipelining in highlevel synthesis",
        "None",
        "Balanced graph partitioning",
        "Rabbit order: Just-in-time parallel reordering for fast graph analysis",
        "Legion: Expressing locality and independence with logical regions",
        "Dgcl: an efficient communication library for distributed gnn training",
        "Link prediction approach to collaborative filtering",
        "FastGCN: Fast learning with graph convolutional networks via importance sampling",
        "Criteo display ad challenge",
        "The university of florida sparse matrix collection",
        "Learning graph representations with embedding propagation",
        "Distributed deep graph learning at scale",
        "Graph embedding in vector spaces by node attribute statistics",
        "node2vec: Scalable feature learning for networks",
        "The architectural implications of facebook's dnn-based personalized recommendation",
        "Inductive representation learning on large graphs",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Improving the accuracy, scalability, and performance of graph neural networks with roc",
        "Graph classification and clustering based on vector space embedding",
        "Batch-aware unified memory management in gpus for irregular workloads",
        "Semi-supervised classification with graph convolutional networks",
        "Learning spectral graph transformations for link prediction",
        "SNAP Datasets: Stanford large network dataset collection",
        "Evaluating modern gpu interconnect: Pcie, nvlink, nv-sli, nvswitch and gpudirect",
        "Pagraph: Scaling gnn training on large graphs via computation-aware caching",
        "Neugraph: parallel deep neural network computation on large graphs",
        "Pytorch-direct: Enabling gpu centric data access for very large graph neural network training with irregular accesses",
        "Large graph convolutional network training with gpu-oriented data communication architecture",
        "Pipedream: generalized pipeline parallelism for dnn training",
        "Memory-efficient pipelineparallel dnn training",
        "Deep learning recommendation model for personalization and recommendation systems",
        "Cloudbank: Managed services to simplify cloud access for computer science research and education",
        "Dgx superpod",
        "Nvidia collective communication library (nccl",
        "Nvidia dgx a100",
        "Nvshmem communication library",
        "None",
        "Unified memory for cuda beginners",
        "Deepwalk: Online learning of social representations",
        "Optimization principles and application performance evaluation of a multithreaded gpu using cuda",
        "Peer-to-peer &amp; unified virtual addressing",
        "Towards time-aware link prediction in evolving social networks",
        "Graph attention networks",
        "Pipad: Pipelined and parallel dynamic gnn training on gpus",
        "Deep graph library: Towards efficient and scalable deep learning on graphs",
        "Gnnadvisor: An efficient runtime system for gnn acceleration on gpus",
        "El-rec: efficient large-scale recommendation model training via tensor-train embedding table",
        "Nvidia gpu micro-architecture",
        "How powerful are graph neural networks?",
        "Hygcn: A gcn accelerator with hybrid architecture",
        "Gnnlab: a factored system for sample-based gnn training over gpus",
        "Hierarchical graph representation learning with differentiable pooling",
        "Exploring the hidden dimension in graph processing",
        "Deep learning based recommender system: A survey and new perspectives",
        "Every document owns its structure: Inductive text classification via graph neural networks",
        "vpipe: A virtualized acceleration system for achieving efficient and scalable pipeline parallel dnn training",
        "Gemini: A computation-centric distributed graph processing system"
    ],
    "65260ee8cd549670787e1513": [
        "Nocaps: Novel object captioning at scale",
        "Flamingo: a visual language model for few-shot learning",
        "Vqa: Visual question answering",
        "Qwen-vl: A frontier large vision-language model with versatile abilities",
        "Evaluating vision-language models by language models",
        "Murel: Multimodal relational reasoning for visual question answering",
        "Shikra: Unleashing multimodal llm's referential dialogue magic",
        "A generalist framework for panoptic segmentation of images and videos",
        "A jointly-scaled multilingual language-image model",
        "On scaling up a multilingual vision and language model",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Universal captioner: Long-tail vision-and-language model training through content-style separation",
        "Instructblip: Towards general-purpose vision-language models with instruction tuning",
        "Cogview: Mastering text-to-image generation via transformers",
        "Palm-e: An embodied multimodal language model",
        "General language model pretraining with autoregressive blank infilling",
        "Matthew Honnibal and Mark Johnson. An improved non-monotonic transition system for dependency parsing",
        "Low-rank adaptation of large language models",
        "Scaling up vision-language pre-training for image captioning",
        "An analysis of visual question answering algorithms",
        "Referitgame: Referring to objects in photographs of natural scenes",
        "Openimages: A public dataset for large-scale multi-label and multi-class image classification",
        "Visual genome: Connecting language and vision using crowdsourced dense image annotations",
        "Blip-2: Bootstrapping languageimage pre-training with frozen image encoders and large language models",
        "Uninext: Exploring a unified architecture for vision recognition",
        "Microsoft coco: Common objects in context",
        "Aligning large multi-modal model with robust instruction tuning",
        "Visual instruction tuning",
        "Referring expression generation and comprehension via attributes",
        "Prismer: A vision-language model with an ensemble of experts",
        "Grounding dino: Marrying dino with grounded pre-training for open-set object detection",
        "None",
        "Unified-io: A unified model for vision, language, and multi-modal tasks",
        "Learn to explain: Multimodal reasoning via thought chains for science question answering",
        "Generation and comprehension of unambiguous object descriptions",
        "Ok-vqa: A visual question answering benchmark requiring external knowledge",
        "Ocr-vqa: Visual question answering by reading text in images",
        "Gpt-4 technical report",
        "Kosmos-2: Grounding multimodal large language models to the world",
        "Flickr30k entities: Collecting region-to-phrase correspondences for richer imageto-sentence models",
        "Glu variants improve transformer",
        "Answer them all! toward universal visual question answering models",
        "Textcaps: a dataset for image captioning with reading comprehension",
        "Towards vqa models that can read",
        "Eva-clip: Improved training techniques for clip at scale",
        "Llama 2: Open foundation and fine-tuned chat models",
        "Multimodal few-shot learning with frozen language models",
        "Git: A generative image-to-text transformer for vision and language",
        "Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework",
        "One-peace: Exploring one general representation model toward unlimited modalities",
        "Large language model is also an open-ended decoder for vision-centric tasks",
        "Image as a foreign language: Beit pretraining for all vision and vision-language tasks",
        "Simple visual language model pretraining with weak supervision",
        "mplug-docowl: Modularized multimodal large language model for document understanding",
        "Coca: Contrastive captioners are image-text foundation models",
        "Modeling context in referring expressions",
        "Glipv2: Unifying localization and visionlanguage understanding",
        "Revisiting visual representations in vision-language models",
        "Llavar: Enhanced visual instruction tuning for text-rich image understanding",
        "Minigpt-4: Enhancing vision-language understanding with advanced large language models",
        "Visual7w: Grounded question answering in images"
    ],
    "6503bec83fda6d7f067c7787": [
        "Case-based reasoning: Foundational issues, methodological variations, and system approaches",
        "Incontext examples selection for machine translation",
        "What learning algorithm is in-context learning? investigations with linear models",
        "None",
        "Language models are few-shot learners",
        "Alec Radford, Ilya Sutskever, and Dario Amodei. 2020b. Language models are few-shot learners",
        "Transformers generalize differently from information stored in context vs in weights",
        "UPRISE: universal prompt retrieval for improving zero-shot evaluation",
        "None",
        "Scaling instruction-finetuned language models",
        "Casebased reasoning for natural language queries over knowledge bases",
        "GoEmotions: A dataset of fine-grained emotions",
        "Incontext learning for few-shot dialogue state tracking",
        "Towards unsupervised dense information retrieval with contrastive learning",
        "SemEval-2023 task 10: Explainable detection of online sexism",
        "Reordering examples helps during priming-based few-shot learning",
        "The power of scale for parameter-efficient prompt tuning",
        "Unified demonstration retriever for incontext learning",
        "The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures",
        "The flan collection: Designing data and methods for effective instruction tuning",
        "Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity",
        "Dr.icl: Demonstration-retrieved in-context learning",
        "Z-ICL: Zero-shot in-context learning with pseudo-demonstrations",
        "Active learning principles for in-context learning with large language models",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "Synchromesh: Reliable code generation from pre-trained language models",
        "Learning to retrieve prompts for in-context learning",
        "XRICL: Cross-lingual retrieval-augmented incontext learning for cross-lingual text-to-SQL semantic parsing",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "An effective refinement strategy for KNN text classifier",
        "None",
        "Mis-classified vector guided softmax loss for face recognition",
        "Investigating the learning behaviour of in-context learning: A comparison with supervised learning",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "Larger language models do in-context learning differently",
        "An explanation of in-context learning as implicit bayesian inference",
        "Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer",
        "Ground-truth labels matter: A deeper look into input-label demonstrations",
        "Active example selection for in-context learning",
        "2021a. Calibrate before use: Improving few-shot performance of language models",
        "2021b. Calibrate before use: Improving few-shot performance of language models"
    ],
    "645dad16d68f896efad9df53": [
        "Coremltools: Use coremltools to convert machine learning models from third-party libraries to the core ml format",
        "Layer normalization. arXiv",
        "Open neural network exchange",
        "Are we done with imagenet? arXiv preprint",
        "Glit: Neural architecture search for global and local image transformer",
        "Mmdetection: Open mmlab detection toolbox and benchmark",
        "Autoformer: Searching transformers for visual recognition",
        "Auto-scaling vision transformers without training",
        "Mobileformer: Bridging mobilenet and transformer",
        "Xception: Deep learning with depthwise separable convolutions",
        "Rethinking attention with performers",
        "Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search",
        "Learning augmentation strategies from data",
        "Coatnet: Marrying convolution and attention for all data sizes",
        "Flashattention: Fast and memoryefficient exact attention with io-awareness",
        "The efficiency misnomer",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Yuandong Tian, qiang liu, and Vikas Chandra. NASVit: Neural architecture search for efficient vision transformers with gradient conflict aware supernet training",
        "Levit: a vision transformer in convnet's clothing for faster inference",
        "Towards memoryefficient neural networks via multi-level in situ generation",
        "Single path one-shot neural architecture search with uniform sampling",
        "Ghostnet: More features from cheap operations",
        "Ghostnets on heterogeneous devices via cheap operations",
        "Gaussian error linear units (gelus). arXiv",
        "Searching for mobilenetv3",
        "Mobilenets: Efficient convolutional neural networks for mobile vision applications",
        "Transformer quality in linear time",
        "Towards light-weight convolutionfree vision transformers",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Data movement is all you need: A case study on optimizing transformers",
        "Characterizing co-located workloads in alibaba cloud datacenters",
        "An optimized dataflow for mitigating attention performance bottlenecks",
        "Reformer: The efficient transformer",
        "3d object representations for fine-grained categorization",
        "Learning multiple layers of features from tiny images",
        "Imagenet classification with deep convolutional neural networks",
        "Optimal brain damage. NeurIPS",
        "Ds-net++: Dynamic weight slicing for efficient inference in cnns and vision transformers",
        "Efficientformer: Vision transformers at mobilenet speed",
        "Focal loss for dense object detection",
        "Microsoft coco: Common objects in context",
        "Swin transformer v2: Scaling up capacity and resolution",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Rethinking the value of network pruning",
        "Decoupled weight decay regularization",
        "Towards lightweight transformer via group-wise transformation for vision-and-language tasks",
        "Shufflenet v2: Practical guidelines for efficient cnn architecture design",
        "Edgenext: efficiently amalgamated cnn-transformer architecture for mobile vision applications",
        "Mobilevit: Lightweight, general-purpose, and mobile-friendly vision transformer",
        "Separable selfattention for mobile vision transformers",
        "Are sixteen heads really better than one? NeurIPS",
        "Importance estimation for neural network pruning",
        "Rectified linear units improve restricted boltzmann machines",
        "A visual vocabulary for flower classification",
        "Edgevits: Competing light-weight cnns on mobile devices with vision transformers",
        "Fast vision transformers with hilo attention",
        "Cats and dogs",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Designing network design spaces",
        "Combiner: Full attention transformer with sparse computation cost",
        "Scaling vision with sparse mixture of experts",
        "Mobilenetv2: Inverted residuals and linear bottlenecks",
        "Rethinking the inception architecture for computer vision",
        "Improving the efficiency of transformers for resource-constrained devices",
        "Mnasnet: Platform-aware neural architecture search for mobile",
        "Efficientnet: Rethinking model scaling for convolutional neural networks",
        "Mixed depthwise convolutional kernels",
        "Training data-efficient image transformers &amp; distillation through attention",
        "Oncel Tuzel, and Anurag Ranjan. An improved one millisecond mobile backbone",
        "Attention is all you need",
        "Swirl: High-performance many-core cpu code generation for deep neural networks",
        "Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned",
        "Linformer: Self-attention with linear complexity",
        "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
        "Pvtv2: Improved baselines with pyramid vision transformer",
        "Pytorch image models",
        "Tinyvit: Fast pretraining distillation for small vision transformers",
        "Pale transformer: A general vision transformer backbone with pale-shaped attention",
        "Early convolutions help transformers see better",
        "Lite vision transformer with enhanced self-attention",
        "Nvit: Vision transformer compression and parameter redistribution",
        "Metaformer is actually what you need for vision",
        "Tokensto-token vit: Training vision transformers from scratch on imagenet",
        "mixup: Beyond empirical risk minimization",
        "Minivit: Compressing vision transformers with weight multiplexing",
        "Shufflenet: An extremely efficient convolutional neural network for mobile devices",
        "Random erasing data augmentation",
        "Learning transferable architectures for scalable image recognition"
    ],
    "64dbf5883fda6d7f060c36fd": [
        "Aws step functions",
        "Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider",
        "Peeking behind the curtains of serverless platforms",
        "Characterizing serverless platforms with serverlessbench",
        "Sequence clock: A dynamic resource orchestrator for serverless architectures",
        "AQUATOPE: QoS-anduncertainty-aware resource management for multi-stage serverless workflows",
        "Heracles: Improving resource efficiency at scale",
        "ReTail: Opting for learning simplicity to enable QoS-aware power management in the cloud",
        "Gemini: Learning to manage cpu power for latency-critical search engines",
        "Rubik: Fast analytical power management for latency-critical systems",
        "Tackling performance variability due to RAS mechanisms with PID-controlled DVFS",
        "Dark silicon aware power management for manycore systems under dynamic workloads",
        "Coordinated, distributed, formal energy management of chip multiprocessors",
        "DPM: Dynamic power management for the microsecond era",
        "RAPL: Memory power estimation and capping",
        "SeBS: A serverless benchmark suite for function-as-a-service computing",
        "WISEFUSE: Workload characterization and DAG transformation for serverless workflows"
    ],
    "62ea18d35aee126c0fca1369": [
        "ETC: Encoding long and structured inputs in transformers",
        "Qampari: : An open-domain question answering benchmark for questions with many answers from multiple paragraphs",
        "Longformer: The long-document transformer",
        "Language models are few-shot learners",
        "Summscreen: A dataset for abstractive screenplay summarization",
        "Rethinking attention with performers",
        "None",
        "Sliding selector network with dynamic memory for extractive summarization of long documents",
        "A dataset of information-seeking questions and answers anchored in research papers",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "A practical survey on faster and lighter transformers",
        "Efficiently modeling long sequences with structured state spaces",
        "Longt5: Efficient textto-text transformer for long sequences",
        "Diagonal state spaces are as effective as structured state spaces",
        "GMAT: Global memory augmentation for transformers",
        "Array programming with NumPy",
        "Efficient attentions for long document summarization",
        "Leveraging passage retrieval with generative models for open domain question answering",
        "Avoiding reasoning shortcuts: Adversarial evaluation, training, and model development for multi-hop QA",
        "Reformer: The efficient transformer",
        "Reformer: The efficient transformer",
        "The NarrativeQA reading comprehension challenge",
        "ContractNLI: A dataset for document-level natural language inference for contracts",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Sylvain Gugger, Cl?ment Delangue, Th?o Matussi?re, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran?ois Lagunas, Alexander Rush, and Thomas Wolf. 2021. Datasets: A community library for natural language processing",
        "ROUGE: A package for automatic evaluation of summaries",
        "Linear unified nested attention",
        "Data Structures for Statistical Computing in Python",
        "Long range language modeling via gated state spaces",
        "None",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Scikitlearn: Machine learning in Python",
        "Random feature attention",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SQuAD: 100,000+ questions for machine comprehension of text",
        "Efficient contentbased sparse attention with routing transformers",
        "Scrolls: Standardized comparison over long language sequences",
        "2022a. Scaling laws vs model architectures: How does inductive bias influence scaling?",
        "Long range arena : A benchmark for efficient transformers",
        "None",
        "2022b. Unifying language learning paradigms",
        "Attention is all you need",
        "Nature Methods",
        "Linformer: Selfattention with linear complexity",
        "Multipassage BERT: A globally normalized BERT model for open-domain question answering",
        "Transformers: Stateof-the-art natural language processing",
        "Simple local attentions remain competitive for long-context tasks",
        "Simple local attentions remain competitive for longcontext tasks",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "Modeling multi-hop question answering as single sequence prediction",
        "Big bird: Transformers for longer sequences",
        "Big bird: Transformers for longer sequences",
        "QMSum: A new benchmark for query-based multi-domain meeting summarization"
    ],
    "64ec1b763fda6d7f0626f480": [
        "ETC: Encoding long and structured inputs in transformers",
        "Solving rubik's cube with a robot hand",
        "Longformer: The long-document transformer",
        "Unlimiformer: Longrange transformers with unlimited length input",
        "TicketTalk: Toward humanlevel performance with end-to-end, transaction-based dialog systems",
        "Rethinking attention with performers",
        "A discourse-aware attention model for abstractive summarization of long documents",
        "The locality principle. Commun",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings",
        "Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model",
        "Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model",
        "A practical survey on faster and lighter transformers",
        "A large-scale multi-document summarization dataset from the Wikipedia current events portal",
        "Recurrent chunking mechanisms for long-text machine reading comprehension",
        "Gmat: Global memory augmentation for transformers",
        "CTRLsum: Towards generic controllable text summarization",
        "Dyne: Dynamic ensemble decoding for multi-document summarization",
        "Toward controlled generation of text",
        "Efficient attentions for long document summarization",
        "Efficient Long-Text Understanding with Short-Text Models",
        "A natural policy gradient. Advances in neural information processing systems",
        "Improved natural language generation via loss truncation",
        "Karthikeyan Natesan Ramamurthy, Payel Das, and Siva Reddy. 2023. The impact of positional encoding on length generalization in transformers",
        "Reformer: The efficient transformer",
        "Spying on your neighbors: Fine-grained probing of contextual embeddings for information about surrounding words",
        "Actor-critic algorithms",
        "The NarrativeQA Reading Comprehension Challenge",
        "Natural Questions: A Benchmark for Question Answering Research",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Leveraging graph to improve abstractive multi-document summarization",
        "ROUGE: A package for automatic evaluation of summaries",
        "Leveraging locality in abstractive text summarization",
        "Multi-document summarization via deep learning techniques: A survey",
        "Linear unified nested attention",
        "DYLE: Dynamic latent extraction for abstractive long-input summarization",
        "On faithfulness and factuality in abstractive summarization",
        "Discriminative marginalized probabilistic neural method for multi-document summarization of medical literature",
        "Abstractive text summarization using sequence-to-sequence RNNs and beyond",
        "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
        "Contrastive learning for many-to-many multilingual neural machine translation",
        "QuALITY: Question answering with long input texts, yes",
        "A multi-document coverage reward for relaxed multi-document summarization",
        "Efficiently summarizing text and graph encodings of multi-document clusters",
        "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "Random feature attention",
        "Investigating efficiently extending transformers for long input summarization",
        "Exploring controllable text generation techniques",
        "Is reinforcement learning (not) for natural language processing: Benchmarks, baselines, and building blocks for natural language policy optimization",
        "Efficient Content-Based Sparse Attention with Routing Transformers",
        "A neural attention model for abstractive sentence summarization",
        "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
        "Highdimensional continuous control using generalized advantage estimation",
        "Proximal policy optimization algorithms",
        "SCROLLS: Standardized CompaRison over long language sequences",
        "Videobert: A joint model for video and language representation learning",
        "Patient knowledge distillation for bert model compression",
        "Scaling laws vs model architectures: How does inductive bias influence scaling?",
        "Grandmaster level in starcraft ii using multi-agent reinforcement learning",
        "Linformer: Self-attention with linear complexity",
        "Sequenceto-sequence learning as beam-search optimization",
        "Transformers: State-of-the-art natural language processing",
        "Transformers and the Representation of Biomedical Background Knowledge",
        "PRIMERA: Pyramid-based masked sentence pre-training for multi-document summarization",
        "Simple local attentions remain competitive for long-context tasks",
        "2019a. End-to-end open-domain question answering with BERTserini",
        "Reducing word omission errors in neural machine translation: A contrastive learning approach",
        "Bartscore: Evaluating generated text as text generation",
        "Big bird: Transformers for longer sequences",
        "PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization",
        "Bertscore: Evaluating text generation with bert",
        "Summ n : A multi-stage summarization framework for long input dialogues and documents"
    ],
    "636482d790e50fcafdccab10": [
        "Deep learning for computer vision: A brief review",
        "Deep convolutional neural networks for image classification: A comprehensive review",
        "Neural machine translation by jointly learning to align and translate",
        "Google's neural machine translation system: Bridging the gap between human and machine translation",
        "Speech recognition using deep neural networks: A systematic review",
        "Deep speech: Scaling up endto-end speech recognition",
        "Threat of adversarial attacks on deep learning in computer vision: A survey",
        "A survey on adversarial attacks and defences",
        "Intriguing properties of neural networks",
        "Explaining and harnessing adversarial examples",
        "Towards deep learning models resistant to adversarial attacks",
        "Adversarial examples in the physical world",
        "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
        "Practical black-box attacks against machine learning",
        "Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models",
        "Practical black-box attacks against machine learning",
        "Black-box generation of adversarial text sequences to evade deep learning classifiers",
        "Mlaas: Machine learning as a service",
        "Knockoff nets: Stealing functionality of black-box models",
        "Black-box ripper: Copying black-box models using generative evolutionary algorithms",
        "Towards datafree model stealing in a hard label setting",
        "Maze: Data-free model stealing attack using zeroth-order gradient estimation",
        "Data-free model extraction",
        "Dast: Data-free substitute training for adversarial attacks",
        "Ten Lectures on Wavelets. Society for Industrial and Applied Mathematics",
        "Highfrequency component helps explain the generalization of convolutional neural networks",
        "Distilling the knowledge in a neural network",
        "Ideal spatial adaptation by wavelet shrinkage",
        "De-noising by soft-thresholding",
        "Image compression using wavelet transform and multiresolution decomposition",
        "Image compression using wavelets and jpeg2000: a tutorial",
        "Performance analysis of image compression using wavelets",
        "Signal processing and compression with wavelet packets",
        "Medical image enhancement algorithm based on wavelet transform",
        "Joint exact histogram specification and image enhancement through the wavelet transform",
        "Microarray image enhancement by denoising using stationary wavelet transform",
        "Combination of contrast limited adaptive histogram equalisation and discrete wavelet transform for image enhancement",
        "Wavecnet: Wavelet integrated cnns to suppress aliasing effect for noiserobust image classification",
        "Defending against adversarial iris examples usingwavelet decomposition",
        "Deflecting adversarial attacks with pixel deflection",
        "Image super-resolution as a defense against adversarial attacks",
        "Defending black box facial recognition classifiers against adversarial attacks",
        "The haar wavelet transform: its status and achievements",
        "Orthonormal bases of compactly supported wavelets",
        "Biorthogonal bases of compactly supported wavelets",
        "U-net: Convolutional networks for biomedical image segmentation",
        "Learning multiple layers of features from tiny images",
        "Reading digits in natural images with unsupervised feature learning",
        "Adversarial examples in the physical world",
        "Towards deep learning models resistant to adversarial attacks",
        "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
        "Imagenet classification with deep convolutional neural networks",
        "Deep residual learning for image recognition",
        "Ten lectures on wavelets",
        "Fast wavelet transforms and numerical algorithms i",
        "Biorthogonal bases of compactly supported wavelets",
        "U-net: Convolutional networks for biomedical image segmentation",
        "A fourier perspective on model robustness in computer vision"
    ],
    "62c4fd9a5aee126c0fad6f58": [
        "Semantic Diversity Learning for Zero-Shot Multi-Label Classification",
        "Emerging Properties in Self-Supervised Vision Transformers",
        "UNITER: Learning UNiversal Image-TExt Representations",
        "Multi-Label Image Recognition With Graph Convolutional Networks",
        "MlTr: Multi-label Classification with Transformer",
        "NUS-WIDE: A Real-World Web Image Database from National University of Singapore",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR 2021: The Ninth International Conference on Learning Representations",
        "Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model",
        "Deep Convolutional Ranking for Multilabel Image Annotation",
        "Openvocabulary Object Detection via Vision and Language Knowledge Distillation",
        "Distilling the knowledge in a neural network",
        "A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning",
        "Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling",
        "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision",
        "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision",
        "Learning to detect unseen object classes by between-class attribute transfer",
        "Attribute-Based Classification for Zero-Shot Visual Object Categorization",
        "General Multi-label Image Classification with Transformers",
        "Multi-Label Zero-Shot Learning With Structured Knowledge Graphs",
        "Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training",
        "Conditional Graphical Lasso for Multi-Label Image Classification",
        "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Query2Label: A Simple Transformer Way to Multi-Label Classification",
        "GPT Understands, Too",
        "Roberta: A robustly optimized bert pretraining approach",
        "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks",
        "Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language Knowledge Distillation",
        "Distributed Representations of Words and Phrases and their Compositionality",
        "Discriminative Region-Based Multi-Label Zero-Shot Learning",
        "We Don't Need No Bounding-Boxes: Training Object Class Detectors Using Only Human Verification",
        "Glove: Global Vectors for Word Representation",
        "Learning Transferable Visual Models From Natural Language Supervision",
        "Language models are unsupervised multitask learners",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Classifier chains for multi-label classification",
        "ImageNet Large Scale Visual Recognition Challenge",
        "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "Learning From Noisy Large-Scale Datasets With Minimal Supervision",
        "Learning From Noisy Large-Scale Datasets With Minimal Supervision",
        "CNN-RNN: A Unified Framework for Multi-Label Image Classification",
        "Multi-Label Image Recognition by Recurrently Discovering Attentional Regions",
        "Zero-Shot Learning -the Good, the Bad and the Ugly",
        "Open-Vocabulary DETR with Conditional Matching",
        "Open-Vocabulary Object Detection Using Captions",
        "Fast Zero-Shot Image Tagging",
        "Zero-Shot Learning via Semantic Similarity Embedding",
        "Learning to Prompt for Vision-Language Models",
        "Learning Spatial Regularization With Image-Level Supervisions for Multi-Label Image Classification"
    ],
    "65123f453fda6d7f06e54a4b": [
        "Vlmo: Unified vision-language pre-training with mixture-of-modality-experts",
        "Translating embeddings for modeling multi-relational data",
        "Food-101-mining discriminative components with random forests",
        "Language models are few-shot learners",
        "Emerging properties in self-supervised vision transformers",
        "Plot: Prompt learning with optimal transport for vision-language models",
        "Knowledge graph transfer network for few-shot recognition",
        "Learning semantic-specific graph representation for multi-label image recognition",
        "Knowledge-embedded routing network for scene graph generation",
        "Debiasing vision-language models via biased prompts",
        "Describing textures in the wild",
        "Imagenet: A large-scale hierarchical image database",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Hypergraph pre-training with graph neural networks",
        "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories",
        "Clip-adapter: Better vision-language models with feature adapters",
        "Finetune like you pretrain: Improved finetuning of zero-shot vision models",
        "Deep residual learning for image recognition",
        "Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification",
        "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "Natural adversarial examples",
        "Parameter-efficient transfer learning for nlp",
        "Unsupervised prompt learning for vision-language models",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "Multi-modal prompt learning",
        "Semi-supervised classification with graph convolutional networks",
        "3d object representations for fine-grained categorization",
        "Ablating concepts in text-to-image diffusion models",
        "Multi-concept customization of text-to-image diffusion",
        "Graph learning regularization and transfer learning for few-shot event detection",
        "Visualbert: A simple and performant baseline for vision and language",
        "Graph signal processing, graph neural network and graph learning on biological data: a systematic review",
        "Few-shot real image restoration via distortionrelation guided transfer learning",
        "Scaling &amp; shifting your features: A new baseline for efficient model tuning",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Swin transformer: Hierarchical vision transformer using shifted windows",
        "Prompt generation networks for efficient adaptation of frozen vision transformers",
        "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
        "Prompt distribution learning",
        "Prediction calibration for generalized few-shot semantic segmentation",
        "Fine-grained visual classification of aircraft",
        "A survey on visual transfer learning using knowledge graphs",
        "Glide: Towards photorealistic image generation and editing with text-guided diffusion models",
        "Automated flower classification over a large number of classes",
        "Svl-adapter: Self-supervised adapter for vision-language pretrained models",
        "Cats and dogs",
        "Styleclip: Text-driven manipulation of stylegan imagery",
        "Learning transferable visual models from natural language supervision",
        "Hierarchical text-conditional image generation with clip latents",
        "Denseclip: Languageguided dense prediction with context-aware prompting",
        "Do imagenet classifiers generalize to imagenet",
        "Stochastic graph as a model for social networks",
        "High-resolution image synthesis with latent diffusion models",
        "Continual diffusion: Continual customization of text-to-image diffusion with c-lora",
        "Testtime prompt tuning for zero-shot generalization in vision-language models",
        "Ucf101: A dataset of 101 human actions classes from videos in the wild",
        "Vl-bert: Pre-training of generic visual-linguistic representations",
        "Vl-adapter: Parameter-efficient transfer learning for visionand-language tasks",
        "Learning cross-modality encoder representations from transformers",
        "Motionclip: Exposing human motion generation to clip space",
        "Learning robust global representations by penalizing local predictive power",
        "Actionclip: A new paradigm for video action recognition",
        "Clip-guided prototype modulating for few-shot action recognition",
        "Simvlm: Simple visual language model pretraining with weak supervision",
        "Vita-clip: Video and text adaptive clip via multimodal prompting",
        "Hierarchical relational learning for few-shot knowledge graph completion",
        "Sun database: Large-scale scene recognition from abbey to zoo",
        "One-shot relational learning for knowledge graphs",
        "Dmh-fsl: Dual-modal hypergraph for few-shot learning",
        "Task residual for tuning vision-language models",
        "Vision-language models for vision tasks: A survey",
        "Vinvl: Revisiting visual representations in vision-language models",
        "Prompt, generate, then cache: Cascade of foundation models makes strong few-shot learners",
        "Tip-adapter: Trainingfree adaption of clip for few-shot classification",
        "Prompting through prototype: A prototype-based prompt learning on pretrained vision-language models",
        "Conditional prompt learning for vision-language models",
        "Learning to prompt for vision-language models",
        "Not all features matter: Enhancing few-shot clip with adaptive prior refinement"
    ],
    "6531e2ca939a5f4082f5d5d2": [
        "Simultaneous multithreading: Maximizing on-chip parallelism",
        "Marvell thunderx3: Nextgeneration arm-based server processor",
        "A top-down method for performance analysis and counters architecture",
        "Symbiotic job scheduling on the ibm power8",
        "Improving ibm power8 performance through symbiotic job scheduling",
        "Article:Processors (Global Market)",
        "Symbiotic jobscheduling for simultaneous multithreading processor",
        "Thread to core assignment in SMT on-chip multiprocessors",
        "Architectural support for enhanced SMT job scheduling",
        "L1-bandwidth aware thread allocation in multicore smt processors",
        "Smt-centric power-aware thread placement in chip multiprocessors",
        "Optimal task assignment in multithreaded processors: A statistical approach",
        "Hy-sched: A simple hyperthreading-aware thread to core allocation strategy",
        "Methods for modeling resource contention on simultaneous multithreading processors",
        "Probabilistic Job Symbiosis Modeling for SMT Processor Scheduling",
        "A performance counter architecture for computing accurate CPI components",
        "Per-thread cycle accounting in SMT processors",
        "SMiTe: Precise QoS prediction on real-system SMT processors to improve utilization in warehouse scale computers",
        "Multi-stage cpi stacks",
        "Armv8.1-m performance monitoring user guide",
        "Maximum matching and a polyhedron with 0, 1-vertices",
        "ThunderX2 CN9975 -Cavium",
        "Vulcan -Microarchitectures -Cavium",
        "System-level performance metrics for multiprogram workloads"
    ],
    "6514e2043fda6d7f062dc9f8": [
        "Cm3: A causal masked multimodal model of the internet",
        "Scaling laws for generative mixed-modal language models",
        "Generative adversarial networks for extreme learned image compression",
        "High quality monocular depth estimation via transfer learning",
        "vq-wav2vec: Self-supervised learning of discrete speech representations",
        "End-to-end optimized image compression",
        "Beit: Bert pre-training of image transformers",
        "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "JAX: composable transformations of Python+NumPy programs",
        "End-to-end object detection with transformers",
        "Masked generative image transformer",
        "Text-to-image generation via masked generative transformers",
        "Learned image compression with discretized gaussian mixture likelihoods and attention modules",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Diffusion models beat gans on image synthesis",
        "ADM TensorFlow Suite",
        "Jukebox: A generative model for music",
        "Image compression with product quantized masked image modeling",
        "Taming transformers for high-resolution image synthesis. 2021 ieee",
        "Vector quantization",
        "Not all image regions matter: Masked vector quantization for autoregressive image generation",
        "Straightening out the straightthrough estimator: Overcoming optimization challenges in vector quantized networks",
        "Magvlt: Masked generative visionand-language transformer",
        "Uvim: A unified modeling approach for vision with learned guiding codes",
        "None",
        "Robust training of vector quantized bottleneck models",
        "Autoregressive image generation using residual quantization",
        "Masked generative encoder to unify representation learning and image synthesis",
        "An algorithm for vector quantizer design",
        "Dvc: An end-to-end deep video compression framework",
        "Conditional probability models for deep image compression",
        "High-fidelity generative image compression",
        "Eirikur Agustsson, and Michael Tschannen. M2t: Masking transformers twice for faster decoding",
        "Joint autoregressive and hierarchical priors for learned image compression",
        "Theory and experiments on vector quantized autoencoders",
        "Assessing generative models via precision and recall",
        "Sq-vae: Variational bayes on discrete representation with self-annealed stochastic quantization",
        "Lossy image compression with compressive autoencoders",
        "Deep generative models for distributionpreserving lossy compression",
        "Neural discrete representation learning",
        "Phenaki: Variable length video generation from open domain textual descriptions",
        "Hierarchical quantized autoencoders",
        "Vector-quantized image modeling with improved vqgan",
        "Soundstream: An end-to-end neural audio codec"
    ],
    "6531e2ca939a5f4082f5d4fe": [
        "Heterogeneous graph neural networks analysis: a survey of techniques, evaluations and applications",
        "COMET: commonsense transformers for automatic knowledge graph construction",
        "Language models are few-shot learners",
        "Node feature extraction by selfsupervised multi-scale neighborhood prediction",
        "A survey on network embedding",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "GLM: general language model pretraining with autoregressive blank infilling",
        "MAGNN: metapath aggregated graph neural network for heterogeneous graph embedding",
        "node2vec: Scalable feature learning for networks",
        "Inductive representation learning on large graphs",
        "Lightgcn: Simplifying and powering graph convolution network for recommendation",
        "Tapas: Weakly supervised table parsing via pre-training",
        "An attentionbased graph neural network for heterogeneous structural learning",
        "Open graph benchmark: Datasets for machine learning on graphs",
        "Heterogeneous graph transformer",
        "2023a. Edgeformers: Graph-empowered transformers for representation learning on textual-edge networks",
        "Heterformer: A transformer architecture for node representation learning on heterogeneous text-rich networks",
        "Heterformer: Transformer-based deep node representation learning on heterogeneous text-rich networks",
        "Semisupervised classification with graph convolutional networks",
        "ALBERT: A lite BERT for self-supervised learning of language representations",
        "The inductive bias of in-context learning: Rethinking pretraining example design",
        "Adsgnn: Behavior-graph augmented relevance modeling in sponsored search",
        "OAG-BERT: towards a unified backbone language model for academic knowledge services",
        "Roberta: A robustly optimized BERT pretraining approach",
        "Decoupled weight decay regularization",
        "Are we really making much progress?: Revisiting, benchmarking and refining heterogeneous graph neural networks",
        "Distributed representations of words and phrases and their compositionality",
        "Improving relevance modeling via heterogeneous behavior graph learning in bing ads",
        "Improving language understanding by generative pre-training",
        "Modeling relational data with graph convolutional networks",
        "Discovering hypernymy in text-rich heterogeneous information network by exploiting context granularity",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Attention is all you need",
        "Item recommendation on monotonic behavior chains",
        "Fine-grained spoiler detection from large-scale review corpora",
        "Neural graph collaborative filtering",
        "Should you mask 15% in masked language modeling?",
        "Graphformers: Gnn-nested transformers for representation learning on textual graph",
        "Xlnet: Generalized autoregressive pretraining for language understanding",
        "Linkbert: Pretraining language models with document links",
        "Hybrid micro/macro level convolution for heterogeneous graph learning",
        "Heterogeneous graph representation learning with relation awareness",
        "Heterogeneous graph neural network",
        "Textgnn: Improving text encoder via graph neural network in sponsored search"
    ],
    "65252d90939a5f40827eabe7": [
        "Language models are few-shot learners",
        "Training a better alpaca with fewer data",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Scaling instruction-finetuned language models",
        "Think you have solved question answering? try arc, the ai2 reasoning challenge",
        "Efficient finetuning of quantized llms",
        "Alpacafarm: A simulation framework for methods that learn from human feedback",
        "The algorithmic foundations of differential privacy",
        "A framework for few-shot language model evaluation",
        "Measuring massive multitask language understanding",
        "On the reliability of watermarks for large language models",
        "Robust optimization as data augmentation for large-scale graphs",
        "Platypus: Quick, cheap, and powerful refinement of llms",
        "Contrastive decoding: Open-ended text generation as optimization",
        "ROUGE: A package for automatic evaluation of summaries",
        "TruthfulQA: Measuring how models mimic human falsehoods",
        "Text-only training for image captioning using noise-injected clip",
        "Introducing chatgpt",
        "Training language models to follow instructions with human feedback",
        "Bleu: a method for automatic evaluation of machine translation",
        "Multitask prompted training enables zero-shot task generalization",
        "None",
        "Stanford alpaca: An instruction-following llama model",
        "Open and efficient foundation language models",
        "Llama 2: Open foundation and fine-tuned chat models",
        "Self-instruct: Aligning language model with self generated instructions",
        "Finetuned language models are zero-shot learners",
        "Empowering large language models to follow complex instructions",
        "Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization",
        "HellaSwag: Can a machine really finish your sentence?",
        "Opt: Open pre-trained transformer language models",
        "Freelb: Enhanced adversarial training for natural language understanding",
        "mental illness can be difficult to treat, especially in the late 19th century when medical knowledge was limited. Despite his success, it's unlikely that Van Gogh's struggles with depression and anxiety would have disappeared. In fact, they may have intensified due to the added pressure and expectations placed upon him by society and his peers",
        "whether or not Van Gogh became a successful artist during his lifetime wouldn't necessarily change the impact he made on modern art history. His work has endured through countless exhibitions, books, films, and reproductions, cementing his legacy as one of the most influential painters of all time. AlpacaEval (1st) Instruction: What are the names of some famous actors that",
        "Richard Gere 10",
        "Al Pacino -He made his stage debut in 1967's \"Does a Tiger Wear a Necktie?",
        "She began her career on Broadway in 1975 with the play \"Julia,\" followed by roles in \"Lost in Yonkers\" (1991), \"A Little Night Music\" (2009) and \"Three Tall Women",
        "James Earl Jones -The actor first appeared on Broadway in 1957's \"The Long Dream,\" going on to star in numerous plays and musicals throughout his career, including \"Of Mice and Men",
        "He made his Broadway debut in 1985's \"A Funny Thing Happened on the Way to the Forum",
        "The singer-actress got her start on Broadway in 1965's \"Fiddler on the Roof,\" later earning critical acclaim for her performances in \"Forbidden Planet"
    ],
    "626b49625aee126c0fffd149": [
        "Guitarset: A dataset for guitar transcription",
        "Guitar tablature estimation with a convolutional neural network",
        "Enabling factorized piano music modeling and generation with the MAESTRO dataset",
        "Onsets and frames: Dual-objective piano transcription",
        "Sequence-to-sequence piano transcription with transformers",
        "MT3: multi-task multitrack music transcription",
        "Maps -a piano database for multipitch estimation and automatic transcription of music",
        "Learning features of music from scratch",
        "Multi-instrument automatic music transcription with self-attention-based instance segmentation",
        "Polyphonic music transcription with semantic segmentation",
        "Reconvat: A semi-supervised automatic music transcription framework for low-resource real-world data",
        "Simultaneous separation and transcription of mixtures with multiple polyphonic and percussive instruments",
        "Escaping from the abyss of manual annotation: New methodology of building polyphonic datasets for automatic music transcription",
        "Creating a musical performance dataset for multimodal music analysis: Challenges, insights, and applications",
        "Virtual adversarial training: A regularization method for supervised and semi-supervised learning",
        "Dynamic time warping",
        "Invariances and data augmentation for supervised music transcription",
        "Highresolution piano transcription with pedals by regressing onset and offset times",
        "Midi dataset"
    ],
    "62a6aabf5aee126c0ff36991": [
        "On the Bottleneck of Graph Neural Networks and its Practical Implications",
        "Scaling Graph Neural Networks with Approximate Pagerank",
        "Spectral Networks and Locally Connected Networks on Graphs",
        "Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks From the Topological View",
        "FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling",
        "Scalable Graph Neural Networks via Bidirectional Propagation",
        "Simple and Deep Graph Convolutional Networks",
        "Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks",
        "Adaptive Universal Generalized PageRank Graph Neural Network",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "An Image is Worth 16x16 Words: Transformers for Image",
        "A Generalization of Transformer Networks to Graphs",
        "Graph Neural Networks for Social Recommendation",
        "GRAND+: Scalable Graph Random Neural Networks",
        "Graph Random Neural Networks for Semi-supervised Learning on Graphs",
        "Diffusion Improves Graph Learning",
        "Neural Message Passing for Quantum Chemistry",
        "Inductive Representation Learning on Large Graphs",
        "Representing Long-Range Context for Graph Neural Networks with Global Attention",
        "Graph Convolutional Networks Meet Markov Random Fields: Semi-supervised Community Detection in Attribute Networks",
        "Node Similarity Preserving Graph Convolutional Networks",
        "Semi-supervised Classification with Graph Convolutional Networks",
        "Predict then Propagate: Graph Neural Networks meet Personalized PageRank",
        "Rethinking Graph Transformers with Spectral Attention",
        "Roberta: A robustly optimized bert pretraining approach",
        "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
        "Decoupled Weight Decay Regularization",
        "Transformer for Graphs: An Overview from Architecture Perspective",
        "Query-driven Active Surveying for Collective Classification",
        "Self-Supervised Graph Transformer on Large-Scale Molecular Data",
        "Pitfalls of Graph Neural Network Evaluation. Relational Representation Learning Workshop",
        "Attention Is All You Need",
        "Graph Attention Networks",
        "A Tutorial on Spectral Clustering",
        "On Layer Normalization in the Transformer Architecture",
        "How Powerful Are Graph Neural Networks",
        "Do Transformers Really Perform Badly for Graph Representation",
        "Graph Convolutional Neural Networks for Web-scale Recommender Systems",
        "GraphSAINT: Graph Sampling Based Inductive Learning Method",
        "Link Prediction Based on Graph Neural Networks",
        "An End-to-End Deep Learning Architecture for Graph Classification",
        "Gophormer: Ego-Graph Transformer for Node Classification",
        "Layerdependent Importance Sampling for Training Deep and Large Graph Convolutional Networks"
    ],
    "6535d747939a5f408295c3c4": [
        "Constitutional AI: Harmlessness from AI Feedback",
        "Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs",
        "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks",
        "GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking",
        "Graph-based Molecular Representation Learning",
        "Inductive Representation Learning on Large Graphs",
        "Explanations as Features: LLM-Based Features for Text-Attributed Graphs. CoRR abs/2305",
        "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation",
        "GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner",
        "Graphmae: Self-supervised masked graph autoencoders",
        "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "Gpt-gnn: Generative pre-training of graph neural networks",
        "Heterogeneous Graph Transformer",
        "Hdmi: High-order deep multiplex infomax",
        "Semi-Supervised Classification with Graph Convolutional Networks",
        "Large Language Models are Zero-Shot Reasoners",
        "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback",
        "Graph communal contrastive learning",
        "Training Graph Neural Networks with 1000 Layers",
        "Resource-Efficient Training for Large Graph Convolutional Networks with Label-Centric Cumulative Sampling",
        "None",
        "Graph self-supervised learning: A survey",
        "Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery",
        "Graphprompt: Unifying pre-training and downstream tasks for graph neural networks",
        "Meta-Weight Graph Neural Network: Push the Limits Beyond Global Homophily",
        "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
        "Training language models to follow instructions with human feedback",
        "Learning Transferable Visual Models From Natural Language Supervision",
        "Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting",
        "Distilling Reasoning Capabilities into Smaller Language Models",
        "Gppt: Graph pre-training and prompt tuning to generalize graph neural networks",
        "All in One: Multi-Task Prompting for Graph Neural Networks",
        "2023. S2GAE: Self-Supervised Graph Autoencoders are Generalizable Learners with Graph Masking",
        "LLaMA: Open and Efficient Foundation Language Models",
        "Llama 2: Open Foundation and Fine-Tuned Chat Models",
        "Attention is all you need",
        "Graph Attention Networks",
        "Deep Graph Infomax. In ICLR (Poster). OpenReview.net",
        "Microsoft Academic Graph: When experts are not enough",
        "Learning Intents behind Interactions with Knowledge Graph for Recommendation",
        "Heterogeneous Graph Attention Network",
        "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources",
        "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
        "Emergent Abilities of Large Language Models",
        "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
        "Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting",
        "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion",
        "NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification",
        "Simgrace: A simple framework for graph contrastive learning without data augmentation",
        "Automated Self-Supervised Learning for Recommendation",
        "Baichuan 2: Open Large-scale Language Models",
        "Geometric Knowledge Distillation: Topology Compression for Graph Neural Networks",
        "Dual space graph contrastive learning",
        "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
        "Autogcl: Automated graph contrastive learning via learnable view generators",
        "Graph contrastive learning automated",
        "Graph contrastive learning with augmentations",
        "Graph Transformer Networks",
        "Graph transformer networks",
        "GLM-130B: An Open Bilingual Pre-trained Model",
        "Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation",
        "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer",
        "Robust Self-Supervised Structural Graph Neural Network for Social Network Prediction",
        "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
        "Graph contrastive learning with adaptive augmentation"
    ],
    "6503bec83fda6d7f067c7717": [
        "Avocodo: Generative adversarial network for artifact-free vocoder",
        "Hifisinger: Towards high-fidelity neural singing voice synthesis",
        "Beyond words: Using nonverbal communication data in research to enhance thick description and interpretation",
        "Ddsp: Differentiable digital signal processing",
        "Fastdiff: A fast conditional diffusion model for high-quality speech synthesis",
        "The lj speech dataset",
        "Introducing parselmouth: A python interface to praat",
        "Universal melgan: A robust neural vocoder for high-fidelity waveform generation in multiple domains",
        "Univnet: A neural vocoder with multi-resolution spectrogram discriminators for highfidelity waveform generation",
        "Maskcycleganvc: Learning non-parallel voice conversion with filling in frames",
        "Istftnet: Fast and lightweight mel-spectrogram vocoder incorporating inverse short-time fourier transform",
        "Alias-free generative adversarial networks",
        "Fre-gan: Adversarial frequency-consistent audio synthesis",
        "Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis",
        "Diffwave: A versatile diffusion model for audio synthesis",
        "Melgan: Generative adversarial networks for conditional waveform synthesis",
        "Bigvgan: A universal neural vocoder with large-scale training",
        "Creating a multitrack classical music performance dataset for multimodal music analysis: Challenges, insights, and applications",
        "Hooligan: Robust, high quality neural vocoding",
        "Differentiable world synthesizer-based neural vocoder with application to end-to-end audio style transfer",
        "Portaspeech: Portable and high-quality generative text-to-speech",
        "Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs",
        "An algorithm for intelligibility prediction of time-frequency weighted noisy speech",
        "Opencpop: A high-quality open source chinese popular song corpus for singing voice synthesis",
        "Parallel wavegan: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram",
        "Gan vocoder: Multi-resolution discriminator is all you need",
        "Neural networks fail to learn periodic functions and how to fix it"
    ],
    "6303504190e50fcafd769fe6": [
        "The UEA multivariate time series classification archive",
        "Correlative Channel-Aware Fusion for Multi-View Time Series Classification",
        "Learning a symbolic representation for multivariate time series classification",
        "Xgboost: A scalable tree boosting system",
        "ROCKET: exceptionally fast and accurate time series classification using random convolutional kernels",
        "MINIROCKET: A very fast (almost) deterministic transform for time series classification",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Learning Discriminative Virtual Sequences for Time Series Classification",
        "Support vector regression machines",
        "UCI Machine Learning Repository",
        "Time-Series Representation Learning via Temporal and Contextual Contrasting",
        "Deep learning for time series classification: a review",
        "Inceptiontime: Finding alexnet for time series classification",
        "Unsupervised scalable representation learning for multivariate time series",
        "Towards automatic spatial verification of sensor placement in buildings",
        "Efficient learning of timeseries shapelets",
        "Explainable Multivariate Time Series Classification: A Deep Neural Network Which Learns to Attend to Important Variables As Well As Time Intervals",
        "Multivariate LSTM-FCNs for time series classification",
        "Learnable Dynamic Temporal Pooling for Time Series Classification",
        "Shapenet: A shapelet-neural network approach for multivariate time series classification",
        "Robust unsupervised anomaly detection via multi-time scale DCGANs with forgetting mechanism for industrial multivariate time series",
        "Joint-Label Learning by Dual Augmentation for Time Series Classification",
        "Adversarial dynamic shapelet networks",
        "Multivariate time series classification with WEASEL+ MUSE",
        "On the nontrivial generalization of dynamic time warping to the multi-dimensional case",
        "Random forest: a classification and regression tool for compound classification and QSAR modeling",
        "Monash university, uea, ucr time series regression archive",
        "Unsupervised representation learning for time series with temporal neighborhood coding",
        "Attention is all you need",
        "Time series classification from scratch with deep neural networks: A strong baseline",
        "Fast time series classification using numerosity reduction",
        "Voice2series: Reprogramming acoustic models for time series classification",
        "Time series shapelets: a new primitive for data mining",
        "Muvan: A multi-view attention network for multivariate temporal data",
        "TS2Vec: Towards Universal Representation of Time Series",
        "Learning Timestamp-Level Representations for Time Series with Hierarchical Contrastive Loss",
        "Dhaval Patel, Anuradha Bhamidipaty, and Carsten Eickhoff",
        "A Transformer-based Framework for Multivariate Time Series Representation Learning",
        "Tapnet: Multivariate time series classification with attentional prototypical network",
        "Time series classification using multi-channels deep convolutional neural networks"
    ],
    "6364c0ba90e50fcafdbb4aad": [
        "The 1st data prefetching championship (dpc-1)",
        "The 2nd data prefetching championship (dpc-2)",
        "Micron dram power calculator",
        "Cloudsuite traces for champsim",
        "SunnyCove microarhcitecture",
        "SunnyCove microarhcitecture latency",
        "The 3rd data prefetching championship (dpc-3)",
        "SPEC CPU 2017 traces for champsim",
        "ChampSim simulator",
        "GAP traces for champsim",
        "Abs: A low-cost adaptive controller for prefetching in a banked shared last-level cache",
        "Domino temporal data prefetcher",
        "Bingo spatial data prefetcher",
        "The GAP benchmark suite",
        "Pythia: A customizable hardware prefetching framework using online reinforcement learning",
        "Dspatch: Dual spatial pattern prefetcher",
        "Perceptron-based prefetch filtering",
        "Leaking control flow information via the hardware prefetcher",
        "DDR standards",
        "Inside intel core microarchitecture and smart memory access",
        "Coordinated control of multiple prefetchers in multi-core systems",
        "Clearing the clouds: A study of emerging scale-out workloads on modern hardware",
        "The microarchitecture of Intel, AMD and VIA CPUs: An optimization guide for assembly programmers and compiler makers",
        "Evolution of the samsung exynos cpu microarchitecture",
        "Learning memory access patterns",
        "Near-side prefetch throttling: Adaptive prefetching for high-performance many-core processors",
        "Tcp: Tag correlating prefetchers",
        "Effective stream-based and execution-based data prefetching",
        "Exploiting long-term behavior for improved memory system performance",
        "Linearizing irregular memory accesses for improved correlated prefetching",
        "High performance cache replacement using re-reference interval prediction (rrip)",
        "Dynamic branch prediction with perceptrons",
        "Prefetching using markov predictors",
        "Instruction criticality based energy-efficient hardware data prefetching",
        "Path confidence based lookahead prefetching",
        "Kill the program counter: Reconstructing program behavior in the processor cache hierarchy",
        "Cacti-p: Architecture-level modeling for sram-based structures with advanced leakage reduction techniques",
        "Best-offset hardware prefetching",
        "An analysis of address and branch patterns with patternfinder",
        "Bouquet of instruction pointers: Instruction pointer classifier-based spatial hardware prefetching",
        "Expert prefetch prediction: An expert predicting the usefulness of hardware prefetchers",
        "SPAC: A synergistic prefetcher aggressiveness controller for multi-core systems",
        "CAFFEINE: A utilitydriven prefetcher aggressiveness engine for multicores",
        "Multilevel adaptive prefetching based on performance gradient tracking",
        "Fetch directed instruction prefetching",
        "Berti: A per-page best-request-time delta prefetcher",
        "A cost-effective entangling prefetcher for instructions",
        "Multi-lookahead offset prefetching",
        "Automatically characterizing large scale program behavior",
        "Efficiently prefetching complex address patterns",
        "A hierarchical neural model of data prefetching",
        "Spatio-temporal memory streaming",
        "Spatial memory streaming",
        "Feedback directed prefetching: Improving the performance and bandwidth-efficiency of hardware prefetchers",
        "Standard Performance Evaluation Corporation",
        "Address re-ordering mechanism for efficient pre-fetch training in an out-of-order processor",
        "RCTP: Region correlated temporal prefetcher",
        "Temporal prefetching without the off-chip metadata",
        "Efficient metadata management for irregular data prefetching",
        "Timing local streams: improving timeliness in data prefetching"
    ],
    "63dcdb422c26941cf00b6339": [
        "Neuro-symbolic language modeling with automaton-augmented retrieval",
        "Neural machine translation by jointly learning to align and translate",
        "Improving language models by retrieving from trillions of tokens",
        "Skeleton-toresponse: Dialogue generation guided by retrieval memory",
        "Retrieval-guided dialogue response generation via a matching-to-generation framework",
        "Neural machine translation with monolingual translation memory",
        "Transformer-XL: Attentive language models beyond a fixed-length context",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Realm: Retrievalaugmented language model pre-training",
        "A retrieve-and-edit framework for predicting structured outputs",
        "Efficient nearest neighbor language models",
        "The curious case of neural text degeneration",
        "Billion-scale similarity search with GPUs",
        "Dense passage retrieval for open-domain question answering",
        "Generalization through memorization: Nearest neighbor language models",
        "Six challenges for neural machine translation",
        "Rankgen: Improving text generation with large ranking models",
        "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
        "Exploring dense retrieval for dialogue response selection",
        "Learning dense representations of phrases at scale",
        "Ankur Parikh, Dipanjan Das, and Jonathan Berant. Learning recurrent span representations for extractive question answering",
        "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "A survey on retrieval-augmented text generation",
        "Pointer sentinel mixture models",
        "Nonparametric masked language modeling",
        "Mauve: Measuring the gap between neural text and human text using divergence frontiers",
        "Language models are unsupervised multitask learners",
        "The probabilistic relevance framework: Bm25 and beyond",
        "Get to the point: Summarization with pointer-generator networks",
        "Neural machine translation of rare words with subword units",
        "Phraseindexed question answering: A new challenge for scalable document comprehension",
        "Effidit: Your ai writing assistant",
        "A contrastive framework for neural text generation",
        "Sequence to sequence learning with neural networks",
        "Attention is all you need",
        "Neural text generation with unlikelihood training",
        "Retrieve and refine: Improved sequence generation models for dialogue",
        "Transformers: State-of-the-art natural language processing",
        "Response generation by context-aware prototype editing",
        "Inference with reference: Lossless acceleration of large language models, 2023. A DATASET STATISTICS The experiments in this paper include three benchmarks",
        "The statistics of these benchmarks are shown in Table 7. En-Wiki corpus is used for the enlarged phrase index settings"
    ],
    "65364bdf939a5f40822568b2": [
        "Noah Fiedel, Romal Thoppilan, ..., and Illia Polosukhin. 2020. Towards a human-like opendomain chatbot",
        "Learning representations by maximizing mutual information across views",
        "Exploring simple siamese representation learning",
        "Learning transferable user representations with sequential behaviors via contrastive pretraining",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Unified language model pre-training for natural language understanding and generation",
        "Exploiting behavioral consistence for universal user representation",
        "Pinner-Former: Sequence Modeling for User Representation at Pinterest",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "One4all user representation for recommender systems in e-commerce",
        "R?nyi divergence and Kullback-Leibler divergence",
        "Attention is All you Need",
        "Attention is all you need",
        "UserBERT: Pretraining User Model with Contrastive Self-supervision",
        "PTUM: Pre-training User Model from Unlabeled User Behaviors via Self-supervision",
        "Unsupervised embedding learning via invariant and spreading instance feature",
        "Large Scale Purchase Prediction with Historical User Actions on B2C Online Retail Platform",
        "RESETBERT4Rec: A pre-training model integrating time and user historical behavior for sequential recommendation",
        "Stock constrained recommendation in tmall"
    ],
    "623184035aee126c0f4848ed": [
        "Some experiments on the perception of synthetic speech sounds",
        "Perception of the speech code",
        "The search for invariant acoustic correlates of phonetic features",
        "Representations of pitch and timbre variation in human auditory cortex",
        "A Course in Phonetics",
        "Static, dynamic, and relational properties in vowel perception",
        "From understanding computation to understanding neural circuitry",
        "Processing interactions and lexical access during word recognition in continuous speech",
        "The TRACE model of speech perception",
        "Estimating spatio-temporal receptive fields of auditory and visual neurons from their responses to natural stimuli",
        "Selective cortical representation of attended speaker in multi-talker speech perception",
        "Emergence of neural encoding of auditory objects while listening to competing speakers",
        "Deep Speech 2: end-to-end speech recognition in English and Mandarin",
        "wav2vec 2.0: a framework for self-supervised learning of speech representations",
        "HuBERT: self-supervised speech representation learning by masked prediction of hidden units",
        "Deep neural networks rival the representation of primate IT cortex for core visual object recognition",
        "A task-optimized neural network replicates human auditory behavior, predicts brain responses, and reveals a cortical processing hierarchy",
        "Inductive biases, pretraining and fine-tuning jointly account for brain responses to speech",
        "Performance-optimized hierarchical models predict neural responses in higher visual cortex",
        "On the relationship between maps and domains in inferotemporal cortex",
        "Using goal-driven deep learning models to understand sensory cortex",
        "How does the brain solve visual object recognition?",
        "Attention is all you need",
        "At 6-9 months, human infants know the meanings of many common nouns",
        "Learning words' sounds before learning how words sound: 9-month-olds use distinct objects as cues to categorize speech information",
        "Unsupervised neural network models of the ventral visual stream",
        "The neural architecture of language: integrative modeling converges on predictive processing",
        "Interpreting and improving naturallanguage processing (in machines) with natural languageprocessing (in the brain)",
        "Self-supervised learning: generative or contrastive",
        "Natural speech reveals the semantic maps that tile human cerebral cortex",
        "Updated parameters and expanded simulation options for a model of the auditory periphery",
        "Speech coding in the brain: representation of vowel formants by midbrain neurons tuned to sound fluctuations",
        "Effects of peripheral tuning on the auditory nerve's representation of speech envelope and temporal fine structure cues",
        "Parallel and distributed encoding of speech across human auditory cortex",
        "Network rhythms influence the relationship between spike-triggered local field potential and functional connectivity",
        "DARPA TIMIT acoustic-phonetic continuous speech corpus CD-ROM. NIST speech disc 1-1.1. NASA STI/Recon Tech",
        "LibriSpeech: an ASR corpus based on public domain audio books",
        "A spatial map of onset and sustained responses to speech in the human superior temporal gyrus",
        "Human cortical encoding of pitch in tonal and non-tonal languages",
        "Predicting human brain activity associated with the meanings of nouns",
        "Ultra-fine frequency tuning revealed in single neurons of human auditory cortex",
        "Phonetic feature encoding in human superior temporal gyrus",
        "Spectro-temporal modulation transfer function of single voxels in the human auditory cortex measured with high-resolution fMRI",
        "A cross-linguistic fMRI study of spectral and temporal cues underlying phonological processing",
        "A cross-linguistic PET study of tone perception in Mandarin Chinese and English speakers",
        "A speech envelope landmark for syllable encoding in human superior temporal gyrus",
        "Intonational speech prosody encoding in the human auditory cortex",
        "Understanding rostral-caudal auditory cortex contributions to auditory perception",
        "Dynamic speech representations in the human temporal lobe",
        "The encoding of speech sounds in the superior temporal gyrus",
        "The cortical organization of speech processing",
        "Dynamic encoding of speech sequence probability in human temporal cortex",
        "Speech computations of the human superior temporal gyrus",
        "Nonlinear auditory models yield new insights into representations of vowels",
        "Shared computational principles for language processing in humans and deep language models",
        "Deep learning",
        "On the computational architecture of the neocortex: II. The role of cortico-cortical loops",
        "The organization and physiology of the auditory thalamus and its role in processing acoustic features important for speech perception",
        "Multisensory convergence in auditory cortex: II. Thalamocortical connections of the caudal superior temporal plane",
        "Thalamic connections of the core auditory cortex and rostral supratemporal plane in the macaque monkey",
        "Speech perception, rapid temporal processing, and the left hemisphere: a case study of unilateral pure word deafness",
        "Subdivisions of auditory cortex and processing streams in primates",
        "Single-cell activity in human STG during perception of phonemes is organized according to manner of articulation",
        "Deep neural network models of sensory systems: windows onto the role of task constraints",
        "Brain-optimized extraction of complex sound features that drive continuous auditory perception",
        "Estimating and interpreting nonlinear receptive field of sensory neural responses with deep neural network models",
        "Latent neural dynamics encode temporal context in speech",
        "Speech corpus of Chinese discourse and the phonetic research",
        "Semi-automated anatomical labeling and inter-subject warping of high-density intracranial recording electrodes in electrocorticography",
        "Speak and unSpeak with PRAAT",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "MAGICDATA Mandarin Chinese read speech corpus",
        "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
        "Convex and semi-nonnegative matrix factorizations",
        "Heschl's gyrus (yellow), planum temporale (blue), planum polare (green). The numbers of significant speech responsive electrodes in each subject, sorted into anatomical areas"
    ],
    "656d3a42939a5f4082629226": [
        "Flamingo: a visual language model for few-shot learning",
        "Palm 2 technical report",
        "Openflamingo: An opensource framework for training large autoregressive visionlanguage models",
        "Qwen-vl: frontier large vision-language model with versatile abilities",
        "Humans predict liquid dynamics using probabilistic simulation",
        "Fully-convolutional siamese networks for object tracking",
        "Token merging: Your vit but faster",
        "Language models are few-shot learners. Advances in neural information processing systems",
        "Shikra: Unleashing multimodal llm's referential dialogue magic",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Transformers predicting the future. applying attention in next-frame and time series forecasting",
        "Sportsmot: A large multi-object tracking dataset in multiple sports scenes",
        "Instructblip: Towards generalpurpose vision-language models with instruction tuning",
        "Atom: Accurate tracking by overlap maximization",
        "Pre-training of deep bidirectional transformers for language understanding",
        "Mevis: A large-scale benchmark for video segmentation with motion expressions",
        "Synergistic multimodal comprehension and creation",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Lasot: A high-quality benchmark for large-scale single object tracking",
        "The free-energy principle: a unified brain theory?",
        "Planting a seed of vision in large language model",
        "Multimodal-gpt: A vision and language model for dialogue with humans",
        "Inductive biases for deep learning of higher-level cognition",
        "Vizwiz grand challenge: Answering visual questions from blind people",
        "Vizwiz grand challenge: Answering visual questions from blind people",
        "Masked autoencoders are scalable vision learners",
        "Got-10k: A large high-diversity benchmark for generic object tracking in the wild",
        "Language is not all you need: Aligning perception with language models",
        "Gqa: A new dataset for real-world visual reasoning and compositional question answering",
        "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
        "Identifying natural images from human brain activity",
        "Referitgame: Referring to objects in photographs of natural scenes",
        "Generating images with multimodal language models",
        "The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale. International",
        "Obelics: An open web-scale filtered dataset of interleaved image-text documents",
        "SiamRPN++: Evolution of siamese visual tracking with very deep networks",
        "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models",
        "Multisports: A multi-person video dataset of spatio-temporally localized sports actions",
        "Evaluating object hallucination in large vision-language models",
        "Improved baselines with visual instruction tuning",
        "Improved baselines with visual instruction tuning",
        "Visual instruction tuning",
        "Is your multi-modal model an all-around player? arXiv preprint",
        "Sgdr: Stochastic gradient descent with warm restarts",
        "Decoupled weight decay regularization",
        "Titan: Future forecast using action priors",
        "A benchmark for multi-object tracking",
        "None",
        "OpenAI. Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Detect what you need via reasoning",
        "Language models are unsupervised multitask learners",
        "Learning transferable visual models from natural language supervision",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "A system in the human brain for predicting the actions of others",
        "Tokenlearner: What can 8 learned tokens do for images and videos?",
        "Neural theory-of-mind? on the limits of social intelligence in large lms",
        "Laion-400m: Open dataset of clip-filtered 400 million image-text pairs",
        "A benchmark for detecting human in a crowd",
        "Objects365: A large-scale, high-quality dataset for object detection",
        "Objects365: A large-scale, high-quality dataset for object detection",
        "Very deep convolutional networks for large-scale image recognition",
        "Sompt22: A surveillance oriented multi-pedestrian tracking dataset",
        "Towards vqa models that can read",
        "Dancetrack: Multi-object tracking in uniform appearance and diverse motion",
        "Stanford alpaca: An instruction-following llama model",
        "Llama: Open and efficient foundation language models",
        "Llama 2: Open foundation and fine-tuned chat models",
        "Large language models fail on trivial alterations to theory-of-mind tasks",
        "Emergent abilities of large language models",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "Star: A benchmark for situated reasoning in real-world videos",
        "Siamfc++: Towards robust and accurate visual tracking with target estimation guidelines",
        "Videogpt: Video generation using vq-vae and transformers",
        "mplug-owl: Modularization empowers large language models with multimodality",
        "Bdd100k: A diverse driving dataset for heterogeneous multitask learning",
        "Mm-vet: Evaluating large multimodal models for integrated capabilities",
        "From recognition to cognition: Visual commonsense reasoning",
        "Glm-130b: An open bilingual pre-trained model",
        "Opt: Open pre-trained transformer language models",
        "Gpt4roi: Instruction tuning large language model on region-of-interest",
        "Bootstrapping multimodal llms via precise referring instruction tuning",
        "Bootstrapping multimodal llms via precise referring instruction tuning",
        "How far are large language models from agents with theory-of-mind?",
        "Minigpt-4: Enhancing vision-language understanding with advanced large language models"
    ],
    "6427029c90e50fcafd5d6bdb": [
        "FlatFlash: Exploiting the Byte-Accessibility of SSDs within a Unified Memory-Storage Hierarchy",
        "Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory Machines",
        "None",
        "Optimizing the TLB Shootdown Algorithm with Page Access Tracking",
        "Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism",
        "Analysts Predict SSD Prices May Halve by Mid-2023",
        "Amazon EC2 On-Demand Pricing",
        "SSDAlloc: Hybrid SSD/RAM Memory Management Made Easy",
        "2B-SSD: The Case for Dual, Byte-and Block-Addressable Solid-State Drives",
        "EC2 High Memory Update: New 18 TB and 24 TB Instances",
        "The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, ser. Synthesis Lectures on Computer Architecture",
        "Attack of the killer microseconds",
        "Efficient virtual memory for big memory servers",
        "IX: A Protected Dataplane Operating System for High Throughput and Low Latency",
        "Architectural and Operating System Support for Virtual Memory, ser. Synthesis Lectures on Computer Architecture",
        "InvisiFence: performance-transparent memory ordering in conventional multiprocessors",
        "Improved Multithreading Techniques for Hiding Communication Latency in Multiprocessors",
        "PARTIES: QoS-Aware Resource Partitioning for Multiple Interactive Services",
        "Taming the Killer Microsecond",
        "PCIe 5.0 is just beginning to come to new PCs, but version 6.0 is already here",
        "The tail at scale",
        "Reducing DRAM footprint with NVM in facebook",
        "Clearing the clouds: a study of emerging scale-out workloads on modern hardware",
        "Is SC + ILP=RC",
        "Accelerating Database Operations Using a Network Processor",
        "DFTL: a flash translation layer employing demand-based selective caching of page-level address mappings",
        "Rebooting Virtual Memory with Midgard",
        "Distributed Logless Atomic Durability with Persistent Memory",
        "Toward Dark Silicon in Servers",
        "Informing Memory Operations: Providing Memory Performance Feedback in Modern Processors",
        "Unified address translation for memory-mapped SSDs with FlashMap",
        "Efficient IO with io uring",
        "Memory Systems: Cache, DRAM, Disk",
        "DRAM price increases will ease",
        "Unison Cache: A Scalable and Effective Die-Stacked DRAM Cache",
        "Die-stacked DRAM caches for servers: hit ratio, latency, or bandwidth? have it all with footprint cache",
        "Why Latency Impacts SSD Performance More Than Bandwidth Does",
        "Exploiting Coroutines to Attack the \"Killer Nanoseconds",
        "Shinjuku: Preemptive Scheduling for ?second-scale Tail Latency",
        "Tailbench: a benchmark suite and evaluation methodology for latency-critical applications",
        "ReFlex: Remote Flash ? Local Flash",
        "Pocket: Elastic Ephemeral Storage for Serverless Analytics",
        "PageSeer: Using Page Walks to Trigger Page Swaps in Hybrid Memory Systems",
        "Reaping the performance of fast NVM storage with uDepot",
        "Meet the walkers: accelerating index traversals for in-memory databases",
        "LATR: Lazy Translation Coherence",
        "Hints for Computer System Design",
        "Architecting phase change memory as a scalable dram alternative",
        "A Case for Hardware-Based Demand Paging",
        "Asynchronous I/O Stack: A Low-latency Kernel I/O Stack for Ultra-Low Latency SSDs",
        "Efficiently enabling conventional block sizes for very large die-stacked DRAM caches",
        "Towards energy-proportional datacenter memory with mobile DRAM",
        "Enhancing Server Efficiency in the Face of Killer Microseconds",
        "Software-Controlled Multithreading Using Informing Memory Operations",
        "A Primer on Memory Consistency and Cache Coherence, Second Edition, ser. Synthesis Lectures on Computer Architecture",
        "Scaleout NUMA",
        "Fast crash recovery in RAMCloud",
        "QFlex",
        "Interleaving with coroutines: a systematic and practical approach to hide memory latency in index joins",
        "Arachne: Core-Aware Thread Management",
        "Tolerating Late Memory Traps in ILP Processors",
        "Fundamental Latency Trade-off in Architecting DRAM Caches: Outperforming Impractical SRAM-Tags with a Simple and Practical Design",
        "Scalable high performance main memory system using phase-change memory technology",
        "AIFM: High-Performance, Application-Integrated Far Memory",
        "Announcing the general availability of 6 and 12 TB VMs for SAP HANA instances on Google Cloud Platform",
        "Intel Skylake",
        "Knights Landing: Second-Generation Intel Xeon Phi Product",
        "Storage Performance Development Kit",
        "Memory Errors in Modern Systems: The Good, The Bad, and The Ugly",
        "Modern operating systems",
        "The context-switch overhead inflicted by hardware interrupts (and the enigma of do-nothing loops)",
        "Design guidelines for high-performance SCM hierarchies",
        "Memory systems and interconnects for scale-out servers",
        "Fat Caches for Scale-Out Servers",
        "Architecting a hardware-managed hybrid DIMM optimized for cost/performance",
        "Mechanisms for store-wait-free multiprocessors",
        "SimFlex: Statistical Sampling of Computer System Simulation",
        "ARM Cortex A76",
        "Tiny-Tail Flash: Near-Perfect Elimination of Garbage Collection Tail Latencies in NAND SSDs",
        "Translation ranger: operating system support for contiguity-aware TLBs"
    ],
    "64a29612d68f896efa28bc9c": [
        "Calculation of Our Inter-layer Space Size",
        "The Optimal Tile Allocation Algorithm",
        "Fusedlayer CNN accelerators",
        "None",
        "Apple A15 Bionic",
        "ARM Artisan",
        "Shortcut Mining: Exploiting Cross-Layer Shortcut Reuse in DCNN Accelerators",
        "None",
        "DianNao: A Small-Footprint High-Throughput Accelerator for Ubiquitous Machine-Learning",
        "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks",
        "Dual Path Networks",
        "DaDianNao: A Machine-Learning Supercomputer",
        "Eyeriss v2: A Flexible Accelerator for Emerging Deep Neural Networks on Mobile Devices",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "ShiDianNao: shifting vision processing closer to the sensor",
        "NeuFlow: A runtime reconfigurable dataflow processor for vision",
        "TETRIS: Scalable and Efficient Neural Network Acceleration with 3D Memory",
        "TANGRAM: Optimized Coarse-Grained Dataflow for Scalable NN Accelerators",
        "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
        "Deep Residual Learning for Image Recognition",
        "Mind mappings: enabling efficient algorithmaccelerator mapping space search",
        "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups",
        "Densely Connected Convolutional Networks",
        "CoSA: Scheduling by Constrained Optimization for Spatial Accelerators",
        "None",
        "None",
        "ISPD 2020 Physical Mapping of Neural Networks on a Wafer-Scale Deep Learning Accelerator",
        "Ten Lessons From Three Generations Shaped Google's TPUv4i : Industrial Product",
        "Proceedings of the 44th Annual International Symposium on Computer Architecture, ISCA 2017",
        "ConfuciuX: Autonomous Hardware Resource Assignment for DNN Accelerators using Reinforcement Learning",
        "GAMMA: Automating the HW Mapping of DNN Models on Accelerators via Genetic Algorithm",
        "Graphcore",
        "ImageNet Classification with Deep Convolutional Neural Networks",
        "Understanding Reuse, Performance, and Hardware Cost of DNN Dataflow: A Data-Centric Approach",
        "MAERI: Enabling Flexible Dataflow Mapping over DNN Accelerators via Reconfigurable Interconnects",
        "A Full HD 60 fps CNN Super Resolution Processor with Selective Caching based Layer Fusion for Mobile Devices",
        "Multi-Million Core, Multi-Wafer AI Cluster",
        "Progressive Neural Architecture Search",
        "TENET: A Framework for Modeling Tensor Dataflow Based on Relation-centric Notation",
        "NASA: Accelerating Neural Network Design with a NAS Processor",
        "A 28nm 12.1TOPS/W Dual-Mode CNN Processor Using Effective-Weight-Based Convolution and Error-Compensation-Based Prediction",
        "Google's Training Chips Revealed: TPUv2 and TPUv3",
        "NVDLA Deep Learning Accelerator",
        "Timeloop: A Systematic Approach to DNN Accelerator Evaluation",
        "SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks",
        "You Only Look Once: Unified, Real-Time Object Detection",
        "ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars",
        "Simba: Scaling Deep-Learning Inference with Multi-Chip-Module-Based Architecture",
        "PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning",
        "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
        "Going deeper with convolutions",
        "DOJO: The Microarchitecture of Tesla's Exa-Scale Computer",
        "NN-Baton: DNN Workload Orchestration and Chiplet Granularity Exploration for Multichip Accelerators",
        "Compute Substrate for Software 2.0",
        "Attention is All You Need",
        "MAGNet: A Modular Accelerator Generator for Neural Networks",
        "NASGuard: A Novel Accelerator Architecture for Robust Neural Architecture Search (NAS) Networks",
        "Spring Hill (NNP-I 1000) Intel's Data Center Inference Chip",
        "Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling",
        "HASCO: Towards Agile HArdware and Software CO-design for Tensor Computation",
        "Deep Learning Training At Scale Spring Crest Deep Learning Accelerator (Intel? Nervana? NNP-T)",
        "Interstellar: Using Halide's Scheduling Language to Analyze DNN Accelerators",
        "Atomic Dataflow based Graph-Level Workload Orchestration for Scalable DNN Accelerators",
        "Efficient Scheduling of Irregular Network Structures on CNN Accelerators",
        "COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning",
        "Scalable Multi-Chip-Module-Based Deep Neural Network Inference Accelerator With Ground-Referenced Signaling in 16 nm"
    ],
    "654f510b939a5f408289af51": [
        "GW4 Supercomputer Isambard",
        "Apple unveils M1 Ultra, the world's most powerful chip for a personal computer",
        "Nvidia's Grace CPU Superchip to power two supercomputers, up to ten \"ai exaflops",
        "None",
        "Europe steps up as RISC-V ships 10bn cores",
        "Apple announces the Apple Silicon M1: Ditching x86what to expect",
        "Automatic throughput and critical path analysis of x86 and arm assembly kernels",
        "Cloverleaf: Preparing hydrodynamics codes for exascale",
        "Memory Bandwidth and Machine Balance in Current High Performance Computers",
        "High performance in silico virtual drug screening on many-core processors",
        "MiniApps derived from production HPC applications using multiple programing models",
        "Nvidia, HPE announce Superchip-powered \"isambard 3\" supercomputer",
        "A performance analysis of modern parallel programming models using a compute-bound application"
    ],
    "646aecaad68f896efa05a6c5": [
        "Large language models and the perils of their hallucinations",
        "Gpt takes the bar exam",
        "Improving language models by retrieving from trillions of tokens",
        "Do as i can, not as i say: Grounding language in robotic affordances",
        "Language models are few-shot learners",
        "Sparks of artificial general intelligence: Early experiments with gpt-4",
        "None",
        "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
        "Scaling language modeling with pathways",
        "Training verifiers to solve math word problems",
        "Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models",
        "A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level",
        "Successive prompting for decomposing complex questions",
        "Gpts are gpts: An early look at the labor market impact potential of large language models",
        "What does it take for an infant to learn how to use a tool by observation?",
        "A survey on complex question answering over knowledge base: Recent advances and challenges",
        "Pal: Program-aided language models",
        "Retrieval augmented language model pre-training",
        "Solving math word problems by combining language models with symbolic solvers",
        "Parameter-efficient transfer learning for nlp",
        "Lora: Low-rank adaptation of large language models",
        "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
        "Inner monologue: Embodied reasoning through planning with language models",
        "Grounded decoding: Guiding text generation with grounded models for robot control",
        "Survey of hallucination in natural language generation",
        "Genegpt: Augmenting large language models with domain tools for improved access to biomedical information",
        "Kamel: Knowledge analysis with multitoken entities in language models",
        "Compacter: Efficient low-rank hypercomplex adapter layers",
        "Decomposed prompting: A modular approach for solving complex tasks",
        "A path towards autonomous machine intelligence version 0.9",
        "The power of scale for parameter-efficient prompt tuning",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Api-bank: A benchmark for tool-augmented llms",
        "Pre-trained language models for interactive decision-making",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Completing tasks by connecting foundation models with millions of apis",
        "Llm+ p: Empowering large language models with optimal planning proficiency",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks",
        "Chameleon: Plug-and-play compositional reasoning with large language models",
        "Faithful chain-of-thought reasoning",
        "Augmented language models: a survey",
        "Browser-assisted question-answering with human feedback",
        "OpenAI. Gpt-4 technical report",
        "Probabilistic reasoning over sets using large language models",
        "Automatic multi-step reasoning and tool-use for large language models",
        "Talm: Tool augmented language models",
        "Language models as knowledge bases? arXiv preprint",
        "Virtualhome: Simulating household activities via programs",
        "Tool learning with foundation models",
        "Sentence-bert: Sentence embeddings using siamese bertnetworks",
        "Recipes for building an open-domain chatbot",
        "Language models can teach themselves to use tools",
        "Solving ai tasks with chatgpt and its friends in huggingface",
        "Retrieval augmentation reduces hallucination in conversation",
        "Progprompt: Generating situated robot task plans using large language models",
        "The web as a knowledge-base for answering complex questions",
        "Language models for dialog applications",
        "Open and efficient foundation language models",
        "Self-instruct: Aligning language model with self generated instructions",
        "Multitask prompt tuning enables parameter-efficient transfer learning",
        "Chain of thought prompting elicits reasoning in large language models",
        "Translating natural language to planning goals with large-language models",
        "Pieter Abbeel, and Dale Schuurmans. Foundation models for decision making: Problems, methods, and opportunities",
        "React: Synergizing reasoning and acting in language models",
        "A survey of knowledge-enhanced text generation",
        "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models"
    ],
    "62c64f2e5aee126c0f6cf0f9": [
        "Query expansion techniques for information retrieval: a survey",
        "Ms marco: A human generated machine reading comprehension dataset",
        "Pre-training tasks for embedding-based large-scale retrieval",
        "Salient phrase aware dense retrieval: Can a dense retriever imitate a sparse one?",
        "Diffcse: Differencebased contrastive learning for sentence embeddings",
        "ELECTRA: pre-training text encoders as discriminators rather than generators",
        "Overview of the trec 2019 deep learning track",
        "Overview of the trec 2020 deep learning track",
        "Context-aware sentence/passage term importance estimation for first stage retrieval",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Unified language model pre-training for natural language understanding and generation",
        "Condenser: a pre-training architecture for dense retrieval",
        "Unsupervised corpus aware language model pre-training for dense passage retrieval",
        "COIL: Revisit exact lexical match in information retrieval with contextualized inverted list",
        "Efficiently teaching an effective dense retriever with balanced topic aware sampling",
        "Learning deep structured semantic models for web search using clickthrough data",
        "Dense passage retrieval for open-domain question answering",
        "Efficient and effective passage search via contextualized late interaction over BERT",
        "Natural questions: A benchmark for question answering research",
        "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations",
        "Roberta: A robustly optimized bert pretraining approach",
        "Retromae: Pre-training retrieval-oriented transformers via masked auto-encoder",
        "Less is more: Pretrain a strong Siamese encoder for dense text retrieval using a weak decoder",
        "Prop: Pretraining with representative words prediction for ad-hoc retrieval",
        "Pre-train a discriminative text encoder for dense retrieval via contrastive span prediction",
        "Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs",
        "Introduction to information retrieval",
        "From doc2query to doctttttquery",
        "Document expansion by query prediction",
        "RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering",
        "The curse of dense low-dimensional information retrieval for large index sizes",
        "PAIR: Leveraging passage-centric similarity relation for improving dense passage retrieval",
        "RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking",
        "Colbertv2: Effective and efficient retrieval via lightweight late interaction",
        "Simple entity-centric questions challenge dense retrievers",
        "URL",
        "Learning semantic representations using convolutional neural networks for web search",
        "The fact extraction and VERification (FEVER) shared task",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
        "Should you mask 15% in masked language modeling?",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Pretrained transformers for text ranking: BERT and beyond",
        "Adversarial retriever-ranker for dense text retrieval"
    ],
    "641137fd90e50fcafd17b84e": [
        "Overview of touch? 2022: argument retrieval",
        "A full-text learning to rank dataset for medical information retrieval",
        "Language models are few-shot learners",
        "Ms marco: A human generated machine reading comprehension dataset",
        "None",
        "Overview of the trec 2019 deep learning track",
        "Overview of the trec 2020 deep learning track",
        "Splade: Sparse lexical and expansion model for first stage ranking",
        "Condenser: a pretraining architecture for dense retrieval",
        "Precise zero-shot dense retrieval without relevance labels",
        "Dbpedia-entity v2: A test collection for entity search",
        "Dense passage retrieval for open-domain question answering",
        "Relevancebased language models",
        "A few brief notes on deepimpact, coil, and a conceptual framework for information retrieval techniques",
        "Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations",
        "A comparative study of methods for estimating query language models with pseudo feedback",
        "WordNet: A lexical database for English",
        "From doc2query to doctttttquery",
        "None",
        "RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering",
        "RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking",
        "Relevance feedback in information retrieval",
        "Recitation-augmented language models",
        "Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models",
        "Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models",
        "Trec-covid: constructing a pandemic information retrieval test collection",
        "Fact or fiction: Verifying scientific claims",
        "2022a. Simlm: Pre-training with representation bottleneck for dense passage retrieval",
        "Rangan Majumder, and Furu Wei. 2022b. Text embeddings by weakly-supervised contrastive pre-training",
        "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
        "Generate rather than retrieve: Large language models are strong context generators",
        "Adversarial retriever-ranker for dense text retrieval"
    ],
    "657c181a939a5f4082ab98e2": [
        "Official RISC-V Benchmark Suites",
        "SPEC CPU",
        "SPEC CPU",
        "Tenstorrent RISC-V OoO Superscalar Processor Family",
        "Continuous Profiling: Where Have All The Cycles Gone?",
        "Energy-performance Tradeoffs in Processor Architecture and Circuit Design: a Marginal Cost Analysis",
        "BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework",
        "The GEM5 Simulator. ACM SIGARCH computer architecture news",
        "New Methodology for Early-stage, Microarchitecture-level Power-performance Analysis of Microprocessors",
        "Sniper: Exploring the Level of Abstraction for Scalable and Accurate Parallel Multi-core Simulation",
        "ArchRanker: A Ranking Approach to Design Space Exploration",
        "Memory Dependence Prediction Using Store Sets",
        "Differentiable Expected Hypervolume Improvement for Parallel Multi-objective Bayesian Optimization. Annual Conference on Neural Information Processing Systems (NIPS)",
        "Microarchitectural Design Space Exploration Using an Architecture-centric Approach",
        "Exploring and predicting the architecture/optimising compiler co-design space",
        "Understanding Some Simple Processor-performance Limits",
        "A Performance Counter Architecture for Computing Accurate CPI Components",
        "A mechanistic performance model for superscalar out-of-order processors",
        "Number-theoretic Methods In Statistics",
        "Slack: Maximizing Performance Under Technological Constraints",
        "Focusing Processor Policies via Critical-path Prediction",
        "Using Interaction Costs for Microarchitectural Bottleneck Analysis",
        "Calipers: A Criticality-aware Framework for Modeling Processor Performance",
        "SPEC CPU2006 benchmark descriptions",
        "Evaluating Associativity in CPU Caches",
        "The Optimal Logic Depth per Pipeline Stage is 6 to 8 FO4 Inverter Delays",
        "Efficiently Exploring Architectural Design Spaces Via Predictive Modeling",
        "The Nonuniform Distribution of Instruction-level and Machine Parallelism and Its Effect on Performance",
        "A First-order Superscalar Processor Model",
        "Automated Design of Application Specific Superscalar Processors: An Analytical Approach",
        "PICO: Automatically Designing Custom Computers",
        "The Alpha 21264 Microprocessor",
        "Computer System Design Using a Hierarchical Approach to Performance Evaluation",
        "Illustrative Design Space Studies with Microarchitectural Regression Models",
        "RpStacks: Fast and Accurate Processor Design Space Exploration Using Representative Stall-event Stacks",
        "Efficient Design Space Exploration Via Statistical Sampling and AdaBoost Learning",
        "McPAT: An Integrated Power, Area, and Timing Modeling Framework for Multicore and Manycore Architectures",
        "The GEM5 Simulator: Version 20.0+",
        "Environment for PowerPC Microarchitecture Exploration",
        "Pioneering Chiplet Technology and Design for the AMD EPYC? and Ryzen? Processor Families: Industrial Product",
        "Critical Path Analysis of the TRIPS Architecture",
        "Theoretical Modeling of Superscalar Processor Performance",
        "A Graph-based Program Representation for Analyzing Hardware Specialization Approaches",
        "Analyzing Behavior Specialized Acceleration",
        "ReSPIR: A Response Surface-based Pareto Iterative Refinement For Application-specific Design Space Exploration",
        "Using SimPoint for Accurate and Efficient Simulation",
        "Branch Target Buffer Design and Optimization",
        "The Peter Principle",
        "Exploiting Criticality to Reduce Bottlenecks in Distributed Uniprocessors",
        "The Graph Neural Network Model",
        "The Boosting Approach to Machine Learning: An Overview. Nonlinear estimation and classification",
        "Pareto Frontier Learning with Expensive Correlated Objectives",
        "Experiments with AdaBoost. RT, An Improved Boosting Scheme for Regression",
        "Moguls: A Model to Explore the Memory Hierarchy for Bandwidth Improvements",
        "Enhanced Dependence Graph Model for Critical Path Analysis on Modern Out-of-order Processors",
        "Visualizing Data Using t-SNE",
        "A Comprehensive Survey on Graph Neural Networks",
        "A Top-down Method for Performance Analysis and Counters Architecture",
        "A Statistically Rigorous Approach for Improving Simulation Methodology",
        "Active Learning Via Transductive Experimental Design"
    ],
    "6326303790e50fcafdf36ca9": [
        "Graph prefetching using data structure knowledge",
        "Software prefetching for indirect memory accesses,'' in Proc",
        "An event-triggered programmable prefetcher for irregular workloads",
        "Compiler-directed contentaware prefetching for dynamic data structures",
        "Classifying memory access patterns for prefetching",
        "The NAS parallel benchmarks",
        "Bingo spatial data prefetcher",
        "Evaluation of hardware data prefetchers on server processors",
        "Array tracking prefetcher for indirect accesses",
        "Informed prefetching for indirect memory accesses",
        "Helper thread prefetching for loosely-coupled multiprocessor systems",
        "Microarchitectural support for precomputation microthreads",
        "Simultaneous subordinate microthreading (SSMT)",
        "Reducing memory latency via non-blocking and prefetching caches",
        "A general framework for prefetch scheduling in linked data structures and its application to multi-chain prefetching",
        "Speculative precomputation: Long-range prefetching of delinquent loads",
        "Dynamic speculative precomputation",
        "Pointer cache assisted prefetching",
        "A stateless, content-directed data prefetching mechanism",
        "Effectiveness of hardware-based stride and sequential prefetching in shared-memory multiprocessors",
        "A primer on hardware prefetching",
        "Make the most out of last level cache in Intel processors",
        "Compiler-directed data prefetching in multiprocessors with memory hierarchies",
        "The IBM Blue Gene/Q compute chip",
        "Continuous runahead: Transparent hardware acceleration for memory intensive workloads",
        "Computer Architecture: A Quantitative Approach",
        "SPEC CPU2006 benchmark descriptions",
        "Memory prefetching using adaptive stream detection",
        "PYNQ-Z1",
        "Access map pattern matching for data cache prefetch",
        "Linearizing irregular memory accesses for improved correlated prefetching",
        "APT-GET: Profile-guided timely software prefetching",
        "Prefetching using Markov predictors",
        "Inter-core prefetching for multicore processors using migrating helper threads",
        "Profiling a warehouse-scale computer",
        "Design and evaluation of compiler algorithms for pre-execution",
        "A study of source-level compiler algorithms for automatic construction of pre-execution code",
        "Path confidence based lookahead prefetching",
        "Multi-chain prefetching: Effective exploitation of inter-chain memory parallelism for pointerchasing codes",
        "The performance of runtime data cache prefetching in a dynamic optimization system",
        "Dynamic helper threaded prefetching on the sun UltraSPARC CMP processor,'' in Proc. 38th Annu",
        "Profile-guided post-link stride prefetching",
        "Analysis and optimization of I/O cache coherency strategies for SoC-FPGA device",
        "Runahead execution: An alternative to very large instruction Windows for out-of-order processors",
        "Techniques for efficient processing in runahead execution engines",
        "Bouquet of instruction pointers: Instruction pointer classifier-based spatial hardware prefetching",
        "Effective jump-pointer prefetching for linked data structures",
        "Energy and performance exploration of accelerator coherency port using Xilinx ZYNQ",
        "Efficiently prefetching complex address patterns",
        "Knights landing: Second-generation Intel Xeon Phi product",
        "Using a user-level memory thread for correlation prefetching",
        "A compilerdirected data prefetching scheme for chip multiprocessors",
        "The AMD 'Zen 2' processor",
        "POWER4 system microarchitecture",
        "Disclosure of Hardware Prefetcher Control on Some Intel Processors",
        "Hitting the memory wall: Implications of the obvious",
        "A programmable memory hierarchy for prefetching linked data structures",
        "IMP: Indirect memory prefetcher",
        "where he is currently pursuing the Ph.D. degree in programming languages and security. His research interests include programming languages, security, computer architecture, and education techniques",
        "IEEE) is currently an Assistant Professor at the National University of Singapore working to develop high-efficiency microarchitectures that can meet the performance and needs of the future IoT and server applications"
    ],
    "64b60eaa3fda6d7f06eaea30": [
        "None",
        "An overview and definition of GIS",
        "GIS basics: New Age International",
        "GIS and modeling overview",
        "Geographical information systems",
        "Does mapping improve public participation? Exploring the pros and cons of using public participation GIS in urban planning practices",
        "Review of GIS-based applications for mining: Planning, operation, and environmental management",
        "Remote sensing and GIS applications for municipal waste management",
        "Why public health needs GIS: a methodological overview",
        "Issues of healthcare planning and GIS: a review",
        "GIS model-builder based on comprehensive geostatistical approach to assess soil quality",
        "Soil erosion analysis in a small forested catchment supported by ArcGIS Model Builder",
        "ChatGPT for good? On opportunities and challenges of large language models for education",
        "The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations",
        "Future of the language models in healthcare: the role of chatGPT",
        "Reasoning with language model is planning with world model",
        "Auto-gpt: An autonomous gpt-4 experiment",
        "Visual chatgpt: Talking, drawing and editing with visual foundation models",
        "Review of Large Vision Models and Visual Prompt Engineering",
        "ChemCrow: Augmenting large-language models with chemistry tools",
        "AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology",
        "Emergent abilities of large language models",
        "A survey of large language models",
        "Language models are few-shot learners",
        "Gpt-4 technical report",
        "Palm: Scaling language modeling with pathways",
        "Palm 2 technical report",
        "Llama: Open and efficient foundation language models",
        "Evaluation of ChatGPT as a question answering system for answering complex questions",
        "Semantic Anomaly Detection with Large Language Models",
        "Towards Understanding the Spatial Literacy of ChatGPT-Taking a Geographic Information Systems (GIS) Exam",
        "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
        "Chat-rec: Towards interactive and explainable llms-augmented recommender system",
        "Prompt, generate, then cache: Cascade of foundation models makes strong few-shot learners",
        "Hierarchical textconditional image generation with clip latents",
        "Zero-shot text-to-image generation",
        "GPT4GEO: How a Language Model Sees the World's Geography",
        "On the opportunities and challenges of foundation models for geospatial artificial intelligence",
        "Chatgpt or human? detect and explain. explaining decisions of machine learning model for detecting short chatgptgenerated text",
        "Why Does ChatGPT Fall Short in Answering Questions Faithfully?",
        "Augmented language models: a survey",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Chain of thought prompting elicits reasoning in large language models",
        "Large language models are zero-shot reasoners",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "Do as i can, not as i say: Grounding language in robotic affordances",
        "Inner monologue: Embodied reasoning through planning with language models",
        "React: Synergizing reasoning and acting in language models",
        "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface",
        "LangChain"
    ],
    "6584f922939a5f408236fc36": [
        "Dynamic word embeddings",
        "Proceedings of the Sixth Conference on Machine Translation",
        "Time-aware language models as temporal knowledge bases",
        "Simple, interpretable and stable method for detecting words with usage change across corpora",
        "Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies",
        "Don't stop pretraining: Adapt language models to domains and tasks",
        "Diachronic word embeddings reveal statistical laws of semantic change",
        "Lora: Low-rank adaptation of large language models",
        "Editing models with task arithmetic",
        "Patching open-vocabulary models by interpolating weights",
        "None",
        "The power of scale for parameter-efficient prompt tuning",
        "Branch-train-merge: Embarrassingly parallel training of expert language models",
        "A pretrainer's guide to training data: Measuring the effects of data age, domain coverage, quality, &amp; toxicity",
        "Time waits for no one! analysis and challenges of temporal misalignment",
        "Task arithmetic in the tangent space: Improved editing of pre-trained models",
        "Exploring the limits of transfer learning with a unified text-to",
        "Temporally-informed analysis of named entity recognition",
        "Temporal adaptation of bert and performance on downstream document classification: Insights from social media",
        "Temporal word analogies: Identifying lexical replacement with diachronic word embeddings",
        "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time",
        "Robust fine-tuning of zero-shot models"
    ],
    "642e38e090e50fcafd6abcf8": [
        "On seeing stuff: the perception of materials by humans and machines. Human vision and electronic imaging VI",
        "What is an object?",
        "Contour detection and hierarchical image segmentation",
        "Layer normalization",
        "BERT pre-training of image transformers",
        "ZeroWaste dataset: Towards deformable object segmentation in cluttered scenes",
        "ilastik: interactive machine learning for (bio)image analysis",
        "On the opportunities and risks of foundation models",
        "Iterative interaction training for segmentation editing networks",
        "Language models are few-shot learners",
        "Cascade R-CNN: Delving into high quality object detection",
        "Nucleus segmentation across imaging experiments: the 2018 data science bowl",
        "A computational approach to edge detection",
        "End-to-end object detection with Transformers",
        "Automatic image colorization via multimodal predictions",
        "Harsh Agrawal, Aroma Mahendru, and Dhruv Batra. Object-proposal evaluation protocol is' gameable",
        "instance segmentation of MVS buildings",
        "FocalClick: towards practical interactive image segmentation",
        "Masked-attention mask transformer for universal image segmentation",
        "Perpixel classification is not all you need for semantic segmentation",
        "Scaling language modeling with pathways",
        "Domain adaptation for traffic density estimation",
        "Night and day instance segmented park (NDIS-Park) dataset: a collection of images taken by day and by night for vehicle detection, segmentation and counting in parking areas",
        "Semantic segmentation in art paintings",
        "The Cityscapes dataset for semantic urban scene understanding",
        "Learning parameterized skills",
        "Rescaling egocentric vision: Collection, pipeline and challenges for EPIC-KITCHENS-100",
        "EPIC-KITCHENS VISOR benchmark: Video segmentations and object relations",
        "Does object recognition work for everyone? CVPR workshops",
        "Crowd-WorkSheets: Accounting for individual and collective identities underlying crowdsourced dataset annotation",
        "PhraseClick: toward achieving flexible interactive segmentation by phrase and click",
        "Fast edge detection using structured forests",
        "An image is worth 16x16 words: Transformers for image recognition at scale",
        "Learning to recognize objects in egocentric activities",
        "Efficient graphbased image segmentation",
        "The validity and practicality of sun-reactive skin types i through vi",
        "Ning Xu, and Franc ?ois Piti?",
        "Instance segmentation for autonomous log grasping in forestry operations",
        "Datasheets for datasets",
        "Simple copy-paste is a strong data augmentation method for instance segmentation",
        "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: Training ImageNet in 1 hour",
        "None",
        "LVIS: A dataset for large vocabulary instance segmentation",
        "Multiple choice learning: Learning to produce multiple structured outputs",
        "SOCRATES: Introducing depth in visual wildlife monitoring using stereo vision",
        "Masked autoencoders are scalable vision learners",
        "Mask R-CNN. ICCV",
        "Deep residual learning for image recognition",
        "Gaussian error linear units (gelus)",
        "Training compute-optimal large language models",
        "TrashCan: A semantically-segmented dataset towards visual detection of marine debris",
        "Deep networks with stochastic depth",
        "Oneformer: One transformer to rule universal image segmentation",
        "Scaling up visual and vision-language representation learning with noisy text supervision",
        "Scaling laws for neural language models",
        "Snakes: Active contour models",
        "Learning open-world object proposals without learning to classify",
        "Panoptic segmentation",
        "The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale",
        "Quantifying the carbon emissions of machine learning",
        "Exploring plain vision transformer backbones for object detection",
        "Delving into egocentric actions",
        "Interactive image segmentation with latent diversity",
        "Focal loss for dense object detection",
        "Common objects in context. ECCV",
        "Sim-pleClick: Interactive image segmentation with simple vision transformers",
        "Decoupled weight decay regularization",
        "Gelatinous zooplankton biomass in the global oceans: geographic variation and environmental drivers",
        "Iteratively trained interactive segmentation",
        "Deep extreme cut: From extreme points to object segmentation",
        "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics",
        "V-Net: Fully convolutional neural networks for volumetric medical image segmentation",
        "Finely-grained annotated datasets for imagebased plant phenotyping",
        "Inioluwa Deborah Raji, and Timnit Gebru. Model cards for model reporting",
        "Extreme clicking for efficient object annotation",
        "Carbon emissions and large neural network training",
        "Semi-supervised sequence tagging with bidirectional language models",
        "EDTER: Edge detection with transformer",
        "DOORS: Dataset fOr bOuldeRs Segmentation",
        "Occluded video instance segmentation: A benchmark",
        "Learning transferable visual models from natural language supervision",
        "Zero-shot textto-image generation",
        "Towards real-time object detection with region proposal networks",
        "Learning a classification model for segmentation",
        "Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding",
        "A step toward more inclusive people annotations for fairness",
        "LightFace: A hybrid deep face recognition framework",
        "HyperExtended LightFace: A facial attribute analysis framework",
        "TextonBoost: Joint appearance, shape and context modeling for mulit-class object recognition and segmentation",
        "STREETS: A novel camera network dataset for traffic flow",
        "Reviving iterative training with mask guidance for interactive segmentation",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "Adaptive background mixture models for real-time tracking",
        "Fourier features let networks learn high frequency functions in low dimensional domains",
        "Multi-stream deep neural networks for RGB-D egocentric action recognition",
        "The world by income and regions",
        "Is learning the n-th thing any easier than learning the first? NeurIPS",
        "NDD20: A large-scale few-shot dolphin dataset for coarse and fine-grained categorisation",
        "Greenhouse Gas Equivalencies Calculator",
        "Segmentation as selective search for object recognition",
        "Attention is all you need",
        "Towards real-world prohibited item detection: A largescale x-ray benchmark",
        "Open-world instance segmentation: Exploiting pseudo ground truth from learned pairwise affinity",
        "Multiview compressive coding for 3D reconstruction",
        "Aude Oliva, and Antonio Torralba. SUN database: Large-scale scene recognition from abbey to zoo",
        "Holistically-nested edge detection",
        "Deep interactive object selection",
        "Towards fairer datasets: Filtering and balancing the distribution of the people subtree in the imagenet hierarchy",
        "A first step towards irregular shape instance segmentation",
        "WoodScape: A multi-task, multicamera fisheye dataset for autonomous driving",
        "Finegrained egocentric hand-object segmentation: Dataset, model, and applications",
        "K-Net: Towards unified image segmentation",
        "Men also like shopping: Reducing gender bias amplification using corpus-level constraints",
        "Places: A 10 million image database for scene recognition",
        "Semantic understanding of scenes through the ADE20K dataset"
    ],
    "64f7fc6a3fda6d7f06f43fbe": [
        "None",
        "A robust algorithm for pitch tracking (RAPT)",
        "Acurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound",
        "PYIN: A fundamental frequency estimator using probabilistic threshold distributions",
        "A sawtooth waveform inspired pitch estimator for speech and music",
        "Noise robust pitch tracking by subband autocorrelation classification",
        "Neural Network Based Pitch Tracking in Very Noisy Speech",
        "Onsets and frames: Dual-objective piano transcription",
        "Adversarial learning for improved onsets and frames music transcription",
        "High-Resolution Piano Transcription with Pedals by Regressing Onset and Offset Times",
        "Transfer learning for music genre classification",
        "Multimodal deep learning for music genre classification",
        "Music Genre Classification: A Review of Deep-Learning and Traditional Machine-Learning Approaches",
        "Deep convolutional networks on the pitch spiral for music instrument recognition",
        "Deep Convolutional Neural Networks for Predominant Instrument Recognition in Polyphonic Music",
        "Music instrument recognition using deep convolutional neural networks",
        "Crepe: A Convolutional Representation for Pitch Estimation",
        "Deep-Learning Architectures for Multi-Pitch Estimation: Towards Reliable Evaluation",
        "Shortcut learning in deep neural networks",
        "SPICE: Self-Supervised Pitch Estimation",
        "Equivariant Self-Supervision for Musical Tempo Estimation",
        "Dimensionality reduction by learning an invariant mapping",
        "A simple framework for contrastive learning of visual representations",
        "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
        "VI-CReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
        "Understanding contrastive representation learning through alignment and uniformity on the hypersphere",
        "Momentum Contrast for Unsupervised Visual Representation Learning",
        "Improved Baselines with Momentum Contrastive Learning",
        "Bootstrap your own latent a new approach to self-supervised learning",
        "Exploring simple Siamese representation learning",
        "Improving Self-Supervised Learning by Characterizing Idealized Representations",
        "Contrastive learning of general-purpose audio representations",
        "Audio Barlow Twins: Self-Supervised Audio Representation Learning",
        "BYOL for Audio: Exploring Pre-Trained General-Purpose Audio Representations",
        "Audio Set: An ontology and human-labeled dataset for audio events",
        "Contrastive Learning of Musical Representations",
        "Equivariant Contrastive Learning",
        "Unsupervised Learning of Group Invariant and Equivariant Representations",
        "Selfsupervised learning of Split Invariant Equivariant representations",
        "Cepstrum pitch determination",
        "Real-Time Digital Hardware Pitch Detector",
        "Average magnitude difference function pitch extractor",
        "YIN, a fundamental frequency estimator for speech and music",
        "Unsupervised disentanglement of pitch and timbre for isolated musical instrument sounds",
        "Unsupervised disentanglement of timbral, pitch, and variation features from musical instrument sounds with random perturbation",
        "Self-Supervised Pitch Detection by Inverse Audio Synthesis",
        "DDSP: Differentiable Digital Signal Processing",
        "Robust Estimation of a Location Parameter",
        "GradNorm: Gradient normalization for adaptive loss balancing in deep multitask networks",
        "Taming transformers for high-resolution image synthesis",
        "Value Function Decomposition for Iterative Design of Reinforcement Learning Agents",
        "A Lightweight Instrument-Agnostic Model for Polyphonic Note Transcription and Multipitch Estimation",
        "Herremans, \"nnAudio: An on-the-Fly GPU Audio to Spectrogram Conversion Toolbox Using 1D Convolutional Neural Networks",
        "Layer Normalization",
        "Deep residual learning for image recognition",
        "Empirical Evaluation of Rectified Activations in Convolutional Network",
        "Dropout: A simple way to prevent neural networks from overfitting",
        "On the Improvement of Singing Voice Separation for Monaural Recordings Using the MIR-1K Dataset",
        "An analysis/synthesis framework for automatic f0 annotation of multitrack datasets",
        "PyTorch: An imperative style, high-performance deep learning library",
        "Adam: A method for stochastic optimization",
        "Melody transcription from music audio: Approaches and evaluation"
    ],
    "6257c63c5aee126c0f47280f": [
        "A tight and unified analysis of gradient-based methods for a whole spectrum of differentiable games",
        "Convex analysis and monotone operator theory in Hilbert spaces",
        "Generalized monotone operators and their averaged resolvents",
        "Mixed equilibria and dynamical systems arising from fictitious play in perturbed games",
        "Nonlinear programming",
        "Ern? Robert Csetnek, and Radu Ioan Bo?. Two steps at a timetaking gan training in stride with tseng's method",
        "Independent policy gradient methods for competitive reinforcement learning",
        "The complexity of constrained min-max optimization",
        "Stochastic subgradient method converges at the rate $O(k {-1/4})$ on weakly convex functions",
        "Efficient methods for structured nonconvex-nonconcave min-max optimization",
        "Finite-dimensional variational inequalities and complementarity problems",
        "Gradient descent-ascent provably converges to strict local minmax equilibria with a finite timescale separation",
        "A variational inequality perspective on generative adversarial networks",
        "Nonlinear forward-backward splitting with projection correction",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
        "Exponential lower bounds for finding Brouwer fixed points",
        "Multiple equilibria and limit cycles in evolutionary games with logit dynamics",
        "The limits of min-max optimization algorithms: Convergence to spurious non-critical sets",
        "Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling",
        "What is local optimality in nonconvexnonconcave minimax optimization?",
        "The extragradient method for finding saddle points and other problems",
        "Asymmetric forward-backward-adjoint splitting for solving monotone inclusions involving three operators",
        "Fast extra gradient methods for smooth structured nonconvexnonconcave minimax problems",
        "Semi-anchored multi-step gradient descent ascent method for structured nonconvex-nonconcave composite minimax problems",
        "First-order convergence theory for weakly-convex-weakly-concave min-max problems",
        "On finding local Nash equilibria (and only local Nash equilibria) in zero-sum games",
        "Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile",
        "Cycles in adversarial regularized learning",
        "Monotone (nonlinear) operators in hilbert space",
        "Solving a class of non-convex min-max games using iterative first order methods",
        "On the complexity of the parity argument and other inefficient proofs of existence",
        "Fast exact multiplication by the hessian",
        "None",
        "Non-convex min-max optimization: Provable algorithms and applications in machine learning",
        "Variational analysis",
        "Monotone operators and the proximal point algorithm",
        "Convex analysis",
        "Modified projection-type methods for monotone variational inequalities",
        "A hybrid projection-proximal point algorithm",
        "Optimistic dual extrapolation for coherent non-monotone variational inequalities",
        "Ordinary differential equations and dynamical systems",
        "A modified forward-backward splitting method for maximal monotone mappings",
        "Global convergence and variance-reduced optimization for a class of nonconvex-nonconcave minimax problems",
        "Stochastic mirror descent in variationally coherent optimization problems"
    ],
    "63dcdb422c26941cf00b61c5": [
        "Stochastic variance reduction for variational inequality methods",
        "Lower bounds for non-convex stochastic optimization",
        "Convex analysis and monotone operator theory in Hilbert spaces",
        "Generalized monotone operators and their averaged resolvents",
        "Incremental proximal methods for large scale convex optimization",
        "Stochastic gradient descent-ascent: Unified theory and new efficient methods",
        "Solving nonconvex-nonconcave min-max problems exhibiting weak minty solutions",
        "Minibatch forwardbackward-forward methods for solving stochastic variational inequalities",
        "A stochastic Halpern iteration with variance reduction for stochastic monotone inclusion problems",
        "A first-order primal-dual algorithm for convex problems with applications to imaging",
        "Solving stochastic compositional optimization is nearly as easy as solving stochastic optimization",
        "Proximal methods for cohypomonotone operators",
        "The complexity of constrained min-max optimization",
        "Efficient methods for structured nonconvex-nonconcave min-max optimization",
        "Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator",
        "Stochastic first-and zeroth-order methods for nonconvex stochastic programming",
        "Stochastic extragradient: General analysis and improved rates",
        "Exponential lower bounds for finding Brouwer fixed points",
        "On the convergence of single-call stochastic extra-gradient methods",
        "Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling",
        "Solving variational inequalities with stochastic mirror-prox algorithm",
        "Optimal stochastic extragradient schemes for pseudomonotone stochastic variational inequality problems and their variants",
        "Asymmetric forward-backward-adjoint splitting for solving monotone inclusions involving three operators",
        "Fast extra gradient methods for smooth structured nonconvexnonconcave minimax problems",
        "On the convergence of stochastic extragradient for bilinear games using restarted iteration averaging",
        "Stochastic hamiltonian gradient methods for smooth games",
        "Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity",
        "Revisiting stochastic extragradient",
        "Finite-sum smooth optimization with SARAH",
        "Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems",
        "Convex analysis",
        "Optimistic dual extrapolation for coherent non-monotone variational inequalities",
        "A modified forward-backward splitting method for maximal monotone mappings",
        "Global convergence and variance-reduced optimization for a class of nonconvex-nonconcave minimax problems"
    ],
    "640fe64790e50fcafd9e276e": [
        "Deepspeed-inference: Enabling efficient inference of transformer models at unprecedented scale",
        "On the opportunities and risks of foundation models",
        "Petals: Collaborative inference and fine-tuning of large models",
        "Language models are few-shot learners",
        "Formula prediction from semi-structured context",
        "Scaling language modeling with pathways",
        "Communication-avoiding algorithms for linear algebra and beyond",
        "The case for 4-bit precision: k-bit inference scaling laws",
        "8-bit matrix multiplication for transformers at scale",
        "Turbotransformers: an efficient gpu serving system for transformer models",
        "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity",
        "Massive language models can be accurately pruned in one-shot",
        "Gptq: Accurate post-training quantization for generative pre-trained transformers",
        "Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks",
        "Pushing deep learning beyond the gpu memory limit via smart swapping",
        "Gpipe: Efficient training of giant neural networks using pipeline parallelism",
        "Opt-iml: Scaling language model instruction meta learning through the lens of generalization",
        "T. I/o complexity: The red-blue pebble game",
        "Alphatuning: Quantization-aware parameter-efficient adaptation of large-scale pre-trained language models",
        "Overcoming the hurdles of gpu memory capacity to train massive dnn models on commodity servers",
        "Holistic evaluation of language models",
        "Pointer sentinel mixture models",
        "None",
        "Can foundation models wrangle your",
        "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
        "Efficient large-scale language model training on gpu clusters using megatron-lm",
        "The lambada dataset: Word prediction requiring a broad discourse context",
        "Quantized matmul for efficient inference of large-scale generative language models",
        "Pytorch: An imperative style, high-performance deep learning library",
        "Efficiently scaling transformer inference",
        "Zero-infinity: Breaking the gpu memory wall for extreme scale deep learning",
        "Zero-offload: Democratizing billion-scale model training",
        "Swarm parallelism: Training large models can be surprisingly communication-efficient",
        "A 176b-parameter open-access multilingual language model",
        "Q-bert: Hessian based ultra low precision quantization of bert",
        "Optimizing the lifetime and location of arrays to reduce the memory usage of neural networks",
        "Superneurons: Dynamic gpu memory management for training deep neural networks",
        "Lightseq: A high performance inference library for transformers",
        "Accurate and efficient post-training quantization for large language models",
        "Efficient and affordable post-training quantization for large-scale transformers",
        "A distributed serving system for {Transformer-Based} generative models",
        "Open pre-trained transformer language models",
        "Alpa: Automating inter-and intra-operator parallelism for distributed deep learning"
    ],
    "6493c733d68f896efad19c1d": [
        "Vision-language model for visual question answering in medical imagery",
        "Meddialog: a large-scale medical dialogue dataset",
        "Pubmedclip: How much does clip benefit visual question answering in the medical domain?",
        "Medalpaca-an open-source collection of medical conversational ai models and training data",
        "Pathvqa: 30000+ questions for medical visual question answering",
        "Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine",
        "The ai revolution in medicine: Gpt-4 and beyond",
        "Llava-med: Training a large languageand-vision assistant for biomedicine in one day",
        "Self-supervised vision-language pretraining for medical visual question answering",
        "Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening",
        "Visual instruction tuning",
        "Q2atransformer: Improving medical vqa via an answer querying decoder",
        "Biogpt: generative pretrained transformer for biomedical text generation and mining",
        "Capabilities of gpt-4 on medical challenge problems",
        "OpenAI. Gpt-4 technical report",
        "Language models are unsupervised multitask learners",
        "Visual med-alpaca: A parameter-efficient biomedical llm with visual capabilities",
        "Open and efficient foundation language models",
        "Openended medical visual question answering through prefix tuning of language models",
        "Biomedlm: a domainspecific large language model for biomedical text",
        "Tuning llama model with chinese medical knowledge",
        "Pmc-llama: Further finetuning llama on medical papers",
        "Doctorglm: Finetuning your chinese doctor is not a herculean task",
        "Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge",
        "Glm-130b: An open bilingual pre-trained model",
        "None",
        "Large-scale domain-specific pretraining for biomedical vision-language processing",
        "None"
    ],
    "62283c435aee126c0fd5de60": [
        "Hierarchical cross-modal talking face generation with dynamic pixel-wise loss",
        "First order motion model for image animation",
        "Story-driven video editing",
        "X2face: A network for controlling face generation using images, audio, and pose codes",
        "Common and innovative visuals: A sparsity modeling framework for video",
        "Video inpainting with shortterm windows: Application to object removal and error concealment",
        "PRRNet: Pixel-region relation network for face forgery detection",
        "Frequency-aware discriminative feature learning supervised by single-center loss for face forgery detection",
        "Deep video portraits",
        "One-shot free-view neural talkinghead synthesis for video conferencing",
        "Tiling in interactive panoramic video: Approaches and evaluation",
        "A signal adaptive prediction filter for video coding using directional total variation: Mathematical framework and parameter selection",
        "Content-aware convolutional neural network for in-loop filtering in high efficiency video coding",
        "Deep head pose: Gaze-direction estimation in multimodal video",
        "Synthesizing obama: Learning lip sync from audio",
        "You said that?",
        "Text-based editing of talking-head video",
        "Oba-maNet: Photo-realistic lip-sync from text",
        "Talking face generation by conditional recurrent adversarial network",
        "End-to-end speech-driven facial animation with temporal GANs",
        "Talking-head generation with rhythmic head motion",
        "Everybody's talkin': Let me talk as you want",
        "An analysis of HMM-based prediction of articulatory movements",
        "BLTRCNN based 3rd articulatory movement prediction: Learning articulatory synchronicity from both text and audio inputs",
        "Taskdependence of articulator synergies",
        "Preliminaries to a theory of action with reference to vision",
        "Multimodal inputs driven talking face generation with spatial-temporal dependency",
        "Talking face generation by adversarially disentangled audio-visual representation",
        "FlowNet 2.0: Evolution of optical flow estimation with deep networks",
        "Video-to-video synthesis",
        "Generating visually aligned sound from videos",
        "Audio-visual scene analysis with selfsupervised multisensory features",
        "The sound of pixels",
        "Music gesture for visual sound separation",
        "2.5D visual sound",
        "Self-supervised learning of audio-visual objects from video",
        "The Sound of Motions",
        "Foley music: Learning to generate music from videos",
        "Looking to listen at the cocktail party: a speakerindependent audio-visual model for speech separation",
        "Audio-driven talking face video generation with natural head pose",
        "Image-to-image translation with conditional adversarial networks",
        "Generative adversarial nets",
        "An adaptive algorithm for mel-cepstral analysis of speech",
        "Restructuring speech representations using a pitch-adaptive time-frequency smoothing and an instantaneous-frequency-based F0 extraction: Possible role of a repetitive structure in sounds",
        "Merlin: An open source neural network speech synthesis system",
        "The HTK book",
        "Effective face frontalization in unconstrained images",
        "DLIB-ML: A machine learning toolkit",
        "To frontalize or not to frontalize: A study of face pre-processing techniques and their impact on recognition",
        "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling",
        "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
        "A computational approach to edge detection",
        "Non-local neural networks",
        "High-resolution image synthesis and semantic manipulation with conditional gans",
        "Faceforensics: A large-scale video dataset for forgery detection in human faces",
        "Image quality metrics: PSNR vs. SSIM",
        "Lip movements generation at a glance",
        "Least squares generative adversarial networks"
    ],
    "639a90a690e50fcafdf0a150": [
        "Third time's the charm? image and video editing with stylegan3",
        "Stochastic variational video prediction",
        "Rewriting a deep generative model",
        "Large scale GAN training for high fidelity natural image synthesis",
        "Generating long videos of dynamic scenes",
        "Everybody dance now",
        "Adversarial video generation on complex datasets",
        "Subroutine package for calculating with b-splines",
        "Unsupervised learning for physical interaction through video prediction",
        "A temporal generative model using a pretrained stylegan",
        "Long video generation with time-agnostic vqgan and time-sensitive transformer",
        "Ganalyze: Toward visual definitions of cognitive image properties",
        "Generative adversarial nets",
        "Recurrent world models facilitate policy evolution",
        "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
        "Video diffusion models",
        "Cogvideo: Large-scale pretraining for text-to-video generation via transformers",
        "On the\" steerability\" of generative adversarial networks",
        "Ivo Danihelka, Oriol Vinyals, Alex Graves, and Koray Kavukcuoglu. Video pixel networks",
        "Progressive growing of gans for improved quality, stability, and variation",
        "A style-based generator architecture for generative adversarial networks",
        "Analyzing and improving the image quality of stylegan",
        "Analyzing and improving the image quality of stylegan",
        "Alias-free generative adversarial networks",
        "Learning to Simulate Dynamic Environments with GameGAN",
        "DriveGAN: Towards a Controllable High-Quality Neural Simulation",
        "Videoflow: A conditional flow-based model for stochastic video generation",
        "Stochastic adversarial video prediction",
        "Infinitenature-zero: Learning perpetual view generation of natural scenes from single images",
        "Tsm: Temporal shift module for efficient video understanding",
        "Infinite nature: Perpetual view generation of natural scenes from a single image",
        "Transformation-based adversarial video prediction on large-scale data",
        "Transframer: Arbitrary frame prediction with generative models",
        "Video generation from single semantic label map",
        "Stylefacev: Face video generation via decomposing and recomposing pretrained stylegan3",
        "Unsupervised representation learning with deep convolutional generative adversarial networks",
        "Latent video transformer",
        "Human motion transfer from poses in the wild",
        "Look outside the room: Synthesizing a consistent long-term 3d scene video from a single image",
        "Temporal generative adversarial nets with singular value clipping",
        "Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan",
        "Interpreting the disentangled face representation learned by gans",
        "Animating arbitrary objects via deep motion transfer",
        "First order motion model for image animation",
        "Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2",
        "A good image generator is what you need for high-resolution video synthesis",
        "Mocogan: Decomposing motion and content for video generation",
        "Towards accurate generative models of video: A new metric &amp; challenges",
        "Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Conditional image generation with pixelcnn decoders",
        "Visualizing data using t-sne",
        "Generating videos with scene dynamics",
        "Predicting video with vqvae",
        "Rewriting geometric rules of a gan",
        "None",
        "Latent image animator: Learning to animate images via latent space navigation",
        "Scaling autoregressive video models",
        "Generating open-domain videos from natural descriptions",
        "N\\\" uwa: Visual synthesis pre-training for neural visual world creation",
        "Learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks",
        "Videogpt: Video generation using vq-vae and transformers",
        "Pose guided human video generation",
        "Semantic hierarchy emerges in deep generative representations for scene synthesis",
        "Diffusion probabilistic modeling for video generation",
        "Generating videos with dynamics-aware implicit generative adversarial networks",
        "Learning to drive by watching youtube videos: Action-conditioned contrastive policy pretraining"
    ],
    "6233f88c5aee126c0f94b3c4": [
        "Advanced profiling topics. pebs and lbr",
        "Defensive loop tiling for shared cache",
        "Hoard: A scalable memory allocator for multithreaded applications",
        "The parsec benchmark suite: Characterization and architectural implications",
        "Data centric cache measurement on the Intel ltanium 2 processor",
        "Featherlight on-the-fly false-sharing detection",
        "Rodinia: A benchmark suite for heterogeneous computing",
        "Intel vtune profiler",
        "Intel math kernel library",
        "Linux kernel profiling with perf",
        "Collective loop fusion for array contraction",
        "Tcmalloc: Thread-caching malloc",
        "Himeno benchmark",
        "Intel. Intel xed",
        "ntel? 64 and IA-32 Architectures Software Developer Manuals",
        "Intel 64 and IA-32 Architectures Software Developer's Manual",
        "Memory profiling using hardware counters",
        "On modeling and analyzing cache hierarchies using casper",
        "Cmp$im: A pin-based on-the-fly multi-core cache simulator",
        "Detection of false sharing using machine learning",
        "Reducing compulsory and capacity misses",
        "Automated memory leak detection for production use",
        "Lulesh programming model and performance ports overview",
        "Dmon: Efficient detection and correction of data locality problems using selective profiling",
        "Huron: Hybrid false sharing detection and repair",
        "Inefficient innodb row stats implementation",
        "Kripke-a massively parallel transport mini-app",
        "Cache profiling and the spec benchmarks: A case study",
        "Performance analysis guide for intel core? i7 processor and intel xeon 5500 processors",
        "Oprofile: A system profiler for linux",
        "Sheriff: precise detection and automatic mitigation of false sharing",
        "Cheetah: Detecting false sharing efficiently and effectively",
        "Predator: Predictive false sharing detection",
        "Arraytool: A lightweight profiler to guide array regrouping",
        "A data-centric profiler for parallel programs",
        "Arraytool: A lightweight profiler to guide array regrouping",
        "Multicachesim: A coherent multiprocessor cache simulator",
        "Laser: Light, accurate sharing detection and repair",
        "Valgrind: A framework for heavyweight dynamic binary instrumentation",
        "Delorean: Virtualized Directed Profiling for Cache Modeling in Sampled Simulation",
        "Delorean: Virtualized directed profiling for cache modeling in sampled simulation",
        "Locating cache performance bottlenecks using data profiling",
        "None",
        "Evaluating mapreduce for multi-core and multiprocessor systems",
        "Lightweight detection of cache conflicts",
        "Analyzing data locality in numeric applications",
        "Addresssanitizer: A fast address sanity checker",
        "Cachegrind: a cache-miss profiler",
        "Racez: A lightweight and non-invasive race detection tool for production applications",
        "Detailed cache simulation for detecting bottleneck, miss reason and optimization potentialities",
        "Detailed cache simulation for detecting bottleneck, miss reason and optimization potentialities",
        "Cache performance measurement and metric: Capacity misses",
        "Team. header only, dependency-free deep learning framework in c++14",
        "Loop optimization",
        "Speckle reducing anisotropic diffusion",
        "A mathematical cache miss analysis for pointer data structures",
        "Dynamic cache contention detection in multi-threaded applications"
    ],
    "634967f890e50fcafdb5120a": [
        "Ntire 2017 challenge on single image super-resolution: Dataset and study",
        "Blind super-resolution kernel estimation using an internal-gan",
        "The 2018 pirm challenge on perceptual image super-resolution",
        "The perception-distortion tradeoff",
        "Toward real-world single image super-resolution: A new benchmark and a new model",
        "Glean: Generative latent bank for large-factor image super-resolution",
        "Second-order attention network for single image super-resolution",
        "Imagenet: A large-scale hierarchical image database",
        "Learning a deep convolutional network for image super-resolution",
        "Image super-resolution using deep convolutional networks",
        "Restoration of a single superresolution image from several blurred, noisy, and undersampled measured images",
        "Frequency separation for real-world super-resolution",
        "Superresolution from a single image",
        "Generative adversarial nets",
        "Generative adversarial nets",
        "Blind super-resolution with iterative kernel correction",
        "Deep backprojection networks for super-resolution",
        "CVPR",
        "Dslr-quality photos on mobile devices with deep convolutional networks",
        "Real-world super-resolution via kernel estimation and noise injection",
        "Perceptual losses for real-time style transfer and super-resolution",
        "Accurate image super-resolution using very deep convolutional networks",
        "Deeplyrecursive convolutional network for image super-resolution",
        "CVPR",
        "Adam: A method for stochastic optimization",
        "Deep laplacian pyramid networks for fast and accurate super-resolution",
        "Photorealistic single image super-resolution using a generative adversarial network",
        "Photorealistic single image super-resolution using a generative adversarial network",
        "Enhanced deep residual networks for single image super-resolution",
        "Blind image super-resolution: A survey and beyond",
        "On bayesian adaptive video super resolution",
        "Non-local recurrent network for image restoration",
        "Estimating generalized gaussian blur kernels for out-of-focus image deblurring",
        "None",
        "Unsupervised learning for real-world super-resolution",
        "Unfolding the alternating optimization for blind super resolution",
        "Nonparametric blind super-resolution",
        "Making a completely blind image quality analyzer",
        "Spectral normalization for generative adversarial networks",
        "A holistic approach to cross-channel image noise modeling and its application to image denoising",
        "Unet: Convolutional networks for biomedical image segmentation",
        "Enhancenet: Single image super-resolution through automated texture synthesis",
        "A u-net based discriminator for generative adversarial networks",
        "Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network",
        "Jpeg-resistant adversarial images",
        "Image superresolution via deep recursive residual network",
        "Ntire 2017 challenge on single image super-resolution: Methods and results",
        "Unsupervised degradation representation learning for blind superresolution",
        "Towards real-world blind face restoration with generative facial prior",
        "None",
        "Recovering realistic texture in image super-resolution by deep spatial feature transform",
        "Esrgan: Enhanced super-resolution generative adversarial networks",
        "Component divide-and-conquer for real-world image super-resolution",
        "Finegrained attention and feature-sharing generative adversarial networks for single image super-resolution",
        "Path-restore: Learning network path selection for image restoration",
        "Unsupervised image superresolution using cycle-in-cycle generative adversarial networks",
        "Luc Van Gool, and Radu Timofte. Designing a practical degradation model for deep blind image super-resolution",
        "Learning a single convolutional super-resolution network for multiple degradations",
        "Image super-resolution using very deep residual channel attention networks",
        "Residual dense network for image super-resolution",
        "CVPR",
        "Semantic understanding of scenes through the ade20k dataset",
        "Kernel modeling superresolution on real low-resolution images",
        "Table 1: NIQE scores on several diverse testing datasets with real-world images. The lower, the better"
    ],
    "6287493f5aee126c0ffedf11": [
        "ESC: Redesigning WSD with extractive sense comprehension",
        "2021b. ConSeC: Word sense disambiguation as continuous sense comprehension",
        "Longformer: The long-document transformer",
        "One SPRING to rule them both: Symmetric AMR semantic parsing and generation without a complex pipeline",
        "Moving down the long tail of word sense disambiguation with gloss informed bi-encoders",
        "Entity Linking in 100 Languages",
        "Signature verification using a \"siamese\" time delay neural network",
        "Investigating entity knowledge in BERT with simple neural end-to-end entity linking",
        "Using encyclopedic knowledge for named entity disambiguation",
        "2021a. Highly parallel autoregressive entity linking with discriminative correction",
        "2021b. Autoregressive entity retrieval",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "The automatic content extraction (ACE) program -tasks, data, and evaluation",
        "FACC1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26",
        "Joint entity linking with deep reinforcement learning",
        "Deep joint entity disambiguation with local neural attention",
        "Learning dense representations for entity retrieval",
        "To link or not to link? a study on end-toend tweet entity linking",
        "Robust named entity disambiguation with random walks",
        "Robust disambiguation of named entities in text",
        "Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring",
        "Knowledge base population: Successful approaches and challenges",
        "Improving entity linking by modeling latent relations between mentions",
        "Boosting entity linking performance by leveraging unlabeled documents",
        "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "On the variance of the adaptive learning rate and beyond",
        "Zero-shot entity linking by reading entity descriptions",
        "Entity linking meets word sense disambiguation: a unified approach",
        "PyTorch: An imperative style, high-performance deep learning library",
        "SGL: Speaking the graph languages of semantic parsing via multilingual translation",
        "Data-to-text generation with entity modeling",
        "Beyond accuracy: Behavioral testing of NLP models with CheckList",
        "Entity-aware elmo: Learning contextual entity representation for entity disambiguation",
        "Named Entity Recognition for Entity Linking: What works and what's next",
        "Attention is all you need",
        "Transformers: State-of-the-art natural language processing",
        "Scalable zeroshot entity linking with dense entity retrieval",
        "Joint learning of the embedding of words and entities for named entity disambiguation",
        "Learning dynamic context augmentation for global entity linking",
        "Collective entity disambiguation with structured gradient tree boosting",
        "Simple question answering by attentive convolutional neural network"
    ],
    "62286c865aee126c0fa71627": [
        "ICCAD-2017 CAD contest in multi-deck standard cell legalization and benchmarks",
        "Method and system for high speed detailed placement of cells within an integrated circuit design",
        "Abacus: Fast legalization of standard cell circuits with minimal movement",
        "An effective legalization algorithm for mixed-cellheight standard cells",
        "Legalization algorithm for multiple-row height standard cell design",
        "Routabilitydriven and fence-aware legalization for mixed-cell-height circuits",
        "History-based VLSI legalization using network flow",
        "Bonnplace legalization: Minimizing movement by iterative augmentation",
        "A fast, robust network flow-based standard-cell legalization method for minimizing maximum movement",
        "Mixed-cell-height standard cell placement legalization",
        "Toward optimal legalization for mixed-cell-height circuit designs",
        "Mixed-cell-height legalization considering technology and region constraints",
        "Analytical mixedcell-height legalization considering average and maximum movement minimization",
        "A robust modulus-based matrix splitting iteration method for mixed-cell-height circuit legalization",
        "ISPD 2015 benchmarks with fence regions and routing blockages for detailedrouting-driven placement",
        "PathFinder: A negotiation-based performance-driven router for FPGAs",
        "Fastroute 4.0: Global router with efficient via minimization",
        "NCTU-GR 2.0: Multithreaded collision-aware global routing with bounded-length maze routing",
        "Nthu-route 2.0: A fast and stable global router",
        "High-performance routing at the nanometer scale",
        "Negotiation-based layer assignment for via count and via overflow minimization",
        "Negotiation-based task scheduling to minimize user's electricity bills under dynamic energy prices",
        "MrDP: Multiple-row detailed placement of heterogeneoussized cells for advanced nodes",
        "R-trees: A dynamic index structure for spatial searching"
    ]
}